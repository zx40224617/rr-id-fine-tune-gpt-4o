{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hyperbaric Oxygen Therapy for Long COVID: 3-Month Follow up Results from a Prospective Registry of 232 patients\nAbstract: A potential beneficial effect of hyperbaric oxygen therapy (HBOT) on complaints of long COVID was found, leading to increased demand for this treatment despite many remaining clinical questions and lack of formal guideline recommendations and reimbursement. A registry was set up in order to gain more insight into patient characteristics and (long-term) outcomes of long COVID patients undergoing HBOT. Patient-reported outcome measures were collected at baseline, after treatment and at 3-month follow up. The primary outcome measures were the mental and physical component score (MCS/PCS) of the SF-36 questionnaire 3 months after HBOT. A clinically relevant positive or negative response was defined as an increase or decrease of [&ge;]10% in MCS and/or PCS after 3 months. Secondary outcomes included the EQ-5D, severity of complaints and ability to work. In this prospective registry of 232 long COVID patients, 65% of long term-ill patients had a clinically relevant increase in quality of life. However, 15% of the patients experienced deterioration in quality of life. Symptoms that showed most improvement were predominantly in the cognitive domain. This indicates that HBOT may have a positive effect on complaints of long COVID, but alertness for worsening of the condition should be exercised.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Determinants of self-treatment with antimalarials in Ndola district, Zambia: a cross-sectional study\nAbstract: Antimalarial drug resistance has been an obstacle in the fight against malaria over the years. Antimalarial self-medication is one of the factors associated with antimalarial resistance, and is on the rise globally and has become quite common among developing populations. Self-medication is when individuals choose and use medications to treat symptoms they perceive or diagnose themselves, without the guidance of a healthcare professional. This study aimed at investigating prevalence and determinants of antimalarial drug self-medication among adults in Ndola district, Zambia. A cross-sectional study was conducted among adults in Ndola district, Zambia in June 2023. Using multistage cluster sampling, 446 participants were randomly selected and interviewed through a mobile-based structured questionnaire administered by the researchers using Kobo collect/kobo toolbox. The head of household was the primary participant. Data was then exported to Microsoft Excel, cleaned and coded, and thereafter exported to STATA version 16.1 for analysis. Chi-square tests and logistic regression analysis was used to test associations between categorical variables and to estimate the odds of antimalarial drug self-medication associated with the explanatory variables. The prevalence of antimalarial drug self-medication was 20% in this study population and the factors significantly associated were; moderate to mild illness, bad experience with hospital care, lack of knowledge about antimalarial drug resistance, and the perception that antimalarial drug self-medication was not risky. The finding that antimalarial self-medication was common in this study population is suggestive of a poor state of the health-care delivery system possibly due to inadequate manpower, stock out of drugs in health facilities, and lack of awareness about the risks of self-medication. This further suggests that there is great need for regulatory authorities to strengthen drug regulations and update the list of over-the-counter and essential medicines to ensure the safety of public health. In addition, authorities should repackage malaria sensitization messages to strongly highlight the risks of antimalarial drug self-medication.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How do socioeconomic trajectories experienced during early adulthood contribute to the development of cardiometabolic health in young adults?\nAbstract: IntroductionSocioeconomic position has been strongly associated with cardiovascular health. However, little is known about the short-term health impacts of socioeconomic exposures during early adulthood. In this study we describe distinct socioeconomic trajectories of early adulthood (age 16-24y), and assess associations of these trajectories with measures of cardiometabolic health at age 24y.  MethodsParticipants of the Avon Longitudinal Study of Parents and Children (ALSPAC), with data across age 16y to 24y (2007-2017) were included (n=7,568). Longitudinal latent class analysis identified socioeconomic trajectories, based on education and employment data across ages 16-24y. Cardiometabolic outcomes at age 24y comprised anthropometric, vascular, metabolic and cardiovascular structure and function measures. We modelled differences in cardiometabolic outcomes at age 24y across the socioeconomic trajectory classes, adjusting for childhood socioeconomic position, adolescent health behaviours and adolescent health.  ResultsFour early adulthood socioeconomic trajectories were identified: (1) Higher Education (41% of the population), (2) Extended Education (9%), (3) Part-Time Employment (21%), and (4) Early Employment (29%). Associations between socioeconomic trajectory and cardiometabolic outcomes differed by sex. Among males, the Higher Education and Extended Education classes showed a healthier cardiometabolic profile, and the Part-time Employment class the least healthy. Among females there was less clear distinction between the classes, and the pattern across different outcomes was not consistent.  ConclusionThe newly identified  Part-time Employment class showed the least healthy cardiometabolic profile, and further research should focus on this group to understand the exposures contributing to poor cardiometabolic health in this sector of the population.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association between urbanicity and depressive symptoms among Chinese middle-aged and older adults\nAbstract: BackgroundDepression is a pressing public health issue and may be affected by multifaceted urban living, yet the specific urbanicity elements associated is unclear. Using a multidimensional urbanicity scale, we explored the association between urbanicity and its components with the risk of depressive symptoms.  MethodsThis study used data from four waves of the China Health and Retirement Longitudinal Study, including 12,515 participants aged [&ge;]45 years at baseline in 2011 in 450 rural and urban communities, and 8,766 with 7 years of follow-up. Multilevel logistics regression and Cox proportional hazards regression models examined the cross-sectional and longitudinal associations between urbanicity and depressive symptoms.  ResultsLiving in areas with the highest tertile of urbanicity was associated with a 61% lower risk of depressive symptoms cross-sectionally (odds ratio (OR): 0.39, 95% confidence interval (CI): 0.30-0.50) and 33% lower risk longitudinally (hazard ratio (HR): 0.67, 95% CI: 0.58-0.77) compared to those living in areas with the lowest tertile of urbanicity. Among components, higher population density (OR: 0.92, 95% CI: 0.87-0.97), better education (OR: 0.94, 95% CI: 0.89-0.99), transportation (OR: 0.95, 95% CI: 0.92-0.98), sanitation (OR: 0.96, 95% CI: 0.93-0.98) was associated with lower odds of depressive symptoms, while greater population educational and socioeconomic diversity (OR, 1.08; 95% CI, 1.03-1.13) had opposite effect. Better economic conditions (HR: 0.94, 95% CI: 0.90-0.98) and availability of social services (HR, 0.96; 95% CI, 0.93-0.99) were longitudinally associated with reduced risk of developing depressive symptoms during 7 years of follow-up. Additionally, differences in associated components were found between urban and rural residents and between midlife and older adults.  ConclusionsOur findings underscore the complex links of urban living with depressive symptoms among middle-aged and older adults, highlighting the need to consider a multidimensional urbanicity perspective to understand the urbanicity-mental health nexus. Tailored urban planning policies should consider the associated urbanicity components, along with temporal effectiveness, urban-rural disparities, and age group differences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association between urbanicity and depressive symptoms among Chinese middle-aged and older adults\nAbstract: BackgroundDepression is a pressing public health issue and may be affected by multifaceted urban living, yet the specific urbanicity elements associated is unclear. Using a multidimensional urbanicity scale, we explored the association between urbanicity and its components with the risk of depressive symptoms.  MethodsThis study used data from four waves of the China Health and Retirement Longitudinal Study, including 12,515 participants aged [&ge;]45 years at baseline in 2011 in 450 rural and urban communities, and 8,766 with 7 years of follow-up. Multilevel logistics regression and Cox proportional hazards regression models examined the cross-sectional and longitudinal associations between urbanicity and depressive symptoms.  ResultsLiving in areas with the highest tertile of urbanicity was associated with a 61% lower risk of depressive symptoms cross-sectionally (odds ratio (OR): 0.39, 95% confidence interval (CI): 0.30-0.50) and 33% lower risk longitudinally (hazard ratio (HR): 0.67, 95% CI: 0.58-0.77) compared to those living in areas with the lowest tertile of urbanicity. Among components, higher population density (OR: 0.92, 95% CI: 0.87-0.97), better education (OR: 0.94, 95% CI: 0.89-0.99), transportation (OR: 0.95, 95% CI: 0.92-0.98), sanitation (OR: 0.96, 95% CI: 0.93-0.98) was associated with lower odds of depressive symptoms, while greater population educational and socioeconomic diversity (OR, 1.08; 95% CI, 1.03-1.13) had opposite effect. Better economic conditions (HR: 0.94, 95% CI: 0.90-0.98) and availability of social services (HR, 0.96; 95% CI, 0.93-0.99) were longitudinally associated with reduced risk of developing depressive symptoms during 7 years of follow-up. Additionally, differences in associated components were found between urban and rural residents and between midlife and older adults.  ConclusionsOur findings underscore the complex links of urban living with depressive symptoms among middle-aged and older adults, highlighting the need to consider a multidimensional urbanicity perspective to understand the urbanicity-mental health nexus. Tailored urban planning policies should consider the associated urbanicity components, along with temporal effectiveness, urban-rural disparities, and age group differences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causal effects of breast cancer risk factors across hormone receptor breast cancer subtypes: A two-sample Mendelian randomization study\nAbstract: BackgroundIt is unclear if established breast cancer risk factors exert similar causal effects across hormone receptor breast cancer subtypes. We estimated and compared causal estimates of height, body mass index (BMI), type 2 diabetes, age at menarche, age at menopause, breast density, alcohol consumption, regular smoking, and physical activity across these subtypes.  MethodsWe used a two-sample Mendelian randomization approach and selected genetic instrumental variables from large-scale risk factor GWAS. Publicly available summary-level data for the following subtypes were included: luminal A-like; luminal B/HER2-negative-like; luminal B-like; HER2-enriched-like; triple negative. We employed multiple methods to evaluate the strength of causal evidence for each risk factor-subtype association.  ResultsCollectively, our analyses indicated that increased height and decreased BMI are probable causal risk factors for all five subtypes. For the other risk factors, the strength of evidence for causal effects differed across subtypes. Heterogeneity in the magnitude of causal effect estimates for age at menopause and breast density was explained by null findings for triple negative tumours. Regular smoking was the sole risk factor for which there was no evidence for a causal effect on any subtype.  ConclusionsThis study suggests that established breast cancer risk factors differ across hormone receptor subtypes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal trajectories of psychological resilience and cognitive impairment among older adults: evidence from a national cohort study\nAbstract: BackgroundThe relationship between resilience trajectories and cognitive health is not well understood. This study aimed to identify subgroups of psychological resilience trajectories in a national sample of older adults and to examine the association with cognitive impairment over time.  MethodsThis study used data from the Chinese Longitudinal Healthy Longevity Survey (CLHLS) from 2008 to 2018, and 2,788 respondents were included in this prospective analysis. Using a group{square}based trajectory modeling approach, we identified resilience trajectory groups within a 6-year period. Cox proportional hazards models were used to assess the relationship between the resilience trajectory groups and cognitive impairment.  ResultsThree distinct trajectories of psychological resilience, including decreasing resilience group (n=131,7.1%), persistent middle resilience group (n=1,808, 58.1%), and persistent high resilience group (n=849, 34.8%). During the 6-year follow-up, compared to those with persistent high resilience, participants with persistent middle resilience (HR=1.43, 95% CI=1.14-1.79) and decreasing resilience (HR=2.46, 95% CI=1.76-3.43) remained consistent associated with a higher risk of cognitive impairment. The associations between resilience trajectories and cognitive impairment varied by lifestyle and health conditions.  ConclusionsPsychological resilience is a relatively stable trait among older adults in China, with most individuals maintaining a persistently high or middle level of resilience throughout the follow-up period; however, declining psychological resilience was significantly associated with the risk of cognitive impairment. Therefore, developing targeted interventions to strengthen psychological resilience in older adults is crucial for promoting cognitive health and successful aging, especially for those who have unhealthy lifestyles and with poorer health conditions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal trajectories of psychological resilience and cognitive impairment among older adults: evidence from a national cohort study\nAbstract: BackgroundThe relationship between resilience trajectories and cognitive health is not well understood. This study aimed to identify subgroups of psychological resilience trajectories in a national sample of older adults and to examine the association with cognitive impairment over time.  MethodsThis study used data from the Chinese Longitudinal Healthy Longevity Survey (CLHLS) from 2008 to 2018, and 2,788 respondents were included in this prospective analysis. Using a group{square}based trajectory modeling approach, we identified resilience trajectory groups within a 6-year period. Cox proportional hazards models were used to assess the relationship between the resilience trajectory groups and cognitive impairment.  ResultsThree distinct trajectories of psychological resilience, including decreasing resilience group (n=131,7.1%), persistent middle resilience group (n=1,808, 58.1%), and persistent high resilience group (n=849, 34.8%). During the 6-year follow-up, compared to those with persistent high resilience, participants with persistent middle resilience (HR=1.43, 95% CI=1.14-1.79) and decreasing resilience (HR=2.46, 95% CI=1.76-3.43) remained consistent associated with a higher risk of cognitive impairment. The associations between resilience trajectories and cognitive impairment varied by lifestyle and health conditions.  ConclusionsPsychological resilience is a relatively stable trait among older adults in China, with most individuals maintaining a persistently high or middle level of resilience throughout the follow-up period; however, declining psychological resilience was significantly associated with the risk of cognitive impairment. Therefore, developing targeted interventions to strengthen psychological resilience in older adults is crucial for promoting cognitive health and successful aging, especially for those who have unhealthy lifestyles and with poorer health conditions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interplay Between the Gut Microbiome and Typhoid Fever: Insights from Endemic Countries and a Controlled Human Infection Model\nAbstract: Typhoid fever is a systemic infection caused by Salmonella enterica serovar Typhi (S. Typhi) bacteria invading through the gut lumen. Transmission occurs through ingestion of contaminated food and water, particularly in settings with poor water, sanitation and hygiene infrastructure, resulting in over 10 million illnesses annually. It is well established that vaccines and natural infections can stimulate protective immunity against S. Typhi. As the pathogen invades through the gastrointestinal tract, it is plausible that the gut microbiome may also influence the outcome of S. Typhi exposure. There is some evidence that bacteria producing short-chain fatty acids (SCFAs) may create an environment unfavourable to invasive Salmonella, but data from humans is very limited.  To investigate the association between gut microbiome and typhoid fever, we analysed samples collected from three all-age cohorts recruited in a prospective surveillance study conducted in parallel in three settings where typhoid fever is endemic (Dhaka, Bangladesh; Blantyre, Malawi; and Kathmandu, Nepal). Cohorts consisted of acute typhoid fever patients (n=92), asymptomatic household contacts of typhoid fever patients (representing individuals who were likely exposed to S. Typhi but did not develop disease, n=97), and asymptomatic serosurvey participants with high Vi antibody titres (representing individuals who were exposed to S. Typhi and may be carriers, n=69). The stool microbiomes of each cohort were characterised using shotgun metagenomics, and bacterial composition and diversity were compared.  We identified four bacterial species and 28 metabolic gene clusters (MGCs) that were significantly lower in abundance in typhoid fever patients compared with household contacts (i.e. probably exposed), in two of the three host populations (Bangladesh and Malawi). These may represent taxa that provide protection against development of clinical infection upon exposure to S. Typhi, and include the inflammation-associated species Prevotella copri clade A and Haemophilus parainfluenzae, and seven MGCs involved in SCFA metabolism. The putative protection provided by SCFA metabolism was supported by data from a controlled human infection model conducted in a UK population, in which participants who did not develop typhoid fever following ingestion of S. Typhi had significantly higher abundance of a putative SCFA-metabolising MGC (q-value = 0.22).  This study identified the same associations between taxonomic and functional microbiota characteristics and non-susceptibility to typhoid fever across multiple cohorts. Future research should explore the potential functional role of SCFAs and inflammation-associated bacteria in resistance to S. Typhi and other enteric infections.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Tuberculosis-Associated Respiratory Disability in Children, Adolescents, and Adults: Protocol for a Systematic Review and Individual Participant Data Meta-Analysis\nAbstract: BackgroundApproximately 2% of the global population has survived tuberculosis (TB). Increasing evidence indicates that a significant proportion of pulmonary TB survivors develop TB-associated respiratory disability, commonly referred to as post-TB lung disease (PLTD) and marked by impaired respiratory function, persistent symptoms, and activity limitations. However, the prevalence, risk factors, and progression of TB-associated respiratory disability throughout the life course are not well understood. To address these gaps, we will undertake a systematic review and individual participant-level data meta-analysis (IPD-MA) focusing on TB-associated respiratory disability in children, adolescents, and adults successfully treated for pulmonary TB.  Methods and analysisWe will systematically search MEDLINE, Embase, CENTRAL, Global Index Medicus, and medRxiv for original studies investigating TB-associated respiratory disability in people of all ages who have completed treatment for microbiologically confirmed or clinically diagnosed pulmonary TB. Authors of eligible studies will be invited to contribute de-identified data and form a collaborative group. Primary outcomes will be (1) abnormal lung function based on spirometry parameters and (2) chronic respiratory symptoms. We will estimate the overall and subgroup-specific prevalence of each outcome through IPD meta-analysis. Next, we will develop clinical prediction tools assessing the risk of future TB-associated respiratory disability at (i) the start of TB treatment and (ii) end of TB treatment for those without existing signs of disability. Finally, we will use stepwise hierarchical modelling to identify epidemiological determinants of respiratory disability.  Ethics and disseminationThis study has been approved by the ethics review boards at the Rhode Island Hospital (2138217-2) and the Research Institute of the McGill University Health Centre (2024-10345). Individual study authors will be required to obtain institutional approval prior to sharing data. Results will be disseminated through open-access, peer-reviewed publications and conference presentations.  Prospero registration numberCRD42024529906  Strengths and limitations of this studyO_LIAn individual participant data meta-analysis allows for data harmonization to help overcome limitations of individual studies and aggregate meta-analysis, including small sample size, heterogeneity, and limited reporting of subgroups, such as age and other risk factors. C_LIO_LIWe will be able to identify weaknesses in current reporting and recommend standards to support high-quality data collection and facilitate pooling of data. C_LIO_LIKey limitations include authors willingness to share data, representativeness of data contributed, and missing data. C_LIO_LIWe will build an ongoing data collection platform to allow updating of evidence. C_LIO_LIResults will have implications for public health, clinical trial design, and clinical practice to support TB survivors. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Advancing Early Warning Systems for Malaria: Progress, Challenges, and Future Directions - A Scoping Review\nAbstract: BackgroundMalaria Early Warning Systems(EWS) are predictive tools that often use climatic and environmental variables to forecast malaria risk and trigger timely interventions. Despite their potential benefits, the development and implementation of malaria EWS face significant challenges and limitations. We reviewed the current evidence on malaria EWS, including their settings, methods, performance, actions, and evaluation.  MethodsWe conducted a comprehensive literature search using keywords related to EWS and malaria in various databases and registers. We included primary research and programmatic reports focused on developing and implementing Malaria EWS. We extracted and synthesized data on the characteristics, outcomes, and experiences of Malaria EWS.  ResultsAfter reviewing 5,535 records, we identified 30 studies from 16 countries that met our inclusion criteria. The studies varied in their transmission settings, from pre-elimination to high burden, and their purposes, ranging from outbreak detection to resource allocation. The studies employed various statistical and machine-learning models to forecast malaria cases, often incorporating environmental covariates such as rainfall and temperature. The most common mode used is the time series model. The performance of the models was assessed using measures such as the Akaike Information Criterion( AIC), Root Mean Square Error (RMSE), and adjusted R squared(R 2). The studies reported actions and responses triggered by EWS predictions, such as vector control, case management, and health education. The lack of standardized criteria and methodologies limited the evaluation of EWS impact.  ConclusionsThis review provides a comprehensive overview of the current status of Malaria EWS, highlighting the progress, challenges, and gaps in the field. The review informs and guides policymakers, researchers, and practitioners in enhancing EWS and malaria control strategies. The review also underscores the need for further research on the integration, sustainability, and evaluation of Malaria EWS usage and harmonized methods to ease review.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: FACILITATORS AND BARRIERS TO UPTAKE OF CHILD-FRIENDLY 3 MONTHS OF ISONIAZID AND RIFAMPICIN (3HR) FIXED DRUG COMBINATION (FDC) FOR TUBERCULOSIS PREVENTIVE THERAPY (TPT) IN NIGERIA\nAbstract: The uptake of TB preventive therapy (TPT) for child and adult contacts of index TB patients in Nigeria has been suboptimal. Nigeria introduced the 3-month isoniazid-rifampicin (3HR) shorter regimen TPT for all eligible contacts through the USAID-funded Stop TB Partnership introducing New Tools Project (iNTP). This study assesses the facilitators and barriers to the uptake of the newly introduced child-friendly 3HR TPT for child contacts of TB patients in Nigeria.  This was a cross-sectional descriptive study using mixed methods. In-depth interviews were conducted among 36 purposely selected Healthcare Workers (HCWs) and 36 caregivers of child contacts. Records of TPT-eligible child contacts (0-14 years) from April to September 2022 were retrospectively extracted. Study data were analyzed using appropriate statistical tools for qualitative and quantitative techniques.  There were 7,906 child contacts identified, of which 7,902 (99.9%) contacts were screened for TB, 1,704 (21.5%) were presumptive, 264 (15.5%) diagnosed with TB, and 6,994 were eligible for TB Preventive Therapy. Additionally, out of 6,994 eligible child contacts, 3984 (57%) were initiated on TPT with 2,982 (74,8%) enrolled on 3HR and 1,002 (25%) on 6H. Of the clients placed on 3HR, 2,499 (85%) completed treatment, 309 (10.5%) lost to follow-up, 27(0.92%) developed Tuberculosis while 48 (1.6%) interrupted treatment.  The key drivers of 3HR TPT uptake among child contacts were TPT-related health education and counseling. Access barriers to 3HR TPT elicited included stigma, poverty, transportation cost, stock out, ineffective monitoring and management of side effects issues of 3HR TPT, subpar Government funding and commitment to addressing TPT implementation challenges and inadequate knowledge among HCWs and caregivers.  In conclusion, 3HR-TPT uptake among child contacts of index TB patients was high. Enhanced provider training and intensive community health education should be sustained while identified individual, structural, and institutional barriers should be addressed to improve implementation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association Between Seasonal Respiratory Virus Activity and Invasive Pneumococcal Disease in Central Ontario, Canada\nAbstract: BackgroundIn central Ontario, influenza, respiratory syncytial virus (RSV), and invasive pneumococcal disease (IPD) follow similar seasonal patterns, peaking in winter. We aimed to quantify the independent and joint impact of influenza A, influenza B, and RSV on IPD risk at the population level.  MethodsWe used a 2:1 self-matched case-crossover study design to evaluate acute effects of respiratory virus activity on IPD risk. This design ensures that effects are not confounded by within-individual characteristics that remain constant over short periods of time. We included 3,892 IPD cases occurring between January 2000 and June 2009. Effects were measured using univariable and multivariable conditional logistic regression. Multivariable models included environmental covariates (e.g., temperature, absolute humidity, and UV index) and interaction terms between viruses.  ResultsInfluenza A activity and influenza B activity were both independently associated with increased IPD risk; however, co-circulation of influenza A and B reduced the impact of both viruses. RSV activity was positively associated with increased IPD risk only in the presence of increased influenza A or influenza B activity.  ConclusionsTo our knowledge this represents the first study to consider the impact of interactions between these viruses on IPD risk in Canada. Our findings suggest that the prevention of IPD should be considered as a potential health benefit of influenza and RSV vaccination programs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Sex differences in the trajectories of plasma biomarkers, brain atrophy, and cognitive decline relative to amyloid onset\nAbstract: INTRODUCTIONThe factors that influence the progression of Alzheimers disease (AD) after individuals become amyloid-positive are poorly understood. This study examines how sex influences the longitudinal trajectories of plasma AD and neurodegenerative biomarkers in the years following a persons estimated onset of amyloid-{beta}.  METHODSLinear mixed effects modeling investigated overall and sex-specific longitudinal trajectories of plasma biomarkers, brain volumes, and cognition relative to estimated age of amyloid onset in a cohort of 78 amyloid-positive Baltimore Longitudinal Study of Aging participants (n=45 male; follow-up time: 6.8 years [SD 3.31]). Amyloid status was ascertained with 11C-Pittsburgh compound B (PiB) PET imaging.  RESULTSAfter amyloid onset, men displayed steeper increases in pTau181, pTau231, and NfL compared to women. In this same period, men demonstrated steeper declines in brain volume and cognitive performance.  DISCUSSIONThese findings suggest that sex influences the trajectory of AD pathology, neuronal injury, and symptom progression after individuals become amyloid-positive.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Life Expectancy Exploration of Heart Failure Patients Presenting with Diabetes\nAbstract: BackgroundDiabetes is a serious medical condition marked by high blood sugar levels, leading to complications in organs like the kidney, liver, and heart. Previous research has identified diabetes as a primary risk factor for congestive heart failure (CHF), a condition where stiffened heart muscles hinder oxygenated blood circulation. Despite its severity, few studies have examined CHF prognosis in diabetic patients. This study aims to provide survival estimates and provide their comparisons among predictors, assess mortality risks based on specific variables, and reveal patient outcome patterns.  MethodsWe analyzed data from a 2015 study at Faisalabad Institute of Cardiology and Allied Hospital (FICAH), Pakistan, focusing on 125 diabetic patients with Class III or IV heart failure and left ventricular systolic dysfunction. Kaplan-Meier estimates provided survival rates, log-rank tests compared survival across variables, Cox regression models estimated hazard ratios, and cluster analysis grouped patients by characteristics and survival rates.  ResultsThe study examined 125 diabetic heart failure patients. Of these, 40(32%) were censored and the remaining 85(68%) died. The total follow-up period was 278 days, on the 120th day, 0.752[95% CI = 0.678,0,883] of the patients survived after initial diagnosis. Log-rank tests showed survival differences linked to high blood pressure, anemia and smoking. Cox regression identified age, smoking and hypertension as major mortality risk factors. Cluster analysis revealed the risk factors associated with middle aged and the older patients.  ConclusionThe overall prognosis of heart failure patients with diabetes was poor with high mortality rates, implying effective treatment and management.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Azithromycin Treatment Response as a Probe to Attribute Bacterial Aetiologies of Diarrhoea using Molecular Diagnostics: A Reanalysis of the AntiBiotics for Children with severe Diarrhoea (ABCD) Trial\nAbstract: BackgroundMulti-pathogen molecular diagnostics enable assignment of diarrhoea aetiology, but defining thresholds of pathogen quantity to accurately attribute aetiology is challenging in high-burden settings where coinfections are common. The Antibiotics for Children with severe Diarrhoea (ABCD) trial provides an opportunity to leverage the azithromycin treatment response to inform which diarrhoea episodes are bacterial.  MethodsWe analysed data from ABCD, which randomized children with watery diarrhoea to azithromycin or placebo. We quantified heterogeneity in the azithromycin treatment response by the quantity of enteric pathogens detected by qPCR as a tool for understanding aetiology.  ResultsThe heterogeneity in azithromycin treatment response was most prominent for Shigella. The risk ratio for diarrhoea on day 3 post enrolment for azithromycin compared to placebo was 13% (95% CI:3, 23) lower per log10 increase in Shigella quantity. The protective effect of azithromycin on diarrhoea at day 3 also became stronger as pathogen quantities increased for Vibrio cholerae, ST-ETEC, and tEPEC. No association between pathogen quantity and azithromycin response was observed for Campylobacter, LT-ETEC or EAEC. The associations were consistent for the outcome of 90-day hospitalisation or death.  ConclusionsThe relationships between response to azithromycin treatment and bacterial pathogen quantities observed for Shigella, Vibrio cholerae, ST-ETEC and tEPEC confirm prior evidence that these pathogens are the likely cause of diarrhoea when detected at high quantities. The lack of a similar response pattern for Campylobacter, LT-ETEC or EAEC is consistent with the limited association between pathogen quantity and diarrhoea symptoms previously observed in large studies of diarrhoea aetiology.  Key message (3 succinct bullet points, each a single sentence)O_LIWe investigated whether heterogeneity in treatment response observed in the ABCD trial, where children with diarrhoea were randomised to receive azithromycin or placebo, could be used to inform aetiological attribution of diarrhoea to bacterial enteric pathogens. C_LIO_LIThe protective effect of azithromycin on diarrhoea at day 3 and hospitalisation or death at day 90 became stronger as pathogen quantities increased for Shigella, Vibrio cholerae, ST-ETEC and tEPEC but not for Campylobacter, LT-ETEC or EAEC. C_LIO_LIThe relationships between Shigella, Vibrio cholerae, ST-ETEC and tEPEC quantity and response to antibiotic treatment confirm prior evidence that these pathogens are the likely cause of diarrhoea when detected at high quantities and could be used to inform which diarrhoea cases should be treated with antibiotics. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Analysis of C-reactive protein omics-measures associates methylation risk score with sleep health and related health outcomes\nAbstract: IntroductionDNA methylation (DNAm) predictors of high sensitivity C-reactive protein (CRP) offer a stable and accurate means of assessing chronic inflammation, bypassing the CRP protein fluctuations secondary to acute illness. Poor sleep health is associated with elevated inflammation (including elevated blood CRP levels) which may explain associations of sleep insufficiency with metabolic, cardiovascular and neurological diseases. Our study aims to characterize the relationships among sleep health phenotypes and CRP markers --blood, genetic, and epigenetic indicators-- within the Hispanic Community Health Study/Study of Latinos (HCHS/SOL).  MethodsIn HCHS/SOL, methylation risk scores (MRS)-CRP and polygenetic risk score (PRS)-CRP were constructed separately as weighted sums of methylation beta values or allele counts, respectively, for each individual. Sleep health phenotypes were measured using self-reported questionnaires and objective measurements. Survey-weighted linear regression established the association between the multiple sleep phenotypes (obstructive sleep apnea (OSA), sleep duration, insomnia and excessive sleepiness symptom), cognitive assessments, diabetes and hypertension with CRP markers while adjusting for age, sex, BMI, study center, and the first five principal components of genetic ancestry in HCHS/SOL.  ResultsWe included 2221 HCHS/SOL participants (age range 37-76 yrs, 65.7% female) in the analysis. Both the MRS-CRP (95% confidence interval (CI): 0.32-0.42, p = 3.3 x 10-38) and the PRS-CRP (95% CI: 0.15-0.25, p = 1 x 10-14) were associated with blood CRP level. Moreover, MRS-CRP was associated with sleep health phenotypes (OSA, long sleep duration) and related conditions (diabetes and hypertension), while PRS-CRP markers were not associated with these traits. Circulating CRP level was associated with sleep duration and diabetes. Associations between OSA traits and metabolic comorbidities weakened after adjusting for MRS-CRP, most strongly for diabetes, and least for hypertension.  ConclusionsMRS-CRP is a promising estimate for systemic and chronic inflammation as reflected by circulating CRP levels, which either mediates or serves as a common cause of the association between sleep phenotypes and related comorbidities, especially in the presence of diabetes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adverse events affecting recovery from seasonal influenza vaccination in the hypertensive population: A population-based pharmacovigilance analysis\nAbstract: Seasonal influenza vaccination is crucial for preventing influenza and its complications. Data from the U.S. Vaccine Adverse Event Reporting System (VAERS) indicate a higher proportion of adverse events (AEs) after influenza vaccination in hypertensive people. However, there is limited evidence on AEs in hypertensive people following seasonal influenza vaccination. We collected a total of 4647 individuals on seasonal influenza vaccination and 6380 AEs from VAERS for hypertensive people aged 18 years or older from 1 January 2013 to 23 June 2023. We conducted propensity score matching (PSM) by adjusting for the demographic characteristics of the seasonal influenza-vaccinated hypertensive population and the season of onset. Cox regression analysis was used to calculate the risk ratio of reported adverse events (AEs) that affected recovery after seasonal influenza vaccination. Most AEs were nonserious and occurred within 48 hours. The most common AEs were general disorders and administration site conditions (therapeutic and non-therapeutic responses, inflammation) and musculoskeletal and connective tissue disorders (musculoskeletal and connective tissue pain and discomfort, bursal disorders, joint-related signs, and symptoms). All three types of seasonal influenza vaccines were associated with injection site reactions (47.07% trivalent influenza vaccine [TIA], hazard ratio, HR 2.04, 95% confidence interval, CI 1.22-3.40; 20.00% quadrivalent influenza vaccine [QIA], HR 2.81, 95% CI, 1.81-4.37; 67.48% influenza vaccine, unknown manufacturer [FLUX], HR 2.83, 95% CI, 1.12-7.15) and were the AEs affecting the largest proportion of delayed recoveries in the hypertensive population. Potential AEs following seasonal influenza vaccination may affect the recovery of the hypertensive population. The majority of AEs reported were general disorders, predominantly injection site reactions, and nonserious.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Short-term and Long-Term Healthcare Costs Attributable to diagnosed COVID-19 in Ontario; Canada: A Population-Based Matched Cohort Study\nAbstract: ObjectivesEstimates of health system costs due to COVID-19, especially for long-term disability (post COVID-19 condition [PCC]) are key to health system planning, but attributable cost data remain scarce. We characterized COVID-19-attributable costs from the health system perspective.  MethodsPopulation-based matched cohort study in Ontario, Canada, using health administrative data. To assign attribution to COVID-19, individuals, defined as exposed (positive SARS-CoV-2 PCR test, 01/2020-12/2020) were matched 1:1 to an unexposed individuals (01/2016-12/2018). Historical matching was used to reduce biases due to overall reductions in healthcare during the pandemic and contamination bias. The index date was defined as the first occurrence of positive SARS-CoV-2 PCR test. We used phase-of-care costing to calculate mean attributable per-person costs (2023 CAD), standardized to 10 days, during four phases of illness: pre-index date, acute care, post-acute care (suggestive of PCC), and terminal phase (stratified by early and late deaths). Finally, we estimated total costs at 360 days by combining costs with survival estimates.  ResultsOf 165,838 exposed individuals, 159,817 were matched (mean age 40{+/-}20 years, 51% female). Mean (95%CI) attributable 10-day costs per person were $1 ($-4, $6) pre-index, $240 ($231, $249) during acute care, and $18 ($14, $21) during post-acute phases. During the terminal phase, mean attributable costs were $3,928 ($3,471, $4,384) for early deaths and $1,781 ($1,182, $2,380) for late deaths. Hospitalizations accounted for 42% to 100% of total costs. Compared to males, costs among females were lower during the acute care phase, but higher during the post-acute care phase. Mean cumulative per-person cost at 360 days was $2,553 ($2,348, $2,756); females had lower costs ($2,194 [$1,945, $2,446]) than males ($2,921 [$2,602, $3,241]).  ConclusionsSARS-CoV-2 infection is associated with substantial long-term healthcare costs, consistent with our understanding of the PCC. Understanding phase-specific costs can inform health sector budget planning, future economic evaluations, and pandemic planning.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of adverse pregnancy outcomes and impact of statin use in pregnant women with familial hypercholesterolemia\nAbstract: Background and aimsSparse data exist on the possible risk of adverse pregnancy outcomes in women with familial hypercholesterolemia (FH). We investigated associations between having a FH diagnosis and adverse pregnancy outcomes, and between statin exposure in pregnancy and adverse pregnancy outcomes among women with FH.  MethodsThis registry-based study included 3869 pregnancies among 1869 women with FH and 68225 pregnancies among 33661 women from the general population. Data on adverse pregnancy outcomes were obtained from the Medical Birth Registry of Norway with data from 1967-2018. Data on pharmacy-dispensed statins were obtained from the Norwegian prescription database (2004-2018) in 1051 women with FH. Associations were presented as odds ratio (OR) with 95% CI from logistic regression adjusted for mothers age, parity, and offsprings birth year.  ResultsWomen with FH had a higher risk of preeclampsia (OR 1.21 [1.00-1.46]), but lower risk for gestational diabetes (OR 0.58 [0.36-0.92]) and intrapartum hemorrhage during delivery (OR 0.81 [0.71-0.92]) compared to controls. No excess risk of adverse pregnancy outcome in offspring was observed for FH vs controls. Women with FH using statins in pregnancy (n=260) had a higher risk of having offspring with low (<2500 g) birth weight (OR 2.20 [1.11, 4.49]) compared to non-exposed women with FH (n=791).  ConclusionsWomen with FH had lower risk of gestational diabetes and intrapartum hemorrhage during delivery and non-significantly higher risk of preeclampsia compared to controls. No difference in adverse pregnancy outcomes in the offspring was observed. Statin exposure in pregnancy was associated with a higher risk of having offspring with low birth weight among women with FH, and this association warrants further investigations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulation of Clade Ia and Ib monkeypox virus in Kinshasa Province, Democratic Republic of the Congo, July - August 2024\nAbstract: Mpox cases have been reported in nearly all provinces of the Democratic Republic of the Congo as of August 2024. Monkeypox virus positive samples from Kinshasa, collected between July and mid-August 2024, were sequenced using a probe-based enrichment or optimized tiling sequencing protocol. With multiple introductions of both Clade Ia (7/12) and Ib (5/12), marking Kinshasa, and its Limete health zone specifically, as an area with co-circulation of both Clade I, a unique observation illustrating the growing complexity of Clade I mpox outbreaks in DRC.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulation of two lineages of Oropouche virus in the Amazon basin, Colombia, 2024\nAbstract: In early 2024, explosive outbreaks of Oropouche virus (OROV) linked to a novel viral lineage were documented in the Brazilian Amazon. Here, we report the introduction of this emerging orthobunyavirus into Colombia and its co-circulation with another OROV lineage. This investigation highlights the complex arbovirus dynamics in South America.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulation of two lineages of Oropouche virus in the Amazon basin, Colombia, 2024\nAbstract: In early 2024, explosive outbreaks of Oropouche virus (OROV) linked to a novel viral lineage were documented in the Brazilian Amazon. Here, we report the introduction of this emerging orthobunyavirus into Colombia and its co-circulation with another OROV lineage. This investigation highlights the complex arbovirus dynamics in South America.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Fetal hemoglobin enables malaria parasite growth in sickle cells but augments production of transmission stage parasites.\nAbstract: Sickle cell trait is the quintessential example of the human response to malaria, providing protection against severe disease, but leading to sickle cell disease (SCD) in the homozygous state. Fetal Hemoglobin (HbF) reduces the pathology of SCD and several mutations lead to the prolonged production of HbF into childhood and adult life. HbF has been suggested to contribute to protection against malaria. Two long-term cohorts were genotyped for three quantitative trait loci associated with HbF production and analyzed for HbF titers, malaria clinical episodes and the production of parasite stages infectious to mosquitoes, gametocytes in asymptomatic infections. Plasmodium falciparum parasites were also grown in vitro in HbSS cells with measured levels of HbF. The genetic determinants of prolonged HbF production were associated with increased HbF titers and that increased HbF afforded protection from malaria disease but increased the production of gametocytes. The presence of HbF in sickled red cells was also shown in in vitro culture to enable parasite persistence in conditions otherwise deleterious for the parasite and enabled complete maturation of gametocytes. The beneficial personal effect of HbF, whether through protection against malaria or alleviating effects of SCD, is offset by increased parasite transmissibility and disease burden for the community. These individuals represent an important reservoir of infection and need to be targeted in elimination strategies.  Key pointsO_LIIndividuals with mutations associated with fetal hemoglobin production had fewer clinical episodes but produced more gametocytes. C_LIO_LIHbF in red blood cells enables gametocyte production at tissue level oxygen partial pressures at which normally parasite lysis would occur. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Humoral Immunity after mRNA Omicron JN.1 Vaccination\nAbstract: In late June 2024, the European Medicines Agency (EMA) recommended market authorization for a monovalent COVID-19 mRNA-vaccine based on JN.1 spike. We assessed immune responses in n=42 health-care workers (median age 47 years, interquartile range, IQR 19{middle dot}5 years, 48% male), who in August 2024 were vaccinated with 30 g of the updated mRNA omicron JN.1 vaccine (bretovameran, BioNTech/Pfizer, Mainz, Germany). Humoral immune responses were analyzed directly prior to and 13 days after vaccination.  The omicron JN.1 vaccination resulted in a significant 1{middle dot}2-fold increase of anti-S IgG and 1{middle dot}2-fold increase of omicron anti-S IgG (p<0{middle dot}0001). To assess plasma neutralisation capacity, we employed a pseudovirus particle (pp) neutralisation assay including S proteins of seven SARS-CoV-2 lineages. Baseline response rates were 100% for XBB.1.5pp, 90% for JN.1pp and KP.2pp, 82% for KP.2.3pp, 92% for KP.3pp, and 72% for LB.1pp. Before JN.1 vaccination, particles bearing KP sublineage S proteins were slightly less efficiently neutralised compared with JN.1pp (median change, 1{middle dot}2-fold to 2{middle dot}6-fold), while LB.1pp neutralisation was 3-fold reduced, indicating antibody evasion. After vaccination, the response rates increased significantly for all pseudoviruses except XBB.1.5pp and KP.3pp. Thus, we observed a significant increase in neutralisation of JN.1pp, KP.2pp, KP.2.3pp, and LB.1pp, showing a median change of 2.2-fold, 3.8-fold, 3.3-fold, and 4.9-fold, respectively.  In summary, bretovameran increased anti-S IgG and strengthened neutralising responses against circulating SARS-CoV-2-variants, except for KP.3. We wish to point out that our study population exhibited high pre-vaccination omicron-related hybrid immunity and may not be representative of other populations. Our data supports the notion that the new mRNA vaccine against omicron JN.1 most likely increases protection against hospitalization and post-COVID sequelae caused by most current variants.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Steroidal Therapy plus Conventional Therapy versus Conventional Therapy alone for Tuberculous Meningitis: A systematic review and Meta-analysis\nAbstract: BackgroundTuberculosis meningitis (TBM) is the most severe form of extrapulmonary tuberculosis with a high rate of morbidity and mortality. Treatments for TBM include conventional therapy alone as well as adjunctive use of steroidal therapy.  MethodsA comprehensive search of electronic databases such as PubMed, Cochrane, and Scopus was conducted from inception to April 2024 to retrieve all randomized controlled trials (RCTs) that compared steroidal therapy plus conventional antituberculosis therapy with antituberculosis therapy alone for patients of TBM. Meta-analysis was performed using Review Manager 5.4. Dichotomous outcomes were compared using risk ratio (RR).  ResultsThere was a statistically significant decrease in risk of mortality in the Steroid group compared to the control group (RR 0.84; 95% CI 0.75, 0.94; p-value < 0.05). However, there was no statistically significant difference in the risk of neurological deficit between the two groups. There was a statistically significant reduction in the risk of adverse events in the steroidal therapy group compared to the control group (RR 0.90; 95% CI 0.83, 0.98; p-value = 0.03). Similarly, there was a significant improvement in the clinical efficacy in the steroidal therapy group compared to the control (RR 1.16; 95% CI 1.02, 1.31; p-value = 0.02).  ConclusionSteroids in addition to antituberculosis therapy significantly reduce mortality and adverse events, while improving clinical outcomes in patients of TBM. There is a need for controlled studies with longer follow-up durations to improve the robustness of the results.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Public Health Interventions for Fractional Optimal Control of Buruli Ulcer\nAbstract: Buruli Ulcer, a devastating skin disease caused by Mycobacterium Ulcerans, poses considerable public health challenges in endemic areas. This article focuses on the use of fractional optimal control theory to prevent the spread of Buruli ulcers via integrated public health interventions. We formulated a mathematical model using the Atangana-Baleanu-Caputo fractional order derivative operator. We investigated the models existence and uniqueness and presented numerical simulations using the predict-evaluate-correct-evaluate (PECE) method of Adam-Bashforth Moulton. We also study the fractional optimal control problem (FOCP) to minimize the spread of the disease in the endemic regions. We employ the Fractional Pontryagins Maximum Principle (FPMP) and implement the forward-backward method to determine the extremals of the problem. Four control strategies were implemented: promoting health education on the use of protective clothing, enhancing vaccination rates, improving treatment protocols for infected individuals, and spraying insecticides to reduce water-bug populations. After examining the optimal control dynamics of the Buruli ulcer transmission model via multiple simulations with and without control, we discover that there is a substantial decrease in the population of infected humans and the water-bug population. Hence we conclude that the best strategy to implement is by applying all the control strategies suggested.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bias from heritable confounding in Mendelian randomization studies\nAbstract: Mendelian randomization (MR) is an approach to causal inference that utilises genetic variants to obtain estimates of the causal effect of an exposure on an outcome in the presence of unobserved confounding. MR relies on a set of assumptions to obtain unbiased effect estimates, one of these assumptions is that there is no pathway from the genetic variants to the outcome that does not act through the exposure. Increasing genome-wide association study (GWAS) sample sizes for the exposure enables discovery of instrumental variables with smaller effect sizes. We illustrate through simulations how smaller effect sizes could arise from genetic variants that act through traits that have greater liability to confound an exposure-outcome relationship. When such genetic variants are selected as instruments this can bias the MR effect estimate obtained from that instrument in the same direction as the confounded observational association but with larger magnitude. Through simulation we illustrate how the total bias of the MR estimates increases across a range of standard MR estimation methods increases as the proportion of the genetic instruments that are associated with the confounder increases. However, if such heritable confounders are known and can be instrumented, the confounder free effect estimate can be obtained through applying a pre-estimation filtering to standard MR methods, removing instruments that explain more variation in that confounder than the exposure, or by estimating effects through multivariable MR. We highlight the potential for SNPs identified in GWAS to be associated with potential confounders through examination of a recent GWAS of C-Reactive Protein. Finally, we illustrate our approach through estimation of the causal effect of age at menarche on type 2 diabetes, hypothesising that the MR effect estimate may be biased by confounding due to the inclusion of genetic variants associated with early life adiposity as instruments.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the (log)book: Comparing accelerometer non-wear detection techniques in toddlers\nAbstract: BackgroundAccelerometers are increasingly used to measure physical activity and sedentary time in toddlers. Data cleaning or wear time validation can impact outcomes of interest, particularly in young children who spend less time awake. However, no study has systematically compared wear time validation strategies in toddlers. As such, the objective of this study is to compare different fully-automated methods of distinguishing wear and non-wear time (counts and raw data algorithms) to the semi-automated (counts with logbooks) criterion method in toddlers.  MethodsWe recruited 109 toddlers (age 12-35 mos) as part of the iPLAY study to wear an ActiGraph w-GT3X-BT accelerometer on the right hip for [~]7 consecutive days (removed for sleep and water activities). Parents completed a logbook to indicate monitor removal and nap times. We tested 15 nonwear detection methods grouped into 4 main categories: semi-automated logbook, consecutive 0 counts, modified consecutive 0 counts (Troiano and Choi), and raw data methods (van Hees and Ahmadi). Using logbooks as the criterion standard (all wear and wake-time only wear), we calculated the accuracy and F1 scores and compared overall wear time with a two one-sided test of equivalence.  ResultsParticipant daily wear time ranged from 556 to 684 minutes/day depending on method. Accuracy and F1 score ranged from 86 to 95%. Five methods were considered equivalent to the AllWear nonwear criterion (true wear time including sleep-time wear), with only one equivalent to the AwakeWear criterion. Mean absolute differences were lower for the AllWear criterion but ranged 49 to 192 minutes/day  ConclusionsThe 5min0count, 10min_0count, 30min_0count, Troiano60s, and Ahmadi methods provide high accuracy and equivalency when compared to semi-automated cleaning using logbooks. This paper provides insights and quantitative results that can help researchers decide which method may be most appropriate given their population of interest, sample size, and study protocol.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Risk of Cardiovascular Adverse Events and Appendicitis After COVID-19 Diagnosis in Adults in the United States: Implications of the Start of Follow-Up\nAbstract: PurposeThis study evaluated the association between coronavirus disease 2019 (COVID-19) diagnosis and adverse events (AEs), including cardiovascular AEs and appendicitis, in US adults before the introduction of COVID-19 vaccines. Real-world studies of AEs after COVID-19 suggest that diagnoses of AEs and COVID-19 frequently occur on the same day and may be a source of bias.  MethodsCohort and self-controlled risk interval (SCRI) designs were used in 2 US administrative claims data sources--Merative MarketScan(R) (ages 18-64 years) and Medicare (ages [&ge;] 65 years). AEs included stroke (nonhemorrhagic and hemorrhagic), acute myocardial infarction, myocarditis/pericarditis, deep vein thrombosis, pulmonary embolism (PE), disseminated intravascular coagulation (DIC), unusual-site and common-site thrombosis with thrombocytopenia syndrome, and appendicitis. In cohort analyses, weighted hazard ratios (HRs) and 95% confidence intervals (CIs) compared adults with a COVID-19 diagnosis and matched comparators. In SCRI analysis, relative incidences (RIs) and 95% CIs compared risk and reference windows within individuals. Analyses were performed starting follow-up on Time 0 and Day 1.  ResultsFor cardiovascular AEs, all estimates starting follow-up on Day 1 were above 1.0 in both data sources. For cohort analyses, the strongest associations were for inpatient PE in both databases: MarketScan, HR=8.65 (95% CI, 6.06-12.35), Medicare HR=3.06 (95% CI, 2.88-3.26). For SCRI analyses, the strongest association in MarketScan was for DIC: RI=32.28 (95% CI, 17.06-61.09) and in Medicare was for myocarditis/pericarditis: RI=4.53 (95% CI, 3.89-5.27). AEs diagnosed concurrently with COVID-19 (ie, on Time 0) were common; including Time 0 in follow-up/risk windows resulted in higher RIs, as well as higher HRs for some AEs. However, some AEs (eg, stroke) were more common on Time 0 in the comparator group resulting in lower HRs.  ConclusionCOVID-19 diagnoses had moderate to strong associations with cardiovascular AEs and weak or inconsistent associations with appendicitis, although estimates varied by design and methodology.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Methodological Challenges using Routine Clinical Care Data for Real-World Evidence: a Rapid Review utilizing a systematic literature search and focus group discussion\nAbstract: BackgroundThe integration of real-world evidence (RWE) from real-world data (RWD) in clinical research is crucial for bridging the gap between clinical trial results and real-world outcomes. Analyzing routinely collected data to generate clinical evidence faces methodological concerns like confounding and bias, similar to prospectively documented observational studies. This study focuses on additional limitations frequently reported in the literature, providing an overview of the challenges and biases inherent to analyzing routine clinical care data, including health claims data (hereafter: routine data).  MethodsWe conducted a literature search on routine data studies in four high-impact journals based on the Journal Citation Reports (JCR) category \"Medicine, General & Internal\" as of 2022 and three oncology journals, covering articles published from January 2018 to October 2023. Articles were screened and categorized into three scenarios based on their potential to provide meaningful RWE: (1) Burden of Disease, (2) Safety and Risk Group Analysis, and (3) Treatment Comparison. Limitations of this type of data cited in the discussion sections were extracted and classified according to different bias types: main bias categories in non-randomized studies (information bias, reporting bias, selection bias, confounding) and additional routine data-specific challenges (i.e., operationalization, coding, follow-up, missing data, validation, and data quality). These classifications were then ranked by relevance in a focus group meeting of methodological experts. The search was pre-specified and registered in PROSPERO (CRD42023477616).  ResultsIn October 2023, 227 articles were identified, 69 were assessed for eligibility, and 39 were included in the review: 11 on the burden of disease, 17 on safety and risk group analysis, and 11 on treatment comparison. Besides typical biases in observational studies, we identified additional challenges specific to RWE frequently mentioned in the discussion sections. The focus group had varied opinions on the limitations of Safety and Risk Group Analysis and Treatment Comparison but agreed on the essential limitations for the Burden of Disease category.  ConclusionThis review provides a comprehensive overview of potential limitations and biases in analyzing routine data reported in recent high-impact journals. We highlighted key challenges that significantly impact analysis results, emphasizing the need for thorough consideration and discussion for meaningful inferences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Methodological Challenges using Routine Clinical Care Data for Real-World Evidence: a Rapid Review utilizing a systematic literature search and focus group discussion\nAbstract: BackgroundThe integration of real-world evidence (RWE) from real-world data (RWD) in clinical research is crucial for bridging the gap between clinical trial results and real-world outcomes. Analyzing routinely collected data to generate clinical evidence faces methodological concerns like confounding and bias, similar to prospectively documented observational studies. This study focuses on additional limitations frequently reported in the literature, providing an overview of the challenges and biases inherent to analyzing routine clinical care data, including health claims data (hereafter: routine data).  MethodsWe conducted a literature search on routine data studies in four high-impact journals based on the Journal Citation Reports (JCR) category \"Medicine, General & Internal\" as of 2022 and three oncology journals, covering articles published from January 2018 to October 2023. Articles were screened and categorized into three scenarios based on their potential to provide meaningful RWE: (1) Burden of Disease, (2) Safety and Risk Group Analysis, and (3) Treatment Comparison. Limitations of this type of data cited in the discussion sections were extracted and classified according to different bias types: main bias categories in non-randomized studies (information bias, reporting bias, selection bias, confounding) and additional routine data-specific challenges (i.e., operationalization, coding, follow-up, missing data, validation, and data quality). These classifications were then ranked by relevance in a focus group meeting of methodological experts. The search was pre-specified and registered in PROSPERO (CRD42023477616).  ResultsIn October 2023, 227 articles were identified, 69 were assessed for eligibility, and 39 were included in the review: 11 on the burden of disease, 17 on safety and risk group analysis, and 11 on treatment comparison. Besides typical biases in observational studies, we identified additional challenges specific to RWE frequently mentioned in the discussion sections. The focus group had varied opinions on the limitations of Safety and Risk Group Analysis and Treatment Comparison but agreed on the essential limitations for the Burden of Disease category.  ConclusionThis review provides a comprehensive overview of potential limitations and biases in analyzing routine data reported in recent high-impact journals. We highlighted key challenges that significantly impact analysis results, emphasizing the need for thorough consideration and discussion for meaningful inferences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Higher dose corticosteroids in hospitalised COVID-19 patients requiring ventilatory support (RECOVERY): a randomised, controlled, open-label, platform trial\nAbstract: BackgroundLow-dose corticosteroids (e.g. 6 mg dexamethasone) have been shown to reduce mortality for hypoxic COVID-19 patients. We have previously reported that higher dose corticosteroids cause harm in patients with hypoxia but not receiving ventilatory support (non-invasive mechanical ventilation, invasive mechanical ventilation or extra-corporeal membrane oxygenation), but the balance of efficacy and safety in patients receiving ventilatory support is uncertain.  MethodsThis randomised, controlled, open-label platform trial (Randomised Evaluation of COVID-19 Therapy [RECOVERY]) assessed multiple possible treatments in patients hospitalised for COVID-19. Eligible and consenting adult patients receiving ventilatory support were randomly allocated (1:1) to either usual care with higher dose corticosteroids (dexamethasone 20 mg once daily for 5 days followed by 10 mg once daily for 5 days or until discharge if sooner) or usual standard of care alone (which includes dexamethasone 6 mg once daily for 10 days or until discharge if sooner). The primary outcome was 28-day mortality; secondary outcomes were duration of hospitalisation and (among participants not on invasive mechanical ventilation at baseline) the composite of invasive mechanical ventilation or death. Recruitment closed on 31 March 2024 when funding for the trial ended. The RECOVERY trial is registered with ISRCTN (50189673) and clinicaltrials.gov (NCT04381936).  FindingsBetween 25 May 2021 and 9 January 2024, 477 COVID-19 patients receiving ventilatory support were randomly allocated to receive usual care plus higher dose corticosteroids versus usual care alone (of whom 99% received corticosteroids during the follow-up period). Of those randomised, 221 (46%) were in Asia, 245 (51%) in the UK and 11 (2%) in Africa. 143 (30%) had diabetes mellitus. Overall, 86 (35%) of 246 patients allocated to higher dose corticosteroids versus 86 (37%) of 231 patients allocated to usual care died within 28 days (rate ratio [RR] 0.87; 95% CI 0.64-1.18; p=0.37). There was no significant difference in the proportion of patients discharged from hospital alive within 28 days (128 [52%] in the higher dose corticosteroids group vs 120 [52%] in the usual care group; RR 1.04, 0.81-1.33]; p=0.78). Among those not on invasive mechanical ventilation at baseline, there was no significant difference in the proportion meeting the composite endpoint of invasive mechanical ventilation or death (76 [37%] of 206 vs 93 [45%] of 205; RR 0.79 [95% CI 0.63-1.00]; p=0.05).  InterpretationIn patients hospitalised for COVID-19 receiving ventilatory support, we found no evidence that higher dose corticosteroids reduced the risk of death compared to usual care, which included low dose corticosteroids.  FundingUK Research and Innovation (Medical Research Council) and National Institute of Health Research (Grant ref: MC_PC_19056), and Wellcome Trust (Grant Ref: 222406/Z/20/Z).\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A multicenter study to assess the performance of the point-of-care RT-PCR Cobas SARS-CoV-2 & Influenza A/B nucleic acid test for use on the Cobas Liat system in comparison with centralized assays across healthcare facilities in the United States\nAbstract: Non-structured abstractRespiratory diseases can share many of the same symptoms, highlighting the need for timely and accurate differentiation to facilitate effective clinical management and reduce transmission. Compared with centralized testing, molecular point-of-care tests (POCT) can provide a faster time to result.  We evaluated the RT-PCR POCT Cobas(R) SARS-CoV-2 & Influenza A/B qualitative assay for use on the Cobas Liat(R) system (the POC SARS-CoV-2 & Influenza A/B test) in nasal and nasopharyngeal swab samples from 10 diverse healthcare facilities in the US. A composite comparator design consisting of three centralized tests was used to analyze SARS-CoV-2, whilst performance versus a single centralized test was used for analysis of influenza A and B. Evaluations included performance stratified by sample type (prospective/retrospective and nasal/nasopharyngeal [paired by subject]), collection method (self/healthcare worker-collected [alternated and approximately balanced], symptom status (symptomatic/asymptomatic), and SARS-CoV-2 vaccination status, as well as assay inclusivity and system ease of use.  A total of 2,247 samples were tested. For SARS-CoV-2, the overall percent agreement (OPA) was 98.8% (95% CI: 97.9, 99.3) in nasal swab samples and 99.0% (95% CI: 98.2, 99.4) in nasopharyngeal swab samples. Regression analysis showed that Ct values from paired nasal and nasopharyngeal swab samples were highly correlated (correlation coefficient 0.83). The OPA was [&ge;]99.5% (sample type dependent) and 100.0% for influenza A and B, respectively. The POC SARS-CoV-2 & Influenza A/B test was easy to use.  These results support the use of the POCT in various sample types and by various operators in the intended-use setting.  Summary statement/importanceThis study highlights the benefits of RT-PCR POCT, namely comparable performance to centralized testing in multiple sample types and ease of use. Utilizing assays such as the POC SARS-CoV-2 & Influenza A/B test may improve timely differentiation of respiratory diseases that share similar symptoms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A multicenter study to assess the performance of the point-of-care RT-PCR Cobas SARS-2 CoV-2 & Influenza A/B nucleic acid test for use on the Cobas Liat system in comparison with 3 centralized assays across healthcare facilities in the United States\nAbstract: Non-structured abstractRespiratory diseases can share many of the same symptoms, highlighting the need for timely and accurate differentiation to facilitate effective clinical management and reduce transmission. Compared with centralized testing, molecular point-of-care tests (POCT) can provide a faster time to result.  We evaluated the RT-PCR POCT Cobas(R) SARS-CoV-2 & Influenza A/B qualitative assay for use on the Cobas Liat(R) system (the POC SARS-CoV-2 & Influenza A/B test) in nasal and nasopharyngeal swab samples from 10 diverse healthcare facilities in the US. A composite comparator design consisting of three centralized tests was used to analyze SARS-CoV-2, whilst performance versus a single centralized test was used for analysis of influenza A and B. Evaluations included performance stratified by sample type (prospective/retrospective and nasal/nasopharyngeal [paired by subject]), collection method (self/healthcare worker-collected [alternated and approximately balanced], symptom status (symptomatic/asymptomatic), and SARS-CoV-2 vaccination status, as well as assay inclusivity and system ease of use.  A total of 2,247 samples were tested. For SARS-CoV-2, the overall percent agreement (OPA) was 98.8% (95% CI: 97.9, 99.3) in nasal swab samples and 99.0% (95% CI: 98.2, 99.4) in nasopharyngeal swab samples. Regression analysis showed that Ct values from paired nasal and nasopharyngeal swab samples were highly correlated (correlation coefficient 0.83). The OPA was [&ge;]99.5% (sample type dependent) and 100.0% for influenza A and B, respectively. The POC SARS-CoV-2 & Influenza A/B test was easy to use.  These results support the use of the POCT in various sample types and by various operators in the intended-use setting.  Summary statement/importanceThis study highlights the benefits of RT-PCR POCT, namely comparable performance to centralized testing in multiple sample types and ease of use. Utilizing assays such as the POC SARS-CoV-2 & Influenza A/B test may improve timely differentiation of respiratory diseases that share similar symptoms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Divergent inflammatory and neurology-related plasma protein profiles in individuals with long COVID following primary and breakthrough SARS-CoV-2 infections.\nAbstract: Long COVID is a complex condition where symptoms persist for more than 3 months after SARS-CoV-2 infection and affects an estimated 5-30% of individuals. While the pathobiology of long COVID is still evolving, persistent inflammation has emerged as an important feature of this condition. However, it is unclear if immune responses from COVID-19 vaccination or SARS-CoV-2 re-infection exacerbate or mirror the initial inflammatory responses. To address this question, we quantified 182 inflammatory and neurology-related proteins in plasma using multiplexed affinity proteomics. Plasma samples were collected 6-9 months after first infection, but before COVID-19 vaccination from individuals who had recovered from COVID-19 (n=21) or from individuals with long COVID (n=12). This was benchmarked against plasma from unvaccinated, SARS-CoV-2 naive individuals (n=24). In addition to this cross-sectional analysis, we performed longitudinal analysis in a subset of individuals (n=34), where paired samples collected 2-4 weeks after a third COVID-19 vaccine dose and after SARS-CoV-2 breakthrough infection were available. Boruta feature selection and lasso regression models identified a distinct plasma profile in long COVID individuals, characterised by elevated IL-20, HAGH, NAAA, CLEC10A, LXN, and MCP-1 and reduced TRAIL, G-CSF, NBL1, and CCL23 protein concentrations. Notably, longitudinal analysis demonstrated that neither COVID-19 booster vaccination nor breakthrough infection replicated inflammatory and neurology-related plasma protein profiles observed after primary infection suggesting an altered immune response outcome in individuals with long COVID upon re-exposure.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Seroprevalence of chikungunya and onyong-nyong viruses in Senegal, West Africa\nAbstract: BackgroundArthritogenic alphaviruses such as chikungunya (CHIKV) and onyong-nyong (ONNV) viruses have shown capacity to cause widespread epidemics, with recurrent and sporadic outbreaks occurring throughout sub-Saharan Africa.  MethodsWe analyzed the seroprevalence for CHIKV and ONNV in 470 non-febrile subjects from three regions in Senegal (Sindia, 2018; Thies, 2018; and Kedougou, 2022/2023) using retrospective samples. We assessed the presence of anti-CHIKV IgG and neutralizing titers against CHIKV and ONNV via enzyme-linked immunosorbent assay (ELISA) and microneutralization tests, respectively, and determined risk factors of CHIKV and ONNV exposure by binary logistic regression.  ResultsThe overall seroprevalence of anti-CHIKV IgG was 24.89% (117/470). Regional seroprevalences were 14.89% (14/94) in Sindia, 28.72% (27/94) in Thies, and 26.95% (76/282) in Kedougou. Among CHIKV IgG-positive samples, 29.91% (35/117) and 39.32% (46/117) had neutralizing antibodies against CHIKV and ONNV, respectively. Of the remaining samples, 20.51% (24/117) were equivocal and 10.26% (12/117) were negative. Multivariate analysis showed that residence in Thies significantly increased the likelihood of CHIKV infection (OR, 3.878; 95% CI: 0.783-19.205), whereas prior malaria infection reduced it (aOR, 0.121; 95% CI: 0.049-0.300). Conversely, older age (OR, 7.896; 95% CI: 1.500-41.556) and residence in Kedougou (OR, 3.180; 95% CI: 0.824-12.276) were significant risk factors for ONNV infection, with prior malaria infection also linked to higher ONNV susceptibility (aOR, 6.961; 95% CI: 2.456-19.732).  ConclusionsOur study confirms significant exposure to CHIKV and ONNV across Senegal, underscoring the importance of ongoing surveillance and alphavirus testing among the population.  Author summaryArthritogenic alphaviruses, such as chikungunya (CHIKV) and onyong-nyong (ONNV) viruses have the potential to cause widespread epidemics, with recurrent and sporadic outbreaks occurring throughout sub-Saharan Africa. This study presents a retrospective evaluation of CHIKV and ONNV seroprevalence among non-febrile subjects from three regions in Senegal: Sindia, Thies, and Kedougou. Our analysis revealed regional variation in alphavirus seroprevalence, with 29.91% of subjects exhibiting neutralizing antibodies against CHIKV and 39.32% against ONNV. We identified that residence in Thies was a risk factor for CHIKV, while residence in Kedougou, a history of malaria, and older age were risk factors for ONNV. These findings suggest significant exposure to CHIKV and ONNV across Senegal, underscoring the importance of ongoing surveillance and alphavirus testing among the population.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Uncertainty quantification in epigenetic clocks via conformalized quantile regression\nAbstract: DNA methylation (DNAm) is a chemical modification of DNA that can be influenced by various factors, including age, environment, and lifestyle. An epigenetic clock is a predictive tool that measures biological age based on DNAm levels. It can provide insights into an individuals biological age, which may differ from their chronological age. This difference, known as the epigenetic age acceleration, may indicate the state of ones health and risk for age-related diseases. Moreover, epigenetic clocks are used in studies of aging to assess the effectiveness of anti-aging interventions and to understand the underlying mechanisms of aging and disease. Various epigenetic clocks have been developed using samples from different populations, tissues, and cell types, typically by training high-dimensional linear regression models with an elastic net penalty. While these models can predict mean biological age with high precision, there is a lack of uncertainty quantification which is important for interpreting the precision of age estimations and for clinical decision-making. To understand the distribution of a biological age clock beyond its mean, we propose a general pipeline for training epigenetic clocks, based on an integration of high-dimensional quantile regression and conformal prediction, to effectively reveal population heterogeneity and construct prediction intervals. Our approach produces adaptive prediction intervals not only achieving nominal coverage but also accounting for the inherent variability across individuals. By using the data collected from 728 blood samples in 11 DNAm datasets from children, we find that our quantile regression-based prediction intervals are narrower than those derived from conventional mean regression-based epigenetic clocks. This observation demonstrates an improved statistical efficiency over the existing pipeline for training epigenetic clocks. In addition, the resulting intervals have a synchronized varying pattern to age acceleration, effectively revealing cellular evolutionary heterogeneity in age patterns in different developmental stages during individual childhoods and adolescent cohort. Our findings suggest that conformalized high-dimensional quantile regression can produce valid prediction intervals and uncover underlying population heterogeneity. Although our methodology focuses on the distribution of aging in children, it is applicable to a broader range of populations to improve understanding of epigenetic age beyond the mean. This inference-based toolbox could provide valuable insights for future applications of epigenetic interventions for age-related diseases.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Medical Risk Classification For Severe COVID-19 Based On Chronic Medical Conditions: A Comparative Analysis\nAbstract: BackgroundThe European Centre for Disease Prevention and Control (ECDC) provides listings of medical conditions conferring high- or moderate-risk for severe COVID-19. In addition, individual European countries developed their own risk classifications for severe COVID-19 to select individuals recommended for annual COVID-19 vaccination. We assessed the discordance between the European and respective national medical risk classifications in assigning children and adults to risk groups for developing severe COVID-19 in populations of the Netherlands and Norway.  MethodsThis multi-country, healthcare data-linkage study covered 17.4 million inhabitants of the Netherlands and 5.6 million inhabitants of Norway by 1 January 2020. Medical conditions were defined based on ICD-10 hospital discharge codes in the European and Dutch classifications, and on ICD-10 and ICPC-2 primary care codes in the Norwegian classification. Subjects were classified as high-, moderate-, or low-risk. Discordance was calculated as the proportion of the population with a different risk status in the respective national compared to the European classification.  FindingsThe overall discordance between European and national risk classification was 12.0% in the Dutch and 13.8% in the Norwegian population. The European classification assigns more individuals to high-risk (9.0% and 9.2% of the Dutch and Norwegian populations, respectively) than the national classifications (1.5% and 3.0%, respectively). National classifications define more individuals as moderate-risk (11.3% and 12.7%, respectively) than the European classification (1.0% and 1.3%, respectively). Classification discordances most frequently involved subjects with cardiovascular disease, lung disease, and diabetes mellitus.  InterpretationThe European classification defines a substantially larger percentage of the population as high-risk for severe COVID-19 than the national classifications. This may have implications for post-pandemic vaccination programs. Further research should assess to what extent the medical conditions responsible for the classification discordances determine the risk of developing severe COVID-19.  FundingZonMw, EU, FCT, Norwegian Research Councils COVID-19 Emergency Call, iAPOGEE.  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSWe searched PubMed for English-language articles published from 1 January 2020 to 1 July 2024, using the search terms ((((\"COVID-19\"[Title] OR \"SARS-CoV-2\"[Title]) AND (\"sever*\"[Title] OR \"hospital*\"[Title] OR \"death\"[Title] OR \"decease*\"[Title]) AND (\"chronic condition*\"[Title/Abstract] OR \"comorbidit*\"[Title/Abstract]) AND (\"guideline\"[Title] OR \"classification\"[Title] OR \"system\"[Title]) AND 2020/01/01:2024/07/01[Date - Create]) NOT \"clinical trial\"[Publication Type]) NOT \"case reports\"[Publication Type]). This search identified 64 studies, but none of them assessed the impact of different medical risk classifications for severe COVID-19 or compared them across countries or to the European classification.  Added value of this studyTo the best of our knowledge, this is the first study that compared the impact of European and national medical risk classifications for severe COVID-19 by assigning the populations of the Netherlands and Norway to medical risk groups using national healthcare registries. We demonstrated important discrepancies between the European and respective national schemes in classifying high- and moderate-risk individuals in both countries. The chronic conditions responsible for the classification discordances were lung disease, cardiovascular disease, neurological disorders, diabetes mellitus, cancer, and hypertension.  Implications of all the available evidenceOur comparative analysis suggests that the choice between the European and national classifications may have important consequences for public health interventions such as vaccination campaigns. The variability in risk assignment based on chronic medical conditions underscores the absence of an international uniform approach. More research is needed to determine the extent to which each chronic medical condition impacts COVID-19 severity in the post-pandemic period, facilitating the refinement of risk classifications and supporting targeted public health interventions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Modeling the Risk of Airborne Transmission of Respiratory Viruses in Microgravity\nAbstract: Airborne transmission is the most efficient and widespread route of viral spread, posing a significant challenge in controlling major infectious diseases such as COVID-19 and influenza. In microgravity environment, such as the International Space Station (ISS), this mode of transmission requires heightened vigilance and preventive measures due to the prolonged suspension of virus-laden particles, which increases the risk of infection. Using the COVID Airborne Risk Assessment (CARA) tool, we assess the risk of airborne transmission of respiratory viruses in microgravity by simulating the emission, dispersion, and inhalation of virus-laden particles. Our findings show that the unique conditions of microgravity allow these particles to remain airborne for significantly longer periods compared to Earth, leading to a 286-fold increase in virus concentration in the air, resulting in nearly twice the probability of infection for a susceptible host. We also evaluated the effectiveness of preventive measures, and found that facemasks can reduce the risk by up to 23% while continuous HEPA filtration at five air changes per hour proves crucial for managing air quality and minimizing infection risks by reducing airborne virus concentration at 99.79%. However, when simulated the infection risk by accounting the spaceflight-induced immune suppression, we found that the infection probability increased by 12% in the condition that viral load in infected host increase for 8-fold and absence of protective measures. Although facemasks and air filtration help mitigate the risk, their effectiveness diminishes when the viral load carrying by host is high. Enhancing host immunity through vaccination or other interventions is vital, potentially reducing infection probability by up to 14.17% when combined with HEPA filtration. These findings highlight the need for robust mitigation strategies to safeguard the health of astronauts against airborne pathogens during future space missions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Loon Lens 1.0 Validation: Agentic AI for Title and Abstract Screening in Systematic Literature Reviews\nAbstract: IntroductionSystematic literature reviews (SLRs) are critical for informing clinical research and practice, but they are time-consuming and resource-intensive, particularly during Title and Abstract (TiAb) screening. Loon Lens, an autonomous, agentic AI platform, streamlines TiAb screening without the need for human reviewers to conduct any screening.  MethodsThis study validates Loon Lens against human reviewer decisions across eight SLRs conducted by Canadas Drug Agency, covering a range of drugs and eligibility criteria. A total of 3,796 citations were retrieved, with human reviewers identifying 287 (7.6%) for inclusion. Loon Lens autonomously screened the same citations based on the provided inclusion and exclusion criteria. Metrics such as accuracy, recall, precision, F1 score, specificity, and negative predictive value (NPV) were calculated. Bootstrapping was applied to compute 95% confidence intervals.  ResultsLoon Lens achieved an accuracy of 95.5% (95% CI: 94.8-96.1), with recall at 98.95% (95% CI: 97.57-100%) and specificity at 95.24% (95% CI: 94.54-95.89%). Precision was lower at 62.97% (95% CI: 58.39-67.27%), suggesting that Loon Lens included more citations for full-text screening compared to human reviewers. The F1 score was 0.770 (95% CI: 0.734-0.802), indicating a strong balance between precision and recall.  ConclusionLoon Lens demonstrates the ability to autonomously conduct TiAb screening with a substantial potential for reducing the time and cost associated with manual or semi-autonomous TiAb screening in SLRs. While improvements in precision are needed, the platform offers a scalable, autonomous solution for systematic reviews. Access to Loon Lens is available upon request at https://loonlens.com/.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pesticides and lifestyle factors are associated with disease severity of Parkinson's disease: a longitudinal study\nAbstract: ObjectiveTo longitudinally analyze the impact of the environment and lifestyle on PD motor sign severity in LRRK2 p. Gly2019Ser-related PD (LRRK2-PD) and idiopathic PD (iPD).  BackgroundThere is increasing evidence that the environment impacts disease severity. Recent studies have shown that pesticide exposure is associated with a faster disease progression. However, the relationship between smoking, caffeine, and disease severity has not yet been investigated longitudinally.  MethodsIn this longitudinal study, we included patients with iPD from the PPMI Online (N=2815) and Fox Insight (N=2319) cohorts, as well as patients with LRRK2-PD (N=81) from Fox Insight. Motor signs were assessed with the MDS-UPDRS Part II, and patients were assessed multiple times, followed up to 35 months or 60 months in the PPMI Online or Fox Insight cohort, respectively. The motor sign severity over time was analyzed by applying a linear mixed effects model. The outcome was the cumulative score of the MDS-UPDRS Part II questionnaire. Subsequently, we investigated the association between environmental exposure, lifestyle factors and motor signs. Pesticide exposure in a work setting, smoking, coffee, black tea, green tea, and caffeinated soda consumption were assessed using the validated PD-RFQ-U questionnaires. The mixed effects model included the environmental and lifestyle factors as binary (yes/no) variables.  ResultsWhen comparing LRRK2-related PD and iPD, motor signs were less severe in patients with LRRK2-PD compared to iPD ({beta}=-0.23, p=0.005). In LRRK2-PD, black tea consumption was associated with less severe motor signs ({beta}=-0.51, p=0.028). In patients with iPD, we observed that pesticide exposure was associated with more severe motor signs over time in PPMI-Online ({beta}=0.23, p=3.56x10-9). Smoking was associated with a higher motor signs score in PPMI-Online ({beta}=0.13, p=0.001). Lastly, caffeinated soda was associated with more severe motor signs in patients with iPD from PPMI-Online ({beta}=0.15, p=3.84x10-8) and Fox Insight ({beta}=0.09, p=0.031).  ConclusionsOur results provide further evidence of the importance of environment and lifestyle in PD, even after the disease onset. We suggest that pesticide exposure and lifestyle factors may affect disease severity in patients with LRRK2-PD and iPD; still, further validation is necessary.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Parenting and Family Adjustment Scales (PAFAS) questionnaire: psychometric qualities of the parenting scale in two large Brazilian birth cohorts\nAbstract: ObjectiveAnalyse the psychometric properties of the Portuguese version of the PAFAS (Parenting and Family Adjustment Scales) parenting scale, using data from two large Brazilian birth cohorts.  MethodsThe original PAFAS parenting scale, which consists of 18 items (parental inconsistency 5 items, coercive parenting 5 items, positive encouragement 3 items, and parent-child relationship 5 items) was applied in two Brazilian birth cohorts in Pelotas (ages 4 [n = 4010] and 6-7 [n = 3867]) and Rio Grande (age 3 [n = 992]). Confirmatory factor analysis was conducted, and internal consistency assessed, as well as construct validity in relation to maternal depression measured on the Edinburgh Postnatal Depression Scale.  ResultsThe model with a structure of 4 subscales showed that the global scale of parenting on the PAFAS had a good fit, but certain items did not fit well on sub-scales and were removed (2 items from parental inconsistency, 1 from coercive parenting, and 1 from positive encouragement). The original form of the parent-child relationship sub-scale was maintained. Considering the total PAFAS parenting score, we found that mothers with maternal depression had a higher likelihood of more problematic parental practices than mothers without depression.  ConclusionsA revised 14-item PAFAS parenting scale has good psychometric properties and we encourage its use in Brazilian populations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dissecting causal relationships between cortical morphology and neuropsychiatric disorders: a bidirectional Mendelian randomization study\nAbstract: Brain cortical morphology, indexed by its surface area and thickness, is known to be highly heritable. Previous research has suggested a relationship of cortical morphology with several neuropsychiatric phenotypes. However, the multitude of potential confounders makes it difficult to establish causal relationships. Here, we employ Generalized Summary-data-based Mendelian Randomization and a series of sensitivity analyses to investigate causal links between 70 cortical morphology measures and 199 neuropsychiatric, behavioral, and metabolic phenotypes. We show that total brain cortical surface area (TSA) has significant positive causal effects on 18 phenotypes. The strongest effects include TSA positively influencing cognitive performance, while reverse analyses reveal small effects of cognitive performance on TSA. Global mean cortical thickness (MTH) exhibits significant causal effects on five phenotypes, including schizophrenia. MTH reduces schizophrenia risk and bidirectional causality is found between MTH and smoking initiation. Finally, in regional analyses we detect positive influences of the transverse temporal surface area on cognitive performance and negative influences of transverse temporal thickness on schizophrenia risk. Overall, our results highlight bidirectional associations between TSA, MTH, and neuropsychiatric traits. These insights offer potential avenues for intervention studies aimed at improving brain health.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exposome-wide gene-environment interaction study of psychotic experiences in the UK Biobank\nAbstract: BackgroundA previous study successfully identified 148 out of 23,098 exposures associated with any psychotic experiences (PE) in the UK Biobank using an exposome-wide association study (XWAS). Research has shown that the polygenic risk score for schizophrenia (PRS-SCZ) is associated with PE. However, the interaction of these exposures and PRS-SCZ remains unknown.  MethodTo systematically investigate gene-environment interaction underlying PE through data-driven agnostic analyses, we conducted 1) a conditional XWAS adjusting for PRS-SCZ to estimate the main effects of the exposures and PRS-SCZ, respectively; 2) exposome-wide interaction studies (XWIS) to estimate multiplicative and additive interactions between PRS-SCZ and exposures; and 3) the correlations between PRS-SCZ and exposures. The study included 148,502 participants from UK biobank.  ResultsIn the conditional XWAS models, the significant effects of PRS-SCZ and 148 exposures on PE remained statistically significant. In the XWIS model, we found a significant multiplicative (Ms, 1.23, 95%CI, 1.10-1.37; P=4.0x10-4) and additive (RERI, 0.55; 95%CI, 0.32-0.77; SI, 0.22; 95%CI, 0.14-0.30; AP, 1.59; 95%CI, 1.30-1.91; all P < 0.05/148) interaction between PRS-SCZ and variable \"serious medical conditions or disability\" on PE. There were six additive gene-environment interactions identified for mental distress, help/treatment-seeking behaviors, vitamin D and sleep problems. In the correlation test focused on seven exposures with significant interaction with PRS-SCZ, no significant or small (r2< 0.04) gene-environment correlations were estimated.  ConclusionThese findings reveal preliminary evidence for gene-environment interaction underlying PEs and suggest that genetic vulnerability and exposures might represent intertwined pathways leading to psychosis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations between accurate measures of adiposity and fitness, blood proteins, and insulin sensitivity among South Asians and Europeans\nAbstract: ObjectiveSouth Asians (SAs) may possess a unique predisposition to insulin resistance (IR). We explored this possibility by investigating the relationship between  gold standard measures of adiposity, fitness, selected proteomic biomarkers, and insulin sensitivity among a cohort of SAs and Europeans (EURs).  MethodsA total of 46 SAs and 41 EURs completed  conventional (lifestyle questionnaires, standard physical exam) as well as  gold standard (dual energy X-ray absorptiometry scan, cardiopulmonary exercise test, and insulin suppression test) assessments of adiposity, fitness, and insulin sensitivity. In a subset of 28 SAs and 36 EURs, we also measured the blood-levels of eleven IR-related proteins. We conducted Spearman correlation to identify correlates of steady-state plasma glucose (SSPG) derived from the insulin suppression test, followed by multivariable linear regression analyses of SSPG, adjusting for age, sex and ancestral group.  ResultsSixteen of 30 measures significantly associated with SSPG, including one conventional and eight gold standard measures of adiposity, one conventional and one gold standard measure of fitness, and five proteins. Multivariable regressions revealed that gold standard measures and plasma proteins attenuated ancestral group differences in IR, suggesting their potential utility in assessing IR, especially among SAs.  ConclusionAncestral group differences in IR may be explained by accurate measures of adiposity and fitness, with specific proteins possibly serving as useful surrogates for these measures, particularly for SAs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Correlates of COVID-19 conspiracy theory beliefs in Japan: A nationally-representative cross-sectional survey\nAbstract: BackgroundThe COVID-19 pandemic was associated with an increase in conspiracy theories worldwide. However, the prevalence of COVID-19 conspiracy beliefs among Japanese has remained unclear. This study aimed to estimate the prevalence and correlates of COVID-19 conspiracy beliefs in Japan using a nationwide survey of 28,175 residents aged 16-81 years old.  MethodsA nationally representative, cross-sectional self-administered survey was conducted from September to October 2021. To assess the number of COVID-19 conspiracy beliefs, we used three questions from the Oxford Coronavirus Explanations, Attitudes, and Narratives Survey. Independent variables included general vaccine conspiracy beliefs, sociodemographic variables, information sources for COVID-19, trust in authorities, and fear of COVID-19.  ResultsAfter applying sampling weights and imputation, the estimated prevalence of holding at least one COVID-19 conspiracy belief was 24.4%. From a linear regression model, several factors were independently associated with conspiracy beliefs. Notably, people with the lowest level of education (lower secondary school) endorsed fewer COVID-19 conspiracy beliefs (B -0.089, vs. upper secondary school). Furthermore, higher socioeconomic backgrounds-such as higher income, higher wealth, and regular employment-were associated with endorsing conspiracy beliefs. Additionally, only 37.3% of respondents trusted the government of Japan, but paradoxically, trust in the government was positively associated with conspiracy beliefs (B 0.175, vs. distrust).  ConclusionsConspiracy beliefs about COVID-19 were prevalent in about a quarter of the Japanese population. Certain groups are more likely to endorse conspiracy beliefs, and targeting interventions towards these groups might be efficient in stemming the spread of conspiracy beliefs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of vaccination on SARS-CoV-2 transmission in the UK: a modelling study\nAbstract: BackgroundEfficacy and effectiveness of vaccines against SARS-CoV-2 infection, severe disease and death have been widely assessed. However, the impact of vaccination against SARS-CoV-2 transmission is far less well-characterized, and has major implications for public health, because it informs the indirect effects of vaccination in addition to its direct effects. Analysing the effects of SARS-CoV-2 vaccination on transmission is challenging, because they must be considered in tandem with the time-varying reproduction number (Rt), while also accounting for regional variability, for example due to the presence of more transmissible variants.  MethodsWe fitted a Bayesian hierarchical model to previously obtained estimates of Rt to estimate the effectiveness of vaccination with one, two and three doses on SARS-CoV-2 transmission in the UK during 2021. Vaccine effectiveness is defined as the proportional reduction in the time-varying reproduction number Rt. The model accounts for transmission at national and Lower Tier Local Authority (LTLA)-level, and uses vaccination data provided by the UK Health Security Agency (UKHSA), detailing the LTLA-specific proportions of people who have received doses one, two and three. The model also incorporates data on the proportion of wild-type, Alpha and Delta SARS-CoV-2 variants over time in each LTLA, obtained from UKHSA and the COVID-19 Genomics UK (COG-UK) Consortium.  ResultsWe find that vaccination had moderate-to-large effectiveness against transmission for dose 1 (39.30%, 95% CrI 26.64% - 48.07%), and for dose 3 (48.69%, 95% CrI 27.97% - 71.30%), but negligible effects on dose 2, likely attributable to the coincident importation and dominance of the Delta variant in the UK. Nationally, our model fitted the previously estimated values of time-series of Rt values well, largely reproducing the reproduction number averaged across LTLAs for each timepoint. This lends support to our hypothesis that the extent of vaccination (or lack thereof) was a major determinant of transmission intensity. Our model fits further reproduced well the reproduction numbers at regional level, although outliers were less well captured, implying some degree of variation that is not explained by our model.  ConclusionsTo our knowledge, our analysis is the first evidence of the effectiveness of SARS-CoV-2 vaccination against its transmission at population level. We find that vaccination is an effective tool for the control of SARS-CoV-2 transmission, in addition to its well-documented effects on disease burden and mortality. Our results allow future assessment of the impact of vaccination accounting for several circulating variants and sociodemographic factors.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The roles of lifestyle factors and genetic risk in the association between night shift work and cholelithiasis: a prospective cohort study.\nAbstract: BackgroundNight shift work has been linked to various adverse health outcomes, but its relationship with incident cholelithiasis remains unclear. This study aims to investigate the association between night shift work and the risk of cholelithiasis, assess the potential modifying effects of genetic susceptibility, and explore the mediating roles of lifestyle factors.  MethodsA total of 219,810 subjects who were either in paid employment or self-employed were included in the UK Biobank. Information on current and lifetime employment were collected. Genetic risk was quantified and stratified by a polygenic risk score (PRS) incorporating 13 known cholelithiasis-associated loci. We used Cox proportional hazard models to investigate associations between night shift work and risk of cholelithiasis. Lifestyle factors measured at baseline were explored as potential mediators.  ResultsDuring a median follow-up of 13.76 years, 6450 incidents of cholelithiasis were documented. Compared with day workers, the hazard ratio (HR) and 95% confidence interval (CI) of cholelithiasis was 1.09 (1.01, 1.17) for individuals with rarely/some night shifts and 1.18 (1.04, 1.35) for those with usual/permanent night shifts. Among the 62,558 participants who had reports on lifetime experience of night shift work, those with a higher frequency of night shifts and a longer length of each night shift were associated with an increased risk of cholelithiasis. Notably, individuals with usual/permanent night shifts and high genetic risk exhibited the highest risk of cholelithiasis (HR: 1.48, 95% CI: 1.21, 1.81), with day workers at low genetic risk serving as the reference. Mediation analysis indicated that a substantial portion (24.6%) of the association was mediated by BMI, followed by unhealthy alcohol intake (4.5%) and sedentary time (1.8%).  ConclusionsNight shift work is associated with an increased risk of cholelithiasis, with this relationship being largely mediated by lifestyle factors. These findings suggest that reducing the frequency and duration of night shifts may help mitigate the incidence of cholelithiasis among night shift workers, particularly for those with heightened genetic susceptibility.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Forecasting COVID-19, Influenza and RSV hospitalisations over winter 2023/24 in England\nAbstract: Seasonal respiratory viruses cause substantial pressure on healthcare systems, particularly over winter. System managers can mitigate the impact on patient care when they anticipate hospital admissions due to these viruses. Hospitalisation forecasts were used widely during the SARS-CoV-2 pandemic. Now, resurgent seasonal respiratory pathogens add complexity to system planning. We describe how a suite of forecasts for respiratory pathogens, embedded in national and regional decision-making structures, were used to mitigate the impact on hospital systems and patient care.  We developed forecasting models predicting hospital admissions and bed occupancy two weeks ahead for COVID-19, influenza, and RSV in England over winter 2023/24. Bed occupancy forecasts were informed by the ensemble admissions models. Forecasts were delivered in real-time at multiple scales. The use of sample-based forecasting allowed for effective reconciliation and trend interpretation.  Admission forecasts, particularly RSV and influenza, showed high skill at regional levels. Bed occupancy forecasts had well-calibrated coverage, owing to informative admissions forecasts and slower moving trends. National admissions forecasts had mean absolute percentage errors of 27.3%, 30.9% and 15.7% for COVID-19, influenza, and RSV respectively, with corresponding 90% coverages of 0.439, 0.807 and 0.779.  These real-time winter infectious disease forecasts produced by the UK Health Security Agency for healthcare system managers played an informative role in mitigating seasonal pressures. The models were delivered regularly and shared widely across the system to key users. This was achieved by producing reliable, fast, and epidemiologically informed ensembles of models. Though, a higher diversity of model approaches could have improved forecast accuracy.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Discriminatory ability of adiposity phenotypes in identifying cardiometabolic disorders in indigenous and non-indigenous African populations\nAbstract: BackgroundWhether any of the anthropometric indices are associated with cardiometabolic outcomes in indigenous Fulani African populations is not known. This study evaluates anthropometric indices in Fulani and non-autochthonous populations in predicting cardiometabolic outcomes in indigenous and non-indigenous populations.  MethodsA population-based cross-sectional study recruited 1 921 participants of similar median aged 32 (24-45) years from Fulbe (settled Fulani), Mbororo (nomadic pastoral Fulani) and the general population. Body weight (BW), height, waist circumference (WC), and hip circumference (HC) were measured and body mass index (BMI), waist-to-hip ratio (WHR), waist-to-height ratio (WHtR), Conicity Index (Cindex), body adiposity index (BAI), body roundness index (BRI) and body shape index (ABSI) were determined. The associations of anthropometric indices with cardiometabolic disorders were assessed by multivariable adjusted logistic regression and the area under the receiver-operating characteristic (ROC) curve compared the predictive abilities.  ResultsWomen had higher prevalence of MetS and the men had higher prevalence of hypertension and IFG/diabetes/hypertension while the prevalence of IFG/diabetes was similar in men and women. In women, the ROC and multivariable logistic regression analyses both showed consistent good performance of BW and BMI in identifying IFG/Diabetes in Fulbe and general population; BW, HC, BMI and BAI in Mbororo and BW, WC, HC, WHtR, and BRI in general population to predict hypertension and IFG/diabetes/hypertension. All the anthropometric indices showed good performance in all the groups to identify MetS. In men, WC, HC and BRI had good performance in all the groups while WC and BRI had good performance in all groups and HC in Fulbe and Mbororo to predict hypertension. The BW, WC, HC, BMI, WHtR, BAI and BRI showed consistent good performance in all the groups to predict MetS.  ConclusionAnthropometric indices of adiposity are important risk assessing tools for cardiometabolic disorders in indigenous as well as non-autochthonous populations varying by ethnic group and sex.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Population Genomics of Plasmodium malariae from Four African Countries\nAbstract: Plasmodium malariae is geographically widespread but neglected and may become more prevalent as P. falciparum declines. We completed the largest genomic study of African P. malariae to-date by performing hybrid capture and sequencing of 77 isolates from Cameroon (n=7), the Democratic Republic of the Congo (n=16), Nigeria (n=4), and Tanzania (n=50) collected between 2015 and 2021. There is no evidence of geographic population structure. Nucleotide diversity was significantly lower than in co-localized P. falciparum isolates, while linkage disequilibrium was significantly higher. Genome-wide selection scans identified no erythrocyte invasion ligands or antimalarial resistance orthologs as top hits; however, targeted analyses of these loci revealed evidence of selective sweeps around four erythrocyte invasion ligands and six antimalarial resistance orthologs. Demographic inference modeling suggests that African P. malariae is recovering from a bottleneck. Altogether, these results suggest that P. malariae is genomically atypical among human Plasmodium spp. and panmictic in Africa.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: COVID-19 real world data infrastructure: A big data resource for study of the impact of COVID-19 in patient populations with immunocompromising conditions\nAbstract: BackgroundWe created a United States-based real-world data resource to better understand the continued impact of the COVID-19 pandemic on immunocompromised patients, who are typically under-represented in prospective studies and clinical trials. Methods: The COVID-19 Real World Data infrastructure (CRWDi) was created by linking and harmonizing deidentified HealthVerity medical and pharmacy claims data from December 1, 2018 to December 31, 2023, with SARS-CoV-2 virologic and serologic laboratory data from major commercial laboratories and Northwell Health; COVID-19 vaccination data; and for patients with cancer, 2010 to 2021 National Cancer Institute Surveillance, Epidemiology, and End Results registry data. Results: The CRWDi dataset contains data on 5.2 million people. Four populations were included in the dataset: (1) patients with cancer (n=1,294,022); (2) patients with rheumatic conditions receiving pharmacotherapy (n=1,636,940); (3) non-cancer solid organ (n=249,797) and hematopoietic stem cell (n=30,172) transplant recipients; and (4) people from the general population including adults (>18 years of age; n=1,790,162) and pediatric patients (<18 years of age; n=198,907).  ConclusionsWe have created a complex real-world data system to address unanswered questions that have arisen during the COVID-19 pandemic. Further, by making the data broadly and freely available to academic researchers from the United States, the CRWDi real-world data system represents an important complement to existing consortia studies and clinical trials that have emerged during the healthcare crisis, and is readily reproducible for future purposing.  SummaryThe COVID-19 Real World Data infrastructure dataset contains 5.2 million deidentified patient records, with focus on immunocompromising conditions, and is freely available to approved researchers to study the impact of coronavirus disease 2019 (COVID-19) on patient morbidities and outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Epidemiological profile of patients diagnosed with covid-19 in the municipality of Sao Goncalo, Rio de Janeiro, Brazil\nAbstract: ObjectivesThe global health crisis caused by SARS-CoV-2 has led to over 760 million confirmed cases and 6.8 million deaths worldwide, primarily impacting the respiratory system with symptoms varying from mild to severe. This study aimed to analyze the interplay between vaccination status, sociodemographic profiles, comorbidities, and COVID-19 outcomes.  Study DesignObservational, cross-sectional, and analytical.  MethodsThe study analyzed data from 6,953 individuals, examining vaccination statuses, sociodemographic profiles, comorbidities, COVID-19 test results, and other relevant variables. The cohort comprised predominantly mixed-race (51%), Caucasian (38%), and Black (9.5%) individuals, with 61% being female and 60% aged between 21-50 years. Prevalent comorbidities included hypertension (18.2%), diabetes (4.9%), and obesity (0.4%).  ResultsPopulation-weighted analysis revealed significant associations between sociodemographic factors and COVID-19 test outcomes. Younger age groups, particularly 11-30 years, had higher positivity rates, which declined with age. Caucasians exhibited higher positivity rates (40.1%) compared to other ethnicities. Cramers V indicated small correlations between symptoms and test outcomes, notably with loss of taste (V = 0.11) and smell (V = 0.08). Odds ratio analysis identified hypertension as significantly associated with higher COVID-19 positivity (OR = 1.54, 95% CI: 1.28-1.83, p < 0.001), while obesity was associated with lower positivity (OR = 0.13, 95% CI: 0.02-0.63, p = 0.025). Symptoms such as fever, cough, loss of taste, loss of smell, and myalgia also showed significant associations with positive test outcomes.  ConclusionsThis study provides valuable insights into the complex interplay of sociodemographic characteristics, comorbidities, symptoms, and COVID-19 outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Accounting for partner notification in epidemiological birth-death-models\nAbstract: Phylodynamics bridges the gap between classical epidemiology and pathogen genome sequence data by estimating epidemiological parameters from time-scaled pathogen phylogenetic trees. The models used in phylodynamics typically assume that the sampling procedure is independent between infected individuals. However, this assumption does not hold for many epidemics, in particular for such sexually transmitted infections as HIV-1, for which partner notification schemes are included in health policies of many countries.  We developed an extension of phylodynamic multi-type birth-death (MTBD) models with partner notification (PN), and a simulator to generate trees under MTBD and MTBD-PN models. We proposed a non-parametric test for detecting partner notification in pathogen phylogenetic trees. Its application to simulated data showed that it is both highly specific and sensitive. For the simplest representative of the MTBD-PN family, the BD-PN model, we solved the differential equations and proposed a closed form solution for the likelihood function. We implemented it in a program, which estimates the model parameters and their confidence intervals from phylogenetic trees. It performed accurate estimations on simulated data, and detected partner notification in HIV-1 B epidemics in Zurich and the UK. Importantly, we showed that not accounting for partner notification when it is present leads to bias in parameter estimation with the BD model, while BD-PN parameter estimator performs well both in presence and in absence of partner notification.  Our PN test, MTBD-PN tree simulator and BD-PN parameter estimator are freely available at github.com/evolbioinfo/treesimulator and github.com/evolbioinfo/bdpn.  Author summaryPhylodynamic models can estimate epidemiological parameters such as the number of secondary infections Re from pathogen phylogenetic trees (i.e., genealogies, inferred from pathogen genomic sequences). These models do not account for partner notification (contact tracing), and instead assume that detection of new cases is independent between infected individuals. However, especially for sexually transmitted infections, partner notification plays an important role and is included in health policies of many countries.  We developed a phylodynamic model accounting for partner notification and a test for the detection of partner notification in pathogen phylogenetic trees. Our test and epidemiological parameter estimator showed good performance both on simulated and real data. We detected the presence of partner notification in the HIV-1 B epidemics in Zurich and the UK, and corrected the previous parameter estimates made without accounting for partner notification.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Detecting imported malaria infections in endemic settings using molecular surveillance: current state and challenges\nAbstract: The Global Technical Strategy for Malaria 2016-2030 targets eliminating malaria from at least 35 countries and reducing case incidence by 90% globally. The importation of parasites due to human mobilization presents a significant challenge to achieve elimination as it can undermine local interventions. A thorough understanding of importation is necessary to support efforts to control and further lead to elimination. Parasite genetic data is extensively deployed to investigate the space-time spread of imported infections. In this matter, this systematic review aimed to aggregate evidence on the use of parasite genetic data for mapping imported malaria and the statistical analytical methods. We discuss the advantages and limitations of the deployed genetic approaches and propose a suitable type of genetic data and statistical framework to discriminate imported malaria infections from local infections. The findings provide actionable insights for national control programs, helping them select the most suitable methods for detecting imported cases while supporting the evaluation of elimination program performance, particularly in low transmission settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adapting COVID-19 research infrastructure to capture influenza and RSV alongside SARS-CoV-2 in UK healthcare workers winter 2022/23: Evaluation of the SIREN Winter Pressures pilot study\nAbstract: BackgroundIn 2022, with high early winter respiratory virus circulation, SIREN, a prospective healthcare worker cohort study monitoring SARS-CoV-2, ran a pilot study introducing multiplex PCR testing for SARS-CoV-2, influenza A/B, and RSV to investigate winter pressures. Three pathways were trialled: (A) on-site swabbing with local laboratory testing, (B) on-site swabbing with UKHSA-commissioned laboratory testing, and (C) postal swabbing with UKHSA-commissioned laboratory testing. Here, we compare pathways in relation to recruitment, testing coverage, participant acceptability, and UKHSA SIREN research team feedback.  MethodsWe conducted a mixed methods evaluation using metrics of quality assurance and study fidelity (participant recruitment and retention; multiplex PCR testing timing and coverage), an adapted NIHR  participant in research feedback questionnaire, and thematic analysis of a UKHSA SIREN research team workshop.  ResultsWith 7,774 participants recruited, target recruitment (N=7,500) was achieved. Thirty-nine sites took part in the sub-study (4,289 participants). Thirty-three used pathway A, and six used pathway B. 3,485 participants enrolled to pathway C (27.8% of invitees). The median number of tests per participant was similar across pathways (6; 4; 5). However, sites using local laboratories showed a wide variation in the date they switched to multiplex testing (28th November 2022 to 16th March 2023). Consequently, influenza and RSV testing coverage was higher for pathways using UKHSA-commissioned laboratories (100.0% vs 45.6% at local laboratories). 1,204/7,774 (15.5%) participants completed the feedback survey. All pathways were acceptable to participants; 98.9% of postal and 97.5% of site-based participants  would consider taking part again.  ConclusionTransitioning SARS-CoV-2 PCR testing to include influenza and RSV was challenging to achieve rapidly across multiple sites. The postal testing pathway proved more agile, and UKHSA-commissioned laboratory testing provided more comprehensive data collection than local laboratory testing. This sub-study indicates that postal protocols are effective, adaptable at pace, and acceptable to participants.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Efficacy of Molnupiravir in reducing the risk of severe outcome in patients with SARS-CoV-2 infection: a real-life full-matched case-control study (SAVALO Study).\nAbstract: IntroductionMolnupiravir (MNP) is an orally administered prodrug which prevents disease progression in patients at high risk for severe COVID-19. We conducted a real-life case-control study on a cohort of outpatients, with Omicron SARS-CoV-2 infection to assess the effectiveness of MNP in reducing the occurrence of hospital admission, admission in intensive care unit (ICU) and death at day 28.  Materials and methodsCases were enrolled among SARS-CoV-2 positive subjects that sought medical care during the first five days of symptoms from January 1st, 2022, to December 31st, 2022, and received MNP. Control participants were selected from a regional database among those who tested positive during the study period and did not receive antiviral treatment for SARS-CoV-2.  Results1382 patients were included (cases: 146, controls: 1236). Vaccinated patients showed lower risk of mortality and composite outcome (at least one among hospital admission, admission in ICU and all-cause death) compared to unvaccinated ones (0.6% vs 7.8%, p<0.001 and 2% vs 7.8%, p=0.001 respectively). After full-matching propensity score, MNP-treated subjects showed a lower incidence of composite outcome, while no effect was observed on the single outcomes. In the subgroup analysis according to the vaccination status, MNP proved effective in preventing all the outcomes among unvaccinated patients, while showed to reduce the risk of ICU admission both in vaccinated and unvaccinated patients.  ConclusionsTreatment with MNP proved effective in reducing the risk of composite outcome among outpatients with SARS-CoV-2 infection. The beneficial effect of MNP treatment in reducing progression is more pronounced in unvaccinated patients.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Antibiotic De-escalation Patterns and Outcomes in Critically Ill Patients with Suspected Pneumonia as Informed by Bronchoalveolar Lavage Results\nAbstract: BackgroundAntibiotic stewardship in critically ill pneumonia patients is crucial yet challenging, partly due to the limited diagnostic yield of noninvasive infectious tests. In this study, we report an antibiotic prescription pattern informed by bronchoalveolar lavage (BAL) results, where clinicians de-escalate antibiotics based on the combination of quantitative cultures and multiplex PCR rapid diagnostic tests.  MethodsWe analyzed data from SCRIPT, a single-center prospective cohort study of mechanically ventilated patients who underwent a BAL for suspected pneumonia. We used the novel Narrow Antibiotic Therapy (NAT) score to quantify day-by-day antibiotic prescription pattern for each suspected pneumonia episode etiology (bacterial, viral, mixed bacterial/viral, microbiology-negative, and non-pneumonia control). We also analyzed and compared clinical outcomes for each pneumonia etiology, including unfavorable outcomes (a composite of in-hospital mortality, discharge to hospice, or requiring lung transplantation during hospitalization), duration of ICU stay, and duration of intubation. Clinical outcomes were compared with the Mann-Whitney U test and Fishers exact test.  ResultsWe included 686 patients with 927 pneumonia episodes. NAT score analysis indicated that an antibiotic de-escalation pattern was evident in all pneumonia etiologies except resistant bacterial pneumonia. Microbiology-negative pneumonia was treated similarly to susceptible bacterial pneumonia in terms of antibiotic spectrum. Over a quarter of the time in viral pneumonia episodes, antibiotics were completely discontinued. Unfavorable outcomes were comparable across all pneumonia etiologies. Patients with viral and mixed bacterial/viral pneumonia had longer durations of ICU stay and intubation.  ConclusionsBAL quantitative cultures and multiplex PCR rapid diagnostic tests resulted in prompt antibiotic de-escalation in critically ill pneumonia patients. There was no evidence of increased incidence of unfavorable outcomes.  Key pointsWe found that bronchoalveolar lavage-based diagnostics is associated with antibiotic de-escalation, including to no antibiotics in more than a quarter of cases where only a virus is recovered.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dutch participatory surveillance framework for evaluating evolutionary changes on SARS-CoV-2 affecting Rapid Diagnostic Test sensitivity in 2022 - 2023.\nAbstract: BackgroundRapid Diagnostic Tests (RDTs) have been pivotal in the diagnostics for SARS-CoV-2 and policies surrounding self-isolation. When self-testing policies are in place a decreased sensitivity of the virus to RDTs can give benefits for viral spread. However, to monitor for reduced sensitivity of RDTs we rely on the collection of SARS-CoV-2 positive samples from RDT negative patients. Infectieradar, a national participatory surveillance that registers influenza-like symptoms is used as a framework to study false-negative RDT results due to emergence of new virus variants.  MethodsParticipants report weekly on RDT use and symptoms linked to Acute Respiratory Illness (ARI). Each week, all RDT positive and a sample of 200 among RDT negative but symptomatic participants were invited to send in nose throat swabs (NTS). SARS-CoV-2 Ct-values are determined using RT-PCR on NTS samples for RDT positive and RDT (false) negative participants and compared. Sequencing is performed on all eligible samples for phylogenetic analysis of the SARS-CoV-2 nucleocapsid protein and the whole genome sequence. NTS samples of participants with discordant RT-PCR and RDT results are also analyzed using RDTs by professionals in the laboratory.  ResultsBetween October 2022 and October 2023, our study had 16,893 participants and we collected 1,757 self-test-positive/NTS PCR positive samples and 359 self-test-negative/NTS PCR positive samples (RDT-/PCR+). These participants were asked to take a SARS-CoV-2 RDT upon symptoms. Within SARS-CoV-2 PCR positive participants, we did not find characteristics that differ in SARS-CoV-2 RDT negative versus positive participants. There were no associations with specific changes in the N protein nor did our phylogenetic analysis show clustering of RDT negative samples.  ConclusionEvaluating brand-specific RDT performance in Dutch population and false-negative RDT analyses, led to no evidence for SARS-CoV-2 evolution affecting RDT sensitivity. The participatory surveillance program Infectieradar is a powerful tool for our national surveillance on acute respiratory illnesses, as well as for research purposes. Since this framework offered both self-testing and the gold standard of PCR testing results.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Modelling the potential spread of Clade Ib MPXV in an Asia Pacific city\nAbstract: BackgroundThe ongoing 2024 mpox outbreak in several African countries, driven by the novel Clade 1b strain, has resulted in imported cases being reported in Sweden and Thailand. The Asia Pacific (APAC) region, with little exposure to previous mpox waves, is particularly vulnerable to local transmission triggered by importation. While this highlights the importance of early preparedness, current knowledge of the viruss transmission dynamics remains too limited to effectively inform policy-making and resource planning.  MethodsA compartmental model was constructed to characterise the potential mpox transmission triggered by importation in an APAC city. Outbreaks were simulated under diverse hypothetical scenarios considering transmission mechanisms, different affected subpopulations, levels of disease transmissibility, and importation frequencies. The impacts of various non-pharmaceutical interventions (NPIs) including isolation, and vaccination strategies were projected and compared.  FindingsUp to 30% of the population would be infected in the scenario of high sexual and moderate non-sexual transmissibility in the general community, with minimal impact from importation frequency on outbreak size and healthcare burden. The sequential introduction of mandatory home isolation for diagnosed cases, pre-departure screening of international arrivals, and contact tracing were projected to lower the peak outbreak size by 35%, 0.04%, and 1.1%, respectively, while the reduction would be 30% with proper vaccination by prioritising the sexually active group. These measures would significantly decrease disease morbidity and mortality rates, thereby alleviating the diseases pressure on healthcare systems.  InterpretationThe potential mpox outbreak in the APAC setting could be alleviated through strong surveillance and timely response from stakeholders. NPIs are recommended over vaccination for outbreak management due to their demonstrated effectiveness and practicability.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic accuracy and analytical sensitivity of the novel Xpert Mpox (Cepheid) and STANDARD M10 MPX/OPX (SD Biosensor) molecular point-of-care assays for the detection of Mpox virus in skin lesion swabs and upper-respiratory swab samples\nAbstract: ObjectivesEvaluation of diagnostic accuracy of two point-of-care (POC) molecular diagnostic tests for the detection of monkeypox virus (MPXV): Xpert(R) Mpox (Cepheid, Inc., USA) and STANDARD M10 MPX/OPX (SD Biosensor, Inc., Korea).  MethodsDiagnostic accuracy of both platforms was evaluated using 53 upper-respiratory swabs (URS) and 32 skin lesions swabs (SS) collected from mpox and COVID-19 patients in the UK against the Sansure (Sansure Biotech Inc.) and the CDC reference qPCR tests. The analytical sensitivity of both platforms was assessed using a viral isolate from the lineage II, B.1.  ResultsThe limit of detection was 1x101 pfu/ml for both tests. The overall sensitivity and specificity of the Xpert(R) Mpox was 97.67% [95% CI 87.71-99.94%] and 88.57% [95% CI 73.26-96.80%] and 97.44% [95% CI 86.52-99.94%] and 74.42% [95% CI 58.83-86.48%] comparing the Sansure and CDC qPCR, respectively and for the M10 MPX/OPX was 87.80% [95% CI 73.80-95.92%] and 76.60% [95% CI 61.97-87.70%] and 94.29% [95% CI 80.84-99.30%] and 86.67% [95% CI 73.21-94.95%] with the Sansure and CDC qPCR.  ConclusionThe Xpert(R) Mpox had good diagnostic accuracy for both sample types while the M10 MPX/OPX clinical accuracy was deficient with URS. Our data supports the use of URS during the first 3 days of symptoms onset for mpox diagnosis.  HighlightsO_LIThe Xpert(R) Mpox detected Monkeypox virus (MPXV) DNA in more samples than the M10 MPX/OPX, CDC qPCR and Sansure qPCR suggesting higher sensitivity at lower viral loads. C_LIO_LIXpert(R) Mpox fulfilled the performance requirements recommended in the World Health Organisation (WHO) target product profile (TPP) using upper-respiratory swabs (URS) and skin lesion swabs (SS) but M10 MPX/OPX performance was only met when using SS. C_LIO_LIMPXV DNA was reliably detectable in SS up to 5 days after onset of symptoms. with all PCR tests C_LIO_LIThe use of URS for mpox diagnosis is not recommended for use more than 3 days after onset of symptoms. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The causal role of thyroid hormones in bipolar disorders: a two-sample Mendelian Randomization study\nAbstract: IntroductionBipolar disorder is a complex psychiatric condition with distinctions between clinical subtypes including Type 1 and 2 disorders. Several studies have proposed thyroid hormones may be involved in the etiology of bipolar disorders.  MethodsThis study employed a two-sample Mendelian Randomization (MR) approach to investigate the causal relationships between six thyroid hormone metrics (TSH, FT4, FT3, TT3, FT3/FT4, and TT3/FT4) and bipolar disorder, and Type 1 and 2 disorders, separately. Genome-wide association (GWAS) data from the Thyroidomics Consortium (up to 271,040 individuals of European ancestry) were used for thyroid function metrics. Bipolar disorder GWAS data included 41,917 cases and 371,549 controls (25,060 Type 1 and 6,781 Type 2 cases). We applied inverse variance weighted (IVW) methods for primary MR analysis, with MR Egger, weighted median, and weighted mode for sensitivity. Additional tests assessed horizontal pleiotropy and heterogeneity.  ResultsHigher FT4 levels showed a protective causal effect against bipolar disorder (OR: 0.92, 95% CI: 0.86-0.97, p=4.58x10-3) and a suggestive effect on Type 1 disorders (OR: 0.92, 95% CI: 0.86-0.99, p=3.21x10-2). Elevated FT3 (OR: 1.18, 95% CI: 1.03-1.35, p=1.55x10-2) and FT3/FT4 ratio (OR: 1.97, 95% CI: 1.02-3.82, p=4.46x10-2) had suggestive harmful effects on Type 1 disorders. Sensitivity analyses showed consistent effects, with no significant horizontal pleiotropy or heterogeneity.  ConclusionsThese findings highlight the protective role of FT4 and the potentially harmful effect of elevated FT3 in Type 1 bipolar disorder, highlighting the need for further research on thyroid hormone levels as a potential treatment strategy for Type 1 bipolar disorder.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Obstructive sleep apnea mediates genetic risk of Diabetes Mellitus: The Hispanic Community Health Study/Study of Latinos\nAbstract: ObjectiveWe sought to evaluate whether obstructive sleep apnea (OSA), and other sleep disorders, increase genetic risk of developing diabetes mellitus (DM).  Research Design and MethodsUsing GWAS summary statistics from the DIAGRAM consortium and Million Veteran Program, we developed multi-ancestry Type 2 Diabetes (T2D) polygenic risk scores (T2D-PRSs) useful in admixed Hispanic/Latino individuals. We estimated the association of the T2D-PRS with cross-sectional and incident DM in the Hispanic Community Health Study/Study of Latinos (HCHS/SOL). We conducted a mediation analysis with T2D-PRSs as an exposure, incident DM as an outcome, and OSA as a mediator. Additionally, we performed Mendelian randomization (MR) analysis to assess the causal relationship between T2D and OSA.  ResultsOf 12,342 HCHS/SOL participants, at baseline, 48.4% were normoglycemic, 36.6% were hyperglycemic, and 15% had diabetes, and 50.9% identified as female. Mean age was 41.5, and mean BMI was 29.4. T2D-PRSs was strongly associated with baseline DM and with incident DM. At baseline, a 1 SD increase in the primary T2D-PRS had DM adjusted odds ratio (OR) = 2.67, 95% CI [2.40; 2.97] and a higher incident DM rate (incident rate ratio (IRR) = 2.02, 95% CI [1.75; 2.33]). In a stratified analysis based on OSA severity categories the associations were stronger in individuals with mild OSA compared to those with moderate to severe OSA. Mediation analysis suggested that OSA mediates the T2D-PRS association with DM. In two-sample MR analysis, T2D-PRS had a causal effect on OSA, OR = 1.03, 95% CI [1.01; 1.05], and OSA had a causal effect on T2D, with OR = 2.34, 95% CI [1.59; 3.44].  ConclusionsOSA likely mediates genetic effects on T2D.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Influenza A (H3) viral aerosol shedding in nasally inoculated and naturally infected cases\nAbstract: Nasally inoculated influenza cases reported milder symptoms and shed lower viral RNA load in exhaled breath aerosols (EBA) than people with classic influenza-like illness including fever, in a previous study. Whether nasally inoculated influenza is representative of mild natural influenza infection, the majority of natural infections, is unknown. Here, we extend our previous analyses to include a broader range of community-acquired influenza cases. Previously, we reported on two groups: (A) volunteers intranasally inoculated with a dose of 5.5 log10TCID50 of influenza A/Wisconsin/67/2005 (H3N2) and (B) cases with cough and sore throat plus fever or a positive rapid antigen test recruited on a college campus in the same year (2013). Here we added two additional groups from a later study: (C) cases from a 2017-2019 surveillance cohort of college dormitory residents and their contacts, and (D) cases recruited from a university health center in 2019. All cases had an influenza A(H3) infection. Using a Gesundheit-II sampler, we collected 30-minute EBA samples. Community-acquired cases from the surveillance cohort (C) shed more EBA viral RNA and were more symptomatic than the nasally inoculated cases (A) but shed less viral RNA than the natural cases that were selected for symptoms (B) in 2013, but not (D) recruited in 2019. Despite sharing a similar symptomatic profile with the 2013 selected natural cases (B), the 2019 community-acquired cases (D) recruited post-infection showed a lower fine aerosol viral RNA load. Nasal inoculation of influenza virus did not reproduce EBA viral RNA shedding or symptoms observed in mild natural infection. Circulating strains of influenza A(H3) may differ, year-to-year in the extent to which symptomatic cases shed virus into fine aerosols. New models, including possibly aerosol inoculation, are needed to study viral aerosol shedding from the human respiratory tract.  Author SummaryIn this study, we compared influenza A (H3) viral aerosol shedding in the exhaled breath of four different groups of influenza cases: (A) volunteers given the influenza virus intranasally, naturally infected (B) college community members with classic influenza-like illness including fever recruited in 2013, (C) dormitory residents undergoing active surveillance, and (D) patients from a university health center recruited in 2019. We found that mild symptomatic cases among healthy college students (C) released more viral RNA in their exhaled breath than those nasally inoculated with influenza virus (A). We also observed that more symptomatic and medically attended cases from different flu seasons (B and D), although reporting similar symptom severity, shed different levels of viral RNA in their exhaled breath. Our findings indicate that influenza viral aerosol shedding varies from season to season. Most volunteers nasally inoculated at a high virus dose did not shed detectable viral RNA in their exhaled breath or show symptoms, suggesting that nasal inoculation may not accurately mimic natural infection. Our results highlight the need for improved models to study the spread of influenza virus in aerosol forms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Influenza A (H3) viral aerosol shedding in nasally inoculated and naturally infected cases\nAbstract: Nasally inoculated influenza cases reported milder symptoms and shed lower viral RNA load in exhaled breath aerosols (EBA) than people with classic influenza-like illness including fever, in a previous study. Whether nasally inoculated influenza is representative of mild natural influenza infection, the majority of natural infections, is unknown. Here, we extend our previous analyses to include a broader range of community-acquired influenza cases. Previously, we reported on two groups: (A) volunteers intranasally inoculated with a dose of 5.5 log10TCID50 of influenza A/Wisconsin/67/2005 (H3N2) and (B) cases with cough and sore throat plus fever or a positive rapid antigen test recruited on a college campus in the same year (2013). Here we added two additional groups from a later study: (C) cases from a 2017-2019 surveillance cohort of college dormitory residents and their contacts, and (D) cases recruited from a university health center in 2019. All cases had an influenza A(H3) infection. Using a Gesundheit-II sampler, we collected 30-minute EBA samples. Community-acquired cases from the surveillance cohort (C) shed more EBA viral RNA and were more symptomatic than the nasally inoculated cases (A) but shed less viral RNA than the natural cases that were selected for symptoms (B) in 2013, but not (D) recruited in 2019. Despite sharing a similar symptomatic profile with the 2013 selected natural cases (B), the 2019 community-acquired cases (D) recruited post-infection showed a lower fine aerosol viral RNA load. Nasal inoculation of influenza virus did not reproduce EBA viral RNA shedding or symptoms observed in mild natural infection. Circulating strains of influenza A(H3) may differ, year-to-year in the extent to which symptomatic cases shed virus into fine aerosols. New models, including possibly aerosol inoculation, are needed to study viral aerosol shedding from the human respiratory tract.  Author SummaryIn this study, we compared influenza A (H3) viral aerosol shedding in the exhaled breath of four different groups of influenza cases: (A) volunteers given the influenza virus intranasally, naturally infected (B) college community members with classic influenza-like illness including fever recruited in 2013, (C) dormitory residents undergoing active surveillance, and (D) patients from a university health center recruited in 2019. We found that mild symptomatic cases among healthy college students (C) released more viral RNA in their exhaled breath than those nasally inoculated with influenza virus (A). We also observed that more symptomatic and medically attended cases from different flu seasons (B and D), although reporting similar symptom severity, shed different levels of viral RNA in their exhaled breath. Our findings indicate that influenza viral aerosol shedding varies from season to season. Most volunteers nasally inoculated at a high virus dose did not shed detectable viral RNA in their exhaled breath or show symptoms, suggesting that nasal inoculation may not accurately mimic natural infection. Our results highlight the need for improved models to study the spread of influenza virus in aerosol forms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations of Insomnia Symptoms and Trajectories with Incident Cardiovascular Disease: A Population-Based Cohort Study\nAbstract: BackgroundThere is limited understanding regarding associations between insomnia symptoms, particularly the trajectories of insomnia symptoms, and cardiovascular disease (CVD). We aimed to investigate the associations of insomnia symptoms and trajectories with the risk of incident CVD.  MethodsThis study used data from the Health and Retirement Study. Insomnia symptoms included non-restorative sleep, difficulty initiating sleep, early morning awakening, and difficulty maintaining sleep, classified on a scale ranging from 0 to 8. We also identified four distinct trajectories of insomnia symptoms: low, decreasing, increasing, and high insomnia symptoms. Examined outcomes included incident heart disease, stroke, and the combination of the two referred as CVD in the present study. Cox proportional hazard models were used to calculate the hazard ratio (HR) and 95% confidence interval (95% CI) after adjusting for potential confounders.  ResultsA total of 12 102 participants aged 50 years or over without CVD at baseline were included. During a median follow-up of 10.2 years, 3 962 first CVD events occurred (3 372 heart disease and 1 200 stroke). Participants experiencing one (HR, 1.16 [95% CI, 1.05-1.27]), two (HR, 1.16 [ 95% CI, 1.05-1.28]), or three to four (HR, 1.26 [95% CI, 1.15-1.38]) insomnia symptoms had a higher risk of incident CVD compared to those not experiencing any insomnia symptoms. After a median follow-up of 8.4 years after the visit 2, 2 375 first CVD events occurred (1 981 heart disease and 705 stroke). Using the trajectory with low insomnia symptoms as the reference, increasing insomnia symptoms (HR, 1.28 [95% CI, 1.10-1.50]) and high insomnia symptoms (HR, 1.32 [95% CI, 1.15-1.50]) were associated with an increased risk of incident CVD.  ConclusionsHigher insomnia symptoms and increasing insomnia symptoms over time are associated with a higher risk of CVD in the community. Public health awareness and screening for insomnia symptoms in the middle-aged and elderly population should be encouraged to reduce CVD.  Clinical PerspectiveO_ST_ABSWhat Is NewC_ST_ABSO_LIParticipants experiencing one, two, or three to four insomnia symptoms had a higher risk of incident CVD compared to those not experiencing any insomnia symptoms. C_LIO_LIHigher insomnia symptoms and increasing insomnia symptoms over time are associated with a higher risk of CVD in the community. C_LI  What Are the Clinical ImplicationsO_LIEarly prevention and mitigation of insomnia symptoms could be beneficial in reducing the population burden of CVD. C_LIO_LIClinicians can provide specific recommendations to improve sleep hygiene as part of a comprehensive approach to reducing the risk of incident CVD. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Collaborative forecasting of influenza-like illness in Italy: the Influcast experience\nAbstract: Collaborative hubs that integrate multiple teams to generate ensemble projections and forecasts for shared targets are now regarded as state-of-the-art in epidemic predictive modeling. In this paper, we introduce Influcast, Italys first epidemic forecasting hub for influenza-like illness. During the 2023/2024 winter season, Influcast provided 20 rounds of forecasts, involving five teams and eight models to predict influenza-like illness incidence up to four weeks in advance at the national and regional administrative level. The individual forecasts were synthesized into an ensemble and bench-marked against a baseline model. The ensemble forecasts consistently outperformed both individual models and baseline forecasts, demonstrating superior accuracy at national and sub-national levels across various metrics. Despite a decline in absolute performance over longer horizons, the ensemble model outperformed the baseline in all considered time frames. These findings underscore the importance of multimodel forecasting hubs in producing consistent short-term influenza-like illnesses forecasts that can inform public health preparedness and mitigation strategies.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-infection dynamics of SARS-CoV-2 and respiratory viruses in the 2022/2023 respiratory season in the Netherlands\nAbstract: ObjectivesEvaluation of the presence and effect of SARS-CoV-2 co-infections on disease severity.  MethodsWe collected both symptom data and nose- and throat samples from symptomatic people during the 2022/2023 respiratory season in a large participatory surveillance study in the Netherlands, and tested these for 18 respiratory viruses including SARS-CoV-2. We compared reported health status, symptoms and odds of having a mono respiratory viral infection or co-infection with SARS-CoV-2 and another respiratory virus.  ResultsIn total 4,655 samples were included with 22% (n=1,017) testing SARS-CoV-2 positive. Of these 11% (n=116) also tested positive for a second respiratory virus. The most frequently occurring co-infections in SARS-CoV-2 positive participants were with rhinovirus (59%; n=69), seasonal coronaviruses (15%; n=17) and adenovirus (7%; n=8). Participants with a co-infection with one of these three viruses did not report more severe disease compared to those with a SARS-CoV-2 mono-infection. The odds of experiencing SARS-CoV-2 co-infection with seasonal coronavirus or rhinovirus were lower compared to the odds of the respective non-SARS-CoV-2 mono-infection (OR: 0.16, CI 95%: 0.10 - 0.24; OR: 0.21 CI 95%: 0.17 - 0.26; respectively).  ConclusionsSARS-CoV-2 co-infections with rhinovirus, seasonal coronavirus and adenovirus are frequently observed in the general population, but are not associated with more severe disease compared to SARS-CoV-2 mono-infections. Furthermore, we found indications for inter-virus interaction with rhinovirus and seasonal coronavirus, possibly decreasing risk of co-infection.  HighlightsOur study showed viral co-infections in 11% of the SARS-CoV-2 positive participants  SARS-CoV-2 mono-infections led to more severe symptoms than the common cold mono-infections with seasonal coronavirus or rhinovirus  SARS-CoV-2 co-infections with common cold viruses did not lead to worse health status compared to SARS-CoV-2 mono-infections  Odds for mono-infection with common cold virus were higher than for co-infection with SARS-CoV-2 and the respective common cold virus\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Border control strategies for reducing importation risk of Clade Ib Mpox\nAbstract: BackgroundThe Clade Ib monkeypox virus (MPXV), newly identified in the ongoing 2024 mpox outbreak, can be more transmissible through non-sexual routes compared to the previous Clade IIb strain. With imported cases sporadically reported globally, concerns have emerged about the potential of widespread transmission in the general community after importation events. Border control measures, such as screening and quarantining of arriving travellers, may help mitigate this risk and prevent localized outbreaks in the event of global spread.  MethodsWe proposed nine border control strategies and evaluated their effectiveness in reducing importation risk using 10,000 microsimulations of individual infection profiles and PCR testing results under scenarios with varying disease prevalence levels (0.01%, 0.05%, and 0.1%) in the country of origin.  ResultsThe proposed border-control measures would reduce missed cases by 40.1% (39.1%-41.0%), 49.8% (48.8%-50.8%), and 58.1% (57.1%-59.0%) for predeparture, on-arrival, and both tests, respectively. Replacing the on-arrival test with a seven-day quarantine and post-quarantine testing would lower the count to 21.8% (20.9%-22.6%). Quarantine-only strategies showed a linear increase in effectiveness against duration, reaching a 90.4% (89.8%-91.0%) reduction with a 28-day quarantine. Disparities in distributions of missed case counts across strategies would become more pronounced at higher prevalence levels, with stringent approaches like quarantining followed by post-quarantine screening and 28-day quarantine keeping counts below two per 10,000 travellers, even at 0.1% prevalence.  ConclusionsWhen disease prevalence in the country of origin is low (0.01%), less restrictive approaches such as single on-arrival testing or a 14-day quarantine can maintain very low imported case counts of one or below. At higher prevalences, seven-day quarantining followed by post-quarantine testing, or 28-day quarantining is required to maintain similar effects. Decision makers will face balancing importation risk management and the negative impacts of such interventions to maintain safe international travel.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reconciling heterogeneous dengue virus infection risk estimates from different study designs\nAbstract: Uncovering rates at which susceptible individuals become infected with a pathogen, i.e. the force of infection (FOI), is essential for assessing transmission risk and reconstructing distribution of immunity in a population. For dengue, reconstructing exposure and susceptibility statuses from the measured FOI is of particular significance as prior exposure is a strong risk factor for severe disease. FOI can be measured via many study designs. Longitudinal serology are considered gold standard measurements, as they directly track the transition of seronegative individuals to seropositive due to incident infections (seroincidence). Cross-sectional serology can provide estimates of FOI by contrasting seroprevalence across ages. Age of reported cases can also be used to infer FOI. Agreement of these measurements, however, have not been assessed. Using 26 years of data from cohort studies and hospital-attended cases from Kamphaeng Phet province, Thailand, we found FOI estimates from the three sources to be highly inconsistent. Annual FOI estimates from seroincidence was 2.46 to 4.33-times higher than case-derived FOI. Correlation between seroprevalence-derived and case-derived FOI was moderate (correlation coefficient=0.46) and no systematic bias. Through extensive simulations and theoretical analysis, we show that incongruences between methods can result from failing to account for dengue antibody kinetics, assay noise, and heterogeneity in FOI across ages. Extending standard inference models to include these processes reconciled the FOI and susceptibility estimates. Our results highlight the importance of comparing inferences across multiple data types to uncover additional insights not attainable through a single data type/analysis.  Significance statementDengue virus infections are surging globally. Knowing who, where, and how many people are at risk of infection is crucial in determining means to protect them. Here, we compare three current approaches in measuring risk (two involving blood samples and one involving case counts) to estimate the risk of infection. Estimates derived from each method differed greatly. By accounting for rise and falls of antibodies following infections, noise in the antibody titer measurements, and heterogeneity in infection risk across ages, we reconciled the measurements. As measurements from blood samples and case counts are pillars in uncovering risk of most infectious diseases, our results signifies integrating these processes into risk measurements of pathogens beyond dengue virus.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mpox vaccination uptake in a UK community sample of gay, bisexual, and other men who have sex with men (GBMSM) the year following the 2022 Clade IIb mpox outbreak\nAbstract: Mpox is an infectious disease transmitted through close contact. It is caused by the monkeypox virus, which is endemic to some countries of West and Central Africa. A multi-country outbreak of mpox occurred in 2022, and the UK experienced rapid community transmission associated with sexual contact, mainly, but not exclusively among networks of gay, bisexual, and other men who have sex with men (GBMSM). In response to the outbreak in the UK, a reactive mpox vaccination programme was targeted to those most at risk. We explore the uptake and course completion of mpox vaccination in GBMSM taking part in an online survey in 2023. Findings from this community sample indicate vaccination uptake in around two-thirds of participants meeting mpox proxy eligibility criteria with high levels of course completion among all and eligible participants that were ever vaccinated. Vaccine non-offer was a barrier to uptake, as nearly a third of those eligible but unvaccinated reported never having received an mpox vaccine offer. Continued targeting of vaccination to GBMSM at highest risk of mpox at SHS, with community-support, will help facilitate equitable uptake of vaccination.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Decoding the Deadly Dance: NETosis Genes Predict Neonatal Sepsis Fate\nAbstract: BackgroundNeonatal sepsis, a systemic inflammatory response to infection, is a major cause of morbidity and mortality in newborns. Neutrophil extracellular trap formation (NETosis), while crucial for pathogen clearance, can contribute to organ dysfunction in sepsis. This study aimed to identify key NETosis-related genes for prognostication in neonatal sepsis.  MethodsWe analysed whole blood transcriptome datasets (GSE26440, GSE26378, GSE25504) from neonates with sepsis and controls. Differentially expressed NETosis genes (DE-NET genes) were identified, and a machine learning approach was used to select the most influential genes. A NET score model was constructed and validated using single-sample gene set enrichment analysis (ssGSEA). The models performance was evaluated using ROC analysis. The interplay between key-NET genes and the complement-coagulation (CC) system was investigated. Clinical samples were also collected for validation.  ResultsSixteen DE-NET genes were identified, and LASSO further refined these to 8 key-NET genes. The key-NET gene signature and NET score model showed excellent predictive performance (AUCs > 89%) in distinguishing survivors from non-survivors. Mediation analysis revealed that key-NET gene expression precedes and potentially drives complement-coagulation activation.  ConclusionsWe present an 8-gene prognostic model for risk stratification in neonatal sepsis, based on early blood transcript signatures in neonates. Our findings underscore the central role of NETosis in sepsis- induced coagulopathy, revealing potential therapeutic targets for intervention.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=135 SRC=\"FIGDIR/small/24313397v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (29K): org.highwire.dtl.DTLVardef@141c8ddorg.highwire.dtl.DTLVardef@1ea52f2org.highwire.dtl.DTLVardef@ebc63eorg.highwire.dtl.DTLVardef@1242a90_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rapid Decline of Mpox Antibody Responses Following MVA-BN Vaccination\nAbstract: The replication-incompetent modified vaccinia Ankara-Bavarian Nordic vaccine (MVA-BN; Jynneos) was deployed during the 2022 clade IIb mpox outbreak. On August 14, 2024, the World Health Organization declared the mpox clade Ib outbreak in the Democratic Republic of the Congo a public health emergency of international concern, which has raised the question about the durability of vaccine immunity after MVA-BN vaccination. In this study, we show that the MVA-BN vaccine generated mpox serum antibody responses that largely waned after 6-12 months.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Inhibition of HIF-2\u03b1 Pathway as a Potential Therapeutic Strategy for Endothelial Dysfunction in Post-COVID Syndrome\nAbstract: BackgroundSARS-CoV-2 infection may lead to Post-COVID Syndrome (PCS), characterized by debilitating symptoms like persistent fatigue, cardiovascular symptoms, and cognitive dysfunction. Persistent endothelial dysfunction (ED) is a potential driver of ongoing symptoms. Yet, the underlying biological mechanisms remain unclear.  MethodsIn this prospective observational study, we characterized 41 PCS patients and 24 healthy controls (HC, matched out of n = 204, recruited before the pandemic) and investigated the effect of SARS-CoV-2 Spike protein 1 (S1) and plasma from PCS patients on human retinal endothelial cells (HREC).  ResultsPlasma samples from PCS patients exhibited significantly elevated erythropoietin, VEGF and MCP-1 alongside decreased IL-6 levels compared to HC. Low Haemoglobin and Haematocrit were negatively associated with PCS severity. VEGF levels were positively correlated with Anti-S1 IgG levels in patients and upregulated on mRNA level in HREC exposed to S1. Additionally, S1 exposure promoted ROS production and transiently activated HIF-1 in HREC. Persistent activation of HIF-2 by S1 led to disrupted endothelial integrity. HREC exposed to plasma from severely affected PCS patients showed increased ROS and compromised barrier function. Treatment with Belzutifan, a HIF-2 inhibitor, restored barrier integrity in HREC exposed to S1 or PCS-plasma.  ConclusionThese findings suggest that HIF-2-mediated ED in PCS might be a potential therapeutical target for Belzutifan.  Trial registrationURL: https://www.clinicaltrials.gov; Unique identifier: NCT05635552  Novelty and significanceO_ST_ABSWhat Is Known?C_ST_ABSO_LIEndothelial dysfunction (ED) is a consequence of acute SARS-CoV-2 infection and may lead to Post-COVID syndrome (PCS) symptoms. C_LIO_LIPatients with PCS show elevated inflammation and endothelial dysfunction markers. C_LIO_LISpike proteins can persist for up to 12 months post-infection, driving ongoing inflammation and immune activation. C_LI  What New Information Does This Article Contribute?O_LILow haemoglobin (Hb) and high VEGF correlate with higher Anti-S1 IgG and low Hb is associated with higher C19-YRS severity score. C_LIO_LIPCS patients exhibit higher Erythropoietin (EPO) levels when compared to HC. C_LIO_LISpike protein 1 (S1) alone and PCS patients plasma induce endothelial dysfunction primarily through HIF-2 activation. C_LIO_LIBoth S1 and PCS plasma cause oxidative stress and disrupting endothelial integrity. C_LIO_LIInhibition of HIF-2 effectively restores endothelial barrier integrity disrupted by S1 and PCS plasma. C_LI  Persistent circulation of spike proteins can sustain chronic inflammation and immune activation in patients with PCS. Here we show that plasma from PCS patients exhibits significantly elevated levels of VEGF which positively correlates with Anti-S1 IgG. Low haemoglobin was associated with higher Anti-S1 IgG titres and correlated with a higher C19-YRS severity score. Levels of EPO were higher in PCS patients, with a more pronounced effect observed in patients with cardiovascular symptoms. In human retinal endothelial cells, both S1 and plasma from PCS patients primarily induce ED through HIF-2 activation, rather than NF-{kappa}B. Both factors lead to significant oxidative stress, evidenced by increased ROS production which in turn disrupts endothelial barrier integrity and function. Notably, Belzutifan, a HIF-2 inhibitor, can restore this compromised endothelial function, offering a potential therapeutic target for PCS.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=143 SRC=\"FIGDIR/small/24313403v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (35K): org.highwire.dtl.DTLVardef@19df9e4org.highwire.dtl.DTLVardef@80eba4org.highwire.dtl.DTLVardef@1ee6680org.highwire.dtl.DTLVardef@8b6bd3_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dissection of the 'Virgin-soil' epizootic of African swine fever in Mizoram, a Northeast state of India\nAbstract: This article aims to analyse the first-time emergence of African swine fever (ASF) in Mizoram. We collated the outbreak data and identified the time and locations of ASF emergence. To understand the impact of the outbreak, we have calculated the morbidity rate, mortality rate, case fatality rate (CFR) and overall pig depopulation rate. We identified that ASF emerged in total 178 locations in all 11 districts of Mizoram between March-July 2021, after a peak in June, and the disease continued to spread till the end of 2021 before re-emergence in March 2022. The overall morbidity rate and mortality rate of ASF between March-July 2021 in Mizoram were estimated to be 33.8% and 31.1%, while the average morbidity rate and the mortality rate of 10 districts were found to be 29.5% and 27.6% respectively. Overall CFR of ASF between March-July 2021 was estimated to be 92.1% and the average of all 11 districts was found to be 96.1%. Toward the end of 2021, the mortality rate increased by a total of 42.7% change and an average of 25.3% change. We estimated an overall 70% depopulation of susceptible pigs by disease and culling by end of 2021. This report is evidence that ASF has remained catastrophic and, keeping in view the complex nature and history of the virus on genotype adaptability associated with a high propensity for transboundary expansion, the virus continues to be a threat.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk factors for typhoid fever: A desk review\nAbstract: Background and AimTyphoid fever, a significant global health problem, demonstrates a multifaceted transmission pattern. Knowledge of the factors driving the transmission of infection is critical for developing effective control strategies and resource allocation. This comprehensive desk review aimed at synthesizing evidence from 1928 to 2023 on risk factors associated with typhoid fever transmission.  MethodWe conducted article searches in PubMed, Scopus, Google Scholar, and Semantic Scholar, using keywords related to risk, contributors, determinants, causes etc. associated with typhoid fever. We followed a registered protocol to support our search and triangulated the results.  ResultsIn all, we retrieved 1614 articles, of which 216 were reviewed. Of these articles reviewed, 106 provided data on typhoid fever risk factors. Unsurprisingly, of the total articles reviewed on risk factors, about 72% (76/106) originated from the Asian (48.1%, 51/106) and African (23.6%, 25/106) continents. A higher proportion, 47.2% (50/106) of the articles indicated risk factors related to socio-economic and housing transmission. Additional risk factors included foodborne transmissions (45.3%, 48/106), WASH: Waterborne transmissions (42.5%, 45/106), Sanitation and Hygiene practices (32.1%, 34/106), travel-related risk (16.0%, 17/106), antimicrobial agents (13.2%, 14/106), climate (13.2%, 14/106), environmental (8.5%, 9/106), typhoid carriers (10.4%, 11/106), and host risk (5.7%, 6/106) factors to disease transmission.  ConclusionThese findings highlight the necessity for targeted and combined interventions including improved sanitation infrastructure, enhanced WASH practices and the use of vaccines in endemic areas. Implementing effective strategies informed by this review can aid clinicians, public health experts, and policymakers in efficiently mitigating the burden of typhoid fever.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk factors for typhoid fever: A desk review\nAbstract: Background and AimTyphoid fever, a significant global health problem, demonstrates a multifaceted transmission pattern. Knowledge of the factors driving the transmission of infection is critical for developing effective control strategies and resource allocation. This comprehensive desk review aimed at synthesizing evidence from 1928 to 2023 on risk factors associated with typhoid fever transmission.  MethodWe conducted article searches in PubMed, Scopus, Google Scholar, and Semantic Scholar, using keywords related to risk, contributors, determinants, causes etc. associated with typhoid fever. We followed a registered protocol to support our search and triangulated the results.  ResultsIn all, we retrieved 1614 articles, of which 216 were reviewed. Of these articles reviewed, 106 provided data on typhoid fever risk factors. Unsurprisingly, of the total articles reviewed on risk factors, about 72% (76/106) originated from the Asian (48.1%, 51/106) and African (23.6%, 25/106) continents. A higher proportion, 47.2% (50/106) of the articles indicated risk factors related to socio-economic and housing transmission. Additional risk factors included foodborne transmissions (45.3%, 48/106), WASH: Waterborne transmissions (42.5%, 45/106), Sanitation and Hygiene practices (32.1%, 34/106), travel-related risk (16.0%, 17/106), antimicrobial agents (13.2%, 14/106), climate (13.2%, 14/106), environmental (8.5%, 9/106), typhoid carriers (10.4%, 11/106), and host risk (5.7%, 6/106) factors to disease transmission.  ConclusionThese findings highlight the necessity for targeted and combined interventions including improved sanitation infrastructure, enhanced WASH practices and the use of vaccines in endemic areas. Implementing effective strategies informed by this review can aid clinicians, public health experts, and policymakers in efficiently mitigating the burden of typhoid fever.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterising global risk profiles of Mpox clade Ib importation\nAbstract: The novel mpox clade Ib initially identified in the Domestic Republic of Congo has spread to its multiple neighbouring countries as well as countries beyond the African continent. We characterised the global risk of importation of mpox clade Ib, highlighting the need to ramp up surveillance capacity for early detection.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Does the choice of stepping intensity metric influence dose-response associations with mortality? A UK population cohort study of 70,174 adults\nAbstract: BackgroundResearch on the health effects of stepping intensity in free-living environments is limited and inconclusive. Inconsistent use of stepping intensity estimation metrics could explain current equivocal results. We aimed to examine and compare a range of different cadence-based metrics in terms of their multivariable-adjusted associations with all-cause (ACM) cardiovascular disease (CVD), cancer and physical-activity (PA)-related cancer mortality.  MethodsThis prospective cohort study included participants with valid wrist-worn accelerometer data from the UK Biobank. We estimated stepping intensity using ten different cadence-based metrics, including eight peak-cadence metrics (defined as averaged steps / min of the highest but not necessarily consecutive minutes) that most of whom have appeared in prior literature, plus two non-peak-cadence metrics: 1) average daily cadence, defined as steps/accelerometer wearing mins, and 2) average cadence of purposeful steps, defined as averaged steps / min of minutes with [&ge;]40 steps. We rescaled each metric into a standardised cadence scale with mean of 0 and standard deviation (SD) of 1, using (absolute-mean)/SD. We compared the dose-response associations of each stepping intensity estimation metrics with mortality outcomes using previously published modelling involving Cox-restricted-cubic-spline model, presented as overlay plots on standardised and absolute cadence scales.  ResultsAmong 70,336 participants (age [SD], 61.6 [7.8] years; female, 40,933 [58%]) followed up for a median of 8.0 years, all cadence-based metrics, besides the average cadence of purposeful steps, exhibited a comparable beneficial dose-response association with ACM/CVD/cancer mortality, with 95% CI largely overlapped (e.g., at -0.2 standardised steps/min, the hazard ratio (HR) of ACM for peak 1- and peak 30-min cadence were: 0.72, 95%CI [0.65, 0.82] and 0.66 [0.60, 0.73], respectively). The average cadence of purposeful steps only did not show dose-response associations with mortality outcomes (e.g., the HR that corresponds to the standardised median for the average cadence of purposeful steps in ACM was 0.98 [95% CI: 0.86, 1.12].  ConclusionBesides the average cadence of purposeful steps, all stepping intensity estimation metrics demonstrated comparable beneficial dose-response associations with mortality of all-cause, CVD and cancer, suggesting these cadence-based metrics may be used interchangeably for estimating associations of free-living stepping intensity with health outcomes and applied in different research scenarios accordingly.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Real-World Effectiveness of Nirsevimab Against Respiratory Syncytial Virus: A Test-Negative Case-Control Study\nAbstract: IMPORTANCENirsevimab, a long-acting monoclonal antibody, has demonstrated efficacy against RSV-related lower respiratory tract infections (LRTIs) in clinical trials. Post-licensure monitoring is essential to confirm these benefits in real-world settings.  OBJECTIVETo evaluate the real-world effectiveness of nirsevimab against medically attended RSV infections in infants and to assess how effectiveness varies by disease severity, dosage, and time since immunization.  DESIGN, SETTING, AND PARTICIPANTSThis test-negative case-control study used inpatient, outpatient, and emergency room data from the Yale New Haven Health System. Nirsevimab-eligible infants who were tested for RSV using polymerase chain reaction between October 1, 2023 and May 9, 2024 were included. Cases were infants with confirmed RSV infections; controls were those who tested negative.  EXPOSURENirsevimab immunization, verified through state immunization registries.  MAIN OUTCOMES AND MEASURESEffectiveness was estimated using multivariable logistic regression, adjusting for age, calendar month, and individual risk factors. Separate models examined effectiveness by clinical setting, disease severity, dose, and time since immunization. Broader outcomes, including all-cause LRTI and LRTI-related hospitalization, were also analyzed, with stratification by early and late respiratory seasons.  RESULTSThe analytic sample included 3,090 infants (median age 6.7 months, IQR 3.6-9.7), with 680 (22.0%) RSV-positive and 2,410 (78.0%) RSV-negative. 21 (3.1%) RSV-positive and 309 (12.8%) RSV-negative infants received nirsevimab. Effectiveness against RSV infection was 68.4% (95% CI, 50.3%-80.8%). Effectiveness was 61.6% (95% CI, 35.6%-78.6%) for outpatient visits and 80.5% (95% CI, 52.0%-93.5%) for hospitalizations. The highest effectiveness, 84.6% (95% CI, 58.7%-95.6%), was observed against severe RSV outcomes requiring ICU admission or high-flow oxygen. Although effectiveness against RSV infections declined over time, it remained significant at 55% (95% credible interval, 16%-75%) at 14 weeks post-immunization. Protective effectiveness was also observed against all-cause LRTI and LRTI-related hospitalizations during peak RSV season (49.4% [95% CI, 10.7%-72.9%] and 79.1% [95% CI, 27.6%-94.9%], respectively). However, from February to May, when RSV positivity was low, effectiveness against these broader outcomes was negligible.  CONCLUSIONS AND RELEVANCENirsevimab provided substantial protection against RSV-related outcomes for at least three months. These findings support the continued use of nirsevimab and provide evidence that may help build public confidence in the immunization program.  Key PointsO_ST_ABSQuestionC_ST_ABSWhat is the effectiveness of nirsevimab against medically attended respiratory syncytial virus (RSV) infections in infants?  Findings680 RSV test-positive cases and 2,410 RSV test-negative controls were included in this test-negative case-control study. Nirsevimabs effectiveness was 69% against RSV infections, 81% against RSV-associated hospitalization, and 85% against severe RSV disease. Effectiveness against RSV infection declined from 79% at 2 weeks post-immunization to 55% at 14 weeks post-immunization.  MeaningNirsevimab provides strong protection against a wide range of RSV outcomes, but its effectiveness diminishes over time. These data can be utilized to optimize nirsevimabs implementation and sustain its uptake.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Shortened SARS-CoV-2 shedding in saliva during early Omicron compared to wild-type pandemic phase\nAbstract: This study compared the dynamics of SARS-CoV-2 viral shedding in saliva between wild-type virus-infected and Omicron-infected household cohorts. Pre-existing immunity in participants likely shortens duration of viral shedding and lowers viral load peaks. Dense saliva sampling can be a convenient tool to study viral load dynamics.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Network biology and bioinformatics-based framework to identify the impacts of SARS-CoV-2 infections on lung cancer and tuberculosis\nAbstract: The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a coronavirus variation responsible for COVID-19, the respiratory disease that triggered the COVID-19 pandemic. The primary aim of our study is to elucidate the complex network of interactions between SARS-CoV-2, tuberculosis, and lung cancer employing a bioinformatics and network biology approach. Lung cancer is the leading cause of significant illness and death connected to cancer worldwide. Tuberculosis (TB) is a prevalent medical condition induced by the Mycobacterium bacteria. It mostly affects the lungs but may also have an influence on other areas of the body. Coronavirus disease (COVID-19) causes a risk of respiratory complications between lung cancer and tuberculosis. SARS-CoV-2 impacts the lower respiratory system and causes severe pneumonia, which can significantly increase the mortality risk in individuals with lung cancer. We conducted transcriptome analysis to determine molecular biomarkers and common pathways in lung cancer, TB, and COVID-19, which provide understanding into the association of SARS-CoV-2 to lung cancer and tuberculosis. Based on the compatible RNA-seq data, our research employed GREIN and NCBIs Gene Expression Omnibus (GEO) to perform differential gene expression analysis. Our study exploited three RNA-seq datasets from the Gene Expression Omnibus (GEO)--GSE171110, GSE89403, and GSE81089--to identify distinct relationships between differentially expressed genes (DEGs) in SARS-CoV-2, tuberculosis, and lung cancer. We identified 30 common genes among SARS-CoV-2, tuberculosis, and lung cancer (25 upregulated genes and 5 downregulated genes). We analyzed the following five databases: WikiPathway, KEGG, Bio Carta, Elsevier Pathway and Reactome. Using Cytohubbas MCC and Degree methods, We determined the top 15 hub genes resulting from the PPI interaction. These hub genes can serve as potential biomarkers, leading to novel treatment strategies for disorders under investigation. Transcription factors (TFs) and microRNAs (miRNAs) were identified as the molecules that control the differentially expressed genes (DEGs) of interest, either during transcription or after transcription. We identified 35 prospective therapeutic compounds that form significant differentially expressed genes (DEGs) in SARS-CoV-2, lung cancer, and tuberculosis, which could potentially serve as medications. We hypothesized that the potential medications that emerged from this investigation may have therapeutic benefits.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dynamic HIV risk differentiation among youth: Validation of a tool for prioritization of prevention in East Zimbabwe\nAbstract: BackgroundDifferentiating risk for HIV infection is important for providing focussed prevention options to individuals. We conducted a longitudinal study to validate a risk-differentiation tool for predicting HIV or HSV-2 acquisition among HIV-negative youth.  SettingPopulation-based household survey in east Zimbabwe.  MethodsHIV and HSV-2 status and HIV behavioural risk factors were assessed in two surveys conducted 12 months apart among young people. Associations between risk-behaviours and combined HIV/HSV-2 incident infection were estimated using proportional hazards models. We calculated the sensitivity and specificity of risk-differentiation questions in predicting HIV/HSV-2 acquisition and quantified changes between surveys among low, medium, and high-risk categories.  ResultsIn total, 44 HIV/HSV-2 seroconversions were observed in 1812 person-years of follow up (2.43/100PY, 95%CI: 1.71-3.15); 50% of incident cases reported never having had sex at baseline. Risk of HIV/HSV-2 acquisition was higher for those reporting non-regular partners (women: HR=2.71, 95% CI:1.12-6.54, men: HR=1.37, 95%CI: 0.29-6.38) and those reporting having a partner with a sexually transmitted infection (STI) (HR=7.62 (1.22-47.51). Adding a question on non-regular partnerships increased tool sensitivity from 18.2% to 38.6%, and further to 77.3% when restricted to those who had ever had sex. Individual risk category increased for 28% of men and 17% of women over 12-months.  ConclusionThe refined risk differentiation tool identified a high proportion of youth at risk of HIV acquisition. Despite this, half of incident infections were among individuals who reported no prior sexual activity. The shifting patterns of risk behaviours underscore the need for dynamic prevention engagement strategies in high HIV prevalence or incidence settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adjusting for specificity of symptoms reveals higher prevalence of asymptomatic SARS-CoV-2 infections than previously estimated\nAbstract: Accurate estimates of the prevalence of asymptomatic SARS-CoV-2 infections,{psi} , have been important for understanding and forecasting the trajectory of the COVID-19 pandemic. Two-part population-based surveys, which test the infection status and also assess symptoms, have been used to estimate{psi} . Here, we identified a widely prevalent confounding effect that compromises these estimates and devised a formalism to adjust for it. The symptoms associated with SARS-CoV-2 infection are not all specific to SARS-CoV-2. They can be triggered by a host of other conditions, such as influenza virus infection. By not accounting for the source of the symptoms, the surveys may misclassify individuals experiencing symptoms from other conditions as symptomatic for SARS-CoV-2, thus underestimating{psi} . We developed a rigorous formalism to adjust for this confounding effect and derived a facile formula for the adjusted prevalence,{psi} adj. We applied it to data from 50 published serosurveys, conducted on the general populations from 28 nations. We found that{psi} adj was significantly higher than the reported prevalence,{psi} c (P=3x10-8). The median{psi} adj was [~]60%, whereas the median{psi} c was [~]40%. In several instances,{psi} adj exceeded{psi} c by >100%. These findings suggest that asymptomatic infections have been far more prevalent than previously estimated. Our formalism can be readily deployed to obtain more accurate estimates of{psi} from standard population-based surveys, without additional data collection. The findings have implications for understanding COVID-19 epidemiology and devising more effective interventions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of Respiratory Syncytial Virus (RSV) in adults 60 years and older in Spain.\nAbstract: Respiratory illnesses frequently lead to hospitalisation in adults aged 60 and older, especially due to respiratory virus infectious (RVIs). This study investigates hospitalisation patterns and characteristics of RVIs at HM Hospitals from October 2023 to March 2024.  We retrospectively explored hospitalisations of patients aged 60 years and older with RVIs, gathering data on demographics, clinical profiles, comorbidities, and treatments. Outcomes included hospitalisation, ICU admissions, and mortality, independent factors associated with outcomes were identified using a multi-state model.  From October 2023 to March 2024, from a total of 3,258 hospitalisation, 1,933 (59.3%) were identified as positive for RVIs. Overall, SARS-CoV-2 was the most prevalent (52.6%), followed by influenza (32.7%) and RSV (11.8%). Most RVIs involved single infections (88.2%). Hospitalisation rates increased with age for SARS-CoV-2, influenza, and RSV, with SARS-CoV-2 showing the highest rate, followed by influenza and RSV.  In the multi-state model, RSV infection significantly increased ICU admission risk (HR: 2.1, 95%, p = 0.037). Age on admission (HR: 1.1, 95%, p < 0.001) and Charlson score (HR: 1.4, 95%, p = 0.001) were associated with transitioning from admission to death. ICU to death risks included age at admission (HR: 1.7, 95%, p < 0.001).  RVIs in adults 60 years and older are associated with high hospitalisation and mortality rates, primarily driven by influenza and SARS-CoV-2, followed by RSV. Age and comorbidities significantly impact disease severity, emphasising the need for targeted prevention and management strategies for RSV in this vulnerable population.  FundingThis studio received no funding.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Malaria prevalence and its associated factors amongst rural adults: Cross-sectional study in East Nusa Tenggara Province Indonesia\nAbstract: IntroductionMalaria is a global health issue including in Indonesia. Currently, most of the cases was in the rural of eastern part of the country. However, malaria risk factors amongst rural adult were less documented. This study investigated malaria risk factors amongst rural adults in East Nusa Tenggara Province (ENTP).  MethodsA community based cross-sectional study was conducted to interview 1495 rural adults in ENTP. A multi-stage cluster random sampling technique was applied to collect data on malaria history, demographic, behavioural and environmental factors of malaria of participants. Logistic regression model was applied to decide significant factors associated with malaria.  ResultsThe prevalence of malaria was 13.4%. The prevalence of malaria was significantly higher for adults with low level of malaria knowledge (Adjusted odd ratio (AOR): 2.43, 95% confidence interval (CI): 1.38 - 4.27) compared to those with high malaria knowledge level, having moderate malaria knowledge level (AOR: 1.99, 95% CI: 1.11 - 3.57) compared to those high malaria knowledge level, having no education (AOR: 2.18, 95% CI: 1.37 - 3.45) compared to those junior high school or above education level, outdoor occupation (AOR: 1.81, 95% CI: 1.22 - 2.68) compared to indoor occupation, having family size > 4 (AOR 2.08, 95% CI: 1.52 -2.87) compared to those [&le;] 4  ConclusionThe study revealed the prevalence of malaria amongst rural adults in this province was high. The study highlights the power of malaria knowledge level on the prediction of malaria prevalence amongst rural adults. Health education intervention is critical for vulnerable groups to reduce malaria prevalence in the province.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence of Chikungunya, Dengue, and West Nile arboviruses in Iran based on enzyme-linked immunosorbent assay (ELISA): A systematic review and meta-analysis\nAbstract: IntroductionArboviruses, including Chikungunya (CHIKV), Dengue (DENV), and West Nile (WNV) viruses, are significant viral threats that affect numerous people globally each year. This report explore the prevalence of these viruses in Iran through a systematic review and meta-analysis.  MethodsThe present survey was performed with a systematic review and meta-analysis method on the seroprevalence of WNV, CHIKV, and DENV using the ELISA test. Based on this, by search in Web of Science, PubMed, Scopus, Cochrane Library, Science Direct, and Google Scholar scientific databases, all relevant published papers were sorted out and reviewed. Power ratification of data was carried out with a random effects model in meta-analysis, meta-regression, I2 index, and Egger test.  ResultsTwelve published papers between 2000 and 2024 were embodied in this meta-analysis report. The seroprevalence of positive ELISA test for WNV in Iran was estimated at 12.9% (CI=95%: 7.4-18.4), and for CHIKV at 6.2% (CI=95%: 0.6-11.8). Regarding DENV, only two studies were conducted with a zero prevalence in one study, and a seroprevalence of 5.6% in another study.  ConclusionAccording to these data, WNV, CHIKV, and DENV fevers have been detected in Iran using ELISA test. Considering the seropositivity of WNV and CHIKV, and the finding of these viruses from several provinces, it could be for granted that these two viruses are ubiquitous and DENV fever is sporadic in Iran.  Author SummaryArboviruses, including Chikungunya (CHIKV), Dengue (DENV), and West Nile (WNV), pose significant health threats globally, with increasing infections reported, including in Iran. This report conducts a systematic review and meta-analysis of the seroprevalence of these viruses in Iran through ELISA testing. A total of twelve studies published from 2000 to 2024 were analyzed, revealing a seroprevalence of 12.9% for WNV and 6.2% for CHIKV, while DENV showed a mixed prevalence of 0% in one study and 5.6% in another. The results suggest that WNV and CHIKV are widespread in Iran, whereas DENV appears to be sporadic.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Antibiotic susceptibility trend estimation for India based on 2018 to 2021 data from GEARS program\nAbstract: Antimicrobial resistance (AMR) continues to be a major public threat due to dwindling supplies of effective antibiotics due to its excessive usage in humans and food producing animals. The objective of our study was to identify and predict future trends in multi-drug resistance amongst enterobacteriaceae and non-enterobacteriaceae family in India for four common broad-spectrum antibiotics. We focussed on four broad spectrum antibiotics levofloxacin, gentamicin, cefepime, and ceftazidime and classified the GEARS program study dataset into sensitive (S), intermediate(I) and resistant (R) isolates based on CLSI breakpoints. Levofloxacin (98.3%) was found to be the most susceptible broad spectrum antibiotic for treatment of non-enterobacteriaceae while it was relatively resistant (56.5%) for enterobacteriaceae treatment. As levofloxacin are among ICMR list of  alert antimicrobial agents,hospitals and clinicans can exercise greater care before prescribing them.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Protection of vaccine boosters and prior infection against mild/asymptomatic and moderate COVID-19 infection in the UK SIREN healthcare worker cohort: October 2023 to March 2024\nAbstract: ObjectiveTo estimate the protection of COVID-19 vaccine boosters against mild/asymptomatic and moderate SARS-CoV-2 infection over a 6-month period of XBB.1.5 and JN.1 variant circulation.  DesignMulti-state model applied to cohort study, adjusted for vaccination, prior infection, and demographic covariates.  SettingNational Health Services (NHS) hospitals in the UK.  ParticipantsHealthcare worker cohort including 2,867 eligible people with >6 months since a previous booster who tested fortnightly for SARS-CoV-2 between October 2023 and March 2024 and completed symptoms questionnaires.  Main outcome measuresVaccine effectiveness (VE) of vaccine boosters received in October 2023 (baseline: booster >6 months prior), and durability of protection from a recent (past 6 months) previous infection (baseline: last infection >2 years prior) against mild/asymptomatic and moderate SARS-CoV-2 infection. Mild symptoms included acute respiratory symptoms for <5 days, moderate symptoms included influenza-like illness, acute respiratory symptoms for 5+ days, or sick-leave. VE and acquired protection were estimated from the multi-state model as: 1 - adjusted hazard ratio.  InterventionsReceipt of a COVID-19 bivalent original/BA.4-5 or monovalent XBB.1.5 booster during October 2023.  ResultsHalf of eligible participants (1,422) received a booster during October 2023 (280 bivalent, 1,142 monovalent) and 536 (19%) had at least one PCR-confirmed infection over the study period. For the monovalent booster, VE against infection was 44.2% (95% confidence interval 21.7 to 60.3%) at 0-2 months, and 24.1% (-0.7 to 42.9%) at 2-4 months post-vaccination, with no evidence of protection by 4-6 months. For the bivalent booster, VE against infection was 15.1% (-55.4 to 53.6%) at 0-2 months and 4.2% (-46.4 to 37.3%) at 2-4 months. VE (monovalent or bivalent) against moderate infection was 39.7% (19.9 to 54.6%), and against mild/asymptomatic infection was 14.0% (-12.1 to 34.0%). Controlling for vaccination, compared to those with an infection >2 years prior, infection within the past 6 months was associated with 58.6% (30.3 to 75.4%) increased protection against moderate infection, and 38.5% (5.8 to 59.8%) increased protection against mild/asymptomatic infection.  ConclusionsMonovalent XBB.1.5 boosters provided short-term protection against SARS-CoV-2 infection, particularly against moderate symptoms. Vaccine formulations which target the circulating variant may be suitable for inclusion in seasonal vaccination campaigns among healthcare workers.  FundingUK Health Security Agency, Medical Research Council, NIHR HPRU Oxford, and others.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Whole genome sequencing of hepatitis B virus (HBV) using tiled amplicon (HEP-TILE) and probe-based enrichment on Illumina and Nanopore platforms.\nAbstract: Hepatitis B virus (HBV) whole genome sequencing (WGS) is currently limited as the DNA viral loads (VL) of many clinical samples are below the threshold required to generate full genomes using current sequencing methods. We developed two pan-genotypic viral enrichment methods, using probe-based capture and tiled amplicon PCR (HEP-TILE) for HBV WGS. We demonstrate using mock samples that both enrichment methods are pan-genotypic (genotypes A-J). Using clinical samples, we demonstrate that HEP-TILE amplification successfully amplifies full genomes at the lowest HBV VL tested (30 IU/ml), and the PCR products can be sequenced using both Nanopore and Illumina platforms. Probe-based capture with Illumina sequencing required VL >300,000 IU/ml to generate full length HBV genomes. The capture-Illumina and HEP-TILE-Nanopore pipelines had consensus sequencing accuracy of 100% in mock samples with known DNA sequences. Together, these protocols will facilitate the generation of HBV sequence data, enabling a more accurate and representative picture of HBV molecular epidemiology, cast light on persistence and pathogenesis, and enhance understanding of the outcomes of infection and its treatment.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Timely vaccine strain selection and genomic surveillance improves evolutionary forecast accuracy of seasonal influenza A/H3N2\nAbstract: For the last decade, evolutionary forecasting models have influenced seasonal influenza vaccine design. These models attempt to predict which genetic variants circulating at the time of vaccine strain selection will be dominant 12 months later in the influenza season targeted by vaccination campaign. Forecasting models depend on hemagglutinin (HA) sequences from the WHOs Global Influenza Surveillance and Response System to identify currently circulating groups of related strains (clades) and estimate clade fitness for forecasts. However, the average lag between collection of a clinical sample and the submission of its sequence to the Global Initiative on Sharing All Influenza Data (GISAID) EpiFlu database is [~]3 months. Submission lags complicate the already difficult 12-month forecasting problem by reducing understanding of current clade frequencies at the time of forecasting. These constraints of a 12-month forecast horizon and 3-month average submission lags create an upper bound on the accuracy of any long-term forecasting model. The global response to the SARS-CoV-2 pandemic revealed that modern vaccine technology like mRNA vaccines can reduce how far we need to forecast into the future to 6 months or less and that expanded support for sequencing can reduce submission lags to GISAID to 1 month on average. To determine whether these recent advances could also improve long-term forecasts for seasonal influenza, we quantified the effects of reducing forecast horizons and submission lags on the accuracy of forecasts for A/H3N2 populations. We found that reducing forecast horizons from 12 months to 6 or 3 months reduced average absolute forecasting errors to 25% and 50% of the 12-month average, respectively. Reducing submission lags provided little improvement to forecasting accuracy but decreased the uncertainty in current clade frequencies by 50%. These results show the potential to substantially improve the accuracy of existing influenza forecasting models by modernizing influenza vaccine development and increasing global sequencing capacity.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How does date-rounding affect phylodynamic inference for public health?\nAbstract: Phylodynamic analyses enable the inference of epidemiological parameters from pathogen genome sequences for enhanced genomic surveillance in public health. Pathogen genome sequences and their associated sampling times are the essential data in every analysis. However, sampling times are usually associated with hospitalisation or testing dates and can sometimes be used to identify individual patients, posing a threat to patient confidentiality. To lower this risk, sampling times are often given with reduced date-resolution to the month or year, which can potentially bias inference of epidemiological parameters. Here, we characterise the extent to which reduced date-resolution biases phylodynamic analyses across a diverse range of empirical and simulated datasets. We develop a practical guideline on when date-rounding biases phylodynamic inference and we show that this bias is both unpredictable in its direction and compounds with decreasing date-resolution, higher substitution rates, and shorter sampling intervals. We conclude by discussing future solutions that prioritise patient confidentiality and propose a method for safer sharing of sampling dates by translating them uniformly by a random number.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Sex-specific Mendelian Randomization-Phenome-Wide Association Study of Body Mass Index\nAbstract: BackgroundTrials of incretins are making it increasingly clear that body mass index (BMI) is linked to several diseases throughout life, but trials cannot provide a comprehensive assessment of the role of BMI in health-related attributes for men and women. To systematically investigate the role of BMI, we conducted a sex-specific Mendelian randomization-phenome-wide association study.  MethodsWe comprehensively examined the associations of genetically predicted BMI in women (n: 194,174) and men (n: 167,020) with health-related attributes from the UK Biobank with inverse variance weighting and sensitivity analysis.  ResultsBMI impacted 232 of 776 traits considered in women and 204 of 681 traits in men, after adjusting for false discovery; differences by sex were found for 105 traits. BMI was more strongly positively associated with heart disease, heart failure and hypertensive heart disease in men than women. BMI was more strongly positively associated with apolipoprotein B (ApoB), diastolic blood pressure, neuroticism, arthritis and triglycerides in women than men.  ConclusionOur study revealed that BMI might affect a wide range of health-related attributes and highlights notable sex differences in its impact, including opposite associations for certain attributes, such as ApoB and neuroticism. These findings emphasize the importance of maintaining a healthy BMI.  FundingNone\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impacts of the COVID-19 pandemic on sepsis incidence, etiology and hospitalization costs in France: a retrospective observational study\nAbstract: BackgroundSepsis is a serious medical condition that causes long-term morbidity and high mortality, annually affecting millions of people worldwide. The COVID-19 pandemic may have impacted its burden.  ObjectiveTo estimate the impact of the COVID-19 pandemic on sepsis incidence, etiology and associated hospitalization costs in metropolitan France.  MethodsThis retrospective observational study used data drawn from a cohort of hospitalized sepsis patients in Frances national healthcare database. Sepsis was identified through both explicit ICD-10 codes (E-sepsis) and implicit codes (I-sepsis). Participants included all patients aged 15 years or older hospitalized with E-sepsis or I-sepsis in metropolitan France between January 1, 2018, and December 31, 2022. Patient and hospital stay characteristics were described by sepsis type (E-sepsis, I-sepsis) and overall. The distribution of sepsis etiology was estimated for each year. Annual incidence rates were estimated overall and by sepsis type and etiology. Total and median per-stay hospitalization costs were calculated.  ResultsThe total age- and sex-standardized sepsis incidence rate per 100,000 increased slightly from 2018 (446, 95% CI 444.2 to 447.7) to 2020 (457, 95% CI 455.1 to 458.6) and then decreased in 2022 (382, 95% CI 380.2-383.7) (p <.0001). Incidence rates decreased for both E-sepsis and bacterial sepsis during the pandemic period, whereas I-sepsis incidence increased in 2020 and 2021, associated with a marked increase in viral sepsis and co-infections (p <.0001 for E- and I-sepsis). Viral sepsis represented about 10% of all sepsis cases during the pandemic, but only about 1% prior to the pandemic. Total sepsis-associated hospitalization costs and extra medication costs increased during the pandemic. Characteristics of patients and their hospital stays were overall stable over the five-year study period.  ConclusionsThe COVID-19 pandemic led to a higher burden of sepsis in French hospitals and an increase in hospital stay costs. Critically, our study highlights the need for introducing explicit viral sepsis codes within the ICD-11 classification system and for achieving a consensus on its definition in order to robustly estimate sepsis incidence.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Steroid Hormone Biosynthesis and Dietary Related Metabolites associated with Excessive Daytime Sleepiness\nAbstract: BackgroundExcessive daytime sleepiness (EDS) is a complex sleep problem that affects approximately 33% of the United States population. Although EDS usually occurs in conjunction with insufficient sleep, and other sleep and circadian disorders, recent studies have shown unique genetic markers and metabolic pathways underlying EDS. Here, we aimed to further elucidate the biological profile of EDS using large scale single- and pathway-level metabolomics analyses.  MethodsMetabolomics data were available for 877 metabolites in 6,071 individuals from the Hispanic Community Health Study/Study of Latinos (HCHS/SOL) and EDS was assessed using the Epworth Sleepiness Scale (ESS) questionnaire. We performed linear regression for each metabolite on continuous ESS, adjusting for demographic, lifestyle, and physiological confounders, and in sex specific groups. Subsequently, gaussian graphical modelling was performed coupled with pathway and enrichment analyses to generate a holistic interactive network of the metabolomic profile of EDS associations.  FindingsWe identified seven metabolites belonging to steroids, sphingomyelin, and long chain fatty acids sub-pathways in the primary model associated with EDS, and an additional three metabolites in the male-specific analysis. The identified metabolites particularly played a role in steroid hormone biosynthesis.  InterpretationOur findings indicate that an EDS metabolomic profile is characterized by endogenous and dietary metabolites within the steroid hormone biosynthesis pathway, with some pathways that differ by sex. Our findings identify potential pathways to target for addressing the causes or consequences of EDS and related sleep disorders.  FundingDetails regarding funding supporting this work and all studies involved are provided in the acknowledgments section.  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSThere is a growing recognition of the paramount importance of sleep on health and cardiometabolic disease. Excessive daytime sleepiness (EDS), one of the key common sleep treatment targets, has been linked to increased risk of mortality, hypertension, cardiovascular disease, car accidents as well as decrease in life quality, and productivity. Despite its impact on health, much remains unknown about the biological mechanisms of EDS and if those mechanisms are independent from other sleep disorders. Recent genetic evidence that shows that EDS is associated with specific genetic biomarkers supports the need to further study the underlying biology of EDS.  Added value of this studyHere, we used measurements of metabolites, the products and by-products of metabolism to identify the metabolomic profile of EDS. Metabolites are produced by the biological reactions within the body via proteins--themselves products of genes--and by the breakdown of external sources such as nutritional intake and breathing air pollutants. Therefore, metabolomics enables study of the effects of nutrition, environmental exposures, and genetics. In this study we aimed to identify the metabolites that were associated with excessive daytime sleepiness. Additionally, we mapped these metabolites into a publicly available online biological network of human metabolism pathways to obtain an understanding of our findings on a larger scale.  Implications of all the available evidenceIdentifying the metabolites and pathways related to daytime sleepiness provides insights into the biological mechanisms of EDS and suggests future research opportunities to identify targets for prevention, prediction, and treatments for EDS and potentially other sleep disorders coupled with sleepiness. In this study we found 7 such metabolites--some endogenously synthesised and some obtained from dietary sources--associated with EDS. The network analysis implicated the steroid hormone biosynthesis pathway as a shared pathway underlying those metabolites, and identified linkages to key metabolites related to sleep: melatonin and cortisol metabolism.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pediatric Kidney Injury in Communities Impacted by Chronic Kidney Disease of Unknown Etiology (CKDu): A Comprehensive Systematic Review of Epidemiologic Studies\nAbstract: BackgroundChronic kidney disease of unknown etiology (CKDu) is a tubulointerstitial disease that disproportionately affects young, primarily male, agricultural workers in Mesoamerica and South Asia who lack traditional risk factors for kidney disease. Extensive research in adult populations suggests the etiology is complex and indicates that early childhood exposures could have an integral role.  ObjectivesTo systematically identify, summarize, and compare research in children living in CKDu endemic areas or with relevant CKDu-related exposures.  MethodsA systematic literature search was conducted in six databases for studies that report kidney health outcomes of pediatric populations living in proximity to CKDu-affected areas with no limitations on geography or study design. Studies were independently screened for inclusion and underwent quality assessment using the Appraisal Tool for Cross-Sectional Studies (AXIS) or the JBI Critical Appraisal Tool for Cohort Studies based on the study design by at least two authors. Data are compared narratively and graphically.  ResultsWe included twenty peer-reviewed publications and two meeting abstracts from eight different countries. The most common study design involved cross-sectional analysis of biological specimens from children in an established CKDu endemic area. Marked decreases in estimated glomerular filtration rate were generally not identified and prevalence of albuminuria differed widely between countries. Novel urinary biomarkers frequently demonstrated subclinical kidney damage, although the specific biomarker(s) varied between studies. Epidemiologic factors associated with evidence of subclinical kidney damage in children included proximity to agriculture or agrochemicals. Despite heterogenous study outcomes, all studies concluded that there were signs of kidney injury in children living in CKDu endemic areas or with a CKDu-relevant environmental exposure.  ConclusionThis systematic review suggests that the pathophysiologic process leading to CKDu may begin prior to adulthood. Future longitudinal research aimed at elucidating the multifaceted factors and exposures impacting entire communities, including children, is imperative for disease prevention strategies.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence of common respiratory viruses in children: insights from post-pandemic surveillance\nAbstract: IntroductionThe COVID-19 pandemic has significantly affected healthcare systems worldwide, impacting the occurrence and management of respiratory illnesses. This has also influenced respiratory infections role in childhood mortality. Surveillance of common respiratory viruses in Ghana is limited, making it crucial to assess the prevalence of respiratory viral infections, particularly in children, in the post-pandemic era. This study provides data on the prevalence of respiratory viruses and the associated risk factors in children aged 5 or younger in an urban paediatric hospital setting.  MethodsThe study was a cross-sectional study with a convenience sampling method, conducted in four health facilities: Asokwa Childrens Hospital, HopeXchange Medical Centre, University Health Services-KNUST, and Kumasi South Hospital in Kumasi, Ghana, between August 2022 and June 2023. Recruitment was not done in parallel in each hospital. Oropharyngeal swabs were collected from children [&le;] 5 years old and screened by RT-qPCR for common respiratory viruses.  ResultsOut of the 303 patients enrolled in the study, 165 (54.4%) were male, and 122 (40.3%) were aged from 13 to 36 months. The median age of the patients was 19 months. The most common symptoms reported were cough (87.0%), runny nose (87.0%), and fever (72.0%). Respiratory viruses were detected in 100 (33.0%) of the samples, with 36 (12.0%) testing positive for Human metapneumovirus (HMPV), 27 (8.9%) for RSV, and 20 (6.6%) for Human Adenovirus (HAdV). In 8.0% of the cases, multiple viruses were detected, with HAdV being the most common (75.0%). Children under 6 months (AOR: 4.81, 95% CI: 1.20-24.60) had a higher risk of RSV detection compared to children aged 37 to 60 months. Furthermore, it was found that caregivers with tertiary education had a higher risk of HMPV detection (AOR: 6.91, 95% CI: 1.71-47.3).  ConclusionThe studys findings emphasize RSV infection in very young children and the potentially significant role of HMPV in causing respiratory infections among children in Ghana. Active surveillance of common respiratory viruses in healthcare facilities could enhance the management of viral respiratory infection cases in the paediatric population in Ghana.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rising prevalence of Plasmodium falciparum artemisinin resistance mutations in Ethiopia\nAbstract: Ethiopia is striving to eliminate local malaria transmission by 2030, despite a recent resurgence of malaria cases due to multiple factors. A significant contributor to this resurgence could be drug resistance, particularly the emergence of partial resistance to artemisinin (ArtR) in Ethiopia and other regions of Eastern Africa. This situation highlights the necessity for genomic surveillance to monitor relevant drug resistance markers. This study reports sentinel site-based genomic surveillance results for P. falciparum antimalarial drug resistance mutations. From 2019 to 2022, dried blood spots (DBS) were collected from febrile outpatients [&ge;]1 year of age with microscopically confirmed falciparum malaria at 12 sentinel sites across 5 regions. Molecular inversion probe (MIP) sequencing targeted mutations associated with artemisinin and partner drug resistance, including k13, mdr1, crt, dhfr, and dhps genes, along with genome-wide markers to assess the complexity of infection (COI) and parasite relatedness. A total of 1,199 falciparum-positive patients were assessed, with a median age of 20 years (IQR: 14-30) and including 463 (38.6%) females. The WHO-validated K13 R622I mutation had a high but regionally variable prevalence (15.7%, range 0-58.8%). The validated K13 A675V mutation was detected for the first time in Ethiopia in the Gambella Region (4.5%), as well as P441L and P574L mutations were detected at low frequencies in Southern and Oromia Regions, respectively. Several partner drug resistance markers were identified, with mutations in MDR1(184F), DHPS, DHFR, and CRT nearly fixed across the country. Most samples (87.2%) were monogenic infections (COI=1) and showed high genetic relatedness, particularly within the health facilities. Principal component analysis revealed regional clustering of parasites, particularly in Gambella. The prevalence of K13 R622I across the country and the presence of multiple additional ArtR markers emphasizes the urgent need for rigorous monitoring of artemisinin combination therapy (ACT) efficacy to detect partner drug resistance and ACT failure early and its impact on malaria resurgence in Ethiopia.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessing the Impact of COVID-19 on Multimorbidity: Insights from Structural Equation Modeling in Colombia\nAbstract: BackgroundMultimorbidity, the coexistence of multiple chronic diseases, poses significant challenges for healthcare systems worldwide. This study aims to assess the situation of multimorbidity in Colombia using structural equation models and to characterize multimorbidity by sex, age group, region, and health insurance regime between 2019 and 2023.  MethodsWe conducted a cross-sectional analytical study utilizing data from the Individual Health Service Provision Registry (RIPS) and other national databases, including the Unit of Payment by Capitation (UPC) Sufficiency Study Database. Structural equation models were employed to identify and analyze multimorbidity clusters among patients with two or more chronic diseases.  ResultsThe study revealed a multimorbidity prevalence of 61.5% in the general population. Hypertension emerged as the most prevalent chronic condition, frequently associated with diabetes and chronic kidney disease. Multimorbidity was more common in women and individuals affiliated with the contributory insurance regime. The study also identified significant variations in multimorbidity prevalence across different regions and age groups.  ConclusionsMultimorbidity is a prevalent issue in Colombia, with substantial variations by sex, age, and insurance regime. These findings underscore the need for tailored healthcare strategies to address the diverse needs of multimorbid patients. The results provide critical insights for health service planning and management, emphasizing the importance of continued research and policy development to mitigate the burden of chronic diseases and multimorbidity in Colombia.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mobility patterns, activity locations, and tuberculosis in Nairobi, Kenya\nAbstract: BackgroundAnnually, over 3 million people develop TB but are not diagnosed and treated. We aimed to characterize the mobility patterns and activity locations of people with TB in an urban, high-burden setting to inform future active case finding (ACF) efforts.  MethodsWe conducted a population-based TB prevalence survey in Nairobi, Kenya, in 2022. Participants aged [&ge;]15 years with TB symptoms or a suggestive chest x-ray submitted sputum for Xpert Ultra and culture. We collected data on individual activity locations and mobility and evaluated their association with the risk of pulmonary TB.  ResultsThe prevalence survey enrolled 6369 participants across nine clusters. There were significant differences in mobility patterns and activity locations between sexes and age groups. Mobility factors were not significantly associated with TB. In the adjusted analysis, age group 45-54 (OR 2.45), male sex (OR 2.95), and use of a social activity location (OR 1.96) were significantly associated with a higher risk of TB.  ConclusionsWe did not find a significant association between mobility patterns and TB but found a positive association between reported  social activity locations and TB. Identification of  social activity locations, particularly bars, provides important insight into possible venues for spatially-targeted ACF activities.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Conceptualising care pathways for neglected tropical diseases in sub-Saharan Africa: A systematic scoping review\nAbstract: BackgroundThere is a lack of synthesized evidence on how best to support care continuity for neglected tropical diseases (NTDs) in sub-Saharan Africa (SSA).  MethodsTo identify all SSA NTD care pathways, we conducted a systematic search of six scientific databases from inception to 18 February 2023. All studies were required to include care pathways for NTDs, defined at minimum as having both NTD diagnosis and treatment or referral to treatment for care continuity. Using an iterative approach to establish an understanding of care pathways relevant for NTDs, concept development drew from data extraction of variables relating to study characteristics; approaches to diagnosis, treatment, and referrals as pathway components; barriers to care and strategies for their resolution; and ethical challenges.  FindingsSearches returned 2178 studies where after de-duplication and eligibility screening, 164 were systematically reviewed. Medical referrals were used to support care continuity in 62.2% (102/164) of studies, and community health workers played roles in patient care in 22.6% (37/164) of studies. Only 6.7% (11/164) of studies explicitly mapped care pathways, none of which were for NTDs where preventive chemotherapy is the primary management strategy. The majority of studies (82.9%; 136/164) presented unmapped care pathways, which were primarily biomedical research studies that provided diagnosis and/or treatment of NTD patients (66.9%; 91/136). Of biomedical research studies, 36.3% (33/91) described strategies to support continuity of care. While there is no singular care pathway for all NTDs in SSA, we proposed a conceptual framework relevant for implementation of biomedical research.  InterpretationFurther research is needed on morbidity management of NTDs typically addressed through mass drug administration in sub-Saharan Africa. To conduct this research, there is a need for guidance on how research sponsors should collaborate with local health systems to enable continuity of care in low-income, NTD-endemic settings.  Key messagesO_ST_ABSWhat is already known on this topicC_ST_ABSProviding continuity of care for neglected tropical diseases (NTDs) in the low-income settings where NTDs are endemic is challenging due to a variety of factors, particularly for chronic NTDs requiring morbidity management.  What this study addsAll NTDs require patient care, yet NTDs are unjustifiably divided into morbidity management NTDs and preventive chemotherapy NTDs. Further research on morbidity management is needed on NTDs typically managed through mass drug administration of preventive chemotherapies. We show that implementation of biomedical research on NTDs creates distinct care pathways that connect research participants with local health systems for continuity of care. These pathways provide a conceptual framework to understand care continuity during biomedical research as a practical ethical issue that merits further exploration, and illuminates how biomedical research studies might support care continuity for NTD patients such as through provision of transport, collaboration with community health workers, or structural support to local health system service providers.  How this study might affect research, practice or policyThis research opens avenues to create tools to assist researchers in providing care in resource-constrained settings. Researchers should consider care pathways for NTDs as a tool to understand local contexts of health seeking and care delivery prior to research implementation. Through these pathways, researchers can understand potential gaps in care continuity during research implementation, and determine what support may be required to address these gaps and facilitate research activities in low-income settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clinical management, epidemiology, and recurrence of human cystic echinococcosis in a secondary care level hospital in an endemic area of the Andes in Sicuani, Cusco, Peru\nAbstract: Peru has the highest incidence of human cystic echinococcosis (CE) in South America and most cases are reported in the Central and Southern Peruvian Andes, including the Cusco region. We reviewed medical records of patients with CE admitted between 2010-2019 to a level 2 Hospital in Sicuani, to collect data on the surgical management and disease recurrence in the Canchis province of Cusco. Records of 115 patients were analyzed in detail. The median age was 25 years (IQR, 16-46) and 60% were female. Most patients (68.7%) presented with a single liver cyst. The Gharbi classification was used in 75/107 (70.1%) patients with an ultrasound and 91/142 cysts (64.8%). Thirty one (34.1%) were classified as Gharbi I, 33 (36.3%) Gharbi II, 21 (23.1%) Gharbi III, and 6 (6.6%) Gharbi IV. Pre-surgical complications were reported in 41.7%. One hundred two patients underwent surgery. In 46.1%, one cyst spillage prevention measure was documented, 5.9% had two, and one had the three recommended measures. Post-surgical cyst recurrence was reported in 16.5% at a median 32.3 months (IQR, 3.9-46.6) and readmissions in 12.7%. In the multivariable analysis, having [&ge;]3 cysts (OR 9.5, 95% CI 1.3-85.5), having two pre-surgical complications (OR 12.6, 95% CI 1.8-125.6), and receiving pre-surgical albendazole (OR 5.2, 95% CI 1.3-23.9) were associated with cyst recurrence. Advanced and complicated CE disease and post-surgical recurrence were common in Sicuani. Standardization of ultrasound staging-guided clinical management along with surgical spillage prevention measures could effectively decrease the disease burden linked to clinical care, improving outcomes and decreasing costs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Direct and indirect genetic pathways between parental neuroticism and offspring emotional problems across development: evidence from 7 cohorts across 5 European nations\nAbstract: Disentangling direct and indirect genetic pathways underlying the intergenerational transmission of emotional problems could guide preventative strategies and further the understanding of the role of parental mental health in childrens outcomes. This study aimed to estimate the extent to which genetic pathways that are direct (via child genotype) and indirect (e.g., via parental phenotype) explain the well-established association between parent and child emotional problems. We leveraged data from seven European cohort studies with a combined population of Ntrios=15,475. Polygenic scores were calculated for parental and offspring neuroticism, as it represents a dispositional trait underlying emotional problems. Emotional problems in offspring were measured using validated scales across various developmental stages from early childhood to adulthood. We used neuroticism polygenic scores within a structural equation modelling framework to distinguish between direct genetic pathways from parental genotype to offspring outcome (acting through offspring genotype), and indirect genetic pathways (acting through parental phenotype and associated environment). Standard errors for direct genetic, indirect genetic and total effects were bootstrapped and meta-analyses pooled effect estimates at three developmental stages (childhood: 3-4 years, adolescence: 11-13 years, adulthood: 18+ years). We found evidence suggesting an indirect genetic pathway between mothers and child emotional problems during early childhood (pooled estimate, mean difference in standardised child emotional problems score per 1SD increase in maternal PGS for neuroticism=0.04, 95% CI: 0.01, 0.07). This association attenuated over child development, while direct genetic pathways strengthened. High attrition rates, measurement error and low variance explained by polygenic scores may have altered precision of the estimates, influencing the interpretation of the results. However, we provide the first multi-cohort study to provide evidence for an indirect genetic pathway from maternal neuroticism to early child emotional problems. This suggests that there are likely processes other than direct genetic pathways involved in the intergenerational transmission of emotional problems, highlighting the importance of timely support to prevent and reduce emotional issues in mothers as a preventative strategy for emotional difficulties.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cohort profile: The Camden Study - a pregnancy cohort study of pregnancy complications and birth outcomes in Camden, New Jersey, USA\nAbstract: BackgroundPregnancy is a unique stage of the life course characterized by trade-offs between the nutritional, immune, and metabolic needs of the mother and fetus. The Camden Study was originally initiated to examine nutritional status, growth, and birth outcomes in adolescent pregnancies and expanded to study dietary and molecular predictors of pregnancy complications and birth outcomes in young women.  MethodsFrom 1985-2006, 4765 pregnant participants aged 12 years and older were recruited from Camden, NJ, one of the poorest cities in the U.S. The cohort reflects a population under-represented in perinatal cohort studies (45% Hispanic, 38% non-Hispanic Black, 17% White participants; 98% using Medicaid in pregnancy). Study visits, including questionnaires, dietary assessments, and biospecimen collection, occurred in early and late pregnancy as well as at delivery. Medical records were abstracted, and a subset of mothers and infants participated in a six-week postpartum visit.  ResultsOver the last five decades, the Camden Study has provided data toward the publication of numerous peer-reviewed papers. Results show that adolescent linear growth in pregnancy is associated with smaller birth size, possibly due to impaired hemodynamics. In the context of preterm birth and other perinatal outcomes, analyses of nutritional data have demonstrated the importance of micronutrients (e.g., folate, iron, zinc), as well as glucose/insulin dynamics and prenatal supplement use. More recent analyses have begun to unpack the biochemical pathways in pregnancy that may be shaped by race as an indicator for systemic racism.  ConclusionsThe Camden Study data and biorepositories are well-positioned to support future research aimed at better understanding perinatal health in under-represented women and infants. Linkages to subsequent health and administrative records and the potential for recontacting participants over 18-39 years after initial participation may provide key insights into the trajectories of maternal and child health across the life course.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence, intensity and risk factors of soil-transmitted helminthiasis after five effective rounds of preventive chemotherapy across three implementation units in Ondo State, Nigeria\nAbstract: BackgroundRoutine epidemiological data are essential for monitoring the effectiveness of preventive chemotherapy (PC), optimizing resource allocation, and addressing the evolving needs in the elimination of soil-transmitted helminthiasis (STH). This study assesses the prevalence, intensity, and associated risk factors of STH following five rounds of albendazole-based PC in three implementation units (IUs) in Ondo State, Nigeria.  MethodologyFresh stool samples were collected from 2,093 children aged 5-14 years across 45 systematically selected schools in three IUs: Ese-Odo, Irele, and Ile-Oluji. The samples were analyzed using the Kato-Katz technique. Additionally, standardized questionnaires were administered to gather data on demographics and access to water, sanitation, and hygiene (WASH) resources. Data analysis was conducted using R software version 4.3.2, with a 95% confidence interval.  Principal Findings/ConclusionsThe parasitological data indicated a significant decline in the aggregated prevalence of STH across the three IUs. In Ese-Odo, the prevalence decreased to 25.8% (95% CI: 23.0-29.0) from 39% at baseline (d = -34%, p = 0.00). In Irele, prevalence dropped to 9.7% (95% CI: 7.6-12.0) from 51.3% at baseline (d = -81%, p = 0.00), and in Ile-Oluji, prevalence was reduced to 6.4% (95% CI: 4.6-8.7) from 23% at baseline (d = -72.2%, p = 0.00). The most prevalent STH species was Ascaris lumbricoides, with infection rates of 25.5%, 9.4%, and 6.4% in Ese-Odo, Irele, and Ile-Oluji, respectively, followed by Trichuris trichiura in Ese-Odo (2.7%) and Irele (0.4%), while hookworm infections were detected only in Irele (0.7%). The majority of infections were of low intensity in Ese-Odo (91.0%), Irele (96.8%), and Ile-Oluji (100%). Access to improved sanitation (17.7%, 54.9%, and 58.2%, p < 0.05), improved water sources (24.5%, 66.1%, and 69.8%, p < 0.05), and handwashing facilities (9.0%, 39.6%, and 25.4%) was suboptimal across Ese-Odo, Irele, and Ile-Oluji, respectively. Open defecation rates were high in Ese-Odo (54.2%), Irele (36.3%), and Ile-Oluji (34.3%). In Ese-Odo, significant risk factors for STH infection included the use of hand-pump boreholes (AOR: 2.44, 95% CI: 1.23-4.88, p = 0.01), unprotected dug wells (AOR: 3.25, 95% CI: 0.96-11.36, p = 0.06), ventilated improved pit latrines (AOR: 3.95, 95% CI: 1.13-16.1, p = 0.04), pit latrines without a slab (AOR: 2.19, 95% CI: 1.27-3.8, p = 0.01), and failure to use soap after defecation, both when soap was available (AOR: 12.09, 95% CI: 1.86-112.97, p = 0.01) and when soap was unavailable (AOR: 8.19, 95% CI: 1.73-76.65, p = 0.04). In Irele, access to protected dug wells was marginally significant (AOR: 1.79, 95% CI: 0.96-3.21, p = 0.06), while in Ile-Oluji, access to river water emerged as a significant risk factor (AOR: 7.97, 95% CI: 1.81-58.58, p = 0.02). The use of rainwater was found to be protective across all three IUs. These findings demonstrate significant progress in reducing STH prevalence across the three IUs following PC interventions. However, the data underscore the need for enhanced efforts to improve access to and use of WASH facilities to achieve STH elimination.  Authors SummaryThe World Health Organization (WHO) recommends reducing soil-transmitted helminthiasis (STH) prevalence to below 20% and moderate-to-heavy infections to less than 2% in treated areas to achieve elimination targets. Endemic countries, including Nigeria, have implemented mass albendazole administration to at-risk populations to meet these goals. After a decade of such interventions in Nigeria, reassessing the infection status is essential for determining whether to adjust or discontinue the program. This study analyzed stool samples from 2,093 children across three implementation units (IUs) in Ondo State. The results indicated significant reductions in STH prevalence to below 20% in two of the three IUs, with no heavy infections reported in any IU. While these findings demonstrate the effectiveness of the PC interventions, the study also identified poor access to water, sanitation, and hygiene (WASH) resources, highlighting the need for improvements in these areas to sustain progress and prevent infection resurgence.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparative Effectiveness of the mRNA-1273 and BNT162b2 COVID-19 Vaccines Among Adults With Underlying Medical Conditions: A Systematic Literature Review and Pairwise Meta-Analysis Using GRADE\nAbstract: IntroductionThis systematic literature review and pairwise meta-analysis evaluated the comparative effectiveness of mRNA-1273 versus BNT162b in patients with at least one underlying medical condition at high risk for severe COVID-19.  MethodsMEDLINE, Embase, and Cochrane databases were searched for relevant articles from January 1, 2019 to February 9, 2024. Studies reporting effectiveness data from at least two doses of mRNA-1273 and BNT162b2 vaccination in adults with medical conditions at high risk of developing severe COVID-19 according to the US Centers for Disease Control and Prevention were included. Outcomes of interest were SARS-CoV-2 infection (overall, symptomatic, and severe), hospitalization due to COVID-19, and death due to COVID-19. Risk ratios (RRs) were calculated with random effects models. Subgroup analyses by specific medical conditions, number of vaccinations, age, and SARS-CoV-2 variant were conducted. Heterogeneity between studies was estimated with chi-square testing. The certainty of evidence was assessed using the Grading of Recommendations, Assessments, Development, and Evaluations framework.  ResultsSixty-five observational studies capturing the original/ancestral-containing primary series to Omicron-containing bivalent original-BA4-5 vaccinations were included in the meta-analysis. mRNA-1273 was associated with significantly lower risk of SARS-CoV-2 infection (RR, 0.85 [95% CI, 0.79-0.92]; I2=92.5%), symptomatic SARS-CoV-2 infection (RR, 0.75 [95% CI, 0.65-0.86]; I2=62.3%), severe SARS-CoV-2 infection (RR, 0.83 [95% CI, 0.78-0.89]; I2=38.0%), hospitalization due to COVID-19 (RR, 0.88 [95% CI, 0.82-0.94]; I2=38.7%), and death due to COVID-19 (RR, 0.84 [95% CI, 0.76-0.93]; I2=1.3%) than BNT162b2. Findings were generally consistent across subgroups. Evidence certainty was low or very low because sufficiently powered randomized controlled trials are impractical in this heterogeneous population.  ConclusionMeta-analysis of 65 observational studies showed that vaccination with mRNA-1273 was associated with a significantly lower risk of SARS-CoV-2 infection and COVID-19-related hospitalization and death than BNT162b2 in patients with medical conditions at high risk of severe COVID-19.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Improved resolution of influenza vaccination responses with high-throughput live virus microneutralisation\nAbstract: Influenza remains a significant threat to human and animal health. Assessing serological protection against influenza has relied upon haemagglutinin inhibition assays, which are used to gauge existing immune landscapes, seasonal vaccine decisions and in systems vaccinology studies. Here, we adapt our high-throughput live virus microneutralisation assay for SARS-CoV-2, benchmark against haemagglutinin inhibition assays, and report serological vaccine responsiveness in a cohort of older (>65yo) community dwelling adults (n=73), after the adjuvanted 2021-22 Northern Hemisphere quadrivalent vaccine. We performed both assays against all four viruses represented in the vaccine (A/Cambodia/H3N2/2020, A/H1pdm/Victoria/2570/2019, B/Yamagata/Phuket/2013, BVIC/Washington/02/201), using sera drawn on days 0 [range: d-28 to d0], 7 [d6-10] and 182 [d161-196] with respect to vaccination. We found population-level concordance between the two assays (Spearmans correlation coefficient range 0.48-0.88; all P[&le;]1.4 x 10-5). The improved granularity of microneutralisation was better able to estimate fold-changes of responses, and quantify the inhibitory effect of pre-existing antibody. Our high-throughput method offers an alternative approach to assess influenza-specific serological responses with improved resolution.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Systematic Review of Air Pollution Exposure and Brain Structure and Function during Development\nAbstract: ObjectivesAir pollutants are known neurotoxicants. In this updated systematic review, we evaluate new evidence since our 2019 systematic review on the effect of outdoor air pollution exposure on childhood and adolescent brain structure and function as measured by magnetic resonance imaging (MRI).  MethodsUsing PubMed and Web of Science, we conducted an updated literature search and systematic review of articles published through March 2024, using key terms for air pollution and functional and/or structural MRI. Two raters independently screened all articles using Covidence and implemented the risk of bias instrument for systematic reviews informing the World Health Organization Global Air Quality Guidelines.  ResultsWe identified 222 relevant papers, and 14 new studies met our inclusion criteria. Including six studies from our 2019 review, the 20 publications to date include study populations from the United States, Netherlands, Spain, and United Kingdom. Studies investigated exposure periods spanning pregnancy through early adolescence, and estimated air pollutant exposure levels via personal monitoring, geospatial residential estimates, or school courtyard monitors. Brain MRI occurred when children were on average 6-14.7 years old; however, one study assessed newborns. Several MRI modalities were leveraged, including structural morphology, diffusion tensor imaging, restriction spectrum imaging, arterial spin labeling, magnetic resonance spectroscopy, as well as resting-state and task-based functional MRI. Air pollutants were associated with widespread brain differences, although the magnitude and direction of findings are largely inconsistent, making it difficult to draw strong conclusions.  ConclusionPrenatal and childhood exposure to outdoor air pollution is associated with structural and functional brain variations. Compared to our initial 2019 review, publications doubled--an increase that testifies to the importance of this public health issue. Further research is needed to clarify the effects of developmental timing, along with the downstream implications of outdoor air pollution exposure on childrens cognitive and mental health.  HighlightsO_LIAir pollutants have emerged as ubiquitous neurotoxicants C_LIO_LIThis field of study has grown substantially in the last 5 years C_LIO_LIExclusion of highly exposed populations poses a barrier to result generalizability C_LIO_LILongitudinal investigations are needed to understand developmental impacts of AP C_LIO_LIAdditional research should aim to clarify which children may be most vulnerable C_LI    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=174 SRC=\"FIGDIR/small/24313629v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (69K): org.highwire.dtl.DTLVardef@721773org.highwire.dtl.DTLVardef@61a94eorg.highwire.dtl.DTLVardef@1b260e7org.highwire.dtl.DTLVardef@1f80484_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOGraphical AbstractC_FLOATNO C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of Health Technology Use and Digital Health Engagement on Clinical Trial Participation: Findings from the Health Information National Trends Survey\nAbstract: BackgroundClinical trials are critical to scientific advances and medical progress, although awareness and participation remain low in the general population. The existing literature indicates that clinical trial knowledge and participation is multifactorial. Yet, little is known about the association between clinical trial participation with health technology use and digital health engagement to search for health information, interact with medical providers, and seek health supports.  ObjectiveExamine the multivariate association between clinical trial knowledge and participation with past-year health technology use and digital health engagement with medical providers.  DesignCross-sectional data from a federal surveillance system.  ParticipantsA total of 3,865 US adult respondents from the Health Information National Trends Survey 5, Cycle 4 conducted in 2020.  Main MeasuresThe two outcomes were clinical trial knowledge (no knowledge, a little knowledge, a lot of knowledge) and participation (never invited, invited did not participate, invited and participated). There were four binary indicators of health technology use for the following purposes in the past year: searching for health or medical information, communicating with a doctors office, looking up medical test results, and making medical appointments. There were four binary indicators of digital health engagement in the past year: sharing health information on social media, participating in a health forum or support group, watching health-related videos on YouTube, and awareness of ClinicalTrials.gov.  Key ResultsSurvey-weighted multivariate regression models demonstrated that awareness of ClinicalTrials.gov had the largest associations with clinical trial knowledge and participation. Digital technology use to engage with medical providers and electronic health records was associated with clinical participation, although the vast majority of respondents had never been invited.  ConclusionsFindings from this study can inform the design of large-scale digital health campaigns and quality improvement programs focused on increasing clinical trial participation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interpreting epidemiological surveillance data: A modelling study from Pune City\nAbstract: Routine epidemiological surveillance data represents one of the most continuous and comprehensive sources of data during the course of an epidemic. This data is used as inputs to epidemiological forecasting models as well as for public health decision making such as imposition and lifting of lockdowns and quarantine measures. However, such data is generated during testing and contact tracing and not through randomized sampling which makes it unclear how representative such data is of the epidemic itself. Using the BharatSim simulation framework, we build an agent-based epidemiological model with a detailed algorithm of testing and contact tracing representative of actual strategies employed in Pune city to generate synthetic surveillance data. We simulate the impact of different public health strategies, availability of tests and contact tracing efficiencies on the resulting surveillance data as well as on the course of the epidemic. The fidelity of the resulting surveillance data in representing the real-time state of the epidemic and in decision-making is explored in the context of Pune city.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interpreting epidemiological surveillance data: A modelling study from Pune City\nAbstract: Routine epidemiological surveillance data represents one of the most continuous and comprehensive sources of data during the course of an epidemic. This data is used as inputs to epidemiological forecasting models as well as for public health decision making such as imposition and lifting of lockdowns and quarantine measures. However, such data is generated during testing and contact tracing and not through randomized sampling which makes it unclear how representative such data is of the epidemic itself. Using the BharatSim simulation framework, we build an agent-based epidemiological model with a detailed algorithm of testing and contact tracing representative of actual strategies employed in Pune city to generate synthetic surveillance data. We simulate the impact of different public health strategies, availability of tests and contact tracing efficiencies on the resulting surveillance data as well as on the course of the epidemic. The fidelity of the resulting surveillance data in representing the real-time state of the epidemic and in decision-making is explored in the context of Pune city.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and determinants of modern contraception use among persons with disabilities in low- and middle-income countries: a systematic review and meta-analysis\nAbstract: BackgroundPersons with disabilities should require the same level of access to contraception as the general population. However, the extent of contraception use among this group is underexplored in low- and middle-income countries (LMICs).  ObjectiveThis study aimed to determine the prevalence of modern contraception use among persons with disabilities in LMICs and identify the key determinants.  MethodsIn June 2024, we conducted a systematic search across six databases to identify studies on disability and modern contraception in LMICs. The primary outcomes were the prevalence of modern contraception use and its determinants among persons with disabilities. Summary estimates were calculated using fixed or random-effects meta-analysis, depending on the level of heterogeneity.  ResultsA total of 19 studies were identified, with 11 included in the meta-analysis. The pooled prevalence of modern contraception use among persons with disabilities was 31.4% (95% CI: 26.5, 36.2), with significant heterogeneity across respondent characteristics. Five factors were significantly associated with higher contraception use: age over 25 years, having some level of education, being in a higher wealth quintile, adequate knowledge of family planning, and being in a formal marital relationship.  ConclusionThis study reveals a significantly lower prevalence of modern contraception use among persons with disabilities in LMICs. Improving access to education, addressing social norms, and strengthening healthcare systems may contribute to increase contraception access and uptake among persons with disabilities in LMICs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of a booster dose of aerosolized or intramuscular adenovirus type 5 vectored COVID-19 vaccine in adults with hybrid immunity against COVID-19: a multicenter, partially randomized, platform trial in China\nAbstract: BackgroundThe primary objective of this research was to assess if a booster dose with COVID-19 vaccines containing ancestral strain could still provide significant protection against symptomatic SARS-CoV-2 infection in a predominantly hybrid-immune population during the period of omicron variant dominance.  MethodsWe did a multicenter, partially randomized, platform trial to evaluate the effectiveness of a booster dose of an aerosolized or intramuscular adenovirus type 5 vectored COVID-19 vaccine (Ad5-nCoV) in adults, after the national-wide omicron circulating at the end of year 2022 in China. Participants who were willing to receive a COVID-19 booster dose were randomly assigned to receive one of the booster doses. While, those participants who refused to take a booster dose but consented to participate COVID-19 surveillance were included in a control group. Both participants receiving a booster dose or not were monitored for symptomatic COVID-19 during a six-month surveillance period.  ResultsBetween May 23, 2023, and August 28, 2023, 4089 eligible participants were equally randomized to receive a booster dose of aerosolized Ad5-nCoV through oral inhalation at 0.1mL (IH Ad5-nCoV, n=2039) or intramuscular injection of Ad5-nCoV at 0.5 mL (IM Ad5-nCoV, n=2050). While, 2008 participants were enrolled in the blank-control group. A total of 79 COVID-19 cases were confirmed, with 22 (0.006%) in the IH Ad5-nCoV group, 23 (0.007%) in the IM Ad5-nCoV group, and 34 (0.01%) in the control group. Adjusted effectiveness of IH Ad5-nCoV and IM Ad5-nCoV from 14 days after the vaccination were 51.6% (95% CI 9.0 to 74.3) and 38.1% (95% CI - 9.6 to 65.1), respectively.  InterpretationSignificant protection against symptomatic COVID-19 caused by the Omicron variant, during the ongoing pandemic of evolving COVID-19 variants, was found to be provided by boosting with the ancestral strain-containing vaccine IH Ad5-nCoV, but not by boosting with IM Ad5-nCoV.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Modeling the effects of COVID-19 mobility disruptions on RSV transmission in Seattle, Washington\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSIntroductionC_ST_ABSRespiratory Syncytial Virus (RSV) infection is a major cause of acute respiratory hospitalizations in young children and older adults. In early 2020 most countries implemented non-pharmaceutical interventions (NPIs) to slow the spread of SARS-CoV-2. COVID-19 NPIs disrupted the transmission of RSV on a global scale, and many locations did not experience widespread re-circulation until late 2020 or 2021. Here, we use a mechanistic transmission model informed by cellphone mobility data to determine which aspects of population behavior had the greatest influence on post-pandemic RSV rebound in Seattle, Washington.  MethodsWe used aggregated mobile device location data to characterize within-city mixing, visitor in-flows, and foot traffic to points of interest in Seattle. We fit an age-structured epidemiological model to data on weekly RSV hospitalizations, allowing for reductions in transmission due to declines in mobility during the pandemic. We compared model fits to observed data to assess which mobility behaviors best capture RSV dynamics during the first two post-pandemic waves in Seattle.  ResultsIn Seattle, COVID-19 NPIs perturbed RSV seasonality from 2020 to 2022. Seattle experienced a small out-of-season outbreak in Summer 2021 and an atypically large and early wave in Fall 2022. RSV transmission models incorporating mobility network connectivity (measured as the average shortest path length between Seattle neighborhoods) or the inflow of visitors from outside of Seattle best captured the timing and magnitude of the first two post-pandemic waves. Models including foot traffic to schools or child daycares or within-neighborhood movement produced poor fits to observed data.  ConclusionsOur results suggest that case importations from other regions and local spread between neighborhoods had the greatest influence on the timing of RSV reemergence in Seattle. These findings contribute to the understanding of behavioral factors underlying RSV epidemic spread and can inform the timing of preventative measures, such as the administration of immunoprophylaxis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neuroinflammatory Disorders of the Central Nervous System Associated with Monkeypox Virus Infection: A Systematic Review and Call to Action\nAbstract: BackgroundThe Monkeypox virus, a zoonotic pathogen of the Orthopoxvirus genus, has shown a marked global spread, resulting in cases of neuroinflammatory disorders. This systematic review aims to summarize the central nervous system manifestations linked to monkeypox virus infection.  MethodsWe conducted a systematic review according to PRISMA guidelines. Databases such as PubMed, EMBASE, Cochrane Library, and Web of Science were searched up to September 2024. Inclusion criteria focused on monkeypox virus-positive patients with confirmed central nervous system inflammatory disorders, including encephalitis, meningitis, myelitis, and related neuroimmune diseases.  ResultsFrom 770 screened articles, 38 studies were included. Of the 20 reported monkeypox virus-infected cases with central nervous system involvement, the most common manifestations were encephalitis (40%), encephalomyelitis (30%), and meningoencephalitis (10%). Additional rarer presentations included Guillain-Barre syndrome (5%) and transverse myelitis (5%). The mean age of affected individuals was 27.9{+/-}13.69 years, and 75% were male. Fever, fatigue, and myalgia were the predominant systemic symptoms, with neurological complications often appearing within 4.6{+/-}2.5 days post-infection. Diagnoses were confirmed by quantitative reverse transcription polymerase chain reaction, magnetic resonance imaging, and cerebrospinal fluid analysis. Treatment strategies varied, with antivirals (e.g., tecovirimat) and immunomodulatory therapies (e.g., methylprednisolone, immunoglobulins, and rituximab) utilized.  ConclusionsMonkeypox virus infection is associated with severe neuroinflammatory disorders, with varying outcomes from complete recovery to mortality. Increased awareness, comprehensive diagnostic approaches, and targeted therapeutic interventions are critical in managing these cases. Further research is required to elucidate the mechanisms of neuroinflammation in the monkeypox virus and establish standardized treatment protocols.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: First imported Cases of MPXV Clade Ib in Goma, Democratic Republic of the Congo: Implications for Global Surveillance and Transmission Dynamics\nAbstract: The ongoing national mpox outbreak in the Democratic Republic of the Congo has resulted in more >30,000 suspected cases in the country from January 2023 to August 2024. While these historic case totals have been driven by primarily by zoonosis, the emergence of Clade Ib monkeypox virus (MPXV), which is connected to more sustained human-to-human transmission, has been associated with increasing public health impacts in eastern DRC. First identified in South Kivu province, Clade Ib MPXV has been identified in multiple non-endemic East African countries for the first time. In DRC, there have been concerns over broader Clade Ib expansion in the country that could further complicate containment and mitigation responses. Here, we report the first introductions of Clade Ib into North Kivu province, including within internal displacement camps, with suspected close contact transmission that includes non-intimate contacts and children. These findings demonstrate that mpox case investigations and community messaging campaigns should include considerations for non-sexual contact-mediated transmission of Clade Ib that includes children <15 years.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Multi-City COVID-19 Categorical Forecasting Model Utilizing Wastewater-Based Epidemiology\nAbstract: The COVID-19 pandemic highlighted shortcomings in forecasting models, such as unreliable inputs/outputs and poor performance at critical points. As COVID-19 remains a threat, it is imperative to improve current forecasting approaches by incorporating reliable data and alternative forecasting targets to better inform decision-makers.  Wastewater-based epidemiology (WBE) has emerged as a viable method to track COVID-19 transmission, offering a more reliable metric than reported cases for forecasting critical outcomes like hospitalizations. Recognizing the natural alignment of wastewater systems with city structures, ideal for leveraging WBE data, this study introduces a multi-city, wastewater-based forecasting model to categorically predict COVID-19 hospitalizations.  Using hospitalization and COVID-19 wastewater data for six US cities, accompanied by other epidemiological variables, we develop a Generalized Additive Model (GAM) to generate two categorization types. The Hospitalization Capacity Risk Categorization (HCR) predicts the burden on the healthcare system based on the number of available hospital beds in a city. The Hospitalization Rate Trend (HRT) Categorization predicts the trajectory of this burden based on the growth rate of COVID-19 hospitalizations. Using these categorical thresholds, we create probabilistic forecasts to retrospectively predict the risk and trend category of six cities over a 20-month period for 1, 2, and 3 week forecasting windows.  We also propose a new methodology to measure forecasting model performance at change points, or time periods where sudden changes in outbreak dynamics occurred. We also explore the influence of wastewater as a predictor for hospitalizations, showing its inclusion positively impacts the models performance. With this categorical forecasting study, we are able to predict hospital capacity risk and disease trends in a novel and useful way, giving city decision-makers a new tool to predict COVID-19 hospitalizations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deep Learning Models for Predicting the Nugent Score to Diagnose Bacterial Vaginosis\nAbstract: The Nugent score is a commonly used tool for diagnosing bacterial vaginosis; however, its accuracy depends on the skills of laboratory technicians. We aimed to evaluate the performance of deep learning models in predicting the Nugent score, with the goal of improving diagnostic consistency and accuracy. A total of 1,510 vaginal images collected from a hospital in Japan between 2021 and 2023 were assessed. Each image was annotated by laboratory technicians into one of four categories based on the Nugent score--normal vaginal flora, absence of vaginal flora, altered vaginal flora, or bacterial vaginosis. Deep learning models were developed to predict these categories, and their performance was evaluated by comparing the predicted scores with technician annotations. A high magnification model was further optimized and evaluated using an independent test set of 106 images to assess its performance relative to that of the technicians. The deep learning models demonstrated an accuracy of 84% at low magnification and 89% at high magnification in predicting the Nugent score categories. After optimization, the high magnification model achieved 94% accuracy, surpassing the average 92% accuracy of the technicians. The agreement between deep learning model predictions and technician annotations was 92% for normal vaginal flora, 100% for absence of vaginal flora, 91% for altered vaginal flora, and 100% for bacterial vaginosis. The deep learning models demonstrated accuracy comparable to that of laboratory technicians, which indicates their potential utility in improving the diagnostic accuracy of bacterial vaginosis.  IMPORTANCEBacterial vaginosis is a global health issue affecting women, causing symptoms such as abnormal vaginal discharge and discomfort. The Nugent score is the standard method for diagnosing bacterial vaginosis and is based on manual interpretation of Gram-stained vaginal smears. However, this method relies on the skill and experience of trained professionals, leading to variability in results and challenges in facilities with limited access to such experts. This poses significant challenges for settings with limited access to experienced technicians. The deep learning models developed in this study predict the Nugent score with high accuracy; thus, they can be used to standardize the diagnosis of bacterial vaginosis, reduce observer variability, and enable reliable diagnosis even in settings without experienced personnel. Although larger scale validation is needed, our results suggest that deep learning models may represent a new approach for the diagnosis of bacterial vaginosis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integration of Group A Streptococcus Rapid Tests with the Open Fluidic CandyCollect Device\nAbstract: The CandyCollect device is a lollipop-inspired open fluidic oral sampling device designed to provide a comfortable user sampling experience. We demonstrate that the CandyCollect device can be coupled with a rapid antigen detection test (RADT) kit designed for Group A Streptococcus (GAS). Through in vitro experiments with pooled saliva spiked with Streptococcus pyogenes we tested various reagents and elution volumes to optimize the RADT readout from CandyCollect device samples. The resulting optimized protocol uses the kit-provided reagents and lateral flow assay (LFA) while replacing the kits pharyngeal swab with the CandyCollect device, reducing the elution solution volume, and substituting the tube used for elution to accommodate the CandyCollect device. Positive test results were detected by eye with bacterial concentrations as low as the manufacturers \"minimal detection limit\" - 1.5x105 CFU/mL. LFA strips were also scanned and quantified with image analysis software to determine the signal-to-baseline ratio (SBR) and categorize positive test results without human bias. We tested our optimized protocol for integrating CandyCollect and RADT using CandyCollect clinical samples from pediatric patients (n=6) who were previously diagnosed with GAS pharyngitis via pharyngeal swabs tested with RADT as part of their clinical care. The LFA results of these CandyCollect devices and interspersed negative controls were determined by independent observers, with positive results obtained in four of the six participants on at least one LFA replicate. Taken together, our results show that CandyCollect devices from children with GAS pharyngitis can be tested using LFA rapid tests.  Table of Contents/Abstract Figure  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=152 SRC=\"FIGDIR/small/24312510v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (44K): org.highwire.dtl.DTLVardef@da56a5org.highwire.dtl.DTLVardef@6e84b8org.highwire.dtl.DTLVardef@1cb5a9dorg.highwire.dtl.DTLVardef@1aa07ac_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulating pathogens of humans: A systematic review of mechanistic transmission models\nAbstract: Historically, most mathematical models of infectious disease dynamics have focused on a single pathogen, despite the ubiquity of co-circulating pathogens in the real world. We conducted a systematic review of 311 published papers that included a mechanistic, population-level model of co-circulating human pathogens. We identified the types of pathogens represented in this literature, techniques used, and motivations for conducting these studies. We also created a complexity index to quantify the degree to which co-circulating pathogen models diverged from single-pathogen models. We found that the emergence of new pathogens, such as HIV and SARS-CoV-2, precipitated modeling activity of the emerging pathogen with established pathogens. Pathogen characteristics also tended to drive modeling activity; for example, HIV suppresses the immune response, eliciting interesting dynamics when it is modeled with other pathogens. The motivations driving these studies were varied but could be divided into two major categories: exploration of dynamics and evaluation of interventions. Finally, we found that model complexity quickly increases as additional pathogens are added. Future potential avenues of research we identified include investigating the effects of misdiagnosis of clinically similar co-circulating pathogens and characterizing the impacts of one pathogen on public health resources available to curtail the spread of other pathogens.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hospital-onset bacteraemia and fungaemia as a novel automated surveillance indicator: results from four European university hospitals\nAbstract: BackgroundConventional manual surveillance of healthcare-associated infections is labour-intensive and therefore often restricted to areas with high-risk patients. Fully automated surveillance of hospital-onset bacteraemia and fungaemia (HOB) may facilitate hospital-wide surveillance.  AimTo develop an algorithm and minimal dataset (MDS) required for automated surveillance of HOB and apply it to real-life routine data in four European hospitals.  MethodsThrough consensus discussion a HOB definition with MDS suitable for automated surveillance was developed and applied in a retrospective multicentre observational study including all admitted adult patients (2018-2022). HOB was defined as a positive blood culture with a recognised pathogen two or more days after hospital admission. For common commensals, two blood cultures with the same commensal within two days were required. Annual HOB rates were calculated per 1,000 patient days for the hospital and for intensive care units (ICU) and non-ICU.  ResultsHOB rates were comparable between the four hospitals (1.0 to 2.2 per 1,000 patient days). HOB rates were substantially higher in ICU than non-ICU across the four hospitals, and HOB with common commensals accounted for 14.8-28.2% of all HOB. HOB rates per 1,000 patient days were rather consistent over time, but were higher in 2020 and 2021. HOB caused by Staphylococcus aureus accounted for 8.4-16.0% of all HOB.  ConclusionAutomated HOB surveillance using a common definition was feasible and reproducible across four European hospitals. Future studies should investigate clinical relevance and preventability of HOB, and focus on strategies to make the automated HOB metric an actionable infection control tool.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Climate variation and serotype competition drive dengue outbreak dynamics in Singapore\nAbstract: Dengue poses a rapidly increasing threat to global health, with Southeast Asia as one of the worst affected regions. Climate-informed early warning systems can help to mitigate the impact of outbreaks; however, prediction of large outbreaks with sufficient lead time to guide interventions remains a challenge. In this work, we quantify the role of climatic variation and serotype competition in shaping dengue risk in Singapore using over 20 years of weekly case data. We integrated these findings into an early warning system framework able to predict dengue outbreaks up to 2 months ahead. While a climate-informed model improved predictive power by 54% compared to a seasonal baseline, including additional serotype information increased predictive performance to 60%, helping to explain interannual variation. By incorporating serotype competition as a proxy for population immunity, this work advances the field of dengue prediction and demonstrates the value of long-term virus surveillance.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging an Online Dashboard to Inform on Infectious Disease Surveillance: A case Study of COVID-19 in Kenya.\nAbstract: A multi-pronged approach to combating the COVID-19 pandemic in Kenya resulted in the formation of multidisciplinary research initiatives including genomic sequencing, syndromic surveillance, sero-surveillance, vaccination, and mathematical modelling. These initiatives generated an overwhelming amount of data that posed a challenge to researchers and public health officials, to effectively manage, analyse and promptly interpret for immediate pandemic response. As a result, there was demand for a platform to collate and integrate these datasets with interpretable findings to aid in pandemic management. In response, we developed a web-based dashboard, and integrated multidisciplinary datasets collected by the Ministry of Health-Kenya (MoH-K) and other research organizations, to support surveillance and monitoring of COVID-19 in Kenya. The developed dashboard combines genomics, epidemiological, seroprevalence, modelling, vaccination, syndromic and phylogenetic data and provides real-time updates to the public and health sector experts. The dashboard provides temporal trends of reported COVID-19 cases, fatalities, variants, and vaccination, in addition to summary reports from multiple cross-sectional seroprevalence studies and ongoing facility-based inpatient syndromic surveillance from 15 health facilities across Kenya. This is the first detailed interactive dashboard in Kenya that combines multiple datasets from a disease outbreak to provide valuable insights to researchers, health policy makers, the media and public not only during pandemic but also during routine surveillance. This resource is a model for digital platform for infectious disease surveillance and for informing public health planning and intervention.  Dashboard Linkhttps://kcd.kemri-wellcome.org/\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A next generation CRISPR diagnostic tool to survey drug resistance in Human African Trypanosomiasis.\nAbstract: The WHO aims to eliminate the gambiense form of human African trypanosomiasis (HAT) by 2030. With the decline of reported cases, maintaining efficient epidemiological surveillance is essential, including the emergence of drug-resistant strains. We have developed new highly specific diagnostic tools using Specific High-Sensitivity Reporter Enzymatic UnLOCKing (SHERLOCK) technology for monitoring the presence of drug-resistant genotypes that (1) are already circulating, such as the AQP2/3(814) chimera providing resistance to pentamidine and melarsoprol, or (2) could emerge, such as TbCPSF3 (N232H), associated to acoziborole resistance in lab conditions. The melarsoprol - pentamidineAQP2/3(814) SHERLOCK assay detected RNA from both cultured parasites and field isolated strains from gHAT patients in relapse following treatment. The acoziborole CPSF3(SNV)SHERLOCK assay discriminated between wild-type CPSF3 RNA and CPSF3 with a single A-C mutation that confers resistance to acoziborole in vitro.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Surveillance and control of neglected zoonotic diseases: methodological approaches to studying Rift Valley Fever, Crimean-Congo Haemorrhagic Fever and Brucellosis at the human-livestock-wildlife interface across diverse agricultural systems in Uganda\nAbstract: Background Zoonoses are of public health importance with most major emerging diseases originating in animal populations. Rift Valley Fever (RVF), Crimean-Congo Haemorrhagic Fever (CCHF) and Brucellosis are circulating in Uganda causing frequent outbreaks, but gaps exist in the understanding of transmission dynamics, community perspectives and effective mitigation strategies of these diseases. With increasing human-livestock-wildlife interaction in Uganda's biodiverse cattle corridor, this study protocol outlines an integrated One Health model to determine the burden of RVF, CCHF and Brucellosis, identify key vectors and reservoirs and assesses the impact of social and policy factors on disease distribution. Methods A series of mixed-methods cross-sectional and longitudinal surveys across six conservation areas experiencing high human-livestock-wildlife interaction spanning Uganda's Cattle Corridor: Queen Elizabeth National Park, Bwindi-Mgahinga Impenetrable Forest, Lake Mburo-Nakivaale, Murchison Falls, Kidepo Valley and Pian Upe Game Reserve. In selected villages household surveys comprise questionnaires, focus-group discussions and in-depth interviews to determine drivers of disease risk with blood-sampling of human population. Questionnaires provide detail on livestock practices and blood-sampling is conducted on cattle, sheep, pigs and goats. Targeted sampling of vectors in these localities including mosquitos, ticks and small mammals using environmental traps and on-host collection. Specimens taken from nearby large wildlife include blood sampling and nasal swabs. Serological testing using indirect ELISA and molecular testing using real-time PCR was conducted to determine disease status of RVF, CCHF and Brucellosis across humans, livestock and wildlife with eco-epi modelling and qualitative analyses used to inform risks and drivers of disease. Results Baseline survey data and blood specimens were obtained from 2894 humans residing in 1602 households across 96 villages in 6 conservation areas of Uganda. A further 379 community members participated in focus group discussions and key informant interviews with 978 reformed and active poachers across 4 conservation areas. 3692 livestock were sampled including 1925 cattle, 1409 goats, 282 sheep and 76 pigs from 358 herds. Vector data were collected for 18236 ticks, 53480 mosquitoes and 768 rodents. 241 large wildlife were sampled including buffalo, kobs, zebras, waterbucks, topi and hartebeest. 127 Community One Health Volunteers (COHVs) were enlisted to monitor and detect outbreaks in the study sites. Conclusions This paper outlines a comprehensive One Health approach to studying neglected zoonotic diseases integrating molecular epidemiology, social sciences and community participatory approaches involving humans, livestock, vectors and wildlife across 6 conservation areas in Uganda. It will inform interventions to enhance the surveillance and control of RVF, CCHF and Brucellosis including strengthening outbreak preparedness and response.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Surveillance and control of neglected zoonotic diseases: methodological approaches to studying Rift Valley Fever, Crimean-Congo Haemorrhagic Fever and Brucellosis at the human-livestock-wildlife interface across diverse agricultural systems in Uganda\nAbstract: Background Zoonoses are of public health importance with most major emerging diseases originating in animal populations. Rift Valley Fever (RVF), Crimean-Congo Haemorrhagic Fever (CCHF) and Brucellosis are circulating in Uganda causing frequent outbreaks, but gaps exist in the understanding of transmission dynamics, community perspectives and effective mitigation strategies of these diseases. With increasing human-livestock-wildlife interaction in Uganda's biodiverse cattle corridor, this study protocol outlines an integrated One Health model to determine the burden of RVF, CCHF and Brucellosis, identify key vectors and reservoirs and assesses the impact of social and policy factors on disease distribution. Methods A series of mixed-methods cross-sectional and longitudinal surveys across six conservation areas experiencing high human-livestock-wildlife interaction spanning Uganda's Cattle Corridor: Queen Elizabeth National Park, Bwindi-Mgahinga Impenetrable Forest, Lake Mburo-Nakivaale, Murchison Falls, Kidepo Valley and Pian Upe Game Reserve. In selected villages household surveys comprise questionnaires, focus-group discussions and in-depth interviews to determine drivers of disease risk with blood-sampling of human population. Questionnaires provide detail on livestock practices and blood-sampling is conducted on cattle, sheep, pigs and goats. Targeted sampling of vectors in these localities including mosquitos, ticks and small mammals using environmental traps and on-host collection. Specimens taken from nearby large wildlife include blood sampling and nasal swabs. Serological testing using indirect ELISA and molecular testing using real-time PCR was conducted to determine disease status of RVF, CCHF and Brucellosis across humans, livestock and wildlife with eco-epi modelling and qualitative analyses used to inform risks and drivers of disease. Results Baseline survey data and blood specimens were obtained from 2894 humans residing in 1602 households across 96 villages in 6 conservation areas of Uganda. A further 379 community members participated in focus group discussions and key informant interviews with 978 reformed and active poachers across 4 conservation areas. 3692 livestock were sampled including 1925 cattle, 1409 goats, 282 sheep and 76 pigs from 358 herds. Vector data were collected for 18236 ticks, 53480 mosquitoes and 768 rodents. 241 large wildlife were sampled including buffalo, kobs, zebras, waterbucks, topi and hartebeest. 127 Community One Health Volunteers (COHVs) were enlisted to monitor and detect outbreaks in the study sites. Conclusions This paper outlines a comprehensive One Health approach to studying neglected zoonotic diseases integrating molecular epidemiology, social sciences and community participatory approaches involving humans, livestock, vectors and wildlife across 6 conservation areas in Uganda. It will inform interventions to enhance the surveillance and control of RVF, CCHF and Brucellosis including strengthening outbreak preparedness and response.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reactogenicity and immunogenicity against MPXV of the intradermal administration of Modified V Vaccinia Ankara compared to the standard subcutaneous route.\nAbstract: The recent resurgence of Mpox in central Africa has been declared again a Public Health Emergency of International Concern (PHEIC) requiring coordinated international responses. Vaccination is a priority to expand protection and enhance control strategies, but the vaccines need exceeds the currently available doses. Intradermal administration of one-fifth of the standard Modified-Vaccinia-Ankara (MVA-BN) dose was temporarily authorized during the 2022 PHEIC. Studies conducted before 2022 provided evidence about the humoral response against the Vaccinia virus (VACV) after vaccination but not against the Mpox virus (MPXV). Moreover, no data are available on the T-cell response elicited by MVA-BN administered subcutaneously or intradermally. Here, we compare the two vaccine administration routes according to reactogenicity and immunogenicity based on data from 943 vaccine recipients during the 2022 vaccination campaign in Rome, Italy. We found that the intradermal route elicited slightly higher titers of MPXV-specific IgG and nAbs than the subcutaneous one. At the same time, no differences in cellular response were detected. MVA-BN was globally well tolerated despite higher reactogenicity for the intradermal than the subcutaneous route, especially for the reactions at the local injection site. The intradermal dose-sparing strategy was proven safe and immunogenic and would make vaccination available to more people.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Metagenomic detection of Mimiviridae reads in upper respiratory tract samples of SARS-CoV-2 patients\nAbstract: The upper respiratory tract (URT) virome is crucial in respiratory health and response to pathogens. While common respiratory viruses are well-studied, the presence and potential impact of giant DNA viruses, such as Mimiviridae, in the human URT remain underexplored. This study employed a whole genome metagenomics approach to profile the URT virome of 48 SARS-CoV-2-positive patients from central India. Mimiviridae reads were detected in two elderly male patients with severe acute respiratory infection (SARI) or influenza-like illness (ILI), contributing to 24% and 44% of the total virome in their samples. The dominant species were Acanthamoeba polyphaga mimivirus and Moumouvirus. Although Mimiviridae are not traditionally associated with human respiratory infections, their presence in SARS-CoV-2 patients raises questions about their potential role in co-infections and disease severity, particularly in individuals with ongoing respiratory infections. These findings underscore the need to investigate further giant viruses clinical significance, transmission, and pathogenicity in humans. Future research should focus on their epidemiology and the development of improved diagnostic tools to assess their contribution to human health.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Metagenomic detection of Mimiviridae reads in upper respiratory tract samples of SARS-CoV-2 patients\nAbstract: The upper respiratory tract (URT) virome is crucial in respiratory health and response to pathogens. While common respiratory viruses are well-studied, the presence and potential impact of giant DNA viruses, such as Mimiviridae, in the human URT remain underexplored. This study employed a whole genome metagenomics approach to profile the URT virome of 48 SARS-CoV-2-positive patients from central India. Mimiviridae reads were detected in two elderly male patients with severe acute respiratory infection (SARI) or influenza-like illness (ILI), contributing to 24% and 44% of the total virome in their samples. The dominant species were Acanthamoeba polyphaga mimivirus and Moumouvirus. Although Mimiviridae are not traditionally associated with human respiratory infections, their presence in SARS-CoV-2 patients raises questions about their potential role in co-infections and disease severity, particularly in individuals with ongoing respiratory infections. These findings underscore the need to investigate further giant viruses clinical significance, transmission, and pathogenicity in humans. Future research should focus on their epidemiology and the development of improved diagnostic tools to assess their contribution to human health.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biomarkers of atrial fibrillation-related pathways and left atrial structure and function in an overweight and obese population\nAbstract: BackgroundExploring longitudinal associations of blood biomarkers with left atrial (LA) structure and function can enhance our understanding of atrial fibrillation (AF) etiopathogenesis.  MethodsWe studied 532 participants of the PREDIMED-Plus trial, a multicenter randomized trial in overweight and obese adults with metabolic syndrome. At baseline, 3 and 5 years after randomization, participants underwent transthoracic echocardiography and provided blood for serum biomarker measurements [propeptide of procollagen type I (PICP), high-sensitivity (hs) troponin T (hsTnT), hs C-reactive protein (hsCRP), 3-nitrotyrosine (3-NT), and N-terminal propeptide of B-type natriuretic peptide (NT-proBNP)]. Outcomes of interest included LA peak systolic longitudinal strain (LA PSLS), LA volume index (LAVi), LA function index (LAFi), and LA stiffness index (LASi). We performed cross-sectional and longitudinal analyses to evaluate relationships between log-transformed biomarkers and echocardiographic measurements using multiple linear regression and mixed models.  ResultsThe participants in this analysis had a mean age of 65.0 (SD 4.8) years, and 40% were females. At baseline, increased NT-proBNP and hsTnT were associated with larger LAVi and worse LA function as measured by the LAFi, LASi, and LA PSLS. Longitudinally, higher NT-proBNP, but not higher hsTnT, was associated with increased LAVi and worsening LA function. Over 5 years, 1 unit increase in log(NT-proBNP) was associated with steeper decline in LA PSLS (-0.19%, 95% CI -0.35%, -0.02%) and greater increase in LAVi (0.28 mL/m2, 95% CI 0.10, 0.45) each year. PICP, hsCRP, and 3-NT did not show consistently significant associations with LA outcomes at baseline and through 5 years.  ConclusionIn an overweight and obese population, higher NT-proBNP was associated with LA volume enlargement and worsening LA function over 5 years. The implications of these findings for the prevention and prediction of AF warrant further investigation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Explicit solution of the SVIR (Susceptible-Vaccinated-Infectious-Recovered) epidemic model\nAbstract: An explicit solution of an initial value problem for the Susceptible-Vaccinated-Infectious-Recovered (SVIR) epidemic model is obtained, and various properties of the explicit solution are investigated. It is shown that the parametric form of the explicit solution satisfies some linear differential system including a positive solution of an integral equation. In this paper integral equations play an important role in establishing the explicit solution of the SVIR epidemic model, in particular, the number of infected individuals can be represented in a simple form by using a positive solution of an integral equation. Uniqueness of positive solutions of the SVIR epidemic model is also investigated, and it is shown that the explicit solution is a unique solution in the class of positive solutions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Public communication and outreach by mosquito programs in the United States\nAbstract: Blood feeding female mosquitoes cause itchy welts and can transmit pathogens that cause diseases such as chikungunya, malaria, West Nile encephalitis, and Zika. Mosquito control programs conduct mosquito, pathogen, and epidemiological surveillance, carry out source reduction, treat mosquito habitats with larvicides or adulticides, and disseminate information to the public. Here, 100 organizations (e.g., private/public mosquito control programs, national professional mosquito/pest control associations) in the United States were asked to complete a survey (N=39 respondents) about their public communication and outreach efforts. Results indicate most programs (N=27, 69%) have dedicated personnel for public communication. A checklist was constructed to compare communication strategies between a subset of program websites and Facebook pages. Recommendations for improving public communication and outreach strategies for mosquito control programs are discussed.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Employment Trajectories During the Menopause Transition: Experiences of Women with Early and Surgical Menopause\nAbstract: This study examines the labour market trajectories of women experiencing early and surgical menopause over a 10-year period surrounding their final menstruation or surgery, representing for most women the menopause transition. We also investigate the potential mediating role of hormone therapy (HT) in early postmenopause (within 5 years of menopause onset or surgery) in these relationships. Using data from the English Longitudinal Study of Aging (ELSA), we employ sequence and cluster analysis, followed by mediation analysis. Our findings indicate that women with early menopause, compared to those who undergo menopause at 45 or older, are less likely to have flexible working arrangements (part-time work or self-employment) compared to full-time work during this sensitive period. However, they are equally likely to exit the labour market as to work full-time, indicating distinct experiences. Surgical menopause, compared to natural menopause, is associated with an increased risk of labour market exit, particularly for women aged 45 or older at the time of surgery, potentially due to higher comorbidities and increased age-related precarity. HT use appears to mitigate the risk of labour market exit for women with both early and surgical menopause, although other factors (e.g., health) may play a more significant role in this transition out of work. We advocate for further research on the impact of early and surgical menopause on womens labour market circumstances and for workplace policies that consider the diverse experiences of women with early and surgical menopause, including their increased risk of chronic conditions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Female Infertility and Neurodevelopmental Disorders in Children: associations and evidence for familial confounding in Denmark\nAbstract: IMPORTANCEExisting research suggests the impact of infertility on the risk of neurodevelopmental disorders in children, however, studies to date have failed to separate the impact of male and female infertility, often blurring the lines with proxies that encompass all forms of infertility. Moreover, while both health conditions co-occurring with infertility and genetic factors operating upstream have been suggested to influence the association between infertility and child outcomes, their roles and potential impact on observed associations remain unclear.  OBJECTIVEThe objectives of this study are to investigate the relationship between female infertility and autism in the child, differentiating it from the effects of male and the couple infertility; consider the role of various maternal and birth factors in the association; and examine the effects of shared familial confounders on the association.  DESIGN SETTING AND PARTICIPANTSDanish population-based cohort study, including all singleton live births in Denmark 1998-2015, their parents and parents siblings. The cohort was followed up until December 31, 2016.  EXPOSURESThe exposure was a history of female infertility in the mother and the mothers sister. We examined four definitions of female infertility based on the ICD-10 codes derived from the Danish National Patient Register - any female infertility; specified female infertility; female exclusive infertility; and female or male infertility.  MAIN OUTCOME AND MEASURESThe outcome was diagnosis of autism spectrum disorder (ASD) in the Danish Psychiatric Central Research Register or the national patient register. A multivariable Cox regression model was used to estimate the associations between female infertility and autism, accounting for childs sex, year of birth, maternal age, education level, chronic comorbidities, and pregnancy and birth complications. The effects of shared familial factors on the association were analyzed using exposure information from the childs maternal aunt.  RESULTSThe cohort included 1,131,899 mother-child pairs, among which 18,374 children with ASD diagnosis. History of female infertility in the mother (all definitions) was significantly associated with autism in the child, with the association remaining robust after adjustment for covariates (HRadj=1.14 (95% CI, 1.03-1.26) for specified infertility). The diagnosis of infertility in a childs maternal aunt was also significantly linked to the childs autism risk, even after adjustment for maternal infertility (HRadj=1.10 (95% CI, 1.00-1.20).  CONCLUSIONS AND RELEVANCEin This population-based birth cohort study, we found a slightly higher risk of autism in children born to mothers with a history of infertility, with the association remaining consistent across various definitions of female infertility and robust to adjustments for demographic, child, and maternal factors. The study suggests for the first time that shared familial factors, possibly both genetic and non-genetic, could be influencing both female infertility and the risk of autism in children, indicating a need for further investigation into these familial effects.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Climate Change and Malaria: A Call for Robust Analytics\nAbstract: Mosquito ecology and malaria parasite development in mosquitoes display marked sensitivity to weather, in particular to temperature and precipitation. Therefore, climate change is expected to profoundly affect malaria epidemiology in its transmission, spatiotemporal distribution and consequent disease burden. However, malaria transmission is also complicated by other factors (e.g. urbanisation, economics, genetics, drug resistance) which together constitute a highly complex, dynamical system, where the influence of any single factor is highly uncertain.  In this study, we therefore aim to re-evaluate the evidence underlying the widespread belief that climate change will increase worldwide malaria transmission. We firstly review the different types of studies that have contributed to this evidence-base: i) studies that project changes in transmission due to inferred relationships between environmental and mosquito entomology; ii) studies that focus on either mechanistic transmission or time series models to estimate the effects of malaria control strategies on prevalence, and iii) regression-based studies that look for associations between environmental variables and malaria prevalence. We then employ a simple statistical model to show that environmental variables alone do not account for the observed spatiotemporal variation in malaria prevalence.  Our review raises several concerns about the robustness of the analyses used for advocacy around climate change and malaria. We find that, while climate changes effect on malaria is highly plausible, empirical evidence is much less certain. Future research on climate change and malaria must become integrated into malaria control programs, and understood in context as one factor among many affecting malaria. Our work outlines gaps in modelling that we believe are priorities for future research.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Statin uses and skeletal muscle-related phenotypes: insights from epidemiological and Mendelian randomization analyses\nAbstract: BackgroundThe association between statin use and skeletal muscle-related side effects is always controversial. This study aimed to comprehensively investigate the associations between statin use and muscle-related phenotypes including sarcopenia, sarcopenic obesity, serum lactate dehydrogenase (LDH), and musculoskeletal pain symptoms among adults with indications for statin use for secondary prevention (cardiovascular disease, diabetes, or hyperlipidemia).  MethodsThis cross-sectional study included 22,549 patients aged [&ge;]20 years with cardiovascular disease, diabetes, or hyperlipidemia. Weighted generalized linear regression analysis and propensity score matching methods were used to estimate the associations between the use of statins or other lipid-lowering agents and skeletal muscle-related phenotypes. Mendelian randomization (MR) analysis was additionally used to verify the causal relationship between statin use and skeletal muscle-related phenotypes.  ResultsThe weighted mean age was 59 years, 50.3% were male, and 37.6% (n=8,481) received statin treatment. In the unadjusted model, compared with adults without any lipid-lowering drugs, statin use was associated with a higher likelihood of sarcopenia (appendicular skeletal muscle mass [ASM]/Body mass index [BMI] OR 1.35 (95%CI 1.12 to 1.62, p < 0.001), ASM/weight [Wt] OR 1.86 (95%CI 1.62 to 2.13, p < 0.001), max HGS {beta} -3.01 (95% CI -3.97 to -2.06, p < 0.001), relative HGS {beta} -0.23 (95% CI -0.30 to -0.17, p < 0.001) and combined HGS {beta} -5.90 (95% CI -7.86 to -3.93, p < 0.001)), sarcopenic obesity (ASM/height squared [Ht2] and body fat percentage definition [OR 1.36 (95% CI 1.13 to 1.63, p < 0.001]). After multivariable adjustment or propensity score match, the independent associations of statin use with sarcopenia, sarcopenic obesity, HGS, LDH, and musculoskeletal pain became nonsignificant. Stepwise regression suggested that age was the predominant confounding factor for the associations. MR analysis also revealed no significant causality between statin use and skeletal muscle-related phenotypes.  ConclusionsOur epidemiological and MR analyses did not support the causality between statin use and skeletal muscle-related phenotypes. A higher likelihood of skeletal muscle-related adverse phenotypes in statin users may be attributed to age. Future studies should further explore the biological factors that may affect statin-related muscle phenotypes to provide evidence for the safety of statins.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Summary Estimates Derived from a Multi-state Non-Markov Framework to Characterize the Course of Heart Disease\nAbstract: Multi-state Markov models have been used to model the course of chronic disease. However, they are unsuitable to chronic disease where past and present states interplay and affect future states, and the estimated transition probabilities are time-specific which are not straightforward for public health interpretation. We have proposed a multi-state non-Markov framework that splits disease states into substates conditioning on past states. As the substates track past states and indicate multimorbidity, the estimated transition rates can be used to derive two summary estimates: Disease path which shows path of state transition, and multimorbidity-adjusted life year (MALY) which represents the adjusted life year in full health. In this paper, we showed the derivation of the two summary estimates and applied them to characterize the course of heart disease using data from the Atherosclerosis Risk in Communities Study (ARIC) study. The course of heart disease was modeled in five states, namely, healthy, at metabolic risk, coronary heart disease (CHD), heart failure, and mortality. In this mid- to old-age population, the estimated MALY was 24.13 (95% CI: 16.55, 32.06) years. For healthy participants at baseline, the most likely disease paths were: \"Healthy [-&gt;] at metabolic risk [-&gt;] mortality\" (37%), \"Healthy [-&gt;] mortality\" (21%), \"Healthy [-&gt;] at metabolic risk [-&gt;] heart failure [-&gt;] mortality\" (19%), and \"Healthy [-&gt;] at metabolic risk [-&gt;] CHD [-&gt;] mortality\" (8%). The MALY was higher among women than men and higher among Whites than Blacks. The distribution of disease path was similar across sex and race subgroups. In summary, MALY and disease path characterize the disease course in a summary manner and have potential use in chronic disease prevention.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Childhood conduct problems, potential snares in adolescence and problematic substance use in Brazil\nAbstract: ObjectiveExamine whether the relationship between childhood conduct problems and substance use in adulthood is explained through potential snares (police arrest, gang membership, school non-completion) in a Brazilian population-based birth cohort.  MethodData were analyzed from 4,599 young people from the 1993 Pelotas Birth Cohort in Brazil. The exposure was conduct problems at age 11 years. Outcomes included hazardous alcohol consumption and illicit drug use (age 22 years). Mediators included police arrest (by age 18 years), gang membership (ages 18 and 22 years), and school non-completion (by age 22 years). We performed counterfactual mediation using the parametric g-computation formula to estimate the indirect effect via all three mediators simultaneously.  ResultsAfter adjusting for confounders (including comorbidity), conduct problems were weakly associated with police arrest [OR (95% CI)=1.45 (0.97, 2.16)] and school non-completion [OR (95% CI)=1.46 (1.22, 1.74)], but not with gang membership. Police arrest and gang membership were associated with illicit drug use [OR (95% CI)=3.84 (2.46, 5.99); OR (95% CI)=7.78 (4.30, 14.10), respectively] and with hazardous alcohol use [OR (95% CI)=1.60 (1.08, 2.38); OR (95% CI)=1.88 (1.07, 3.30)]. However, there was no association between school non-completion and either outcome after confounder adjustment. There was little evidence for an indirect effect of conduct problems on hazardous alcohol use and illicit drug use via all three mediators after confounder adjustment.  ConclusionThe indirect effects of childhood conduct problems on substance use in early adulthood via police arrest, gang membership, and school non-completion were very small, after accounting for confounders and comorbidity.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Latent class growth mixture modelling of HbA1C trajectories identifies individuals at high risk of developing complications of type 2 diabetes mellitus in the UK Biobank\nAbstract: AimsGlycated Hemoglobin A1c (HbA1c) is widely used for the diagnosis and management of type 2 diabetes mellitus (T2D), with regular testing in primary care recommended every three to six months. We aimed to identify distinct, long-term HbA1c trajectories following a T2D diagnosis and investigate how these glycaemic control trajectories were associated with health-related traits and T2D complications.  MethodsA cohort of 12,435 unrelated individuals of European ancestry with T2D was extracted from the UK Biobank data linked to primary care records. Latent class growth mixture modelling was applied to identify classes with similar HbA1c trajectories over the 10-years following T2D diagnosis. We tested for associations of HbA1c class membership with sociodemographic factors, biomarkers, polygenic scores, and T2D-related outcomes, using logistic regression and Cox proportional hazards models.  ResultsSix HbA1c trajectory classes were identified. The largest class (76.8%) maintained low and stable HbA1c levels over time. The other five classes demonstrated higher and more variable trajectories and included: two with parabolic shapes (starting low and distinguished by the height of their peaks), two with high initial HbA1c levels that declined over time (one rapidly, one slowly), and one class with a rapid increase in HbA1c five years after diagnosis. Younger age at T2D diagnosis, higher fasting glucose levels, higher random glucose levels, and higher body mass index polygenic score were associated with membership of these five classes. These classes were also more likely to be prescribed glucose-lowering medication at diagnosis and had fewer primary care visits in the month and year prior to diagnosis. Relative to the low and stable class, these five showed increased risks of T2D complications, including stroke (HR=1.55 [1.31-1.84]), kidney disease (HR=1.39 [1.27-1.53]), all-cause mortality (HR=1.36 [1.23-1.51]), and progression to combination therapy (HR=3.22 [3.04-3.41]) or insulin (HR=3.21 [2.89-3.55]).  ConclusionIndividuals with T2D who show higher and more variable HbA1c trajectories are at increased risk of developing T2D-related complications. Early identification of patients at risk, based on factors such as age at diagnosis and previous healthcare utilisation could improve patient outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Temporal trends in the occurrence, mortality, and cost of brain disorders in Denmark\nAbstract: BackgroundBrain disorders, including neurological and mental disorders, are common and burdensome diseases.  AimTo examine temporal trends in occurrence, mortality, and cost of brain disorders in Denmark for the period of 2015-2021.  MethodsWe conducted a nationwide population-based cohort study using individual-level data recorded in the Danish health registries during 2011-2021. We computed the prevalence of any brain disorder and 25 individual brain disorders for each year from 2015 to 2021 and the incidence for the periods 2011-2015 and 2016-2021 by combining hospital diagnoses and filled prescriptions for relevant medications. We computed one-year hazard ratios (HRs) for mortality by comparing individuals with brain disorders to matched controls without. We also calculated attributable direct and indirect costs (i.e., lost productivity) of brain disorders.  ResultsThe prevalence of any brain disorder in Denmark was 33.2% in 2015, increasing to 35.2% in 2021. The three most prevalent conditions were depression (13.5% in 2021), sleep disorders (13.5% in 2021), and headache (7.9% in 2021). The incidence rate of any brain disorder was 1,792 and 1,634 per 100,000 person-years in 2011-2015 and 2016-2021, respectively. The one-year HR of mortality for any brain disorder was 5.5 (95% confidence internal [CI]: 5.4; 5.6) for 2011-2015 and 5.3 (95% CI: 5.2; 5.3) for 2016-2021. The total attributable direct costs for individuals with any brain disorder were {euro}7.5 billion in both 2015 and 2021. In 2021, the total attributable indirect costs were highest for depression ([~]{euro}3.5 billion) and lowest for neuromuscular disorders ([~]{euro}53.5 million). Total indirect costs increased from {euro}17.7 billion in 2015 to {euro}23.2 billion in 2021. In 2021, the total indirect costs were highest for depression ([~]{euro}14 billion) and lowest for other neurodegenerative disorders ([~]{euro}60 million).  ConclusionBrain disorders remain common, with a fivefold higher one-year mortality compared to persons without brain disorders. While total direct costs were similar in 2015 and 2021, total indirect costs increased over this period.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Overview and evaluation of a nationwide hospital-based surveillance system for Influenza and COVID-19 in Switzerland (CH-SUR): 2018-2023\nAbstract: BackgroundIn 2018, a hospital-based surveillance system for influenza (CH-SUR) was established in six tertiary care hospitals in Switzerland. From March 2020 onwards, this surveillance system was expanded to include more institutions, as well as COVID-19.  AimTo evaluate quantitatively and qualitatively the surveillance system CH-SUR.  MethodsAll patients admitted to one of the participating centres for more than 24 hours and who had a laboratory-confirmed influenza virus or SARS-CoV-2 infection were included in CH-SUR. For all cases, we evaluated the quality of the CH-SUR data, including timeliness and completeness of reporting. A qualitative survey among CH-SUR stakeholders assessed perceived importance, understanding, reliability and adaptability of CH-SUR.  ResultsUp to 20 centres participated in CH-SUR. Between December 2018 and October 2023, 7,375 cases of influenza were reported and between March 2020 and October 2023, 49,235 cases of COVID-19 were reported to CH-SUR. During the COVID-19 pandemic, time to data entry and completeness improved over time; the median delay of data entry in CH-SUR was 5 days (IQR=2-23) for COVID-19 and 4 days (IQR=2-15) for influenza during the period 2018-2023. The completeness of variables was high (99.4%), with the exception of COVID-19 or annual influenza vaccination status (respectively 15% and 72% of \"Unknown\" responses). Stakeholders perceived the system as important, relevant, understandable and adaptable.  ConclusionCH-SUR has provided critical epidemiological and clinical information on hospitalised influenza and COVID-19 cases across Switzerland during the pandemic. Our evaluation highlighted the importance and relevance of this system among CH-SUR stakeholders, as well as its importance for preparedness and response to future infectious disease outbreaks.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Overview and evaluation of a nationwide hospital-based surveillance system for Influenza and COVID-19 in Switzerland (CH-SUR): 2018-2023\nAbstract: BackgroundIn 2018, a hospital-based surveillance system for influenza (CH-SUR) was established in six tertiary care hospitals in Switzerland. From March 2020 onwards, this surveillance system was expanded to include more institutions, as well as COVID-19.  AimTo evaluate quantitatively and qualitatively the surveillance system CH-SUR.  MethodsAll patients admitted to one of the participating centres for more than 24 hours and who had a laboratory-confirmed influenza virus or SARS-CoV-2 infection were included in CH-SUR. For all cases, we evaluated the quality of the CH-SUR data, including timeliness and completeness of reporting. A qualitative survey among CH-SUR stakeholders assessed perceived importance, understanding, reliability and adaptability of CH-SUR.  ResultsUp to 20 centres participated in CH-SUR. Between December 2018 and October 2023, 7,375 cases of influenza were reported and between March 2020 and October 2023, 49,235 cases of COVID-19 were reported to CH-SUR. During the COVID-19 pandemic, time to data entry and completeness improved over time; the median delay of data entry in CH-SUR was 5 days (IQR=2-23) for COVID-19 and 4 days (IQR=2-15) for influenza during the period 2018-2023. The completeness of variables was high (99.4%), with the exception of COVID-19 or annual influenza vaccination status (respectively 15% and 72% of \"Unknown\" responses). Stakeholders perceived the system as important, relevant, understandable and adaptable.  ConclusionCH-SUR has provided critical epidemiological and clinical information on hospitalised influenza and COVID-19 cases across Switzerland during the pandemic. Our evaluation highlighted the importance and relevance of this system among CH-SUR stakeholders, as well as its importance for preparedness and response to future infectious disease outbreaks.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genomic recombination of rapidly evolving mpox Ib strains compounds the challenges of the 2024 outbreak\nAbstract: The World Health Organization recently declared the 2024 mpox virus (MPXV Ib) outbreak a public health emergency of international concern. We report that in 2023-2024, MPXV clade Ib genomes are diverging at a faster rate than clade IIb (2022), primarily due to an unusually high incidence of recombination. Phylogenetic analysis revealed that Ib strains have diverged into four lineages, and they have evolved into 14 subgroups based on nine tandem repeat (TR) polymorphisms. These findings confirms that TRs in MPXV Ib are mutating at a significantly higher frequency compared to the 2022 outbreak (clade IIb, 11 subgroups). Linkage disequilibrium analysis also identified 10 recombination clusters among all 4 lineages, with recombination incidence in Ib being twice as high as in IIb. This suggests that a higher rate of superinfection is contributing to ongoing recombination among populations infected with clade Ib. Prompt action is necessary to prevent the emergence of more lethal mpox strains.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of Ghanas COVID-19 policy responses and lessons learnt for the future: A multi-methods evaluation\nAbstract: Ghana implemented various mitigating policies in response to the COVID-19 outbreak. This study examined the effectiveness of these policies to contribute to the ongoing discussions on proactive and pre-emptive interventions for similar future outbreaks.  A mix of qualitative and quantitative methods were used for the analysis. Data were drawn from multiple sources, including peer-reviewed and grey literature, and academic experts from Ghanaian universities. The data from the literature informed a questionnaire that was sent to independent academic experts to explore their opinions on whether the policies met their intended objectives. The experts opinions were collected on a 5-point Likert scale and from an open-ended question using an online data collection platform, Qualtrics. The data were evaluated using narrative synthesis, descriptive statistics and thematic analysis.  We identified and evaluated eight key COVID-19 policy responses in Ghana: (1) partial lockdown of epicentres; (2) COVID-19 public awareness campaigns; (3) ban on public gatherings; (4) COVID-19 vaccination; (5) border closures; (6) entry border COVID-19 screening; (7) incentives for healthcare workers (HCWs); and (8) the Ghana Alleviation and Revitalisation of Enterprises Support (GCARES). Two policies - the COVID-19 awareness campaigns and border closure - effectively improved public awareness of COVID-19 and helped to reduce COVID-19 case importation (median score [&ge;]4).  Ghanas COVID-19 public awareness campaigns and border closure policies could serve as a valuable model for informing proactive interventions to address future infectious disease outbreaks.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mapping and sequencing of cases from an ongoing outbreak of Clade Ib monkeypox virus in South Kivu, Eastern Democratic Republic of the Congo between September 2023 to June 2024\nAbstract: BackgroundIn September 2023, an mpox outbreak was reported in the eastern part, South Kivu Province, of Democratic Republic of the Congo. This outbreak is still ongoing and expanding to other regions and countries. Here, we describe the epidemiological and genomic evolution of the outbreak from September 2023 to June 2024.  MethodsConsenting patients with mpox-like symptoms admitted to the Kamituga and the Kamanyola hospitals were recruited to the study. Samples from throat, lesions, breast milk and placenta were collected for PCR testing and sequencing. For the patients from Kamituga hospital, data on place of residence and possible exposures were collected by interviews. The location and numbers of employees were collected for all bars with sex workers. Where possible, exposures were linked to the genomic sequencing data for cluster analysis.  FindingsIn total, 670 (suspected) mpox cases were admitted to the Kamituga hospital. There were slightly more female than male cases (351/670 [52,4%] versus 319/670, [47,6%], and cases were reported from 17 different health areas. The majority of cases were reported in Mero (205/670 [30,6%]), followed by Kimbangu (115/670 [17,2%]), Kabukungu (105/670 [16,7%]), and Asuku (73/670 [10.9%]). During this period, 7 deaths occurred and 8 out of 14 women who were pregnant had fetal loss. Three healthcare workers acquired mpox infection when caring for patients. In depth case ascertainment showed that 83,4% of patients reported recent visits to bars for (professional) sexual interactions as a likely source of infection. Whole genome sequencing resulted in the generation of 58 genome sequences. Three main clusters characterized by specific mutations were identified and several miniclusters of 2 or more sequences with over two shared mutations. No clear link between sequence cluster, bar or health area was observed. The more recent sequences from Kamanyola were related to the sequences in Kamituga and confirmed to be Clade Ib. However, relatively long branches were observed and one of the sequences clustered with publicly released sequences from travelers in Kenya, Uganda, Sweden and Thailand, indicating more undocumented ongoing spread for cluster A than for the other clusters. Most observed mutations were APOBEC-3 related mutations indicative of ongoing human-to-human transmission.  InterpretationThese data suggests that the rapid transmission of monkeypox virus until June 2024 was mostly related to interactions with professional sex workers (PSW) within densely populated health areas. The expanding number of cases and the recent expansion to 29 other nearby health zones of South -Kivu as well as Rwanda, Burundi, Uganda and Kenya stresses the need for cross border surveillance and collaboration. Urgent enhanced response action is needed, including case finding, diagnostic capacity building, health education programmes focussing on sex workers, and possibly vaccination to limit further escalation and stop this outbreak.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Humoral Immune Responses in German Dialysis Patients after mRNA Omicron JN.1 Vaccination\nAbstract: To assess the effect of the updated mRNA JN.1 omicron vaccine (bretovameran, BioNTech/Pfizer, Mainz, Germany) in an immunocompromised and elderly population, we measured humoral immune responses after mRNA omicron JN.1 vaccination in 37 haemodialysis patients before and 21 days after vaccination.  We observed a 3-fold change in anti-S IgG, and a 4{middle dot}7-fold change in anti-S omicron IgG. Memory B cells (MBC) exclusively binding the receptor binding domain (RBD) of JN.1 displayed a median frequency of 0{middle dot}11% before vaccination and changed significantly 3{middle dot}9-fold to a median of 0{middle dot}43%. Cross reactive JN.1 RBD and Wuhan-Hu-1 S-binding MBCs and MBCs only binding to Wuhan-Hu-1 S changed 2{middle dot}3-fold and 1{middle dot}8-fold, respectively. Using a vesicular stomatitis virus-based pseudovirus particle (pp) neutralisation assay, baseline response rates were 86% for XBB.1.5pp, 78% for JN.1pp, 73% for and KP.2pp, 65% for KP.2.3pp and KP.3pp, and 68% for LB.1pp. After vaccination, the response rates for all pseudoviruses increased significantly, and we observed a mean increase in neutralisation of XBB.1.5pp, JN.1pp, KP.2pp, KP.2.3pp, KP.3pp, and LB.1pp of 8{middle dot}3-fold, 18{middle dot}7-fold, 22{middle dot}5-fold, 18{middle dot}7-fold, 25{middle dot}5-fold, and 23{middle dot}5-fold, respectively. In summary, our report provides first evidence for a firm humoral immune response in dialysis patients after mRNA omicron JN.1 vaccination.  Our data suggest that the vaccine could be highly effective at enhancing protection of vulnerable populations against evolving SARS-CoV-2 variants.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integrating Clinical Research with Electronic Health Records to Improve Diversity in Research: Findings from an Urban Hospital System\nAbstract: BackgroundThe under-representation of racial, ethnic, and other minority populations in clinical research has threatened the validity of novel therapeutic interventions and exacerbated the longstanding inequities in health outcomes. Despite attention and mandates across institutions and federal agencies to address these disparities, effective and actionable strategies have remained a subject of debate in the existing literature. Thus, the need for comprehensive and rigorous methods to assess diversity in study population samples as well as strategies for improved recruitment and retention has been made clear.  ObjectiveExamine the distribution of research participant demographics at Norton Healthcare (NHC) and compare to applicable benchmarks from the overall NHC patient population and local census.  DesignSuccessive-independent samples comparison of EPIC electronic health records (EHR) and census data from Jefferson County.  ParticipantsA total of 2,053 adult research participants enrolled at NHC from 2020 - 2024.  Main MeasuresDemographic data were reported as frequency and percentage across the three benchmarks. The z-test for independent proportions was used to compare the research participant demographics to the NHC patients and Jefferson County during a consistent time period. Temporal trends in research participant demographics were also examined.  Key ResultsApart from being relatively older, the NHC research participant population closely resembled the NHC patient population. A similar age-related pattern emerged as well as an over-representation of White individuals in the research participant group when compared to the census data. When looking at research participant demographic trends overtime, increases in White, Black and older cohorts were noted while decreases were observed in Hispanic/Latinx and younger cohorts. Trends related to participant sex remained stable.  ConclusionsThe findings from this study will inform future strategies for setting enrollment goals and facilitate the creation of tools and metrics to evaluate appropriate standards for diversity in clinical research study population samples.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cohort profile: design, sociodemographic characteristics, chronic disease risk factors, and baseline hypertension and diabetes care cascades of the open, prospective Community-Based chronic disease Care Lesotho (ComBaCaL) cohort\nAbstract: PurposeThe open, prospective Community-Based chronic Care Lesotho (ComBaCaL) cohort is the first study to comprehensively investigate socioeconomic indicators, common chronic diseases and their risk factors in a remote rural setting in Lesotho. It serves as a platform for implementing nested trials using the Trials within Cohorts (TwiCs) design to assess community-based chronic care interventions. Here, we present the cohorts sociodemographic and chronic disease risk factor profile, including self-reported HIV prevalence and hypertension and diabetes care cascades.  ParticipantsSince February 2023, Community Health Worker (CHWs) supported by a clinical decision support and data collection application, have enrolled inhabitants from 103 randomly selected rural villages in Butha-Buthe and Mokhotlong districts in North-East Lesotho. As of May 31, 2024, the cohort includes 5008 households with 14735 participants (55% female, median age 19 years). The cohorts socioeconomic status is low with an International Wealth Index of 26, a monthly household income of 42.4 USD and low levels of formal education. Among the 7917 adult participants, 42.5% are overweight or obese, with higher rates among women, and 33.1% smoke tobacco, with higher rates among men. Self-reported HIV prevalence is 15.1% with a 98.4% treatment rate. Hypertension prevalence is 17% with a 56% control rate and diabetes prevalence is 4% with a 39% control rate.  Findings to dateThe cohorts low socioeconomic status is linked to multiple health risks including insufficient access to clean energy, essential healthcare services, adequate sanitary facilities and secure food supply. Besides the expected high HIV prevalence, we found significant hypertension, diabetes and cardiovascular risk factor prevalences. While treatment and control rates for diabetes and hypertension are higher than in similar settings, they remain below global targets.  Future plansOngoing cluster-randomized TwiCs, which will be completed in 2025, are assessing the effectiveness of community-based, CHW-led care interventions for diabetes and hypertension. CHWs will continue to closely monitor the cohort and integrate additional measurements such as HIV testing. This will provide further insights into the dynamics and interactions of chronic diseases and inform the development of future nested trials on innovative community-based prevention and care interventions.  RegistrationNCT05596773  Strengths and limitations- Comprehensive Data Collection: The ComBaCaL cohort offers comprehensive data on sociodemographics, chronic disease risk factors, and hypertension and diabetes care cascades within a large, representative sample of the rural population in Lesotho. - Community-Based Approach: Data is captured by local Community Health Workers residing in the study villages using a tailored clinical decision support and data collection application. This approach allows for continuous data collection, remote monitoring by study staff, and data verification, ensuring nearly complete village enrolment and high data quality. - Efficient study design: The cohort utilizes the Trials within Cohorts (TwiCs) design, which allows for the efficient implementation of multiple randomized nested trials to assess the effectiveness of innovative health interventions. - Reliance on self-reported data: Assessments other than hypertension and diabetes screening outcomes rely on self-reported data, which may have limited correlation with objective assessments. - Limitations in data scope: Clinical data on chronic conditions other than hypertension and diabetes remain limited and anthropometric and behavioural risk factor data for children has not yet been collected.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The potential global impact and cost-effectiveness of next-generation influenza vaccines: a modelling analysis\nAbstract: BackgroundNext-generation influenza vaccines (NGIVs) are in development and have the potential to achieve greater reductions in influenza burden, with resulting widespread health and economic bene[fi]ts. Understanding the prices at which their market can be sustained and which vaccination strategies may maximise impact and cost-effectiveness, particularly in low- and middle-income countries, can provide a valuable tool for vaccine development and investment decision-making at a national and global level. To address this evidence gap, we projected the health and economic impact of NGIVs in 186 countries and territories.  Methods and FindingsWe inferred current influenza transmission parameters from World Health Organization (WHO) FluNet data in regions de[fi]ned by their transmission dynamics, and projected thirty years of influenza epidemics, accounting for demographic changes. Vaccines considered included current seasonal vaccines, vaccines with increased efficacy, duration, and breadth of protection, and universal vaccines, de[fi]ned in line with the WHO Preferred Product Characteristics. We estimated cost-effectiveness of different vaccination scenarios using novel estimates of key health outcomes and costs.  NGIVs have the potential to substantially reduce influenza burden: compared to no vaccination, vaccinating 50% of children aged under 18 annually prevented 1.3 (95% uncertainty range (UR): 1.2-1.5) billion infections using current vaccines, 2.6 (95% UR: 2.4-2.9) billion infections using vaccines with improved efficacy or breadth, and 3.0 (95% UR: 2.7-3.3) billion infections using universal vaccines. In many countries, NGIVs were cost-effective at higher prices than typically paid for existing seasonal vaccines. However, cross-subsidy may be necessary for improved vaccines to be cost-effective in lower income countries.  This study is limited by the availability of accurate data on influenza incidence and influenza-associated health outcomes and costs. Furthermore, the model involves simplifying assumptions around vaccination coverage and administration, and does not account for societal costs or budget impact of NGIVs. How NGIVs will compare to the vaccine types considered in this model when developed is unknown. We conducted sensitivity analyses to investigate key model parameters.  ConclusionsThis study highlights the considerable potential health and economic bene[fi]ts of NGIVs, but also the variation in cost-effectiveness between high-income and low- and middle-income countries. This work provides a framework for long-term global cost-effectiveness evaluations, and contributes to a full value of influenza vaccines assessment to inform recommendations by WHO, providing a pathway to developing NGIVs and rolling them out globally.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The impact of service wait times on General Practitioners' treatment of adolescent depression and anxiety\nAbstract: BackgroundGeneral Practitioners (GPs) play a key role in the treatment of adolescent depression and anxiety, but their capacity to provide effective care may be compromised by long wait times.  AimTo examine the treatments and recommendations of GPs for adolescent patients with depression and/or anxiety in Australia, their referral practices to specialist care and estimated wait times for these, and the perceived impact of long wait times on GPs, their patients and their treatment.  Design, Setting and MethodsAn online survey of 192 GPs in Australia who treated adolescents (12 to 17 years old) with depression and/or anxiety.  ResultsGPs frequently referred adolescents with depression and/or anxiety to psychologists. The estimated wait time for psychologists (M: 57 days, SD: 47.9) was four times the proposed acceptable wait time (M: 16.7 days, SD: 27.0). The frequency of medication prescribing almost doubled during the wait time when compared to routine practice (14.6% versus 8.3%, respectively). Almost all GPs (81.8%) increased their level of care due to long wait times but had limited training in youth mental health and knowledge on appropriate strategies to do so effectively.  ConclusionThe findings signify the discrepancies between the preferences of GPs for treatment availability in Australia and what they see as the experience for many adolescents with depression and/or anxiety who are referred to specialist care. Greater training, improved communication between referrer and referred services, and digital interventions may help GPs to reduce the negative impacts of long wait times on their adolescent patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: From peas to people - using quantitative traits to aid genetic discovery in depression\nAbstract: A key component of Mendels work is what we now refer to as pleiotropy - when variation in one gene gives rise to variation in multiple phenotypes.  This study focuses on aiding genetic discovery in depression by revisiting the depressed phenotype and developing a quantitative trait in a large mixed family and population study, using analyses built upon the theory which underpins Mendels pleiotropic observations - the relationship between phenotypic variation and genetic variation.  Measures of genetic covariation were used to evaluate and rank ten measures of mood, personality, and cognitive ability as endophenotypes for depression. The highest-ranking traits were subjected to principal component analysis, and the first principal component used to create multivariate measures of depression.  Four traits fulfilled most endophenotype criteria, however, only two traits (neuroticism and the general health questionnaire) consistently ranked highest across all measures of covariation. As such, three composite traits were derived incorporating two, three, or four traits.  Composite traits were compared to the binary classification of depression and to their constituent univariate traits in terms of their coheritability, their ability to identify risk loci in a genome-wide association analysis, and phenotypic variance explained by polygenic profile scores for depression.  Association analyses of binary depression, univariate traits, and composite traits yielded no genome-wide significant results. However, composite traits were more heritable and more highly correlated with depression than their constituent traits, suggesting that analysing candidate endophenotypes in combination captures more of the heritable component of depression and may in part be limited by sample size in the current study.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mapping the Psychopathic Brain: Divergent Neuroimaging Findings converge onto a Common Brain Network\nAbstract: Psychopathy is a personality disorder characterized by a constellation of interpersonal, affective, lifestyle, and antisocial features. However, its neural underpinnings remain poorly understood because functional neuroimaging studies have produced disparate findings. Here, we tackled this lack of replication by investigating whether peak coordinates of studies on psychopathy could in fact map onto a common functional connectivity network. An updated meta-analysis of 23 functional neuroimaging studies (534 cases vs 594 controls) first revealed no significant regional spatial convergence. However, using functional connectomes of 1,000 healthy participants, we demonstrated that the heterogeneous study findings do indeed converge onto a common brain network with a replicability reaching up to 85.2% across studies. We subsequently showed strong associations between this Psychopathy Network and a lesion network of 17 lesion sites causally linked to antisocial behaviors, as well as its association with neurotransmission systems and genetic markers previously implicated in the pathophysiology of psychopathy. Taken together, our study highlights the importance of examining the neural correlates of psychopathy from a network perspective, which can be validated using a multilevel approach, encompassing neural, genetic and neurochemical data. Ultimately, this approach may pave the way for novel and more personalised treatments.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Healthy Human Global Project - Hong Kong : a community-based cross-sectional study of a healthy Asian population\nAbstract: Immune responses are highly variable from one individual to another, with this variability determined by factors such as age, sex, genetics and environment, which also affect physical and mental well-being. Systems immunology studies have been applied to human cohort studies to better understand these effects, but most are performed in Western populations of mostly European ancestry, neglecting the vast majority of human global diversity. To overcome this limitation, we established the Healthy Human Global Project - Hong Kong (HHGP-HK) cohort to allow the study of immune variability in a healthy Asian population. Taking inspiration from the established French Milieu Interieur study we adapted inclusion and exclusion criteria to identify healthy donors, and to facilitate cross comparison between the two cohorts we collected similar demographic, medical and lifestyle information. To study the effects of age and sex, donors were stratified for both ranging from 20-79 years. We report here significant age and sex effects on multiple clinical laboratory measures, many of which were consistently observed in the Milieu Interieur cohort. C-reactive protein and liver enzymes were two exceptions perhaps reflecting different environmental effects between the two cohorts. We applied biological aging, physiological, and mental health scores to our cohort which highlights the need to develop and adapt such scores for application to populations of non-European descent. We also included wearable fitness trackers from which we observed significant age and sex differences for sleep, physical activity, and heart rate variability. This unique cohort will enable the better understanding of factors that determine immune variability within Asian populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Time on Task in Psychotherapeutic/Psychoeducational Intervention with Intermittent Explosive Disorder\nAbstract: ObjectiveAnger control has been seen as a set of learnable skills. How much time is necessary for such learning? Comparisons with time requirements for other skills make it plausible that for many people, learning anger control may require well over 100 hours of time on task. Research interventions have been shorter -- a mean of 9 sessions was reported in one meta-analysis. In this study, our goal was to examine how much psychotherapeutic intervention is being delivered in the \"real world\" to patients with Intermittent Explosive Disorder.  MethodWe studied a de-identified electronic health record data from TriNetX, collected from 87 medical institutions. We studied 32,322 individuals with Intermittent Explosive Disorder. We examined the distribution of the number of individuals across numbers of sessions received.  ResultsThe distribution for the numbers of sessions is highly skewed, resembling a curve of inverse proportion, or a Pareto function. The mode and the median were zero. Only about 25% of patients received any psychotherapy. For that subset, the median was 5 sessions, and the mean was 16. Approximately 10% received 9 visits or more; 5% 30 or more; 2% 50 or more. A large fraction of the psychotherapeutic labor was devoted to a small fraction of the patients: 80% of the sessions went to 7.5% of the patients.  ConclusionsThe ability of health care systems to reduce the societal problem of aggression, at least by psychotherapeutic intervention, appears limited by the factors leading to low, or no, time on task.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Selected miRNAs in urinary extracellular vesicles show promise for non-invasive diagnostics of diabetic kidney disease\nAbstract: Diabetic kidney disease is a growing health burden that lacks specific early non-invasive diagnostic procedures. To approach a solution for this clinical need, we sequenced microRNAs of urinary extracellular vesicles and performed biomarker discovery by small RNA sequencing in a type 1 diabetes cohort including males with and without albuminuria. The results were replicated by sequencing or qPCR in two independent cohorts and four previously published datasets including type 1 and 2 diabetes as well as both sexes. Non-diabetic and prostate cancer cohorts were used as additional controls and miRNAs changed due to preanalytical urine collection variables were excluded. Using these data, we additionally validated previously identified reference candidate miRNAs. Correlations with clinical parameters, receiver operating characteristic analysis, targeted mRNAs and pathways including integrated single cell data, and targeted circulating proteins from type 1 and 2 diabetes cohorts were analyzed. We pinpointed 6 stable microRNAs, 11 differentially expressed microRNAs, 9 target proteins and 16 DKD-associated pathways in individuals with diabetic kidney disease. Replication showed that the differentially expressed miRNAs in DKD were partly shared between diabetes subtypes and sexes with overall strongest evidence for miR-192-5p, miR-146a-5p, miR-486-5p, and miR-574-5p. Combination of these miRNAs with clinical variables showed potential to classify individuals with the fastest kidney function decline (sensitivity 0.75-1.00 and specificity 0.83-1.00) even in the normoalbuminuria group, thus holding the potential as early diagnostic markers. Altogether, the candidate microRNAs show specificity for diabetic kidney disease, identify declining kidney function, and target key kidney cell types, mRNAs, proteins, and pathogenic mechanisms.  Lay summaryDiabetic kidney disease (DKD) damages the kidneys severely. DKD progression differs between diabetes subtypes and sexes and currently the diagnosis comes too late when the kidney is already damaged. Thus, clinical care needs better and earlier diagnostic markers. Here we studied the microRNAs in urinary extracellular vesicles, small particles secreted actively by the kidney cells. We found 11 candidate microRNA markers for DKD. The discovery was made in males with type 1 diabetes, but some of the microRNAs were confirmed across type 1 and 2 diabetes, as well as female or combined sex populations. Altogether we studied over 250 samples. Analysis of miRNAs regulatory pathways and correlations with clinical measurements in individuals with DKD suggest that some miRNAs may hold the potential as early diagnostic markers. Our findings could thus impact clinical practice by providing early and specific DKD diagnostic tools allowing effective care at an early DKD stage.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Low-intensity focused ultrasound stimulation in stroke: An intensity escalation phase I safety and feasibility study\nAbstract: BACKGROUNDLow-intensity focused ultrasound stimulation (LIFUS) has recently emerged as a promising neuromodulation tool for certain neuropsychiatric diseases. However, its safety and feasibility in stroke patients remains unknown. Intensity is a critical safety parameter for LIFUS. We aimed to determine the maximum safe and tolerable intensity of LIFUS in stroke patients, and to explore its effect on upper-extremity motor learning and corticospinal excitability.  METHODSSubjects with first-ever stroke participated in this Phase I study. We adopted the classic 3+3 dose-escalation paradigm to sham/0, 1, 2, 4, 6, and 8 W/cm2 spatial-peak pulse-average intensity (ISPPA, estimated in-vivo transcranial value; LOW: sham/0, 1 and 2 W/cm2, HIGH: 4, 6 and 8 W/cm2). Stopping rules (dose limiting toxicities) were pre-defined: [&ge;]2nd-degree scalp burn, clinical seizures, [&ge;]20% topical apparent diffusion coefficient change, or participant discontinuation due to any reason. A 12-minute LIFUS was applied over the ipsilesional motor cortex while participants were concurrently practicing three blocks of motor sequence learning (MSL) task using the affected hand. We collected the occurrences of pre-defined adverse events, post-minus-pre improvements in MSL response time, and post-minus-pre differences in corticospinal excitability quantified by motor evoked potentials.  RESULTSISPPA was escalated to 8 W/cm2 with eighteen stroke participants without meeting stopping rules. Compared to the LOW, the HIGH performed significantly better on the MSL (24.7{+/-}13.3% vs. 13.2{+/-}10.9%, p=0.01). Similarly, the HIGH also showed signs of increased corticospinal excitability (32.0{+/-}34.3% vs. 12.9{+/-}48.0%) but did not reach significance, p=0.53.  CONCLUSIONSOur Phase I safety study suggests that a single session of 12-minute LIFUS up to 8 W/cm2 ISPPA is safe and feasible in stroke patients. Higher LIFUS intensities can induce greater MSL retention. The next logical step is to conduct a Phase II study to further test the efficacy of LIFUS and monitor its safety profiles in stroke patients.  REGISTRATIONURL: https://www.clinicaltrials.gov; Unique identifier: NCT05016531\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Systematic Review of the Etiology and Neurobiology of Intermittent Explosive Disorder\nAbstract: Intermittent Explosive Disorder (IED) is characterized by repeated inability to control aggressive impulses. Although the etiology and neurobiology of impulsive anger and impulse control disorders have been reviewed, no systematic review on these aspects has been published for IED specifically. We conducted a systematic search in seven electronic databases for publications about IED, screened by two authors, and retained twenty-four studies for the review. Our findings highlight a multifactorial etiology and neurobiology of IED, emphasizing the role of the amygdala and orbitofrontal cortex in emotional regulation and impulse control, and supporting interventions that target serotonergic signaling. Research also shows that childhood trauma and adverse family environment may significantly contribute to the development of IED. Yet, genetic studies focusing on IED were largely lacking, despite many examining the genetics underlying aggression as a general trait or other related disorders. Future research using consistently defined IED as a phenotype is required to better understand the etiology and underlying mechanisms and assist in informing the development of more effective interventions for IED.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Forecasting local surges in COVID-19 hospitalizations through adaptive decision tree classifiers\nAbstract: During the COVID-19 pandemic, many communities across the US experienced surges in hospitalizations, which strained the local hospital capacity and affected the overall quality of care. Even when effective vaccines became available, many communities remained at high risk of surges in COVID-19-related hospitalizations due to waning immunity, low uptake of booster vaccinations, and the continual emergence of new variations of SARS-CoV-2. Some risk metrics, such as the CDCs Community Levels, were developed to predict the impact of COVID-19 on the community-level healthcare system based on routine surveillance data. However, they had limited utility as they were not routinely updated based on accumulating data and were not directly linked to specific outcomes, such as surges in COVID-19 hospitalizations beyond local capacities. Regression models could resolve these limitations, but they have limited interpretability and do not convey the reasoning behind their predictions. In this paper, we evaluated decision tree classifiers that were developed in \"real-time\" to predict surges in local hospitalizations due to COVID-19 between July 2020 and November 2022. These classifiers would have provided visually intuitive and interpretable decision rules for local decision-makers to understand and act upon, and by being updated weekly, would have responded to changes in the epidemic. We showed that these classifiers exhibit reasonable predictive ability with the area under the receiver operating characteristic curve (auROC) > 80%. These classifiers maintained their performance temporally (i.e, over the duration of the pandemic) and spatially (i.e., across US counties). We also showed that these classifiers outperformed the CDCs Community Levels for predicting high hospital occupancy.  Significance StatementA major concern during the COVID-19 pandemic was the risk of exceeding local healthcare capacity due to COVID-19-related hospitalizations. To assess this risk and inform mitigating strategies, several risk assessment tools were developed during the pandemic. Many of these tools, however, did not predict local outcomes, were not updated as the pandemic progressed, and/or were not interpretable by decision-makers. We propose an adaptive framework of decision tree classifiers to predict whether COVID-19-related hospital occupancy would exceed a given capacity threshold. This framework would provide interpretable classification rules to predict surges in local hospitalizations,and maintained its performance over time and across US counties, and outperformed the CDCs Community Level tool.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Framework to Assess Clinical Safety and Hallucination Rates of LLMs for Medical Text Summarisation\nAbstract: The integration of large language models (LLMs) into healthcare settings holds great promise for improving clinical workflow efficiency and enhancing patient care, with the potential to automate tasks such as text summarisation during consultations. The fidelity between LLM outputs and ground truth information is therefore paramount in healthcare, as errors in medical summary generation can lead to miscommunication between patients and clinicians, leading to incorrect diagnosis and treatment decisions and compromising patient safety. LLMs are well-known to produce a variety of errors. Currently, there is no established clinical framework for assessing the safety and accuracy of LLM-generated medical text.  We have developed a new approach to: a) categorise LLM errors within the clinical documentation context, b) establish clinical safety metrics for the live usage phase, and c) suggest a framework named CREOLA for assessing the safety risk for errors. We present clinical error metrics over 18 different LLM experimental configurations for the clinical note generation task, consisting of 12,999 clinician-annotated sentences. We illustrate the utility of using our platform CREOLA for iteration over LLM architectures with two experiments. Overall, we find our best- performing experiments outperform previously reported model error rates in the note generation literature, and additionally outperform human annotators. Our suggested framework can be used to assess the accuracy and safety of LLM output in the clinical context.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development and Validation of Nomograms for predicting Coronary Artery Calcification and Severe Coronary Artery Calcification: a retrospective cross-sectional study\nAbstract: IntroductionThere is a significant lack of effective pharmaceutical interventions for treating coronary artery calcification (CAC). Severe CAC (sCAC) poses a formidable challenge to interventional surgery and exhibits robust associations with adverse cardiovascular outcomes. Therefore, it is imperative to develop tools capable of early-stage detection and risk assessment for both CAC and sCAC. This study aims to develop and validate nomograms for the accurate prediction of CAC and sCAC.  MethodsThis retrospective cross-sectional study was conducted in Taizhou, Jiangsu Province, China. CAC assessment was performed using non-gated thoracic CT scans. Demographic data and clinical information were collected from patients who were then randomly divided into a training set (70%) or a validation set (30%). Least absolute shrinkage and selection operator (LASSO) regression as well as multiple logistic regression analyses were utilized to identify predictive factors for both CAC and sCAC development. Nomograms were developed to predict the occurrence of CAC or sCAC events. The models performance was evaluated through discrimination analysis, calibration analysis, as well as assessment of their clinical utility.  ResultsThis study included 666 patients with an average age of 75 years, of whom 56% were male. 391 patients had CAC, with sCAC in 134 cases. Through LASSO and multiple logistic regression analysis, age increase, hypertension, carotid artery calcification, CHD, and CHADS2 score were identified for the CAC risk predictive nomogram with an area under the receiver operating characteristic (ROC) curve (AUC) of 0.845(95%CI 0.809-0.881) in the training set and 0.810(95%CI 0.751-0.870) in the validation set. Serum calcium level, carotid artery calcification, and CHD were identified for the sCAC risk predictive nomogram with an AUC of 0.863(95%CI 0.825-0.901) in the training set and 0.817(95%CI 0.744-0.890) in the validation set. Calibration plots indicated that two models exhibited good calibration ability. According to the decision curve analysis (DCA) results, both models have demonstrated a positive net benefit within a wide range of risks.  ConclusionsThe present study has successfully developed and validated two nomograms to accurately predict CAC and sCAC, both of which have demonstrated robust predictive capabilities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Methodological issues in visible LED therapy dermatological research and reporting\nAbstract: The advent of mass-market Light Emitting Diodes (LEDs) has seen considerable interest in potential dermatological applications of LED light photobiomodulation (PBM) for a range of conditions, with a thriving market for direct-to-consumer LED treatments, including red light, blue light, and yellow light wavelengths. Evidence of efficacy for many conditions is however decidedly mixed, with starkly different outcomes reported by different authors. Due to the wide range of irradiances and wavelengths used, interpretation, comparison, and even efficacy evaluation is often impossible or prohibitive, impeding evidence synthesis. This work establishes a framework for objectively cross-comparing patient dose in terms of fluence, and a model for contrasting received dose to typical solar dose at ground level to facilitate interpretation of results and evidence synthesis. This allowes direct cross-comparison of patient skin fluence from LED PMB treatments under different regimes, and a means for evidence synthesis. This was applied to LED PMB data from 27 clinical trials to examine fluences and patient-equivalent solar exposure from LED light-sources for dermatological conditions, including acne vulgaris, wrinkle-reduction, wound-healing, psoriasis severity, and erythemal index. The results of this analysis suggest that fluences, wavelengths, and solar exposure equivalent differed by orders of magnitude in he studies analysed, with effective doses often comparable to typical daily solar exposure. Better dose quantification and plausible biological justification for various wavelengths and fluences are imperative if LED therapy studies for dermatology are to be informative and research replicability improved.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How young people experienced Long COVID services: a qualitative analysis.\nAbstract: ObjectiveWe aimed to evaluate how acceptable paediatric Long COVID services were to patients and clinicians. This paper focuses on how acceptable Long COVID services were to paediatric patients.  DesignThis study was explorational. Semi-structured qualitative interviews with 13 paediatric patients were used to understand the experiences of patients with Long COVID.  SettingParticipants were recruited from specialist paediatric services in the Southwest of England from June 2022 to September 2023.  PatientsParticipants were children and young people (CYP) aged 11-17 years old with a Long COVID diagnosis who accessed the specialist services in the Southwest of England.  ResultsFour themes were reported. Accessing specialist clinics helped CYP to feel validated, they appreciated consulting with clinicians who were knowledgeable about Long COVID and empathetic. CYP found comfort in knowing other CYP were experiencing Long COVID. CYP wanted to be proactive in their Long COVID management, appreciating regular appointments and the opportunity to learn about their condition. CYP desired normality, and therefore sought flexible appointment times, online appointments, and reasonable adjustments. CYP found the waiting times to access Long COVID services were too long.  ConclusionsOur results stress the importance to CYP of several features of the care received in the specialist clinics. These relate to the experiences of CYP with Long COVID but potentially extend to CYP with other conditions, particularly long-term and/or poorly understood conditions. The results support creating community-based support groups for CYP with long-term medical conditions, providing online flexible appointments, offering early reasonable adjustments for school and providing quicker access to specialist clinics.  Key messages/Summary boxO_ST_ABSWhat is already known on this topicC_ST_ABSThe existing literature which explores adult experiences of Long COVID services is in agreement with this study in multiple ways. Firstly, it appears that clinician validation is very important to the clinician patient relationship (1-5). Peer support and building a Long COVID community for patients is also valued by individuals with Long COVID (1, 3, 5, 6), as are online appointments (1,3). Finally, long waiting lists to access Long COVID clinics are a barrier to care (1, 3). This can be mitigated to some extent by providing sign-posting or self-management resources while waiting for clinic access (3). However, the literature regarding paediatric experiences of Long COVID is limited. Two papers discuss the impact of a lack of reasonable adjustments on school (7,8) and the importance of validation through peer support (7).  What this study addsTo the best of our knowledge, there are no studies on Long COVID services for paediatric patients that highlight how patients experienced management of their condition. Our study highlights the patients desire to be proactive in their management, including being given opportunities to learn about Long COVID.  How this study might affect research, practice or policyThis study highlights recommendations for clinical practice. It is recommended to consider the following when designing specialist paediatric services for CYP with Long COVID: CYP with complex medical conditions want clinicians to validate their experience by acknowledging that their symptoms are real and their concerns are valid. Community-based groups for CYP experiencing the same condition are valued by patients, as are online flexible appointments, liaison with schools to provide early reasonable adjustments and rapid access to services for CYP. Future research should explore how these recommendations positively impact patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Psychiatric, Neurological, and Somatic Comorbidities in Intermittent Explosive Disorder: a retrospective cohort study of electronic health records\nAbstract: ImportanceIntermittent Explosive Disorder (IED) is an understudied psychiatric condition that presents with repeated episodes of impulsive aggression and poorly regulated emotional control, often resulting in interpersonal and societal consequences. Better understanding of comor-bidities will allow for enhanced screening, diagnosis, and treatment of patients.  ObjectiveTo investigate prevalence and associations of IED with psychiatric, neurological, and somatic disorders using real-world data  DesignMatched cohorts of patients with or without IED diagnosis were identified using data from the TriNetX Research Network (until January 31, 2024). Cox proportional hazard models were used to estimate and compare the probabilities of acquiring other diagnoses using pa-tients available medical records.  SettingAnalysis of electronic medical records from two patient populations.  Participants30,357 individuals with IED and equal number of demographically matched individuals without IED from the TriNetX Research.  ExposureIED diagnosis identified through the associated ICD codes.  Main Outcomes and MeasuresThe main outcomes were ICD-10-CM diagnostic categories and root codes for disorders and health conditions in both cohorts. Main measures are total numbers and proportions of patients who had the diagnostic codes, as well as adjusted hazard ratios for IED diagnosis.  ResultsAlthough only 0.03% of the total patient population had an IED diagnosis, we found extensive and widespread comorbidities with psychiatric, neurological and somatic conditions. A significant 95.7% of the individuals with IED had another psychiatric diagnosis. All psychiatric sub-categories and 95% of the psychiatric diagnoses were significantly associated with IED, with HRs ranging from 2 to 77. Among neurological conditions, neurodegenerative diseases and epilepsy had the highest HRs, followed by extrapyramidal and movement disorders, cerebral palsy and other paralytic syndromes, and sleep disorders. Notable associations with IED also includes conditions such as obesity, hyperlipidemia, hypertension, and GERD.  Conclusion and RelevanceOur findings illuminate the extensive comorbid relationships between IED and psychiatric, neurological, and somatic disorders. This underscores the necessity for an integrated diagnostic and treatment approach that addresses both the psychological and physical health aspects of IED. Additionally, our work highlights the need for more accurate and inclusive diagnosis of IED in patients with mental disorders.  Key PointsFocused Question: What is the pattern of comorbidity of IED with other disorders?  Findings: Despite being underdiagnosed in the clinical cohort, IED was found significantly associated with a wide range of psychiatric disorders, many neurological, and some somatic disorders.  Meaning: The widespread comorbidity highlights the critical need for integrated care approaches that consider the multifaceted health challenges faced by individuals with IED.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of the WHELD/Brief Psychosocial Therapy intervention on psychosis in people with dementia: A Cluster Randomized Trial\nAbstract: Neuropsychiatric Symptoms (NPS), particularly psychosis, are common in dementia and can significantly impact patient outcomes, caregivers and disease trajectory. Psychosis, which includes hallucinations and delusions, occurs in up to 50% of people with dementia and has been linked with lower quality of life and faster cognitive decline. While best practice guidelines have highlighted the importance of non-pharmacological treatments for NPS, evidence-based non-pharmacological approaches are limited. This exploratory analysis of a cluster randomized control trial (RCT) from the WHELD programme compares the WHELD/Brief Psychosocial Therapy intervention with treatment as usual in a 9-month trial across 69 UK nursing homes (N=8477, 553 completed). The current report analyzed outcomes for the participants with dementia-related psychosis (N=163) participating in the trial. Whilst the WHELD/Brief Psychosocial Therapy intervention did not significantly reduce NPI psychosis score, it did significantly improve apathy (p=0.006), agitation (p=0.038) and quality of life (p=0.01) in participants with psychosis. In addition there was a non-significant numerical improvement in caregiver perceived disruptiveness. These findings suggest that whilst the WHELD/ Brief Psychosocial Therapy intervention does not directly alleviate psychosis in people with dementia, it does significantly improve related neuropsychiatric symptoms and quality of life, offering meaningful benefits to people with dementia experiencing distressing psychotic symptoms.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of Parental Prenatal Mental Health on Offspring Neurodevelopmental Disorders: A Systematic Review and Meta-Analysis\nAbstract: ObjectiveParental prenatal mood and anxiety disorders (PMAD) are linked to child neurodevelopmental disorders (NDDs), but evaluations of the magnitude and mechanisms of this association are limited. This study estimates the strength of the association and whether it is impacted by genetic and environmental factors.  MethodA systematic search of PubMed, CENTRAL, PsycINFO, OVID, and Google Scholar was performed for articles published from January 1988 to January 2024. Of 2,170 articles screened, 64 met the inclusion criteria. Meta-analyses were conducted on 20 studies, and 44 were included in the narrative synthesis. We conducted random-effects meta-analyses, along with tests for heterogeneity (I{superscript 2}) and publication bias (Eggers test). The review followed PRISMA and MOOSE guidelines.  ResultsMaternal PMADs were associated with a significantly increased risk of ADHD (OR 1.91, 95% CI 1.45-2.52) and ASD (OR 1.57, 95% CI 1.37-1.81) in children. Paternal PMADs were also associated with the risk of NDDs, with combined odds for ASD and ADHD (OR 1.24, 95% CI 1.15-1.34). Several studies suggested that the link between parental PMADs and offspring NDDs might be impacted by both genetic and environmental factors, including the impact of ongoing parental depression on child behavior.  Conclusions and RelevanceParental PMADs are significantly associated with an increased risk of NDDs in children. These associations may be influenced by both genetic predispositions and environmental factors. Understanding these pathways is important for informing interventions aimed at mitigating mental health risks in families and supporting child development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Scoping Review: Outpatient Psychotherapeutic Care for Children and Adolescents in Germany - Status Quo and Challenges in Assessment\nAbstract: In the context of multiple global crises, including the COVID-19 pandemic, climate change, and global conflicts, children and adolescents worldwide are experiencing heightened psychological stress. As the foundation for lifelong mental health is established during childhood and adolescence, early prevention and treatment of mental health problems, such as through psychotherapy, are crucial. In Germany, current outpatient psychotherapeutic care capacities appear inadequate, while systematic evaluations of the care situation are lacking. This study investigates the state of statutory health insurance-funded outpatient psychotherapeutic care for children and adolescents in Germany and evaluates various methodological approaches for its assessment. We conducted a scoping review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) guidelines. Publications from January 2018 to December 2023 were sourced from PubPsych, PubMed, APA PsycInfo, Google Scholar, and ProQuest. Included studies reported quantitative primary data on the mental health of community samples of children and adolescents in Germany or their outpatient psychotherapeutic care. We included 41 publications comprising epidemiological studies, administrative data, and psychotherapist and patient reports. A lack of systematic and standardized research approaches resulted in significant variance in data. Nonetheless, qualitative analysis revealed that approximately one four children and adolescents in Germany is affected by mental health problems, while one in six to seven children and adolescents requires psychotherapeutic treatment. Yet, only up to one in fifty receives guideline-based psychotherapy. Most requests for initial psychotherapeutic consultations are unmet, with waiting times for guideline-based psychotherapy exceeding six months for at least half of the patients. Overall, our findings suggest that outpatient psychotherapeutic care for children and adolescents in Germany is still insufficient. They advocate for a systematic, multimodal, and longitudinal assessment of statutory health insurance-funded outpatient psychotherapeutic care, along with an expansion of treatment capacities to enhance access for children and adolescents in Germany.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Developing and validating modular surveys for vector-borne diseases: a study protocol\nAbstract: Vector-borne diseases are an increasing threat to human health and well-being in the United States. Understanding public perception and practices taken to reduce vector abundance and vector-human contact can guide effective interventions that can mitigate health risks. Nevertheless, vector-borne disease surveys, which are widely used in the field to understand public perception and practices, are often inconsistent in terms of structure and implementation. This protocol is designed to provide guidance for public health professionals and researchers in the development of future KAP studies by ensuring uniformity in design and structure. This manuscript describes a rigorous three-phase protocol for the development of standardized vector-borne disease survey modules that can be used throughout the United States to generate data that are comparable across diverse regions. During phase one, a workshop with subject matter experts and a comprehensive literature review will be conducted to identify survey domains and generate items of interest. Survey items will also be mapped based on two theoretical frameworks, the Health Belief Model and the Risks, Attitudes, Norms, Abilities and Self-Regulation framework, to help gauge individual perceptions of risk severity and self-efficacy. During phase two, a group of expert judges will evaluate survey items based on content relevance, representativeness, and technical quality. During the final phase, cognitive interviews and surveys with target audience groups will be conducted to ensure the face validity of the modules. Participants will be drawn from a diverse range of educational and geographic locations, and computer-assisted personal interviewing will be implemented. The surveys developed through this protocol will be available to researchers aiming to gain deeper insights into the publics knowledge, attitudes, and practices concerning vector-borne diseases, facilitating the collection of more comparable data across various regions in the United States.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Impacts of Neighborhood Disparities on US Population Health During the COVID-19 Pandemic: A Literature Review and Policy Analysis for Future Response\nAbstract: Introduction/BackgroundThe COVID-19 pandemic has disrupted major aspects of daily life since its emergence in late 2019, impacting health and well-being worldwide. Aside from genetic predisposition, numerous external factors play key roles in determining levels of disease susceptibility and overall health status.  Aim/ObjectivesThis review and policy analysis sought to examine literature focused on the impact of neighborhood environments on population health and well-being during the COVID-19 pandemic period. Examined studies explore the impacts of various aspects of the neighborhood environment (i.e., walkability, transportation, access to healthcare/vaccination, etc.) during the COVID-19 era on population health and well-being.  MethodsDatabases were searched for studies published from March 2020 to August 2022. Selected studies examine the impacts of various aspects of the neighborhood environment (i.e., walkability, transportation, access to healthcare/vaccination, climate, crime rates, persistent poverty, the social spread of misinformation, etc.) during the COVID-19 era on population health and well-being.  ResultsFindings from our review suggest that those living in less-than-favorable environments were faced with significant challenges, making vulnerable populations more prone to the severity of COVID-19 infection.  ConclusionWe argue these results establish cause for the consideration of the effects of neighborhood environments in developing intelligent intervention strategies for both pandemic recovery and preparation for future public health emergencies, especially among vulnerable populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of early postoperative ambulation on gait recovery after hip fracture surgery: A multicenter cohort study\nAbstract: ObjectiveThis study aimed to investigate the effect of early postoperative ambulation on gait recovery at the initial postoperative week and at discharge after hip fracture surgery in older patients.  DesignMulticenter prospective cohort study.  Setting and ParticipantsThe study included 882 patients aged [&ge;]65 years from 10 acute hospitals in Japan.  MethodsPatients were divided into two groups according to the interval between surgery and first ambulation: early-ambulation (EA) group (initiation of ambulation on postoperative day 1 or 2) and late-ambulation (LA) group (initiation of ambulation on postoperative day 3 or later). The Functional Independence Measure (FIM) was assessed 1 day postoperatively, 1 week postoperatively, and at discharge. Independent walking regardless of use of walking aids was defined as walking FIM [&ge;]5. Confounding variables were age, mobility and cognitive function before injury, medical history, fracture type, and waiting days for surgery.  Multivariate logistic regression analysis was conducted to determine whether EA affected independent walking at 1 week postoperatively and at discharge.  ResultsThe number of patients in the EA and LA groups was 292 (33.1%) and 590 (66.9%), respectively. The number of patients walking independently 1 week postoperatively and at discharge was 156 (17.7%) and 292 (33.1%), respectively. Multivariate logistic regression analysis revealed that EA was associated with independent walking at 1 week postoperatively (odds ratio [OR], 3.27; 95% confidence interval [CI], 2.17-4.94; P < .0001) and at discharge after adjusting for confounders (OR, 3.33; 95% CI, 2.38-4.69; P < .0001). EA was associated with the recovery to pre-injury walking status at discharge after adjusting for confounders (OR, 3.05; 95% CI, 1.59-5.93; P =.0009).  Conclusion and ImplicationsEarly ambulation after hip fracture surgery has an impact on independent walking and recovery of pre-injury walking status at 1 week postoperatively and at discharge from acute hospitals in older patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Building and validating a predictive model for stroke risk in Chinese community-dwelling patients with chronic obstructive pulmonary disease using machine learning methods\nAbstract: BackgroundThe occurrence of stroke in patients with chronic obstructive pulmonary disease (COPD) can have potentially devastating consequences; however, there is still a lack of predictive models that accurately predict the risk of stroke in community-based COPD patients in China. The aim of this study was to construct a novel predictive model that accurately predicts the predictive model for the risk of stroke in community-based COPD patients by applying a machine learning methodology within the Chinese community.  MethodsThe clinical data of 809 Community COPD patients were analyzed by using the 2020 China Health and Retirement Longitudinal Study (CHARLS) database. The least absolute shrinkage and selection operator (LASSO) and multivariate logistic regression were used to analyze predictors. Multiple machine learning (ML) classification models are integrated to analyze and identify the optimal model, and Shapley Additive exPlanations (SHAP) interpretation was developed for personalized risk assessment.  ResultsThe following six variables:Heart_disease,Hyperlipidemia,Hypertension,ADL_score, Cesd_score and Parkinson are predictors of stroke in community-based COPD patients. Logistic classification model was the optimal model, test set area under curve (AUC) (95% confidence interval, CI):0.913 (0.835-0.992), accuracy: 0.823, sensitivity: 0.818, and specificity: 0.823.  ConclusionsThe model constructed in this study has relatively reliable predictive performance, which helps clinical doctors identify high-risk populations of community COPD patients prone to stroke at an early stage.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring the intersection between orthostatic hypotension and daytime sleepiness in Parkinson disease\nAbstract: IntroductionDaytime sleepiness, reported in about 50% of patients with Parkinsons disease (PD), is associated with high morbidity, poor quality of life and increased risk for accidents. While an association between dysautonomia and daytime sleepiness in early, de-novo PD has been reported, our understanding of the role of medications, cognitive status and disease duration on this relationship is inadequate.  MethodsData were analyzed from the prospective Cincinnati Cohort Biomarkers Program. The primary outcome of interest was daytime sleepiness, as measured by the Epworth Sleepiness Scale (ESS). The primary exposure variable was orthostatic hypotension (OH) with a sub-analysis for the neurogenic OH (nOH) subtype. Regression analyses were carried out adjusting for the following covariates: age, sex, disease duration, education, comorbidities, anti-cholinergic burden, levodopa equivalent dose (LEDD), motor subscore of the Movement disorder society-unified Parkinsons disease rating scale, Hoehn and Yahr stage (H&Y), Beck Depression Inventory, and Beck Anxiety Inventory.  ResultsData on 456 subjects with PD were analyzed. OH was strongly associated with ESS scores, particularly in those with anticholinergic medication use after adjusting for all covariates (RC, 4.30; p<0.001). This adjusted association was more pronounced in men with early disease duration, early H&Y stage, no cognitive decline, and LEDD[&le;]750 mg. Similar results were noted with nOH.  ConclusionsOH is associated with daytime sleepiness to a greater extent in male patients with early disease and magnified by such prescribing practices as anticholinergic medication use and dopaminergic dosage in early PD. This relationship is independent of cognitive decline.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Oral-motor complexity influences center of pressure patterns in adults with stroke-related communication disorders\nAbstract: People with stroke (PwS) often exhibit altered postural control, and concomitant stroke-related communication disorders (e.g., aphasia, dysarthria) may be an underrecognized risk factor for post-stroke falls. This heightened fall risk may be related to alterations in postural control that emerge during different speaking and listening conditions. This study evaluated how variations in the relative articulatory demands during speech production--termed \"oral-motor complexity\"--affect postural center of pressure (COP) patterns among PwS, both with communication disorders (PwS-CDis) and without (PwS). Three groups of adults (PwS, PwS-CDis, and a nondisabled Control group) stood on a force platform while completing four 30-second quiet stance trials, followed by twelve 30-second trials randomized across three experimental conditions of varying oral-motor complexities (\"ba\", \"puh tuh kuh\", \"rah shah lah nah\"). COP variability (SD) was significantly higher during experimental conditions compared to quiet stance, regardless of group and movement plane. Differences in nonlinear time-dependent metrics were found across oral-motor task conditions, particularly among PwS-CDis, suggesting oral-motor complexity may influence underlying postural-motor organization. Distinct temporal-dynamical patterns observed in PwS-CDis indicate a possible link between pathology, postural control, and speech motor tasks, which is relevant when evaluating postural control in individuals with stroke-related communication disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development of a Novel Dynamic Leak Model to Simulate Leak for Performance Testing of Manual Neonatal Resuscitation Devices. Does Leak Matter? A Bench Study\nAbstract: BackgroundNewborn resuscitation is commonly performed in the presence of face mask leak. Leak is highly variable, pressure dependent and often unrecognised. The effectiveness of resuscitation devices to deliver adequate inflations in the presence of leak is unknown. Bench models simulating continuous leak have disadvantages of not accurately reflecting leak occurring during clinical resuscitation. A dynamic leak model based on pressure release valves was thus developed.  AimTo assess self-inflating bag (SIB) and T-piece resuscitator (TPR) ventilation performance in the presence of dynamic (DLM) compared to continuous (CLM) leak models in a bench study.  MethodFive predefined leak levels were tested for each leak model (0-87%). Resuscitation devices were connected to a test lung (compliance 0.6 mL/cmH2O) and respiratory parameters were measured using respiratory function monitors before (patient interface) and after (actual) an induced leak at 40, 60, 80 inflations/min.  Results3,600 inflations were analysed. DLM showed a decrease in actual tidal volumes from 0%-87% leak with tidal volume differences (SIB 4.8mL, TPR 2.9mL), contrasting to minimal change for CLM (SIB -0.6mL, TPR 0.3mL). CLM demonstrated larger differences between patient interface and actual leak. The absolute difference at 60 inflations/min at 87% leak were SIB 37.5%, TPR 18.2% for CLM compared to SIB 4.6%, TPR 1.4% for DLM.  ConclusionCLM may underestimate the impact of resuscitation device performance with poor correlation between patient interface and actual delivered volume. DLM demonstrates several advantages with more accurate representation of face mask leak and will prove useful in modelling all systems delivering PPV.  O_LIWhat is already known on this topic? - Mask leak is common, variable and often unrecognised during newborn resuscitation. - Excessive or insufficient tidal volumes may cause newborn lung and brain injury. - Current leak models used to test ventilation devices have a poor fidelity in modelling clinical mask leak.  C_LIO_LIWhat this study adds? - Development of a novel dynamic leak model to enhance performance testing of resuscitation devices by representing pressure dependent leak. - Highlights the dynamic nature of leak during clinical resuscitation. - Relates RFM displayed leak reliably determining delivered lung volume with leak levels to 86%.  C_LIO_LIHow this study might affect research, practice or policy? - The use of dynamic leak model as a higher fidelity simulation tool for the testing of not only resuscitation devices but also ventilators and RFMs. - Further research will determine the ability of currently used ventilation devices to perform in the presence of dynamic leak.  C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Non-pharmacological interventions for psychotic symptoms in people with dementia: a Delphi consensus\nAbstract: BackgroundPsychotic symptoms such as delusion and hallucinations are common in people with dementia. They are associated with various deleterious outcomes including reduced quality of life and increased caregiver burden. Pharmacological interventions to combat psychotic symptoms have shown limited efficacy and can be associated with significant adverse events. Non-pharmacological interventions are recommended as the first line option for treatment, however there is a paucity of evidence for specific non-pharmacological options to primarily target psychotic symptoms in people with dementia. Further work is needed to identify, adapt and develop possible non-pharmacological options to target psychotic symptoms in dementia.  AimTo establish which non-pharmacological interventions could be used or adapted to treat psychotic symptoms and/or confer benefits in people with dementia  DesignModified Delphi consensus process. Two rounds of feedback were conducted and included a directed scoping review, based on the interventions recommended in the first round of the Delphi.  ParticipantsAn expert panel consisted of 12 members with clinical and research expertise in managing psychotic symptoms in people with dementia  ResultsThere were three top nominated treatment options: cognitive behavioural therapy (CBT), family intervention, and personalized activities/environmental/sensory interventions, without a clear priority between the 3 approaches.  The WHELD/Brief Psychosocial Therapy programme focussing on personalized activities improves concurrent neuropsychiatric symptoms in people with dementia related psychosis. Preliminary studies also suggest that combining personalized activities with family training may improve the direct impact on psychosis. There are also opportunities to adapt CBT interventions for people with psychosis related to early or mild dementia.  ConclusionsThere were clear recommendations for three non-pharmacological options that could be used or adapted to benefit people with psychosis in the context of dementia.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of chronic sedative-hypnotic use on sleep architecture and brain oscillations in older adults with chronic insomnia.\nAbstract: RationaleHigh rates of insomnia in older adults lead to widespread benzodiazepine (BZD) and benzodiazepine receptor agonist (BZRA) use, even though chronic use has been shown to disrupt sleep regulation and impact cognition. Little is known about sedative-hypnotic effects on NREM slow oscillations (SO) and spindles, including their coupling, which is crucial for memory, especially in the elderly.  ObjectivesOur objective was to investigate the effect of chronic sedative-hypnotic use on sleep macro-architecture, EEG relative power, as well as SO and spindle characteristics and coupling.  MethodsOne hundred and one individuals (66.05 {+/-} 5.84 years, 73% female) completed a one-night study and were categorized into three groups: good sleepers (GS, n=28), individuals with insomnia (INS, n=26) or individuals with insomnia who chronically use either BZD or BZRA to manage their insomnia difficulties (MED, n=47; dose equivalent in Diazepam: 6.1 {+/-} 3.8 mg/week). We performed a comprehensive comparison of sleep architecture, EEG relative spectrum, and associated brain oscillatory activities, focusing on NREM brain oscillations crucial for sleep-dependent memory consolidation (i.e., SO and spindles) and their temporal coupling.  ResultsChronic use of BZD/BZRA worsened sleep architecture and spectral activity compared to older adults with and without insomnia disorder. The use of BZD/BZRAs also altered the characteristics of sleep-related brain oscillations and their synchrony. An exploratory interaction model suggested that BZD use exacerbated sleep alterations compared to BZRA, and higher BZD/BZRA dosage worsened alteration in sleep micro-architecture and EEG spectrum.  ConclusionsOur results suggest that chronic use of sedative-hypnotics is detrimental to sleep when compared to drug-free GS and INS. Such alteration of sleep regulation - at the macro and micro-architectural levels - may contribute to the reported association between sedative-hypnotic use and cognitive impairment in older adults.  STATEMENT OF SIGNIFICANCEWidespread use of sedative-hypnotics is driven by high insomnia rates among older adults. Chronic use can disrupt sleep and cognitive function, however, its impact on sleep regulation - at the macro and micro-architecture levels - is not well understood. We assessed the effect of chronic sedative-hypnotic use in older adults using a between-group design involving good sleepers, individuals with insomnia disorder who do not take any pharmacological treatment to manage their symptoms and individuals with insomnia disorder who chronically use sedative-hypnotics as a sleep aid. We performed a comprehensive comparison of sleep architecture, EEG relative spectrum, and associated NREM brain oscillations crucial for sleep-dependent memory consolidation (i.e., SO and spindles) and their temporal coupling. We showed that chronic use of sedative-hypnotics is detrimental to sleep regulation - at the macro and micro level - compared to drug-free GS and INS, and this may contribute to the reported link between sedative-hypnotic use and cognitive impairment in older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Trans-Ancestry GWAS of Hot Flashes Reveals Potent Treatment Target and Overlap with Psychiatric Disorders\nAbstract: BackgroundMost women experience hot flashes (hot flushes) during the menopause transition. Menopausal hot flashes typically persist for years. For a sizeable minority of women, hot flashes are severe and substantially impairing. It is worthwhile to further investigate the genetic underpinnings of hot flashes.  MethodWe conducted the largest trans-ancestry genome-wide association study (GWAS) of hot flashes available to date (N=149,560). We used self-assessment of hot flashes in the Nurses Health Study, Nurses Health Study II, Womens Health Initiative, and Queensland Institute of Medical Research samples (total n=42,489). In one sample (UK Biobank, n=107,071) direct assessment of hot flashes was not available, so menopausal hormone therapy was used as a proxy variable. We estimated the heritability of hot flashes and genetic correlations with psychiatric phenotypes using linkage disequilibrium score regression (LDSR).  ResultsIn component analyses and our trans-ancestry meta-analysis, the top locus was on chromosome 4 in the neurokinin 3 receptor gene (TACR3, position 104,556,732, trans-ancestry p=7.2x10-41). A second novel locus was identified (LINC02428, p=3.5x10-8). Gene results implicated TACR3, GRID1, NUDT4, and PHF21B. Using the hot flash GWAS meta-analysis (n=42,489; i.e., no proxy variable), SNP heritability was estimated: h2liab=.08 (h2SNP=.04, se=.02). Genetic correlations were statistically significant between hot flashes and posttraumatic stress disorder (PTSD, rg=0.25, p=0.01), schizophrenia (rg=0.17, p=0.02), and depression (rg=0.21, p=0.01).  DiscussionThese genomic findings are consistent with independent, robust basic science research which led to a novel treatment for hot flashes, namely, neurokinin 3 receptor antagonists. This new class of hot flash drugs blocks the receptor (neurokinin 3 receptor) coded for by the top locus for hot flashes (TACR3). This GWAS of hot flashes provides an uncommonly clear example of how GWAS findings can point to potent treatment targets for complex brain phenotypes. We also found that the proxy variable (menopausal hormone therapy) pointed to the same target (TACR3), and that exclusively intronic and intergenic variants signaled this target.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gut-Brain Nexus: Mapping Multi-Modal Links to Neurodegeneration at Biobank Scale\nAbstract: Alzheimers disease (AD) and Parkinsons disease (PD) are influenced by genetic and environmental factors. Using data from UK Biobank, SAIL Biobank, and FinnGen, we conducted an unbiased, population-scale study to: 1) Investigate how 155 endocrine, nutritional, metabolic, and digestive system disorders are associated with AD and PD risk prior to their diagnosis, considering known genetic influences; 2) Assess plasma biomarkers specificity for AD or PD in individuals with these conditions; 3) Develop a multi-modal classification model integrating genetics, proteomics, and clinical data relevant to conditions affecting the gut-brain axis. Our findings show that certain disorders elevate AD and PD risk before AD and PD diagnosis including: insulin and non-insulin dependent diabetes mellitus, noninfective gastro-enteritis and colitis, functional intestinal disorders, and bacterial intestinal infections, among others. Polygenic risk scores revealed lower genetic predisposition to AD and PD in individuals with co-occurring disorders in the study categories, underscoring the importance of regulating the gut-brain axis to potentially prevent or delay the onset of neurodegenerative diseases. The proteomic profile of AD/PD cases was influenced by comorbid endocrine, nutritional, metabolic, and digestive systems conditions. Importantly, we developed multi-modal prediction models integrating clinical, genetic, proteomic and demographic data, the combination of which performs better than any single paradigm approach in disease classification. This work aims to illuminate the intricate interplay between various physiological factors involved in the gut-brain axis and the development of AD and PD, providing a multifactorial systemic understanding that goes beyond traditional approaches.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Patterns and functional consequences of antibody speciation in maternal-fetal transfer of coronavirus-specific humoral immunity\nAbstract: Maternal antibodies serve as a temporary form of inherited immunity, providing humoral protection to vulnerable neonates. Whereas IgG is actively transferred up a concentration gradient via the neonatal Fc Receptor (FcRn), maternal IgA and IgM are typically excluded from fetal circulation. Further, not all IgG molecules exhibit the same transfer efficiency, being influenced by subclass, Fab and Fc domain glycosylation, antigen-specificity, and the temporal dynamics of maternal antibody responses. Here, we investigate the phenotypes and functions of maternal and cord blood antibodies induced by SARS-CoV-2 infection and compare them to those induced by mRNA vaccination, focusing on breadth of antigen recognition and antiviral functions including neutralization and effector function. While cord blood coronavirus-specific antibody functional breadth and potency appeared to be more compromised than binding breadth and potency in both groups, vaccination induced substantially greater function and breadth in cord blood than did natural infection. These functional phenotypes were associated with speciation of the maternal serum repertoires, as some IgG subpopulations were enriched while others were relatively depleted. Relevant to the continued protection of vulnerable populations in the context of a diversifying pathogen, greater breadth was observed for antibody effector functions than for neutralization, and these activities were associated with greater affinity for antigen. This work provides insights into the functional breadth of maternal-fetal antibody responses in the context of novel mRNA vaccines and a recently emerged pathogen that is likely to be a public health burden for the foreseeable future.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Using Genomic Context Informed Genotype Data and Within-model Ancestry Adjustment to Classify Type 2 Diabetes\nAbstract: Despite high heritability estimates, complex genetic disorders have proven difficult to predict with genetic data. Genomic research has documented polygenic inheritance, cross-disorder genetic correlations, and enrichment of risk by functional genomic annotation, but the vast potential of that combined knowledge has not yet been leveraged to build optimal risk models. Additional methods are likely required to progress genetic risk models of complex genetic disorders towards clinical utility. We developed a framework that uses annotations providing genomic context alongside genotype data as input to convolutional neural networks to predict disorder risk. We validated models in a matched-pairs type 2 diabetes dataset. A neural network using genotype data (AUC: 0.66) and a convolutional neural network using context-informed genotype data (AUC: 0.65) both significantly outperformed polygenic risk score approaches in classifying type-2 diabetes. Adversarial ancestry tasks eliminated the predictability of ancestry without changing model performance.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Optimizing Large Language Models for Discharge Prediction: Best Practices in Leveraging Electronic Health Record Audit Logs\nAbstract: Electronic Health Record (EHR) audit log data are increasingly utilized for clinical tasks, from workflow modeling to predictive analyses of discharge events, adverse kidney outcomes, and hospital readmissions. These data encapsulate user-EHR interactions, reflecting both healthcare professionals behavior and patients health statuses. To harness this temporal information effectively, this study explores the application of Large Language Models (LLMs) in leveraging audit log data for clinical prediction tasks, specifically focusing on discharge predictions. Utilizing a years worth of EHR data from Vanderbilt University Medical Center, we fine-tuned LLMs with randomly selected 10,000 training examples. Our findings reveal that LLaMA-2 70B, with an AUROC of 0.80 [0.77-0.82], outperforms both GPT-4 128K in a zero-shot, with an AUROC of 0.68 [0.65-0.71], and DeBERTa, with an AUROC of 0.78 [0.75-0.82]. Among various serialization methods, the first-occurrence approach--wherein only the initial appearance of each event in a sequence is retained--shows superior performance. Furthermore, for the fine-tuned LLaMA-2 70B, logit outputs yield a higher AUROC of 0.80 [0.77-0.82] compared to text outputs, with an AUROC of 0.69 [0.67-0.72]. This study underscores the potential of fine-tuned LLMs, particularly when combined with strategic sequence serialization, in advancing clinical prediction tasks.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Technology-Supported Self-Triage Decision Making: A Mixed-Methods Study\nAbstract: Symptom-Assessment Application (SAAs) and Large Language Models (LLMs) are increasingly used by laypeople to navigate care options. Although humans ultimately make a final decision when using these systems, previous research has typically examined the performance of humans and SAAs/LLMs separately. Thus, it is unclear how decision-making unfolds in such hybrid human-technology teams and if SAAs/LLMs can improve laypeoples decisions. To address this gap, we conducted a convergent parallel mixed-methods study with semi-structured interviews and a randomized controlled trial. Our interview data revealed that in human-technology teams, decision-making is influenced by factors before, during, and after interaction. Users tend to rely on technology for information gathering and analysis but remain responsible for information integration and the final decision. Based on these results, we developed a model for technology-assisted self-triage decision-making. Our quantitative results indicate that when using a high-performing SAA, laypeoples decision accuracy improved from 53.2% to 64.5% (OR = 2.52, p < .001). In contrast, decision accuracy remained unchanged when using a LLM (54.8% before vs. 54.2% after usage, p = .79). These findings highlight the importance of studying SAAs/LLMs with humans in the loop, as opposed to analyzing them in isolation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Challenging the Chronic Perverse Bias in Prosthetic Valve Design: A Pathway Opens for Advanced Mechanical Valves.\nAbstract: Objective- In vitro evaluation of several prototype mechanical valves compared to present-day controls.   Method- simulated normal cardiac pressures and flows - gravity pressure head column tester flows. - recorded valve hydrodynamics and kinematics   Results- valves superior in performance to clinical controls   Conclusions- Prototype MHV candidates outperform the closing performance of present day SAVR prosthetic valves, including bioprosthetic control.   Competing InterestsNone declared  Financial DisclosureThis research was performed on a pro bono basis by indicted coauthors*, in part, to assist coauthor and Ph.D. candidate Dylan Goode.  CENTRAL MESSAGEIn-vitro dynamics of optimized prototype mechanical heart valves (MHVs) outperformed those of current clinical prosthetic SAVR valves. -Achieving the objective of an anticoagulation-free and durable MHV is directly related to mitigation of detrimental valve closing hydrodynamics and kinematics.  PERSPECTIVEImprovements in prosthetic valve performance and durability notwithstanding, the objective of an anti-coagulation free device with durability exceeding the projected life expectancy of all recipients has not been achieved. Our work identifies a design and development void that may have significantly delayed progress toward this objective.  SIGNIFICANCEOur results challenge a longstanding bias in valve design, shifting the focus towards crucial behavior during valve closure. This study paves the way for advanced mechanical valves bringing us closer to the elusive goal of anticoagulation-free performance--a long-awaited milestone in the evolution of prosthetic valves.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mosaic loss of chromosome Y characterizes late-onset rheumatoid arthritis and contrasting associations of polygenic risk score based on age at onset.\nAbstract: Objectivesmosaic chromosomal alterations (mCAs) increase with age and are associated with age-related diseases. The association between mCAs and rheumatoid arthritis (RA), particularly late-onset rheumatoid arthritis (LORA), has not been explored.  MethodsmCAs were detected in peripheral blood samples from two independent Japanese datasets (Set 1:2,107 RA cases and 86,998 controls; Set 2:2,359 RA cases and 86,998 controls). The associations between mCAs and RA were evaluated in each dataset using logistic regression models and meta-analysis. In each dataset, we evaluated the effect sizes of mosaic loss of Y (mLOY) and polygenic risk score (PRS) of RA in males and subsequently performed a meta-analysis. The interaction between mLOY and PRS was assessed. These models were applied separately to RA, LORA, and young-onset RA (YORA).  ResultsmLOY increased significantly in LORA (OR=1.43, P=0.0070). We observed a negative association between mLOY and YORA (OR=0.66, P=0.0034). On the other hand, we found consistently negative associations of autosomal mCAs or mosaic loss of X (mLOX) with RA, LORA, and YORA. The effect sizes of PRS were lower for LORA than for YORA. mLOY with a high cell fraction strengthened the association between PRS and LORA (P=0.0036), whereas the association with YORA was independent of mLOY.  ConclusionLORA was characterised by the presence of a high burden of mLOY. The observed interaction between mLOY and PRS in LORA, but not in YORA, supports different gene-environment interactions between the subsets. These data suggest that distinct pathophysiological mechanisms underlie the development of LORA and YORA.  Key messagesO_ST_ABSWhat is already known about this subject?C_ST_ABS{square} The prevalence of late-onset rheumatoid arthritis (LORA) in aging societies is increasing worldwide. {square}LORA has unique clinical characteristics, including higher prevalence in males, acute onset of the disease, and lower proportion of seropositivity compared with young-onset RA (YORA), suggesting distinct genetic and environmental components between the RA subsets. {square}Mosaic chromosomal alterations (mCAs) accumulate with age and are associated with age-related disorders. mCAs occur in both autosomes and sex chromosomes and would reflect the clonal expansion of dysregulated immune cells.   What does this study add?{square} Mosaic loss of Y (mLOY) is increased in male patients with LORA. {square}While mLOY is positively associated with LORA, mLOY is negatively associated with YORA. {square}The association of the RA-polygenic risk score (PRS) with LORA was more apparent in the presence of mLOY, while the association with YORA was independent of mLOY.   How might this impact clinical practice or future developments?{square} mLOY plays an acquired risk for RA in males by modifying the contribution of the genetic risk to RA development depending on age at onset. {square}Further investigation of the different effects of mLOY on LORA and YORA would lead to a better understanding of the pathological basis of RA influenced by aging and sex.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Utilizing AI-Generated Plain Language Summaries to Enhance Interdisciplinary Understanding of Ophthalmology Notes: A Randomized Trial\nAbstract: BackgroundSpecialized terminology employed by ophthalmologists creates a comprehension barrier for non-ophthalmology providers, compromising interdisciplinary communication and patient care. Current solutions such as manual note simplification are impractical or inadequate. Large language models (LLMs) present a potential low-burden approach to translating ophthalmology documentation into accessible language.  MethodsThis prospective, randomized trial evaluated the addition of LLM-generated plain language summaries (PLSs) to standard ophthalmology notes (SONs). Participants included non-ophthalmology providers and ophthalmologists. The study assessed: (1) non-ophthalmology providers comprehension and satisfaction with either the SON (control) or SON+PLS (intervention), (2) ophthalmologists evaluation of PLS accuracy, safety, and time burden, and (3) objective semantic and linguistic quality of PLSs.  Results85% of non-ophthalmology providers (n=362, 33% response rate) preferred the PLS to SON. Non-ophthalmology providers reported enhanced diagnostic understanding (p=0.012), increased note detail satisfaction (p<0.001), and improved explanation clarity (p<0.001) for notes containing a PLS. The addition of a PLS narrowed comprehension gaps between providers who were comfortable and uncomfortable with ophthalmology terminology at baseline (intergroup difference p<0.001 to p>0.05). PLS semantic analysis demonstrated high meaning preservation (BERTScore mean F1 score: 0.85) with greater readability (Flesch Reading Ease: 51.8 vs. 43.6, Flesch-Kincaid Grade Level: 10.7 vs. 11.9). Ophthalmologists (n=489, 84% response rate) reported high PLS accuracy (90% \"a great deal\") with minimal review time burden (94.9% [&le;] 1 minute). PLS error rate on initial ophthalmologist review and editing was 26%, and 15% on independent ophthalmologist over-read of edited PLSs. 84.9% of identified errors were deemed low risk for patient harm and 0% had a risk of severe harm/death.  ConclusionsLLM-generated plain language summaries enhance accessibility and utility of ophthalmology notes for non-ophthalmology providers while maintaining high semantic fidelity and improving readability. PLS error rates underscore the need for careful implementation and ongoing safety monitoring in clinical practice.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Barriers and Facilitators to Community Pharmacist-Provided Injectable Naltrexone for Formerly Incarcerated Individuals During Community Reentry in Wisconsin\nAbstract: Medications for opioid use disorder (MOUD), including injectable naltrexone, are a key component in the treatment of opioid use disorder (OUD). These medications are especially important for individuals transitioning out of correctional facilities and back into their communities, as individuals receiving MOUD are 85% less likely to die due to drug overdose in the first month post-release and have a 32% lower risk of rearrest. Unfortunately, few formerly incarcerated individuals have access to MOUD upon reentry, incurring a 40-fold greater likelihood of overdose following release compared to the general population. While 84% of Wisconsin jails offering MOUD offer naltrexone, less than half provide linkage to community treatment for reentering individuals. In Wisconsin, community pharmacists have the authority to provide naltrexone injections. However, they have not been explored as a resource for improving access to this medication for formerly incarcerated individuals. As a first step, the goal of this study was to understand the barriers and facilitators impacting access to community pharmacist-provided injectable naltrexone for this patient population during community reentry period. The researcher conducted semi-structured interviews with 18 individuals representing five stakeholder groups. Deductive and inductive content analysis were used to identify barrier and facilitator categories across the five levels of the Socioecological Model. Overall, participants discussed factors at every level, and many barriers and facilitators confirmed findings from existing literature focused on MOUD access for formerly incarcerated individuals. Participants also identified factors more specific to community pharmacies, including 1) lack of interagency collaboration between pharmacists, prescribers, and correctional facilities and 2) lack of awareness of community pharmacist-provided MOUD services. Future research should explore interventions to address the barriers identified in this study and improve connections between community pharmacists and formerly incarcerated individuals. This work can help ensure that these individuals are given the chance to successfully reintegrate into society.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Effectiveness of Nirsevimab in Reducing Pediatric RSV Hospitalizations\nAbstract: Background and objectiveRespiratory syncytial virus (RSV) is a major cause of hospitalization in infants. Nirsevimab has demonstrated to be a promise tool for preventing severe RSV disease. Although clinical trials have demonstrated the efficacy of Nirsevimab in preventing severe RSV disease, evidence regarding its performance in real-world clinical settings is still limited due to its recent introduction. This study aims to fill this knowledge gap by evaluating the impact of Nirsevimab in a cohort of infants and determining its effectiveness in reducing the burden of RSV disease.  Material and MethodsRetrospective study of RSV hospitalizations in children under six months of age, between October 1st and March 31st, across four seasons: pre-COVID (2018-2019), COVID (2019-2020), post-COVID pre-Nirsevimab (2022-2023), and Nirsevimab season (2023-2024).  ResultsNirsevimab has demonstrated significant efficacy in reducing RSV-related hospitalizations in infants under six months of age. During the 2023/24 season, following the introduction of Nirsevimab, there was a substantial reduction in RSV-related lower respiratory tract infection (LRTI) hospitalizations. Among infants under 3 months of age, hospitalizations decreased by 79.3% (IRR: 0.21, 95% CI: 0.12-0.34). In infants aged 3 to 6 months, there was a 66.9% reduction (IRR: 0.33, 95% CI: 0.15- 0.64). Additionally, Nirsevimab decreased the severity of RSV cases with LRTI who required support of equipment for sanitary use further reducing overall healthcare burden.  ConclusionThese results underscore Nirsevimabs vital role in preventing severe RSV infections and hospitalizations, especially among the most vulnerable infants, positioning it as a critical advancement in pediatric respiratory care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Effectiveness of Nirsevimab in Reducing Pediatric RSV Hospitalizations in Spain\nAbstract: Background and objectiveRespiratory syncytial virus (RSV) is a major cause of hospitalization in infants. Nirsevimab has demonstrated to be a promise tool for preventing severe RSV disease. Although clinical trials have demonstrated the efficacy of Nirsevimab in preventing severe RSV disease, evidence regarding its performance in real-world clinical settings is still limited due to its recent introduction. This study aims to fill this knowledge gap by evaluating the impact of Nirsevimab in a cohort of infants and determining its effectiveness in reducing the burden of RSV disease.  Material and MethodsRetrospective study of RSV hospitalizations in children under six months of age, between October 1st and March 31st, across four seasons: pre-COVID (2018-2019), COVID (2019-2020), post-COVID pre-Nirsevimab (2022-2023), and Nirsevimab season (2023-2024).  ResultsNirsevimab has demonstrated significant efficacy in reducing RSV-related hospitalizations in infants under six months of age. During the 2023/24 season, following the introduction of Nirsevimab, there was a substantial reduction in RSV-related lower respiratory tract infection (LRTI) hospitalizations. Among infants under 3 months of age, hospitalizations decreased by 79.3% (IRR: 0.21, 95% CI: 0.12-0.34). In infants aged 3 to 6 months, there was a 66.9% reduction (IRR: 0.33, 95% CI: 0.15- 0.64). Additionally, Nirsevimab decreased the severity of RSV cases with LRTI who required support of equipment for sanitary use further reducing overall healthcare burden.  ConclusionThese results underscore Nirsevimabs vital role in preventing severe RSV infections and hospitalizations, especially among the most vulnerable infants, positioning it as a critical advancement in pediatric respiratory care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neural emotion regulation during pregnancy - a fMRI study investigating a transdiagnostic mental health factor in healthy first-time pregnant women\nAbstract: Pregnancy is a psycho-neuro-endocrinological transition phase in which a plethora of hormone levels rise substantially, modulating socioemotional functions, brain structures, and networks and thus presenting a window of vulnerability for mental health. A transdiagnostic factor for psychopathology is emotion regulation, which is influenced by sex hormones, such as estradiol (E2), across the menstrual cycle on the behavioral and neural level. Whether this is also the case in the antepartum period remains unknown. For the first time, behavioral and neural emotion regulation were investigated in healthy primiparous pregnant females with extremely high E2 levels during the second trimester (N = 15) using a functional magnetic resonance imaging (fMRI) paradigm. Results were compared with naturally-cycling females with high E2 levels (after E2-administration, N = 16) and low E2 levels (early follicular phase, N = 16). Although pregnant females reported the lowest trait use of cognitive reappraisal, all females successfully regulated their emotions by applying cognitive reappraisal in the scanner. On the neural level, all females had increased activity in the left middle frontal gyrus during downregulation of negative emotions. Pregnant females showed no significant differences in functional connectivity (psychophysiological interaction, resting-state) related to emotion regulation compared to the nonpregnant group. However, group differences emerged for amygdala activation. In pregnant females, increased amygdala activity predicted reduced regulation success and was positively associated with depression scores. This first fMRI study during pregnancy indicates that depression scores are reflected in heightened amygdala activity already observable in the antepartum period. Thus, through its association with reduced regulation success, increased amygdala activity suggests a neural risk marker for peripartum mental health. Future research needs to investigate emotion regulation in pregnant and postpartum women to further understand pregnancy-related changes and associations of mood, emotional and neural functions. Eventually, this will allow enhanced identification, prevention, and treatment of peri- and postpartum mental ill-health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A multi-omics bidirectional mendelian randomization study and meta-analysis on the causal relationship between gut microbiota, inflammatory proteins, and fibromyalgia.\nAbstract: BackgroundFibromyalgia (FM) is a chronic disorder characterized by widespread pain and immune dysregulation. Emerging evidence suggests that gut microbiota and inflammatory proteins may contribute to the development of FM.  ObjectiveThe aim of this study was to investigate the causal relationships between gut microbiota, inflammatory proteins (cytokines/chemokines), and FM using bidirectional Mendelian randomization (MR) and meta-analysis approaches.  MethodsMR analyses were conducted using genetic data from European populations, employing methods such as MR-IVW, MR-Egger, and MR-weighted median. Reverse MR was also performed, with FM treated as the exposure. A meta-analysis was conducted to consolidate the findings.  ResultsRuminococcus gauvreauii was identified as a risk factor for FM, while Enterorhabdus, Parabacteroides, Butyricicoccus, and Prevotella 9 were found to be protective. Five inflammatory proteins--C-X-C motif chemokine 5 (CXCL5), S100-A12, Leukemia inhibitory factor receptor (LIFR), Monocyte chemoattractant protein 2 (MCP-2/CCL8), and Tumor necrosis factor (TNF-)--exhibited protective associations, while Natural killer cell receptor 2B4 (NKCR-2B4/CD244) and Interleukin-12 subunit beta (IL-12{beta}) were associated with an increased risk of FM.  ConclusionThis study highlights the role of gut microbiota and inflammatory proteins (cytokines/chemokines) in the pathogenesis of FM. Through Gene Ontology (GO) functional enrichment and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analyses, the findings suggest their involvement in immune regulation, inflammatory responses, and viral pathways. These findings provide new insights into potential therapeutic targets for modulating gut health and immune responses, opening new avenues for future research and clinical interventions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Conspiratorial thinking in a 50-state survey of American adults\nAbstract: BackgroundWhile the NIMH Research Domain Criteria framework stresses understanding how neuropsychiatric phenotypes vary across populations, little is known outside of small clinical cohorts about conspiratorial thoughts as an aspect of cognition.  MethodsWe conducted a 50-state non-probability internet survey conducted in 6 waves between October 6, 2022 and January 29, 2024, with respondents age 18 and older. Respondents completed the American Conspiratorial Thinking Scale (ACTS) and the 9-item Patient Health Questionnaire (PHQ-9). Survey-weighted regression models were used to examine sociodemographic and clinical associations with ACTS score, and associations with vaccination status.  ResultsAcross the 6 survey waves, there were 123,781 unique individuals. After reweighting, a total of 78.6% of respondents somewhat or strongly agreed with at least one conspiratorial idea; 19.0% agreed with all four of them. More conspiratorial thoughts were reported among those age 25 - 54, males, individuals who finished high school but did not start or complete college, those with household income between $25,000 and $50,000 per year, and those who reside in rural areas, as well as those with greater levels of depressive symptoms. Endorsing more conspiratorial thoughts was associated with a significantly lower likelihood of being vaccinated against COVID-19.  DiscussionA substantial proportion of US adults endorsed at least some conspiratorial thinking, which varied widely across population subgroups. The extent of correlation with non-vaccination suggests the importance of considering such thinking in designing public health strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: High power transient 15-29Hz beta event features as early biomarkers of Alzheimer's Disease conversion: a MEG study\nAbstract: A typical pattern observed in M/EEG recordings of Mild Cognitive Impairment (MCI) patients progressing to Alzheimers disease is a continuous slowing of brain oscillatory activity. Definitions of oscillatory slowing are imprecise, as they average across time and frequency bands, masking the finer structure in the signal and potential reliable biomarkers of the disease.  Recent studies show that high averaged band power can result from transient increases in power, termed  events or  bursts. To better understand MEG oscillatory slowing in AD progression, we analyzed features of high-power oscillatory events and their relationship to cognitive decline. MEG resting-state oscillations were registered in age-matched patients with MCI who later convert (CONV, N=41) or do not convert (NOCONV, N=44) to AD, in a period of 2.5 years. To distinguish future CONV from NOCONV, we characterised the rate, duration, frequency span and power of transient high-power events in the alpha and beta band in anterior cingulate (ACC) and precuneus (PC).  Results revealed event-like patterns in resting-state power in both the alpha and beta-bands, how-ever only beta-band features were predictive of conversion to AD, particularly in PC. Specifically, compared to NOCONV, CONV had a lower number of beta events, along with lower power events and a trend toward shorter duration events in PC (p < 0.05). Beta event durations were also significantly shorter in ACC (p < 0.01). Further, this reduced expression of beta events in CONV predicted lower values of mean relative beta power, increased probability of AD conversion, and poorer cognitive performance.  Our work paves the way for reinterpreting M/EEG slowing and examining beta event features as a new biomarker along the AD continuum, and a potential link to theories of inhibitory cognitive control in neurodegeneration. These results may bring us closer to understanding the neural mechanisms of the disease that help guide new therapies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cross-Sectional Analysis of the Association Between Abnormal Immune Responses in the Pathogenesis of Postpartum Cardiomyopathy in Ethiopian Women: A Hospital-based Study at Saint Paul Hospital\nAbstract: 1.0BackgroundPostpartum cardiomyopathy (PPCM) is a condition that is characterized by the weakening of heart muscles which is known as left ventricular dysfunction and occurs during the later stages of pregnancy or during the early stages of postpartum.  ObjectiveTo evaluate the role of abnormal immune responses and risk factors such as advanced age, high parity, and presence of gestational diabetes in the pathogenesis of PPCM in Ethiopia.  MethodA cross-sectional hospital-based study was conducted at Saint Paul Millennium Medical College (SPMCC) between January 2021 and January 2023. All female pregnant patients who were attending the Maternal Care Fetal Unit, Antenatal Unit, and High-Risk Unit at SPMMC were included in this study. However, among those patients, those mothers younger than 20 years old and older than 40 years old were excluded from the study. The total sample size collected from this facility was 250 patients.  ResultsOxidative stress and inflammation were primarily correlated with pre-eclampsia and gestational diabetes. These risk factors were particularly prevalent within patients diagnosed with PPCM, 52.8% and 40% respectively. Prolactin Cleavage and Microvascular Dysfunction was associated with higher BMI and advanced age. With a general increasing trend observed in PPCM incidence and advancing age. As well as a high prevalence rate of PPCM in patients with Obesity Class I (at 33.0%). Another notable risk factor was high parity ( 45.0% with 4+ prior pregnancies). The most common symptom presented was dyspnea at 35.0%. The mortality rate was 14% whilst recurrence and the fully recovered ratio were at 13.1% and 34.0%, respectively.  ConclusionResults aligned with those conducted in other African countries (e.g. Zambia and South Africa) however mitigating high mortality as well as low full recovery rate will need to be done by earlier diagnosis, effective treatment, and intervention mechanisms. A different study design will need to be conducted (over a longer time period) to support and make findings more holistic.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The VIPR-1 trial (Visualizing Ischemia in the Pancreatic Remnant) - Assessing the role of intraoperative indocyanine green perfusion of the transected pancreas in predicting postoperative pancreatic leaks: protocol for a prospective phase II trial.\nAbstract: Surgery of the pancreas has come a long way since its inception; however, postoperative morbidity is still high. Pancreatic leaks and fistulas are common complications in patients undergoing surgery to remove the pancreas. Fistulas delay subsequent oncological care after surgery and prolong the hospital stay. Hypoperfusion to the pancreas has been characterized as one factor leading to fistulas. Indocyanine green (ICG) injection allows the surgeon to evaluate blood perfusion to tissue in real-time. This protocol describes a trial that aims to assess the effectiveness of intraoperative ICG metrics of the cut edge of the pancreas to predict postoperative fistulas. A single group will participate in an observational, surgeon-blinded, phase II trial. ICG measurements of the cut edge of the pancreas will be recorded before reconstruction. International Study Group on Pancreatic Surgery criteria for pancreatic fistula will be used to define leaks and fistulas. The primary outcome will be the correlation between ICG measurements and the development or absence of fistula formation. Currently, limited objective intraoperative predictors exist for predicting postoperative fistulas. Having a reliable predictive tool could decrease the healthcare burden posed by fistulas. The findings of this trial will provide conclusions on the usefulness of ICG measurements in predicting postoperative pancreatic fistulas and leaks. This clinical trial is registered in ClinicalTrials.gov with the ID NCT06084013. The current protocol version is v1.0.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Altered Cytokine Profile in Clinically Suspected Seronegative Autoimmune Associated Epilepsy\nAbstract: Background and ObjectivesAutoimmune-associated epilepsy (AAE), a condition which responds favorably to immune therapies but not traditional anti-seizure interventions, is emerging as a significant contributor to cases of drug-resistant epilepsy. Current standards for the diagnosis of AAE rely on screening for known neuronal autoantibodies in patient serum or cerebrospinal fluid. However, this diagnostic method fails to capture a subset of drug-resistant epilepsy patients with suspected AAE who respond to immunotherapy yet remain seronegative (snAAE) for known autoantibodies.  MethodsTo identify potential biomarkers for snAAE, we evaluated the most comprehensive panel of assayed cytokines and autoantibodies to date, comparing patients with snAAE, anti-seizure medication (ASM) responsive epilepsy, and patients with other neuroinflammatory diseases.  ResultsWe found a unique signature of 14 cytokines significantly elevated in snAAE patients including: GM-CSF, MCP-2/CCL8, MIP-1a/CCL3, IL-1RA, IL-6, IL-8, IL-9, IL-10, IL-15, IL-20, VEGF-A, TNF-b, LIF, and TSLP. Based on prior literature, we highlight IL-6, IL-8, IL-10, IL-13, VEGF-A, and TNF-b as potentially actionable cytokine biomarkers for snAAE, which could be of diagnostic utility in clinical evaluations of snAAE patients. Autoantibody-ome screening failed to identify autoantibodies targeting neuronal channel proteins in snAAE patients. Interestingly, ASM-responsive epilepsy patients displayed elevations in the proportion of autoantibodies targeting brain plasma membrane proteins, possibly pointing to the presence of immune hyperactivity/dysfunction despite well-controlled seizure activity and suggesting ASM-responsive patients may experience disease progression independent of seizure activity (PISA).  DiscussionOverall, our findings suggest that simply expanding existing autoantibody screens may not sufficiently enhance diagnostic power for snAAE. Instead, we propose that cytokine analysis may serve as a promising diagnostic avenue for identifying immune dysregulation in AAE patients and enabling opportunities for trials of immunotherapies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-center improvement in screening for dystonia in young people with cerebral palsy\nAbstract: Background and ObjectivesDystonia is a common, debilitating, and often treatment refractory motor symptom of cerebral palsy (CP), affecting 70-80% of this population based on research assessments. However, routine clinical evaluation for dystonia in CP has failed to match these expected numbers. Addressing this diagnostic gap is a medical imperative because the presence of dystonia rules in or out certain treatments for motor symptoms in CP. Therefore, our objective was to optimize rates of clinical dystonia screening to improve rates of clinical dystonia diagnosis.  MethodsUsing the quality improvement (QI) infrastructure of the Cerebral Palsy Research Network (CPRN), we developed and implemented interventions to increase the documentation percentage of five features of dystonia in young people with CP, aged 3-21 years old. This QI initiative was implemented by seven physiatry and pediatric movement disorders physicians at four tertiary-care pediatric hospitals between 10/10/21 and 7/1/23. We collected visit data cross-sectionally across all participating sites every 2 weeks and tracked our progress using control charts.  ResultsWe assessed 847 unique visits, mostly for established patients (719/847, 85%) who were 9.2 years old on average (95% CI 8.8-9.5). By 4/10/22, the mean percentage of dystonia screening elements documented across all sites rose from 39% to 90% and the mean percentage of visits explicitly documenting the presence or absence of dystonia rose from 65% to 94%. By 10/23/22, the percentage of visits diagnosing dystonia rose from 57% to 74%. These increases were all sustained through the end of the study period in 7/1/23.  DiscussionUsing a rigorous QI-driven process across four member sites of a North American learning health network (CPRN), we demonstrated that we could increase screening for dystonia and that this was associated with increased clinical dystonia diagnosis, matching expected research-based rates. We propose that similar screening should take place across all sites caring for people with CP.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Predicting cancer patient mortality within 30 days of radiotherapy consultation to inform palliative radiotherapy fractionation decisions\nAbstract: BackgroundRadiation and medical oncologists evaluate patients risk of imminent mortality with scales like Karnofsky Performance Status (KPS) and predicate treatment decisions on these evaluations. However, we hypothesized that statistical models derived from structured electronic health record (EHR) data could predict patient deaths within 30 days of radiotherapy consultation better than models developed only with patient age and physician-reported KPS.  MethodsClinical data from patients who consulted in a radiotherapy department from June 2018 - February 2024 were abstracted from EHR databases, including patient demographics, laboratory results, medications, comorbidities, KPS, cancer stages, oncologic treatment histories, oncologist notes, radiologist reports, and pathologist narratives. A subset of structured features known or believed to be associated with mortality were curated and used to train and test logistic regression, random forest, and gradient-boosted decision classifiers.  ResultsOf 38,262 patients, 951 (2.5%) died within 30 days of radiotherapy consultation. From 34.5 gigabytes of tabular data, 2,977 clinical features were chosen or derived by a radiation oncologist, then reduced to 1,000 features using ANOVA F values. Using an event probability classification threshold of 0.2, optimized logistic regression, random forest, and gradient-boosted decision classifiers tested with high accuracy (0.97, 0.98, and 0.98, respectively) and F1 scores (0.50, 0.54, and 0.52). The areas under receiver operating and precision-recall curves for the random forest model were respectively 0.94 and 0.55, which outperformed a model trained only with patient age and KPS (0.61 and 0.06). Models prominently weighed features that were rationally associated with mortality.  ConclusionStatistical models developed from a physician-curated feature space of structured EHR data predicted patient deaths within 30 days of radiotherapy consultation better than a model developed only with a patients age and physician-assessed KPS. With clinically explicable feature weights, these models could influence treatment decisions such as the length of palliative radiotherapy courses.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prediction of the ectasia screening index from raw Casia2 volume data for keratoconus identification by using convolutional neural networks\nAbstract: PurposePrediction of Ectasia Screening Index (ESI), an estimator provided by the Casia2 for identifying keratoconus, from raw Optical Coherence Tomography (OCT) data with Convolutional Neural Networks (CNN).  MethodsThree CNN architectures (ResNet18, DenseNet121 and EfficientNetB0) were employed to predict the ESI. Mean Absolute Error (MAE) was used as the performance metric for predicting the ESI by the adapted CNN models on the test set. Scans with an ESI value higher than a certain threshold were classified as Keratoconus, while the remaining scans were classified as Not Keratoconus. The models performance was evaluated using metrics such as accuracy, sensitivity, specificity, Positive Predictive Value (PPV) and F1 score on data collected from patients examined at the eye clinic of the Homburg University Hospital. The raw data from the Casia2 device, in 3dv format, was converted into 16 images per examination of one eye. For the training, validation and testing phases, 3689, 1050 and 1078 scans (3dv files) were selected, respectively.  ResultsIn the prediction of the ESI, the MAE values for the adapted ResNet18, DenseNet121 and EfficientNetB0, rounded to two decimal places, were 7.15, 6.64 and 5.86, respectively. In the classification task, the three networks yielded an accuracy of 94.80%, 95.27% and 95.83%, respectively; a sensitivity of 92.07%, 94.64% and 94.17%, respectively; a specificity of 96.61%, 95.69% and 96.92%, respectively; a PPV of 94.72%, 93.55% and 95.28%, respectively; and a F1 score of 93.38%, 94.09% and 94.72%, respectively.  ConclusionsOur results show that the prediction of keratokonus based on the ESI values estimated from raw data outperforms previous approaches using processed data. Adapted EfficientNetB0 outperformed both the other adapted models and those in state-of-the-art studies, with the highest accuracy and F1 score.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: APOE4 and Infectious Diseases Jointly Contribute to Brain Glucose Hypometabolism, a Biomarker of Alzheimers Pathology: New findings from the ADNI\nAbstract: Background Impaired brain glucose metabolism is a preclinical feature of neurodegenerative diseases such as Alzheimers disease (AD). Infections may promote AD-related pathology. Therefore, we investigated the interplay between infections and APOE4, a strong genetic risk factor for AD. Methods We analyzed data on 1,509 participants in the Alzheimers Disease Neuroimaging Initiative (ADNI) database using multivariate linear regression models. The outcomes were rank-normalized hypometabolic convergence index (HCI), statistical regions of interest (SROI) for AD, and mild cognitive impairment (MCI). Marginal mean estimates for infections, stratified by APOE4 carrier status, were then computed. Results Prior infections were associated with greater HCI [beta=0.15, 95% CI: 0.03, 0.27, p=0.01]. The combined effects of infections and APOE4 carriers on HCI levels were significantly greater than either variable alone. Among APOE4 carriers, the estimated marginal mean was 0.62, rising to 0.77, with infections (p<0.001), indicating an interaction effect. Carriers with multiple infections showed greater hypometabolism (higher HCI), with an estimate of 0.44 (p=0.01) compared to 0.11 (p=0.08) for those with a single infection, revealing a dose-response relationship. The estimates for the association of infections with SROI AD and SROI MCI were beta=-0.01 (p=0.02) and beta=-0.01 (p=0.04), respectively. Conclusion Our findings suggest that infections and APOE4 jointly contribute to brain glucose hypometabolism and AD pathology, supporting a multi-hit mechanism in AD development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: APOE4 and Infectious Diseases Jointly Contribute to Brain Glucose Hypometabolism, a Biomarker of Alzheimers Pathology: New findings from the ADNI\nAbstract: Background Impaired brain glucose metabolism is a preclinical feature of neurodegenerative diseases such as Alzheimers disease (AD). Infections may promote AD-related pathology. Therefore, we investigated the interplay between infections and APOE4, a strong genetic risk factor for AD. Methods We analyzed data on 1,509 participants in the Alzheimers Disease Neuroimaging Initiative (ADNI) database using multivariate linear regression models. The outcomes were rank-normalized hypometabolic convergence index (HCI), statistical regions of interest (SROI) for AD, and mild cognitive impairment (MCI). Marginal mean estimates for infections, stratified by APOE4 carrier status, were then computed. Results Prior infections were associated with greater HCI [beta=0.15, 95% CI: 0.03, 0.27, p=0.01]. The combined effects of infections and APOE4 carriers on HCI levels were significantly greater than either variable alone. Among APOE4 carriers, the estimated marginal mean was 0.62, rising to 0.77, with infections (p<0.001), indicating an interaction effect. Carriers with multiple infections showed greater hypometabolism (higher HCI), with an estimate of 0.44 (p=0.01) compared to 0.11 (p=0.08) for those with a single infection, revealing a dose-response relationship. The estimates for the association of infections with SROI AD and SROI MCI were beta=-0.01 (p=0.02) and beta=-0.01 (p=0.04), respectively. Conclusion Our findings suggest that infections and APOE4 jointly contribute to brain glucose hypometabolism and AD pathology, supporting a multi-hit mechanism in AD development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma glucosylceramide levels are regulated by ATP10D and are not involved in Parkinson's disease pathogenesis.\nAbstract: GBA1 variants and decreased glucocerebrosidase (GCase) activity are implicated in Parkinsons disease (PD). We investigated the hypothesis that increased levels of glucosylceramide (GlcCer), one of GCase main substrates, are involved in PD pathogenesis. Using multiple genetic methods, we show that ATP10D, not GBA1, is the main regulator of plasma GlcCer levels, yet it is not involved in PD pathogenesis. Plasma GlcCer levels were associated with PD, but not in a causative manner, and are not predictive of disease status. These results argue against targeting GlcCer in GBA1-PD and underscore the need to explore alternative mechanisms and biomarkers for PD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma glucosylceramide levels are regulated by ATP10D and are not involved in Parkinson's disease pathogenesis.\nAbstract: GBA1 variants and decreased glucocerebrosidase (GCase) activity are implicated in Parkinsons disease (PD). We investigated the hypothesis that increased levels of glucosylceramide (GlcCer), one of GCase main substrates, are involved in PD pathogenesis. Using multiple genetic methods, we show that ATP10D, not GBA1, is the main regulator of plasma GlcCer levels, yet it is not involved in PD pathogenesis. Plasma GlcCer levels were associated with PD, but not in a causative manner, and are not predictive of disease status. These results argue against targeting GlcCer in GBA1-PD and underscore the need to explore alternative mechanisms and biomarkers for PD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Generative AI and Large Language Models in Reducing Medication Related Harm and Adverse Drug Events - A Scoping Review\nAbstract: BackgroundMedication-related harm has a significant impact on global healthcare costs and patient outcomes, accounting for deaths in 4.3 per 1000 patients. Generative artificial intelligence (GenAI) has emerged as a promising tool in mitigating risks of medication-related harm. In particular, large language models (LLMs) and well-developed generative adversarial networks (GANs) showing promise for healthcare related tasks. This review aims to explore the scope and effectiveness of generative AI in reducing medication-related harm, identifying existing development and challenges in research.  MethodsWe searched for peer reviewed articles in PubMed, Web of Science, Embase, and Scopus for literature published from January 2012 to February 2024. We included studies focusing on the development or application of generative AI in mitigating risk for medication-related harm during the entire medication use process. We excluded studies using traditional AI methods only, those unrelated to healthcare settings, or concerning non-prescribed medication uses such as supplements. Extracted variables included study characteristics, AI model specifics and performance, application settings, and any patient outcome evaluated.  FindingsA total of 2203 articles were identified, and 14 met the criteria for inclusion into final review. We found that generative AI and large language models were used in a few key applications: drug-drug interaction identification and prediction; clinical decision support and pharmacovigilance. While the performance and utility of these models varied, they generally showed promise in areas like early identification and classification of adverse drug events and support in decision-making for medication management. However, no studies tested these models prospectively, suggesting a need for further investigation into the integration and real-world application of generative AI tools to improve patient safety and healthcare outcomes effectively.  InterpretationGenerative AI shows promise in mitigating medication-related harms, but there are gaps in research rigor and ethical considerations. Future research should focus on creation of high-quality, task-specific benchmarking datasets for medication safety and real-world implementation outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A case is not a case is not a case - challenges and solutions in determining urolithiasis caseloads using the digital infrastructure of a clinical data warehouse\nAbstract: BackgroundTo provide more evidence in urolithiasis research, we have established the German Nationwide Register for RECurrent URolithiasis (RECUR) using local clinical data warehouses (CDWH). For RECUR and other registers relying on digitalized clinical data, it is crucial to ensure the datas reliability for answering scientific questions. In this work, we aim to compare the results of different CDWH-based queries on urolithiasis cases next to manual case extraction from the primary source.  MethodsSources for data extraction included the Medical Center University of Freiburg (MCUF) hospital information system (HIS), MCUF performance data (a clinical data set with merged data from patients including data from vari-ous time points throughout their treatment), and MCUF reimbursement data. We extracted data on caseloads in urolithiasis algorithmically (performance and reimbursement data) and compared those to a reference group compiled of man-ually extracted data from the local HIS and algorithmically extracted data.  ResultsAlgorithmic extraction based on performance data resulted in correct and complete case identification as compared to the reference group. The case numbers from manual extraction from HIS data and algorithmic extraction from reimbursement data differed by 14% and 12%, respectively. The reasons for devi-ations in HIS data included human errors and a lack of data availability from different wards. Deviations in reimbursement data arose primarily due to the merging of cases in the context of reimbursement mechanisms. As the CDWH at MCUF is part of the German Medical Informatics Initiative (MII), the results can be transferred to other medical centers with similar CDWH structure.  ConclusionsThe current study provides firm evidence of the importance of clearly defining a studys target variable, e.g., urolithiasis cases, and a thorough understanding of the data sources and modes used to extract the target data. Our work clearly shows that, depending on various data sources, a case is not a case is not a case.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A case is not a case is not a case - challenges and solutions in determining urolithiasis caseloads using the digital infrastructure of a clinical data warehouse\nAbstract: BackgroundTo provide more evidence in urolithiasis research, we have established the German Nationwide Register for RECurrent URolithiasis (RECUR) using local clinical data warehouses (CDWH). For RECUR and other registers relying on digitalized clinical data, it is crucial to ensure the datas reliability for answering scientific questions. In this work, we aim to compare the results of different CDWH-based queries on urolithiasis cases next to manual case extraction from the primary source.  MethodsSources for data extraction included the Medical Center University of Freiburg (MCUF) hospital information system (HIS), MCUF performance data (a clinical data set with merged data from patients including data from vari-ous time points throughout their treatment), and MCUF reimbursement data. We extracted data on caseloads in urolithiasis algorithmically (performance and reimbursement data) and compared those to a reference group compiled of man-ually extracted data from the local HIS and algorithmically extracted data.  ResultsAlgorithmic extraction based on performance data resulted in correct and complete case identification as compared to the reference group. The case numbers from manual extraction from HIS data and algorithmic extraction from reimbursement data differed by 14% and 12%, respectively. The reasons for devi-ations in HIS data included human errors and a lack of data availability from different wards. Deviations in reimbursement data arose primarily due to the merging of cases in the context of reimbursement mechanisms. As the CDWH at MCUF is part of the German Medical Informatics Initiative (MII), the results can be transferred to other medical centers with similar CDWH structure.  ConclusionsThe current study provides firm evidence of the importance of clearly defining a studys target variable, e.g., urolithiasis cases, and a thorough understanding of the data sources and modes used to extract the target data. Our work clearly shows that, depending on various data sources, a case is not a case is not a case.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Breast Cancer Genetic Testing Experience: Probing the Potential Utility of an Online Decision Aid in Risk Perception and Decision Making\nAbstract: BackgroundDespite the role of pathogenic variants (PVs) in cancer predisposition genes conferring significantly increased risk of breast cancer (BC), uptake of genetic testing (GT) remains low, especially among ethnic minorities. Our prior study identified that a patient decision aid, RealRisks, improved patient-reported outcomes relative to standard educational materials. This study examined patients GT experience and its influence on subsequent actions. We also sought to identify areas for improvement in RealRisks that would expand its focus from improved GT decision-making to understanding results.  MethodsWomen enrolled in the parent randomized controlled trial were recruited and interviewed. Demographic data was collected from surveys in the parent study. Interviews were conducted, transcribed, and coded to identify recurring themes. Descriptive statistics were generated to compare the interviewed subgroup to the original study cohort of 187 women.  ResultsOf the 22 women interviewed, 11 (50%) had positive GT results, 2 (9.1%) with a BRCA1/2 PV, and 9 (40.9%) with variants of uncertain significance (VUS). Median age was 40.5 years and 15 (71.4%) identified as non-Hispanic. Twenty (90.9%) reported a family history of BC, and 2 (9.1%) reported a family history of BRCA1/2 PV. The emerging themes included a preference for structured communication of GT results and the need for more actionable knowledge to mitigate BC risk, especially among patients with VUS or negative results. Few patients reported lifestyle changes following the return of their results, although they did understand that their behaviors can impact their BC risk.  ConclusionsPatients preferred a structured explanation of their GT results to facilitate a more personal testing experience. While most did not change lifestyle behaviors in response to their GT results, there was a consistent call for further guidance following the initial discussion of GT results. Empowering patients, especially those with negative or VUS results, with the knowledge and context to internalize the implications of their results and form accurate risk perception represents a powerful opportunity to mediate subsequent risk management strategies. Informed by this study, future work will expand RealRisks to foster an accurate perception of GT results and include decision support to navigate concrete next steps.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Accuracy of Online Symptom-Assessment Applications, Large Language Models, and Laypeople for Self-Triage Decisions: A Systematic Review\nAbstract: Symptom-Assessment Application (SAAs, e.g., NHS 111 online) that assist medical laypeople in deciding if and where to seek care (self-triage) are gaining popularity and their accuracy has been examined in numerous studies. With the public release of Large Language Models (LLMs, e.g., ChatGPT), their use in such decision-making processes is growing as well. However, there is currently no comprehensive evidence synthesis for LLMs, and no review has contextualized the accuracy of SAAs and LLMs relative to the accuracy of their users. Thus, this systematic review evaluates the self-triage accuracy of both SAAs and LLMs and compares them to the accuracy of medical laypeople. A total of 1549 studies were screened, with 19 included in the final analysis. The self-triage accuracy of SAAs was found to be moderate but highly variable (11.5 - 90.0%), while the accuracy of LLMs (57.8 - 76.0%) and laypeople (47.3 - 62.4%) was moderate with low variability. Despite some published recommendations to standardize evaluation methodologies, there remains considerable heterogeneity among studies. The use of SAAs should not be universally recommended or discouraged; rather, their utility should be assessed based on the specific use case and tool under consideration.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Machine Learning Insights into HLA Noncoding Sequence Mismatches and Their Impact on DPB1 Matching in Hematopoietic Cell Transplantation\nAbstract: PurposeHCT is vital for treating hematological malignancies, relying on HLA matching between unrelated patient-donor pairs to significantly reduce adverse outcomes. Recent studies recognize the potential impact of HLA-DPB1 mismatches on HCT outcomes. Multiple approaches focus on finding better-tolerated HLA-DPB1 mismatches. Additionally, recent studies suggest matching at noncoding HLA sequence may improve HCT outcomes. This study aims to evaluate different approaches for categorizing DPB1 mismatches in patient-donor pairs and explore the potential impact of noncoding mismatches (available in class I HLA genes) on clinical outcomes.  MethodsA retrospective study of 5,106 HCT pairs using Cox proportional hazards models, weighted by a machine learning algorithm, evaluates the impact of particular combinations of HLA-DPB1 mismatches in the context of noncoding HLA class I mismatches on outcomes of HCT. HLA-DPB1 mismatch criteria included T-cell epitope permissive/non-permissive mismatches, expression markers, and evolutionary clade mismatches.  ResultsTwo HLA-DPB1 mismatches, using multiple criteria, lead to significant hazards of acute graft versus host disease grades 2-4, in the T cell replete group. When HLA-DPB1 mismatches occurred across evolutionary clades (DP2 allele/low-expression patient vs DP5 allele/high-expression in the donor), the deplete group showed significant hazards for treatment-related mortality (TRM) (HR=1.94, p-value=8.9x10-7) and overall survival (OS) (HR=1.67, p-value=1.3x10-5) for additive effects of noncoding mismatches with two HLA-DPB1 mismatches.  ConclusionTwo HLA-DPB1 mismatches remain to predict worse outcomes. However, noncoding mismatches in HLA class I genes confer elevated hazards of TRM and OS in conjunction with mismatches across evolutionary branches of HLA-DPB1. Therefore, noncoding mismatches may inform donor selection in the presence of HLA-DPB1 mismatches and improve HCT outcomes, emphasizing the utility of comprehensive sequencing of HLA alleles in HCT settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparing the test performance of dried-blood-spot and plasma HIV recent infection testing samples in a nationally scaled sex worker programme in Zimbabwe\nAbstract: Recency testing can provide strategic insights as to whether a person newly diagnosed with HIV recently acquired their infection or not. To understand potential biases associated with HIV recency testing, we explored the extent sample type influences whether a person is assigned as being recent. Implementing a laboratory-based Recent Infection Testing Algorithm (RITA) across the Centre for Sexual Health and HIV/AIDS Research (CeSHHAR) key populations programme in Zimbabwe between October 2021 and January 2023, we compared plasma-based and dried-bloodspot (DBS) HIV recency samples. Over the study period, 24,976 individual female sex workers HIV tested, of whom 9.5% (2,363/24,979) newly tested HIV positive. Of these 2,363 women, 55.5% (1311/2,363) were offered and gave consent for a sample to be taken for DBS recency and viral load testing, among whom 11.7% (153/1,311) were classified as having a recent infection. A subset of 464 women were offered and consented to paired sample collection, among whom 10.1% (47) and 12.3% (57) of plasma and DBS samples, respectively, were classified as recent. Overall, categorical determination was good, with 97% of results concordant. Of 58 women with paired sample collection who had a test result classified as recent, 46 (79.3%) were concordant recent on both DBS and plasma, with 12 (20.7%) being dis-concordant. Of these 12 womens samples, 11 were deemed long-standing by the plasma assay but recent by the paired DBS, and one deemed long-standing by DBS but recent by the paired plasma sample. Depending on use-case and setting, there are trade-offs when considering DBS or plasma-based samples between test performance and ease of implementation. Our data can help inform statistical adjustments to harmonise cut-offs on DBS and plasma assays, thereby improving the use and interpretation of recency assays in population-level HIV surveillance activities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Lipoprotein (a) is associated with increased risk of Abdominal Aortic Aneurysm\nAbstract: IntroductionLipoprotein(a) (Lp(a)) is a circulating apolipoprotein B (ApoB) containing particle that has been observationally linked to atherosclerotic cardiovascular disease and is the target of emerging therapeutics. Recent work has highlighted the role of circulating lipoproteins in abdominal aortic aneurysm (AAA). We sought to triangulate human observational and genetic evidence to evaluate the role of Lp(a) in AAA.  MethodsWe tested the association between circulating levels of Lp(a) and clinically diagnosed abdominal aortic aneurysms while controlling for traditional AAA risk factors and levels of ApoB using logistic regression among 795 individuals with and 374,772 individuals without AAA in the UK Biobank (UKB). Multivariable Mendelian randomization (MVMR) was used to test for putatively causal associations between Lp(a) and AAA controlling for ApoB. Genetic instruments for Lp(a) and ApoB were created from genome-wide association studies (GWAS) of Lp(a) and ApoB comprising 335,796 and 418,505 UKB participants, respectively. The instruments were tested for association with AAA using data from a GWAS of 39,221 individuals with and 1,086,107 without AAA.  ResultsElevated Lp(a) levels were observationally associated with an increased risk of AAA (OR 1.04 per 10 nmol/L Lp(a); 95%CI 1.02-1.05; P<0.01). Clinically elevated Lp(a) levels (>150nmol/L) were likewise associated with an increased risk of AAA (OR 1.47; 95% CI 1.15-1.88; P < 0.01) when compared to individuals with Lp(a) levels <150nmol/L. MVMR confirmed a significant, ApoB-independent association between increased Lp(a) and increased risk of AAA (OR 1.13 per SD increase in Lp(a); 95%CI 1.02-1.24; P<0.02).  ConclusionBoth observational and genetic analyses support an association between increased Lp(a) and AAA risk that is independent of ApoB. These findings suggest that Lp(a) may be a therapeutic target for AAA and drive the inclusion of AAA as an outcome in clinical trials of Lp(a) antagonists.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Donor HLA class 1 evolutionary divergence and late allograft rejection after liver transplantation in children: an emulated target trial.\nAbstract: HLA evolutionary divergence (HED), a continuous metric quantifying the differences between each amino acid of two homologous HLA alleles, reflects the importance of the immunopeptidome presented to T lymphocytes. It has been associated with rejection after liver transplantation. This retrospective cohort study aimed to analyze the potential effect of donor or recipient HED on liver transplant rejection in a new series of patients transplanted during childhood and followed in adulthood. The study included 120 children who had been transplanted between 1991 and 2010 and were followed by routine biopsies and histological evaluations with a median of 14.1 years post-LT. Liver biopsies were performed routinely 1, 5, 10 and 20 years after transplantation and in the event of liver dysfunction. HED was calculated using the physicochemical Grantham distance for donor and recipient class I (HLA-A, -B, -C) and class II (HLA-DRB1, -DQB1) alleles. The influence of HED on rejection was analyzed using IPW and target trial emulation using the g method. Based on the IPW score, donor HED class I was correlated with the occurrence of late (>90 days) rejection (HR, 1.19, 95% CI: 1.01-1.40) independently of HLA mismatches, donor age and initial induction. This emulated target trial confirmed that donor HED class I has a causal effect on liver graft rejection and this relationship was observed long-term.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal changes in epigenetic clocks predict survival in the InCHIANTI cohort\nAbstract: AbstractsO_ST_ABSImportanceC_ST_ABSCross-sectional assessment of epigenetic clocks provides information on the pace of aging. Whether longitudinal acceleration or deceleration of epigenetic clocks over time provides additional mortality prediction is unknown.  ObjectiveTo test the independent associations of baseline levels and longitudinal changes in epigenetic clocks with mortality  DesignLongitudinal study  SettingInCHIANTI, a population-based study of community dwelling individuals in Tuscany, Italy.  Participants699 InCHIANTI study participants aged 21-95 years at baseline with longitudinal measurements of DNA methylation.  ExposureBaseline levels and longitudinal changes in seven epigenetic clocks, including two first-generation clocks developed using chronological age for reference (Hannum Clock, Horvath Clock), three second-generation clocks developed using time-to-death for references (DNAmPhenoAge, DNAmGrimAge, DNAmGrimAge Version 2), and two third-generation clocks developed using longitudinal rate of change of multiple phenotypes for reference (DunedinPOAm_38, DunedinPACE).  Main Outcomes and MeasuresMortality was the primary outcome. Cox regression was used to estimate independent associations of baseline and longitudinal changes in epigenetic clocks with mortality.  ResultsAdjusting for age, sex, study sites, and epigenetic clock at the baseline, longitudinal changes of the following epigenetic clocks were associated with mortality: Hannum clock (aHR = 1.14, 95% CI:[1.03, 1.26]), DNAmPhenoAge (aHR = 1.23, 95% CI: [1.10,1.37]), DNAmGrimAge (aHR = 1.13, 95% CI: [1.02,1.26]), DNAmGrimAge Version 2 (aHR = 1.18, 95% CI:[1.06,1.31]), and DunedinPOAm_38 (aHR = 1.15, 95%CI: [1.01,1.30]).  Conclusions and RelevanceOur findings confirm that epigenetic clocks capture a dimension of health that is predictive of mortality and add the notion that time changes of epigenetic age reflect changes in health that additionally and independently contribute to mortality prediction. Future studies should test whether interventions that slow down the rate of epigenetic aging are associated with longer healthspan and lifespan.  Key PointsQuestion: Is the rate of change in epigenetic clock associated with differential mortality?  Findings: In 699 adults with followed for up to 24 years, faster longitudinal changes in epigenetic clocks (Hannum clock, DNAmPhenoAge, DNAmGrimAge, DNAmGrimAge version 2, DunedinPOAm_38, DunedinPACE) were significantly associated with higher mortality, independent of baseline epigenetic age and other confounders.  Meaning: Independent of chronological age, epigenetic clock and change over time of epigenetic clock independently predicted the risk of death. Interventions that slow down the pace of epigenetic aging may enhance healthy longevity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human genetic evidence to inform clinical development of interleukin-6 signaling inhibition for abdominal aortic aneurysm\nAbstract: BackgroundAbdominal aortic aneurysm (AAA) represents a significant cause of mortality, yet no medical therapies have proven efficacious. The aim of the current study was to leverage human genetic evidence to inform clinical development of interleukin-6 (IL6) signaling inhibition for treatment of AAA.  MethodsWe focused on rs2228145, a missense variant in the IL6R gene region whose associations are expressed per additional copy of the C allele, corresponding to the genetically-predicted effect of IL6 signaling inhibition. We consider genetic associations with AAA risk in the AAAgen consortium (39,221 cases, 1,086,107 controls) and UK Biobank (2215 cases, 365,428 controls). To validate against known effects of IL6 signaling inhibition, we present associations with rheumatoid arthritis, polymyalgia rheumatica, and severe COVID-19. To explore mechanism specificity, we present associations with thoracic aortic aneurysm, intracranial aneurysm, and coronary artery disease. We further evaluated associations with measures of the abdominal aorta in UK Biobank, and explored genetic associations in clinically-relevant subgroups of the population.  ResultsWe observed strong genetic associations with AAA risk in the AAAgen consortium and in UK Biobank: odds ratio (OR) 0.91 (95% confidence interval [CI]: 0.90 to 0.92, p = 4x10-30) and OR 0.90 (95% CI: 0.84, 0.96, p=0.0007), respectively. The association with AAA risk in UK Biobank was linear in the number of minor alleles: OR 0.91 (95% CI: 0.83, 1.00) in heterozygotes and OR 0.80 (95% CI: 0.71, 0.92) in minor homozygotes. The association was similar for fatal AAA, but with greater uncertainty due to the lower number of events. The association with AAA was of greater magnitude than associations with coronary artery disease and even rheumatologic disorders for which IL6 inhibitors have been approved. No strong associations were observed with thoracic aortic aneurysm, intracranial aneurysm, or abdominal aorta diameter in the general population without AAA. Associations attenuated towards the null in populations with concomitant inflammatory or connective tissue disease.  ConclusionsThis drug target Mendelian randomization study supports that IL6 signaling inhibition will be efficacious for treating AAA, but not other types of aneurysmal disease. These findings serve to help inform clinical development of IL6 signaling inhibition for AAA treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Circulating Biomarkers as Predictors of Improvement in Physical Function in Hospitalized Older Adults with Geriatric Syndromes: Findings from the REHAB-HF Trial\nAbstract: IntroductionCirculating biomarkers play an important role in patients with heart failure (HF) for risk stratification and mechanistic insights. We aimed to examine if a diverse set of biomarkers in the REHAB-HF trial would predict improvement in physical function following a 12-week tailored physical therapy rehabilitation intervention compared to attention control.  MethodsThe study population consisted of participants [&ge;]60 years of age who were hospitalized with acute HF and randomized to a subsequent multidomain outpatient physical rehabilitation intervention vs. attention control with outcomes of 12-week functional change including the Short Physical Performance Battery (SPPB) and six-minute walk distance (6MWD). Blood was collected prior to randomization and at 12-weeks for cardiac, renal, and inflammatory biomarkers. Linear trends across progressively higher biomarker values versus improvement in functional outcomes based on treatment assignment were evaluated. Classification and regression trees (CART) were created to estimate optimal biomarker levels associated with differential improvement in the two functional outcomes.  ResultsA total of 242 of 349 participants (69%) had baseline biomarkers measured. In an adjusted regression model, higher baseline cardiac troponin (cTn) I and T were associated with greater gains in SPPB and 6MWD respectively with the rehabilitation intervention (P=0.04 and 0.03 for interaction) versus attention control. In the CART analysis of the physical rehabilitation and attention control participants, those with baseline C-reactive protein (CRP) [&ge;]9.9 mg/L and hs-cTnT [&ge;]36 ng/L receiving the rehabilitation intervention had a 129 m (95% CI 78-180m) greater 12-week 6MWD increase vs attention control. In contrast, for participants with CRP<9.9 mg/L there was no significant incremental 6MWD difference (30m, 95% CI -0.5m, 60.2m). For SPPB, a CRP [&ge;]9.9 mg/L and creatinine [&ge;]1.4 mg/dL optimally identified a differential improvement with the rehabilitation intervention versus attention control. The biomarkers (except for creatinine) decreased by 12 weeks post hospitalization but with no differences based on treatment assignment.  ConclusionHigher baseline levels of biomarkers of inflammation, cardiac injury, and renal dysfunction identified older adults after a HF hospitalization with the greatest differential improvement in physical function with a rehabilitation intervention. Biomarkers may help clinicians predict the benefits of this treatment.  (Funded by the National Institutes of Health and others; REHAB-HF ClinicalTrials.gov number, NCT02196038).\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Primary Care Physicians' Practices and Barriers in Evaluating and Managing Chronic Kidney Disease in New Providence, The Bahamas\nAbstract: ObjectivesTo assess the practices and barriers in evaluating and managing chronic kidney disease among primary care physicians in New Providence, The Bahamas.  MethodsA cross-sectional study utilizing an anonymous, self-administered questionnaire was given to General Practitioners, Family Medicine, and Internal Medicine physicians after using a simple random sampling approach. Descriptive and inferential statistical analysis was conducted using IBM SPSS software.  ResultsThere were 119 physicians in this study with Family Medicine specialty area representing 52.1%. Seventy-four (74) physicians reported following CKD guidelines. The most common at-risk groups identified were Diabetes Mellitus (100%), Hypertension (98.3%), and use of nephrotoxic agents (97.5%). The most common diagnostic test used to identify CKD was eGFR (97.5%) and 72.2% of physicians used eGFR alone to stage CKD. Physicians overall agreed (40.3 - 50.4%) they were comfortable in diagnosing and managing CKD and its complications except for bone disorders (43.2%) and metabolic acidosis (34.7%) where responses were neutral. Physicians were neutral in having tools/resources to help them manage bone disorders (35.3%) and metabolic acidosis (31.9%) and disagreed to having educational tools for patients to understand bone disorders (32.2%) and metabolic acidosis (32.8%). Physicians agreed-strongly agreed with 12 of 13 perceived barriers, and there were 26 unique barriers expressed (8 patient-level, 7 provider-level, 11 systems-level).  ConclusionsDeficits in the evaluation and management of CKD, and numerous barriers to CKD care were discovered. Recommendations include the development of a national CKD guideline, local CKD continuous medical education seminars, and public health campaigns on CKD education.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Covidization and decovidization of the scientific literature and scientific workforce\nAbstract: We examined the growth trajectory and impact of COVID-19-related papers in the scientific literature until August 1, 2024 and how the scientific workforce was engaged in this work. Scopus indexed 718,660 COVID-19-related publications. As proportion of all indexed scientific publications, COVID-19-related publications peaked in September 2021 (4.7%) remained at 4.3-4.6% for another year and then gradually declined, but was still 1.9% in July 2024). COVID-19-related publications included 1,978,612 unique authors: 1,127,215 authors had [&ge;]5 full papers in their career and 53,418 authors were in the top-2% of their scientific subfield based on a career-long composite citation indicator. Authors with >10%, >30% and >50% of their total career citations be to COVID-19-related publications were 376,942, 201,702, and 125,523, respectively. As of August 1, 2024, 65 of the top-100 most-cited papers published in 2020 were COVID-19-related, declining to 24/100, 19/100, 7/100, and 5/100 for the most-cited papers published in 2021, 2022, 2023, and 2024, respectively. Across 174 scientific subfields, 132 had [&ge;]10% of their active influential (top-2% by composite citation indicator) authors publish something on COVID-19 during 2020-2024. Among the 300 authors with highest composite citation indicator specifically for their COVID-19-related publications, 41 were editors or journalists/columnists and another 23 had most of their COVID-19 citations to published items other than full papers (opinion pieces/letters/notes). COVID-19 massively engaged the scientific workforce in unprecedented ways. As the pandemic ended, there has been a sharp decline in the overall volume and high impact of newly published COVID-19-related publications.  Significance statementCOVID-19 massively mobilized the scientific workforce. Between 2020 and 2024, over 700,000 papers were published on COVID-19, including 2 million different authors. Across science, almost a third of authors at the top-2% of citation impact in their subfield published on COVID-19. There was a sharp decline in the proportion of COVID-19 papers across science after 2022 and an even more sharp decline in the proportion of COVID-19 papers reaching the highest level of citations. Authors with the highest COVID-19 citation impact prominently included many who were editors, journalists/columnists and opinion writers publishing massively. While other epidemics also witnessed sharp increases and subsequent decline in interest, the magnitude of the covidization and decovidization process is unique in the scientific literature to-date.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Normal feeding movements expressed by dimensionality reduction of whole-body joint motions using principal component analysis\nAbstract: Understanding elementary feeding movements and postures is essential for improving assessment and intervention strategies in occupational therapy, particularly for individuals with eating difficulties, and for educating caregivers and students; however, current assessment tools lack precision in evaluating complex feeding movements and often rely on subjective judgments rather than objective measures. We aimed to determine elementary movements and postures corresponding to different feeding phases using principal component analysis (PCA). This cross-sectional observational study was conducted at a Local National University Hospital and included 45 healthy, right-handed adult volunteers (23 men and 22 women) aged 20-39 years (mean age, 27.3 years), with no neurological or musculoskeletal impairments. Movements during yogurt feeding using a spoon were captured with a three-dimensional inertial sensor motion capture system. Principal components (PCs) and their scores were derived from PCA of whole-body joint motion data across four feeding phases. PC scores were compared between phases using Friedmans and post-hoc tests. The primary PC, representing whole-body movement, accounted for 50.0% of the variance; the second PC, associated with hand direction changes, accounted for 13.7%. The cumulative variance of the first six PCs was 87.4%, including individual body-part movements and fixations or combinations of these. Significant differences existed between feeding phases, particularly in the reaching and transport phases, which showed greater whole-body movement than that during the spooning and mouth phases. Hand direction changes were more prominent during the spooning phase than during the mouth phase. PCA helped determine key elementary movements and their corresponding feeding phases, which can be used to assess patients with feeding difficulties and guide occupational therapy interventions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Knowledge and experiences of adolescent girls and young women in the use of sexual reproductive health and HIV services at health facilities in Maputo City, Mozambique\nAbstract: BackgroundKnowledge and use of sexual reproductive health and human immunodeficiency virus (SRH and HIV) services are crucial for the prevention of pregnancy and sexually transmitted infections (STIs) among adolescent girls and young women (AGYW). This study aims to assess the knowledge and perceptions of AGYW about the SRH and HIV services offered in health facilities in Maputo, Mozambique.  Material and methodsA cross-sectional descriptive study was conducted based on exit surveys with AGYW held at Zimpeto and 1{degrees} de Junho Health Facilities in Maputo City, between May 1, and June 9, 2023. Data were analyzed through descriptive statistics, t-test and ANOVA, using SPSS version 20.  Results590 AGYW, aged 15-24 years of age, were included in the study. In general, knowledge of SRH and HIV services was fairly high, with knowledge of each specific service offered ranging between 38% and 97%. Knowledge about SRH and HIV services differed depending on the health facility where the AGYW sought SRH and HIV services; the participants age; their occupation; their religion, and who they lived with. Counseling services were the most commonly reported services attended, with >90% of participants reporting having received counseling for each of the following: STI and HIV and pregnancy prevention, sexuality, and safer sex practices. The quality of SRH and HIV services, and attitudes of the providers were considered good by >90% of AGYW. Roughly 95% of AGYW at Zimpeto Health Facility were either \"satisfied\" or \"very satisfied\". Whereas at 1{degrees} de Junho Health Facility, only roughly 75% of AGYW were either \"satisfied\" or \"very satisfied\", and roughly 20% of AGYW were \"little satisfied that their needs had been met that day.  ConclusionsAmong AGYW there is high levels of knowledge about counseling services in contrast to diagnostics, treatment and clinical care. Specific attention should be given to ensuring appropriate physical infrastructure, such as dedicated adolescent friendly spaces and comfortable seating, and targeted interventions designed and implemented for those health facilitiess identified. Targeted interventions should be designed and implemented for those HFs identified with lower AGYW perceived quality of service delivery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Relationship Between Electrodermal Activity and Cardiac Troponin in Patients with Paroxysmal Sympathetic Hyperactivity\nAbstract: ObjectiveTo determine the relationship between electrodermal activity (EDA) and cardiac troponin in patients with paroxysmal sympathetic hyperactivity (PSH).  MethodsThis was a study with prospectively-identified patients and a retrospective analysis utilizing electrodermal data taken from the wrist-worn Empatica E4 device (Empatica Srl, Milan, Italy) and troponin values obtained from critically-ill patients with suspected PSH (N=10). The maximum EDA value and temporally-nearest cardiac troponin were correlated to test for significance using Pearson correlation coefficient.  ResultsA moderate correlation was found between EDA and troponin in 10 patients using the most temporally-proximal troponin to each patients maximal EDA (r=0.634; p = 0.049). A subanalysis was performed excluding any patients whose available troponin data did not fall within seven days of their maximal EDA, which demonstrated a strong correlation (r=0.943; p = 0.005). No relationships between troponin and pulse, blood pressure, or temperature were found.  ConclusionsThis study establishes an association between wrist-worn EDA and a measure of possible myocardial injury in critically ill patients with PSH. Patients with elevated sympathetic activity may be at increased risk for concurrent cardiac injury or dysfunction, and thus EDA data from wrist-worn monitors may provide clinically significant data regarding sympathetic function.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Do editorial board members publish in their own journal? Review of editorial board members as authors in the main foot and ankle journals\nAbstract: BackgroundScientific publications by editorial board members in their own journals raise questions about potential biases in the peer-review process. This study investigates the prevalence of self-publishing in high-impact factor foot and ankle focused journals.  MethodsA review was performed of the highest impact factor foot and ankle focused journals/: Foot and Ankle International, Foot and Ankle Surgery y Journal of Foot and Ankle Surgery. In January 2023, the editorial board members were identified, and their names, roles, academic backgrounds, and regions were obtained. For each board member, the number of total published articles listed in PubMed and those for each corresponding journal over their entire history, during the last 5 years and during the last 3 years were compiled. Descriptive statistics analyses were performed using IBM SPSS Statistics v26.0.  ResultsThe study included 196 editorial board members from the 3 selected journals. Editorial board members have published 1694 articles in their own journals (9.17% of all the articles published in those 3 journals). Editorial board members published 23.4% (SD 23.6) of their overall production in their affiliated journals. Of that production, 39.0% (SD 38.6) have been published in the last 5 years, considering this 5-year period as the baseline for their role on the editorial board in question. Some 10% of editorial board members have published more than 50% of their scientific production in their own affiliated journal in the last 5 years. European editors (51%) have published more in their own journal over the last 5-year period than North Americans (29%) (p<0.001). Being a surgeon is related to greater publication rates in ones own affiliated journal when compared to other specialist profiles (p=0.003).  ConclusionThe publication scientific articles by editorial board members as authors in journals with which they are affiliated is a present-day phenomenon in the highest impact factor journals with a focus on the foot & ankle. Knowledge of this data could be the key to understanding the prevalence of this phenomenon, and lead to making this data more accessible.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A plasma proteomic signature for atherosclerotic cardiovascular disease risk prediction in the UK Biobank cohort\nAbstract: BackgroundWhile risk stratification for atherosclerotic cardiovascular disease (ASCVD) is essential for primary prevention, current clinical risk algorithms demonstrate variability and leave room for further improvement. The plasma proteome holds promise as a future diagnostic and prognostic tool that can accurately reflect complex human traits and disease processes. We assessed the ability of plasma proteins to predict ASCVD.  MethodClinical, genetic, and high-throughput plasma proteomic data were analyzed for association with ASCVD in a cohort of 41,650 UK Biobank participants. Selected features for analysis included clinical variables such as a UK-based cardiovascular clinical risk score (QRISK3) and lipid levels, 36 polygenic risk scores (PRSs), and Olink protein expression data of 2,920 proteins. We used least absolute shrinkage and selection operator (LASSO) regression to select features and compared area under the curve (AUC) statistics between data types. Randomized LASSO regression with a stability selection algorithm identified a smaller set of more robustly associated proteins. The benefit of plasma proteins over standard clinical variables, the QRISK3 score, and PRSs was evaluated through the derivation of {Delta} AUC values. We also assessed the incremental gain in model performance using proteomic datasets with varying numbers of proteins. To identify potential causal proteins for ASCVD, we conducted a two-sample Mendelian randomization (MR) analysis.  ResultThe mean age of our cohort was 56.0 years, 60.3% were female, and 9.8% developed incident ASCVD over a median follow-up of 6.9 years. A protein-only LASSO model selected 294 proteins and returned an AUC of 0.723 (95% CI 0.708-0.737). A clinical variable and PRS-only LASSO model selected 4 clinical variables and 20 PRSs and achieved an AUC of 0.726 (95% CI 0.712-0.741). The addition of the full proteomic dataset to clinical variables and PRSs resulted in a {Delta} AUC of 0.010 (95% CI 0.003-0.018). Fifteen proteins selected by a stability selection algorithm offered improvement in ASCVD prediction over the QRISK3 risk score [{Delta} AUC: 0.013 (95% CI 0.005-0.021)]. Filtered and clustered versions of the full proteomic dataset (consisting of 600-1,500 proteins) performed comparably to the full dataset for ASCVD prediction. Using MR, we identified 11 proteins as potentially causal for ASCVD.  ConclusionA plasma proteomic signature performs well for incident ASCVD prediction but only modestly improves prediction over clinical and genetic factors. Further studies are warranted to better elucidate the clinical utility of this signature in predicting the risk of ASCVD over the standard practice of using the QRISK3 score.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma proteomic signatures for type 2 diabetes mellitus and related traits in the UK Biobank cohort\nAbstract: Aims/hypothesisThe plasma proteome holds promise as a diagnostic and prognostic tool that can accurately reflect complex human traits and disease processes. We assessed the ability of plasma proteins to predict type 2 diabetes mellitus (T2DM) and related traits.  MethodsClinical, genetic, and high-throughput proteomic data from three subcohorts of UK Biobank participants were analyzed for association with dual-energy x-ray absorptiometry (DXA) derived truncal fat (in the adiposity subcohort), estimated maximum oxygen consumption (VO2max) (in the fitness subcohort), and incident T2DM (in the T2DM subcohort). We used least absolute shrinkage and selection operator (LASSO) regression to assess the relative ability of non-proteomic and proteomic variables to associate with each trait by comparing variance explained (R2) and area under the curve (AUC) statistics between data types. Stability selection with randomized LASSO regression identified the most robustly associated proteins for each trait. The benefit of proteomic signatures (PSs) over QDiabetes, a T2DM clinical risk score, was evaluated through the derivation of delta ({Delta}) AUC values. We also assessed the incremental gain in model performance metrics using proteomic datasets with varying numbers of proteins. A series of two-sample Mendelian randomization (MR) analyses were conducted to identify potentially causal proteins for adiposity, fitness, and T2DM.  ResultsAcross all three subcohorts, the mean age was 56.7 years and 54.9% were female. In the T2DM subcohort, 5.8% developed incident T2DM over a median follow-up of 7.6 years. LASSO-derived PSs increased the R2 of truncal fat and VO2max over clinical and genetic factors by 0.074 and 0.057, respectively. We observed a similar improvement in T2DM prediction over the QDiabetes score [{Delta} AUC: 0.016 (95% CI 0.008, 0.024)] when using a robust PS derived strictly from the T2DM outcome versus a model further augmented with non-overlapping proteins associated with adiposity and fitness. A small number of proteins (29 for truncal adiposity, 18 for VO2max, and 26 for T2DM) identified by stability selection algorithms offered most of the improvement in prediction of each outcome. Filtered and clustered versions of the full proteomic dataset supplied by the UK Biobank (ranging between 600-1,500 proteins) performed comparably to the full dataset for T2DM prediction. Using MR, we identified 4 proteins as potentially causal for adiposity, 1 as potentially causal for fitness, and 4 as potentially causal for T2DM.  Conclusions/InterpretationPlasma PSs modestly improve the prediction of incident T2DM over that possible with clinical and genetic factors. Further studies are warranted to better elucidate the clinical utility of these signatures in predicting the risk of T2DM over the standard practice of using the QDiabetes score. Candidate causally associated proteins identified through MR deserve further study as potential novel therapeutic targets for T2DM.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Improving Access and Efficiency of Acute Ischemic Stroke Treatment Across Four Canadian Provinces: A Stepped-Wedge Trial\nAbstract: BackgroundAn evidence-to-practice gap exists in acute ischemic stroke treatment, and improvements in access and efficiency of treatment with iv thrombolysis and endovascular thrombectomy (EVT) is needed. The objective of this study was to improve access and efficiency of ischemic stroke treatment across four Atlantic Canadian Provinces.  MethodsA stepped-wedge cluster trial was conducted over 30 months with 3 clusters covering 34 sites. The trial was conducted across all 4 Atlantic Canadian provinces: Nova Scotia (NS), New Brunswick (NB), Prince Edward Island (PE), and Newfoundland and Labrador (NL). The design was quasi-randomized, with each cluster associated with one or more provinces: cluster 1 - NS; cluster 2 - NB and PE; and cluster 3 - NL. The patient population was all ischemic stroke patients across all 4 provinces. The intervention was a 6-month modified Quality Improvement Collaborative (mQIC), which was modified from the Breakthrough Series Collaborative to be half of the 1-year period and conducted virtually. The intervention consisted of assembling an interdisciplinary improvement team, 2 full-day workshops, webinars, and virtual site visits. Suggested changes included 6 process improvement strategies.  ResultsThe proportion of patients that received treatment did not increase significantly with the intervention [0.4% increase for patients that received thrombolysis and/or EVT (p=0.68)]. Median door-to-needle time was reduced by 9.2 minutes with the intervention (p=0.01). Cluster 3 saw the greatest improvements in both access and efficiency.  ConclusionsA mQIC intervention resulted in improvement of process measures like door-to-needle time. Quality improvement initiatives may need to be longer to see improvements in proportion of patients treated. Tailored interventions for each health system can ensure that each system sees improvement. In-person activities might be critical to ensure fidelity of the intervention.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: I am a quarterback: A mixed methods study of death investigators' communication with family members of young sudden cardiac death victims from suspected heritable causes\nAbstract: BackgroundSudden cardiac death (SCD) is a devastating event and a leading cause of mortality, globally. In the young (2-45 years), SCD is often attributable to a heritable cardiac condition. Death investigators are often responsible for investigating the cause of death and communicating their results and risk of heritable cardiac conditions with family members of SCD victims. Family often struggles to comprehend the information that is communicated to them.  PurposeTo understand the delivery, reach and impact of communication strategies informing family members of SCD victims about their relatives cause of death and their own risk for heritable cardiac conditions.  MethodsWe conducted an explanatory sequential mixed methods study. We collected quantitative data via a web-based survey and qualitative data via telephone interviews to investigate how death investigators in Ontario and Nova Scotia, Canada, communicate with family members of SCD victims. We used descriptive statistics to analyze the survey data and thematic analysis to analyze the qualitative data. We triangulated data at multiple levels.  ResultsBetween October 2022 and July 2023, we surveyed 78 death investigators and interviewed a subset (n=20). Death investigators reported that SCDs due to suspected heritable cardiac conditions were more difficult (40%, n=31) or slightly more difficult (35%, n = 27) to investigate, often requiring a higher frequency of communication with families. Death investigators reported contacting family members via phone (n=75, 96.1%) and used various strategies to achieve their communication goals. Strategies were influenced by family characteristics; involvement of other professionals; characteristics of the investigation, access to resources, and system-level barriers.  ConclusionSCD investigations in the young due to suspected heritable cardiac conditions were more challenging and required a higher frequency of communication. Death investigators used various strategies to achieve their communication goals. Further research should examine how systematic changes can improve communication with family members.  What is Known?O_LISudden cardiac death (SCD) is a devastating and unexpected event that can be caused by heritable cardiac conditions, putting the decedents family at risk of SCD. C_LIO_LICommunication with death investigators and other health care professionals influences families experiences learning about the cause of death and about their risk for heritable cardiac condition. C_LI  What this Study AddsO_LIAccording to death investigators, SCD cases due to suspected heritable cardiac conditions are more difficult to investigate, require a higher frequency of communication with family members than other types of cases, and benefit from using different communication modalities. C_LIO_LIDespite their best intentions, death investigators are contending with many factors beyond their control that influence how communication with family members is carried out. C_LIO_LIProvincial death investigation systems alone do not currently provide families of SCD victims with sufficient communication, as families often seek external resources. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A GWAS of ACE Inhibitor-Induced Angioedema in a South African Population.\nAbstract: BackgroundAngiotensin-converting enzyme inhibitor-induced angioedema (AE-ACEI) is a life-threatening adverse event and, globally, the commonest cause of emergency presentations with angioedema. Several large genome-wide association studies (GWAS) have found genomic associations with AE-ACEI. However, despite African Americans having a 5-fold increased risk of AE-ACEI, there are no published GWAS from Africa. The aim of this study was to conduct a case-control GWAS of AE-ACEI in a South African population and perform a meta-analysis with an African American and European American population.  MethodsThe GWAS included 202 South African adults with a history of AE-ACEI and 513 controls without angioedema following angiotensin-converting enzyme inhibitor (ACEI) treatment for at least 2 years. A meta-analysis was conducted with GWAS summary statistics from an African American and European American cohort (from Vanderbilt/Marshfield with 174 cases and 489 controls).  ResultsNo SNPs attained genome-wide significance. However, 26 SNPs in the post-imputation standard GWAS of the South African cohort and 37 SNPs in the meta-analysis were associated to AE-ACEI with suggestive threshold(p-value<5.0x10-06). Some of these SNPs were found to be located close to the genes PRKCQ and RIMS1, previously linked with drug-induced angioedema, and also close to the CSMD1 gene linked to ACEI cough, providing replication at the gene level, but with novel lead SNPs.  ConclusionsOur results highlight the importance of African populations to detect novel variants in replication studies. Further increased sampling across the continent and matched functional work are needed to confirm the importance of genetic variation in understanding the biology of AE-ACEI.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: is metallic perception a taste, an aroma or a flavor?\nAbstract: AimMetallic taste is known to vanish with nasal occlusion, suggesting it should be termed metallic \"aroma\" rather than metallic \"taste.\" However, it also appears after neurological injuries, such as a chorda tympani section, which suppresses taste perception mediated by the facial nerve.  MethodsIn 120 healthy volunteers, the perception of an iron sulfate solution was assessed at different lingual locations--corresponding to the facial and glossopharyngeal nerves--and with either open (n=60) or closed (n=60) noses to evaluate if it is a taste or an aroma.  ResultsNasal occlusion significantly reduced the perception of iron sulfate. It prevented perception in 31.7% of participants, though it did not completely eliminate it in the remaining 68.3%. Additionally, in open-nosed subjects, the intensity of iron sulfate perception was significantly greater when applied to the base of the tongue (glossopharyngeal nerve) than to the tip (facial nerve). These differences did not persist with nasal occlusion.  ConclusionNasal occlusion diminished but did not abolish the perception of iron sulfate. With an open nose, a differential taste perception was significant, but not with a closed nose. Therefore, metallic perception involves both retro-olfactory and gustatory components, suggesting it is a metallic flavor.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diagnostic Validity of Drinking Behaviour for Identifying Alcohol Use Disorder: Findings from a Nationally Representative Sample of Community Adults and an Inpatient Clinical Sample\nAbstract: Background and AimsAlcohol consumption is an inherent feature of alcohol use disorder (AUD), and drinking characteristics may be diagnostically informative. This study had three aims: (1) to examine the classification accuracy of several drinking quantity/frequency indicators in a large representative sample of U.S. community adults; (2) to extend the findings to a clinical sample of adults; and (3) to examine potential sex differences.  DesignThis retrospective study utilized receiver operating characteristic (ROC) curves to evaluate area under the curve (AUC). Optimal cut-offs were identified using the Youden Index. Diagnostic validity was evaluated using accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV).  MeasurementsIndex tests included measures of quantity/frequency (e.g., drinks/drinking day, largest drinks/drinking day, number of drinking days, and heavy drinking frequency). The reference standard was AUD status as determined via a clinical interview (community sample) or a symptom checklist (clinical sample).  Setting and ParticipantsTwo samples were examined: A large, nationally representative random sample of U.S. community adults who reported past-year drinking (N=25,778, AUD=20%) and a consecutive drinking clinical sample from a Canadian mental health and addictions inpatient treatment centre (N=1,341, AUD=82%).  FindingsAll drinking indicators performed much better than chance at classifying AUD (AUCs=0.60-0.92, ps<.0001). Heavy drinking frequency indicators performed optimally in both the community (AUCs=0.78-0.87; accuracy=0.72-0.80) and clinical (AUC=0.85-0.92; accuracy =0.77-0.89) samples. Collectively, the most discriminating drinking behaviors were heavy drinking episodes and exceeding NIAAA drinking low-risk guidelines. No substantive sex differences in optimal cut-offs or variable performance were observed.  ConclusionsDrinking patterns performed well at classifying AUD in both a nationally representative and large inpatient sample, robustly identifying AUD at rates much better than chance and above accepted benchmarks, with limited differences by sex. Findings broadly support the potential utility of quantitative drinking indicators as being diagnostically informative in clinical settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Education as a Proxy for Cognitive Reserve: Moderating Effects on White Matter Hyperintensity Burden in Healthy Aging and Cognitive Decline\nAbstract: BackgroundCognitive reserve, often approximated by levels of education, is thought to protect against the deleterious effects of brain pathology on cognitive function. White matter hyperintensities (WMHs) are commonly associated with aging and cognitive decline, and higher WMH burden has been linked to the progression from healthy cognitive status (HC) to mild cognitive impairment (MCI). Understanding how cognitive reserve, as indicated by education, influences the relationship between WMH burden and cognitive outcomes can provide valuable insights for interventions aimed at delaying cognitive decline.  ObjectiveThis study investigates the moderating role of education, as a proxy for cognitive reserve, on the relationship between WMH burden and the transition from HC to MCI.  MethodsData were obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) database, focusing on participants classified as cognitively healthy at baseline. A total of 153 cognitively healthy adults at the baseline were split into two groups: one group (n=85) remained cognitively healthy for at least 7 years, while the other group (n=68) progressed to MCI within 7 years. A multiple linear regression model was used to examine the interaction between group membership, baseline age, education, and sex in predicting WMH loads. The primary focus was on the interaction between group membership and education to assess the protective effect of cognitive reserve.  ResultsThe regression model explained 18.5% of the variance in WMH load. The analysis revealed statistically significant interaction between group membership and education on WMH loads (Interaction term: {beta} = -0.097, p = 0.047), indicating that higher education levels are associated with a reduced WMH burden among individuals who progressed to MCI. The main effect of education alone was not significant, nor were the interactions involving sex (p > 0.05).  ConclusionThese findings support the hypothesis that education, as a proxy for cognitive reserve, provides a protective effect against the accumulation of WMH burden in older adults. The results suggest that higher cognitive reserve may mitigate the impact of neurodegenerative processes, thereby delaying the transition from HC to MCI. This underscores the importance of educational attainment in the preservation of cognitive health during aging.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Impact of Chlorinated Drinking Water Exposure on Gut Microbiota Development in Infants: a Randomised Controlled Trial.\nAbstract: BackgroundEarly gut microbiota disruptions can increase the risk for dysbiosis and predispose to chronic diseases. While chlorinated drinking water is generally considered safe, the antimicrobial effects of chlorine-based disinfectants may negatively impact the developing infant microbiota, which is particularly vulnerable during this critical period. This study investigates the specific effects of chlorinated water on the gut microbiome in infants.  MethodsThe waTer qUality and Microbiome Study (TUMS) is a double-blinded, randomized controlled trial (RCT). Six-month old infants (n=197) received either de-chlorinated drinking water (via benchtop filtration), or regular tap water for twelve months. Stool samples were collected at six-months (baseline) and at eighteen-months of age. Metagenomic sequencing was used for faecal microbiome analysis. Samples of participant tap water was also collected pre- and post-intervention.  ResultsParticipants were balanced for sex, delivery method, and breast-feeding status at time of recruitment between the control (n=98) and treatment (n=99) groups. We collected a total of 170 baseline stool samples (83 in the control group and 87 in the treatment group), and 130 follow-up stool samples (65 in the control group and 65 in the treatment group). Interindividual variation was higher at six-months compared to eighteen months. No significant differences in overall community structure (beta diversity (p=0.35), richness (p=0.98) or Shannon Index (p=0.45)) were found between treatment groups. However, 55 genera were differentially abundant at follow-up (adjusted p-value < 0.01), primarily within the Firmicutes phylum. Analysis of metabolic pathways revealed the chlorinated water group showed significantly higher abundance of antibiotic resistance genes mostly attributable to Escherichia and Klebsiella species.  ConclusionWater chlorination induces predominantly minor changes in infant gut microbiome composition; but appears to increase the abundance of antibiotic-resistant genes. While water chlorination remains a vital public health tool for ensuring safe drinking water, our findings underscore the need for continued research into the potential for increased antibiotic resistance and suggest there may be value in exploring alternative disinfectant strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mayo Normative Studies: regression-based normative data for remote self-administration of the Stricker Learning Span, Symbols Test and Mayo Test Drive Screening Battery Composite and validation in individuals with Mild Cognitive Impairment and dementia\nAbstract: ObjectiveFew normative data for unsupervised, remotely-administered computerized cognitive measures are available. We examined variables to include in normative models for Mayo Test Drive (a multi-device remote cognitive assessment platform) measures, developed normative data, and validated the norms.  Method1240 Cognitively Unimpaired (CU) adults ages 32-100-years (96% white) from the Mayo Clinic Study of Aging and Mayo Alzheimers Disease Research Center with Clinical Dementia Rating(R) of 0 were included. We converted raw scores to normalized scaled scores and derived regression-based normative data adjusting for age, age2, sex and education (base model); alternative norms are also provided (age+age2+sex; age+age2). We assessed additional terms using an a priori cut-off of 1% variance improvement above the base model. We examined low test performance rates (<-1 standard deviation) in independent validation samples (n=167 CU, n=64 mild cognitive impairment (MCI), n=14 dementia). Rates were significantly different when 95% confidence intervals (CI) did not include the expected 14.7% base rate.  ResultsNo model terms met the a priori cut-off beyond the base model, including device type, response input source (e.g., mouse, etc.) or session interference. Norms showed expected low performance rates in CU and greater rates of low performance in MCI and dementia in independent validation samples.  ConclusionTypical normative models appear appropriate for remote self-administered MTD measures and are sensitive to cognitive impairment. Device type and response input source did not explain enough variance for inclusion in normative models but are important for individual-level interpretation. Future work will increase inclusion of individuals from under-represented groups.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: EEG frontal alpha asymmetry mediates the association between maternal and child internalizing symptoms in childhood\nAbstract: BackgroundAnxiety and depression are highly prevalent in youth and can cause significant distress and functional impairment. The presence of maternal anxiety and depression are well-established risk factors for child internalizing psychopathology, yet the responsible mechanisms linking the two remain unclear.  MethodsWe examined the potential mediating and moderating roles of EEG frontal alpha asymmetry (FAA) in the intergenerational transmission of internalizing symptoms in a longitudinal sample of N = 323 mother-child dyads. Self-report maternal internalizing symptoms were evaluated at child age 3 years and 5 years, child EEG at 5 years, and parent-report child internalizing symptoms at age 7 years. Mediation was evaluated via bootstrapped (N = 5000) confidence intervals.  ResultsWe found significant associations among maternal internalizing (anxiety, depressive) symptoms at child ages 3 and 5 years, child FAA at age 5 years, and child internalizing symptoms at age 7 years. There was a significant mediation effect, whereby greater maternal anxiety and depressive symptoms at age 3 years were significantly associated with greater relative right FAA in children at age 5 years, which, in turn, was significantly associated with greater child internalizing symptoms at age 7 years (ps<.001). There was no moderating effect of FAA on the association between maternal internalizing symptoms at age 5 years and child internalizing symptoms at age 7 years.  ConclusionsGreater right frontal asymmetry may be a neurophysiological mechanism that mediates the intergenerational transmission of internalizing symptoms.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and real-world effectiveness of popular smoking cessation aids in England: a population-based study\nAbstract: ImportanceA wide range of medications, non-combustible nicotine products, behavioural support, and alternative treatments are available in England to help people stop smoking. Understanding their effectiveness in the real world can support informed decision-making.  ObjectivesTo provide up-to-date estimates of the prevalence and real-world effectiveness of different smoking cessation aids and explore moderation of effectiveness by socioeconomic position.  DesignPopulation-based survey, 2006-2024.  SettingEngland.  Participants25,094 adults ([&ge;]16y) who reported having tried to quit smoking in the past year.  Main outcomes and measuresThe outcome variable was self-reported continuous abstinence from the start of the most recent quit attempt up to the time of survey. Independent variables were use (yes/no) of the following aids in the most recent attempt: nicotine replacement therapy (NRT) obtained on prescription or over-the-counter; varenicline; bupropion; e-cigarettes; face-to-face behavioural support; telephone support; written self-help materials; websites; smartphone apps; hypnotherapy; Allen Carrs Easyway method; heated tobacco products (HTPs); nicotine pouches. Covariates included sociodemographic characteristics and features of the quit attempt.  ResultsWe analysed data from 25,094 participants (mean [SD] age = 38.7y [15.3]; 48.5% women). In 2023/24, the most used aids were e-cigarettes (40.2%) and over-the-counter NRT (17.3%); 40.8% of quit attempts were unaided. While e-cigarette use was associated with higher odds of abstinence after adjustment for use of other aids and covariates (OR=1.95 [1.74-2.17]), use of over-the-counter NRT was not (OR=1.03 [0.93-1.15]). Other aids positively associated with abstinence were websites (used by 4.6% in 2023/24; OR=1.43 [1.03-1.98]), prescription NRT (4.5%; OR=1.33 [1.12-1.58]), varenicline (1.1%; OR=1.80 [1.50-2.18]), and HTPs (0.7%; OR=2.37 [1.24-4.51]). Face-to-face behavioural support (used by 2.2% in 2023/24) was also associated with higher odds of abstinence among those from less advantaged (OR=1.59 [1.19-2.14]) but not more advantaged social grades (OR=0.91 [0.65-1.29]). There was not clear evidence of a benefit of any other aid, although some analyses were inconclusive.  Conclusions and relevanceA range of effective smoking cessation aids are available in England, but many people try to quit using less effective forms of support or none at all. Quit success rates could be improved by encouraging people to use more effective methods.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of air pollution from a landfill site with primary care consultation\nAbstract: BackgroundWaste landfill sites are associated with gaseous emissions and this air pollution can cause unpleasant smells (\"malodour\"). This causes concerns about its impact on the health of the local population. This study assessed change in general practice consultation behaviour during a period of increased complaints associated with air pollution at a UK landfill site.  MethodsThe study period was October 2020 to December 2021. The age-sex standardised prevalence and incidence of consultations for mental health, respiratory, and other symptoms hypothesised to be impacted by the air pollution issues were determined and compared between: i) 6 practices located close to the landfill site (zone A), ii) 6 practices located a mid-distance from the site (zone B), iii) 6 practices located further away and expected to have had less impact (zone C).  ResultsWhilst there was an increased consultation for mental health problems in practices nearest to the landfill site compared to those furthest away, consultation frequencies for respiratory and other potentially associated symptoms were lower and likelihood of consultation was consistently highest in practices located in zone B.  ConclusionThis study did not show clear evidence of an increase in recorded primary healthcare contacts for conditions and symptoms hypothesised to be connected to air pollution. It highlighted the challenges of examining the impact of air pollution on the health of local populations. Since this study focussed on coded consultations in primary care and not symptoms present in the general population, an impact on the health of individuals cannot be ruled out.  How this fits inO_LIAir pollution from waste landfill sites may impact on the health of the local population. C_LIO_LIWe did not find consistent evidence of increased healthcare consultations to general practices which were nearest to such pollution. C_LIO_LIThis study highlights the challenges in examining the impact of air pollution on health. C_LIO_LISymptoms may still be increased in the general population and an impact on the health of individuals cannot be ruled out. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: INCIDENCE OF BENIGN PROSTATIC HYPERPLASIA IN TESTICULAR CANCER SURVIVORS IN THE VETERANS AFFAIRS HEALTH SYSTEM\nAbstract: Testosterone and prostatic inflammation have been postulated to influence the development of benign prostatic hyperplasia (BPH). Our study aims to evaluate the incidence of BPH in Testicular Cancer (TCa) survivors, focusing on the impact of chemotherapy and post TCa diagnosed hypogonadism. We conducted a retrospective cohort analysis of US veterans diagnosed with TCa between 1990 to 2021, using the Veterans affairs database. BPH was defined using International Classification of Diseases (ICD) codes, Current Procedural Terminology (CPT) codes, or a 6-month prescription of medications. Associations with BPH were analysed, stratifying the cohort by receipt of chemotherapy and presence of hypogonadism. Multivariable cox regression models were used to determine statistical significance (p-value <0.05). Our cohort included 2038 TCa survivors with a median age at diagnosis of 41 years. On multivariable cox regression analysis, receipt of chemotherapy wasnt significantly associated with incidence of BPH (p-value= 0.13). When stratified by diagnosis of hypogonadism prior to BPH, no significant associations were found on univariable (p=0.81) as well as multivariable (p=0.65) analyses. In the multivariable model, age at diagnosis was significantly associated with an increased incidence of BPH (Hazard ratio: 1.06, p<0.001). Our findings demonstrate that age is a significant factor associated with development of BPH in this population, while suggesting that chemotherapy for TCa and hypogonadism might not substantially alter the development of BPH.  Patient summaryIn this study, we looked at whether testicular cancer survivors are more likely to develop an enlarged prostate (Benign Prostatic Hyperplasia), especially if they received chemotherapy or had low testosterone afterward. We found that age, rather than cancer treatment or testosterone levels, was the main factor linked to developing an enlarged prostate.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Barriers and facilitators for the implementation of wiki- and blog-based Virtual Learning Environments as tools for improving collaborative learning in the Bachelor of Nursing degree.\nAbstract: There is little research on teachers perceptions of the use of Virtual Learning Environments (VLEs) in undergraduate nursing education. The aim of this study was to understand teachers perceptions of the barriers and facilitators for the implementation of wiki- and blog-based VLEs as tools to improve collaborative learning.  A qualitative action-research study in an intentional opinion-intensity sample of teachers on the Bachelor of Nursing degree course was used. The data were collected and analysed according to the SWOT approach, the constant comparison method, and the coding process.  The analysis highlighted weaknesses (e.g., limited audio-visual communication and feedback, privacy concerns), threats (e.g., training, pre-planning, and time cost), strengths (e.g., being intuitive, friendly and accessible, creating shared knowledge) and opportunities (e.g., improving technological skills, teaching innovation, evaluation and peer learning) for the incorporation of VLEs to promote collaborative learning in nursing training.  Although both our study and the existing literature on the subject show many advantages that encourage the implementation of VLEs in nursing training, the barriers described in this paper cannot be ignored in the context in which the university currently finds itself.  These barriers and facilitators to implementing VLEs in nursing training will be of interest to educational authorities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Contraceptive Outcomes of the Natural Cycles Birth Control App: A Study of Canadian Women\nAbstract: ObjectiveThis study aimed to investigate the key demographics and evaluate the real-world contraceptive failure and continuation rates of the Natural Cycles app in a cohort of women from Canada.  MethodsThis was a real-world, prospective cohort study. Demographics were assessed via in-app questionnaires. Contraceptive failure rates in typical and perfect use were calculated using the 13-cycle cumulative pregnancy probability (Kaplan-Meier survival analysis) and the one-year Pearl Index (PI). One-year continuation rates were estimated through survival analysis.  ResultsThe study included 8  798 women who contributed an average of 9.2 months of data, amounting to a total of 7 063 woman-years of exposure. The average user was 27.3 years old, had a body mass index of 24.6, and reported being in a stable relationship. With typical use, the app demonstrated a 13-cycle cumulative pregnancy probability of 4.8 [95% CI: 4.3, 5.4] and a Pearl Index of 4.3 [95% CI: 3.9, 4.8]. Under perfect use, the contraceptive failure rate was 2.3 [95% CI: 0.7, 3.9] for life table analysis and 1.7 [95% CI: 0.5, 2.8] for the 1-year PI. The contraceptive methods continuation rate after one year was 62.4%.  ConclusionsThe data presented in this study offer valuable insights into the cohort of women using the Natural Cycles app in Canada and provide country-specific effectiveness estimates. The apps contraceptive effectiveness aligns with previously published data on Natural Cycles.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PSMA+ Extracellular Vesicles are a Biomarker for SABR in Oligorecurrent Prostate Cancer Analysis from the STOMP-like and ORIOLE trial cohorts\nAbstract: PurposeTwo randomized clinical trials (STOMP and ORIOLE) demonstrated that stereotactic ablative radiotherapy (SABR) can prolong ADT-free survival or progression-free survival (PFS) in patients with metachronous oligometastatic prostate cancer (omCSPC) patients. While most omCSPC patients have a more modest delay in progression, a small subset achieves a durable response following SABR. We investigated the prognostic and predictive value of circulating PSMA-positive extracellular vesicles (PSMA+EV) and prostate specific antigen (PSA) in a biomarker correlative study using blood samples from three independent patient cohorts.  MethodsPlasma samples from 46 patients on the ORIOLE trial and 127 patietns on the STOMP trial protocol with omCSPC patients treated with SABR. Pre-SABR PSMA+EV levels (EVs/ml) were measured by nanoscale flow cytometry. Kaplan-Meier curves and logistic regression models were used to determine the association of PSMA+EV and PSA levels with clinical outcomes.  ResultsIn the pooled cohorts, median bPFS were 26.1 and 15.0 months (p=0.005) and median rPFS were 36.0 and 25.0 months (p=0.003) for PSMA+EV low and high groups, respectively. The combination of pre-SABR low levels of both PSMA+EV and PSA was associated with lower risk of radiographic progression (HR=0.34, 95% CI: 0.18-0.58, p=0.0002). In the ORIOLE cohort, which included both a SABR arm and an observation arm, low PSMA+EV was predictive of benefit from SABR (p=0.012).  ConclusionsPSMA+EV is a novel prognostic and predictive biomarker of radiographically occult tumor burden in omCSPC. PSMA+EV may inform clinical decisions regarding which patients achieve a durable benefit from consolidative SABR alone.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deciphering the functional impact of Alzheimers Disease-associated variants in resting and proinflammatory immune cells\nAbstract: Genome-wide association studies have identified loci associated with Alzheimers Disease (AD), but identifying the exact causal variants and genes at each locus is challenging due to linkage disequilibrium and their largely non-coding nature. To address this, we performed a massively parallel reporter assay of 3,576 AD-associated variants in THP-1 macrophages in both resting and proinflammatory states and identified 47 expression-modulating variants (emVars). To understand the endogenous chromatin context of emVars, we built an activity-by-contact model using epigenomic maps of macrophage inflammation and inferred condition-specific enhancer-promoter pairs. Intersection of emVars with enhancer-promoter pairs and microglia expression quantitative trait loci allowed us to connect 39 emVars to 76 putative AD risk genes enriched for AD-associated molecular signatures. Overall, systematic characterization of AD-associated variants enhances our understanding of the regulatory mechanisms underlying AD pathogenesis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Linking the plasma proteome to genetics in individuals from continental Africa provides insights into type 2 diabetes pathogenesis\nAbstract: Individuals of African ancestry remain largely underrepresented in genetic and proteomic studies. Here, we measure the levels of 2,873 proteins using the Olink proximity extension assay in plasma samples from 163 individuals with type 2 diabetes (T2D) or prediabetes and 362 normoglycemic controls from the Ugandan population for the first time. We identify 88 differentially expressed proteins between the two groups and 208 proteins associated with cardiometabolic traits. We link genome-wide data to protein expression levels and construct the first protein quantitative trait locus (pQTL) map in this population. We identify 399 independent associations with 346 (86.7%) cis-pQTLs and 53 (13.3%) trans-pQTLs. 16.7% of the cis-pQTLs and all of the trans-pQTLs have not been previously reported in African-ancestry individuals. Of these, 37 pQTLs have not been previously reported in any population. We find evidence for colocalization between a pQTL for SIRPA and T2D genetic risk. Mendelian randomization analysis identified 20 proteins causally associated with T2D. Our findings reveal proteins causally implicated in the pathogenesis of T2D, which may be leveraged for personalized medicine tailored to African-ancestry individuals.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterizing the connection between Parkinson's disease progression and healthcare utilization\nAbstract: Background and ObjectivesParkinsons disease (PD) progression can be characterized in terms of healthcare utilization by analyzing clinical events across different stages of disease.  MethodsPD progression was measured by the Hoehn & Yahr (H&Y) clinical rating scale and clinical events at each stage were evaluated. Natural language processing and a large language model were used to extract H&Y values from real-world data enabling a larger cohort than manually collected studies, and multi-state hidden Markov models were used for H&Y progression likelihood.  ResultsWithin the one year, most patients in H&Y stages 2-5 remained in the same stage. Stage transitions, when they occurred, were most frequently to the next higher stage. Higher H&Y stages were associated with discharges into long term care and higher rates of additional clinical events.  ConclusionsStratifying key clinical events by H&Y score demonstrates the increases of health care utilization and economic burden with PD severity. Modelling the progression likelihood establishes a progression timeline and emphasizes the unmet need to identify treatment options that stop or slow these transitions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparing Client and Provider Preferences for HIV Care Coordination Program Features using Discrete Choice Experiments\nAbstract: IntroductionThe New York City (NYC) HIV Care Coordination Program (CCP) is designed to promote care engagement and treatment adherence among the people with HIV (PWH) who struggle the most with these key components of managing their health. We assessed preferences for CCP components among PWH enrolled in the program (\"clients\") and among providers of CCP services. In this report we compare the preferences between clients and providers, previously analyzed separately.  MethodsWe used a discrete choice experiment to assess preferences for four CCP features (\"attributes\"): Help with Adherence to Antiretroviral Therapy (ART), Help with Primary Care Appointments, Help with Issues other than Primary Care, and Where Program Visits Happen. Each of these attributes had three to four variants (\"levels\"). In the original surveys, levels within Where Program Visits Happen varied by participant type (client versus provider). We re-coded the levels by visit location (VL) or by travel time (TT) to make them comparable, and report results from both approaches. Preferences were quantified using the relative importance of the attributes and utility of the levels.  ResultsJanuary 2020 to March 2021, 152 providers and 181 clients completed the survey. In both the VL and TT analyses, clients were most influenced by Help with Adherence to ART, preferring medication reminders via phone or text, and Where Program Visits Happen, preferring visits via phone or video chat. In the VL analysis, providers were most influenced by Help with Adherence to ART, valuing directly observed therapy most highly, and Help with Issues other than Primary Care, valuing helping clients with connections to specialty medical care. In the TT analysis, providers were most influenced by Where Program Visits Happen, preferring to meet at clients homes, and Help with Issues other than Primary Care, again preferring helping clients make connections to specialty medical care.  ConclusionsClient and provider preferences clearly diverged with regard to CCP service intensity: in the aggregate, clients tended to prefer lower-intensity services, whereas providers endorsed higher-intensity services. These results highlight the importance of engaging clients as partners in decisions about program services so that they are aligned with client values.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Efficacy and Safety of Nicorandil for Prevention of Contrast-Induced Nephropathy in Patients Undergoing Coronary Procedures: A Systematic Review and Meta-Analysis\nAbstract: BackgroundContrast-induced nephropathy (CIN) is a potentially serious complication of intravenous or intra-arterial contrast administration during angiographic procedures that results in renal dysfunction. This meta-analysis assesses the efficacy and safety of nicorandil for the prevention of CIN in patients undergoing percutaneous coronary intervention (PCI) or coronary angiography (CAG).  MethodsCochrane Central Register of Controlled Trials, MEDLINE, Embase, and ClinicalTrials.gov were used to perform a thorough literature search from their inception to July 2024. A random-effects meta-analysis was performed on RevMan and pooled estimates were presented as forest plots. The Mantel-Haenszel method was used for dichotomous outcomes and risk ratios (RRs) were calculated along with 95% confidence intervals (95% CI).  ResultsThis meta-analysis included 12 RCTs consisting of 2787 participants (nicorandil: 1418, control: 1394). The use of nicorandil was protective against CIN (RR 0.38, 95% CI 0.29-0.50). The incidence of major adverse events was comparable in both groups (RR 0.77, 95% CI 0.52-1.13, p=0.18). Similarly, the use of nicorandil did not affect the risk of developing stroke (RR 1.05), myocardial infarction (RR 0.90), heart failure (RR 0.81), cardiac death (RR 0.90), and dialysis (RR 0.70).  ConclusionThis study revealed that nicorandil effectively reduced the risk of developing CIN in patients undergoing angiographic procedures like PCI or coronary angiography. However, more RCTs should be conducted for a more definitive conclusion.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of Major Adverse Cardiovascular Events following Nicotinamide Exposure: Cohort Study\nAbstract: IMPORTANCENicotinamide metabolites have recently been implicated in increased risk of major cardiovascular events (MACE). Supportive data about clinical risk of MACE for nicotinamide users is lacking.  OBJECTIVETo determine whether nicotinamide use results in an increase of MACE.  DESIGN, SETTING, PARTICIPANTSRetrospective cohort study of two patient cohorts, Vanderbilt University Medical Center (VUMC) and Military Veteran Program (MVP). The risk of MACE in patients exposed to nicotinamide was compared to the risk of MACE in unexposed patients. In the VUMC cohort, 1228 patients were exposed to nicotinamide based on keyword entry for \"nicotinamide\" or \"niacinamide\" and hand-review of charts, while 253 were unexposed but had documented recommendation for use. In the MVP cohort, there were 1594 with exposure to nicotinamide propensity score matched to 2694 without exposure.  EXPOSURESThe primary exposure for the VUMC cohort was a confirmed exposure to nicotinamide in chart review. The primary exposure for the MVP cohort was medication entry for \"nicotinamide\" or \"niacinamide\".  MAIN OUTCOME(S) AND MEASURE(S)The primary outcome was development of MACE based on a validated phenotype.  RESULTSBetween both cohorts, 6039 patients were included, of whom 5125 were male with a mean age of 63.2 years. Neither cohort had significant differences in mean age, sex, race and ethnicity between the nicotinamide exposed and unexposed groups. In the VUMC cohort, there was no significant association between nicotinamide exposure and the primary outcome of MACE (HR 0.76, 95% CI 0.46 - 1.25, p = 0.28). MACE prior to nicotinamide exposure was strongly associated with subsequent MACE (HR 9.01, 95% CI 5.90 - 13.70, p < 0.001). In the MVP cohort, we adjusted for MACE risk factors as potential confounding variables and saw no significant association between nicotinamide exposure and MACE (HR 1.00 95% CI 0.75 - 1.32), while history of prior MACE remained strongly associated with subsequent MACE (HR 9.50, 95% CI 6.38 - 14.1).  CONCLUSIONS AND RELEVANCEIn this retrospective cohort study of 6039 adults from two different patient populations, we found no increased risk of MACE in patients with nicotinamide exposure.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rapid emergence of UV stabilizer Bis(2,2,6,6-tetramethyl-4-piperidyl) sebacate (BTMPS) in the illicit fentanyl supply across the United States in July-August 2024: Results from drug and drug paraphernalia testing\nAbstract: BackgroundChanges to the US drug supply historically unfold slowly with predictable patterns of geographic diffusion. Here we draw on drug checking results from around the United States to report a rapid shift in the illicit drug supply with important implications for public health. Bis(2,2,6,6-tetramethyl-4-piperidyl) sebacate, or \"BTMPS\" is a hindered amine light stabilizer with various industrial applications. Animal studies indicate multiple kinds of adverse health effects.  MethodsDrug samples collected by community-based drug checking programs in Los Angeles and Philadelphia, along with drug residue samples from other jurisdictions in California, Delaware, Maryland, and Washington, were submitted to the National Institute on Standards and Technology. Samples were qualitatively tested with Direct Analysis in Real Time mass spectrometry, with reflex to liquid chromatography mass spectrometry (LCMS) for confirmatory testing. Quantitation - percent by mass - was performed using LCMS. At both sites where drug samples were collected, participants were asked to respond to a survey that included questions about what the substance was sold as and any unexpected effects.  ResultsBetween June 1, 2024 and August 31, 2024, a total of 178 samples sold as fentanyl were tested. Of these, 43 (24%) contained BTMPS, with the proportion per month rising from 0% in June to more than a third in August. An additional 23 residue samples from sites doing residue testing contained BTMPS. Fentanyl samples with BTMPS also contained many other compounds, including local anesthetics and alpha-2 agonists. Average fentanyl purity was significantly lower in samples with BTMPS compared to samples without.  ConclusionsThe introduction of an industrial chemical to the illicit drug supply at this speed and scale is unprecedented and concerning. Further research is urgently needed to determine why it is present in the fentanyl supply and characterize effects on human health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deriving Imaging Biomarkers for Primary Central Nervous System Lymphoma Using Deep Learning\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSPurposeC_ST_ABSPrimary central nervous system lymphoma (PCNSL) is typically treated with chemotherapy, steroids, and/or whole brain radiotherapy (WBRT). Identifying which patients benefit from WBRT following chemotherapy, and which patients can be adequately treated with chemotherapy alone remains a persistent clinical challenge. Although WBRT is associated with improved outcomes, it also carries a risk of neuro-cognitive side effects. This study aims to refine patient phenotyping for PCNSL by leveraging deep learning (DL) extracted imaging biomarkers to enable personalized therapy.  MethodsOur study included 71 patients treated at our institution between 2009-2021. The primary outcome of interest was overall survival (OS) assessed at one-year, two-year, and median cohort survival cutoffs. The DL model leveraged an 8-layer 2D convolutional neural network which analyzed individual slices of post-contrast T1-weighted pre-treatment MRI scans. Survival predictions were made using a weighted voting system related to tumor size. Model performance was assessed with accuracy, sensitivity, specificity, and F1 scores. Time-dependent AUCs were calculated and C-statistics were computed to summarize the results. Kaplan-Meier (KM) survival analysis assessed differences between low and high-risk groups and statistically evaluated using the log-rank test. External validation of our model was performed with a cohort of 40 patients from an external institution.  ResultsThe cohorts average age was 65.6 years with an average OS of 2.80 years. The one-year, two-year, and median OS models achieved AUCs of 0.73 (95% C.I., 0.60-0.85), 0.70 (95% C.I., 0.58-0.82), and 0.73 (95% C.I., 0.58-0.82) respectively. KM survival curves showcased discrimination between low and high-risk groups in all models. External validation with our one-year model achieved AUC of 0.64 (95% C.I., 0.63-0.65) and significant risk discrimination. A sub-analysis showcased stable model performance across different tumor volumes and focality.  ConclusionsDL classifiers of PCNSL MRIs can stratify patient phenotypes beyond traditional risk paradigms. Given dissensus surrounding PCNSL treatment, DL can augment risk stratification and treatment personalization, especially with regards to WBRT decision making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deriving Imaging Biomarkers for Primary Central Nervous System Lymphoma Using Deep Learning\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSPurposeC_ST_ABSPrimary central nervous system lymphoma (PCNSL) is typically treated with chemotherapy, steroids, and/or whole brain radiotherapy (WBRT). Identifying which patients benefit from WBRT following chemotherapy, and which patients can be adequately treated with chemotherapy alone remains a persistent clinical challenge. Although WBRT is associated with improved outcomes, it also carries a risk of neuro-cognitive side effects. This study aims to refine patient phenotyping for PCNSL by leveraging deep learning (DL) extracted imaging biomarkers to enable personalized therapy.  MethodsOur study included 71 patients treated at our institution between 2009-2021. The primary outcome of interest was overall survival (OS) assessed at one-year, two-year, and median cohort survival cutoffs. The DL model leveraged an 8-layer 2D convolutional neural network which analyzed individual slices of post-contrast T1-weighted pre-treatment MRI scans. Survival predictions were made using a weighted voting system related to tumor size. Model performance was assessed with accuracy, sensitivity, specificity, and F1 scores. Time-dependent AUCs were calculated and C-statistics were computed to summarize the results. Kaplan-Meier (KM) survival analysis assessed differences between low and high-risk groups and statistically evaluated using the log-rank test. External validation of our model was performed with a cohort of 40 patients from an external institution.  ResultsThe cohorts average age was 65.6 years with an average OS of 2.80 years. The one-year, two-year, and median OS models achieved AUCs of 0.73 (95% C.I., 0.60-0.85), 0.70 (95% C.I., 0.58-0.82), and 0.73 (95% C.I., 0.58-0.82) respectively. KM survival curves showcased discrimination between low and high-risk groups in all models. External validation with our one-year model achieved AUC of 0.64 (95% C.I., 0.63-0.65) and significant risk discrimination. A sub-analysis showcased stable model performance across different tumor volumes and focality.  ConclusionsDL classifiers of PCNSL MRIs can stratify patient phenotypes beyond traditional risk paradigms. Given dissensus surrounding PCNSL treatment, DL can augment risk stratification and treatment personalization, especially with regards to WBRT decision making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deriving Imaging Biomarkers for Primary Central Nervous System Lymphoma Using Deep Learning\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSPurposeC_ST_ABSPrimary central nervous system lymphoma (PCNSL) is typically treated with chemotherapy, steroids, and/or whole brain radiotherapy (WBRT). Identifying which patients benefit from WBRT following chemotherapy, and which patients can be adequately treated with chemotherapy alone remains a persistent clinical challenge. Although WBRT is associated with improved outcomes, it also carries a risk of neuro-cognitive side effects. This study aims to refine patient phenotyping for PCNSL by leveraging deep learning (DL) extracted imaging biomarkers to enable personalized therapy.  MethodsOur study included 71 patients treated at our institution between 2009-2021. The primary outcome of interest was overall survival (OS) assessed at one-year, two-year, and median cohort survival cutoffs. The DL model leveraged an 8-layer 2D convolutional neural network which analyzed individual slices of post-contrast T1-weighted pre-treatment MRI scans. Survival predictions were made using a weighted voting system related to tumor size. Model performance was assessed with accuracy, sensitivity, specificity, and F1 scores. Time-dependent AUCs were calculated and C-statistics were computed to summarize the results. Kaplan-Meier (KM) survival analysis assessed differences between low and high-risk groups and statistically evaluated using the log-rank test. External validation of our model was performed with a cohort of 40 patients from an external institution.  ResultsThe cohorts average age was 65.6 years with an average OS of 2.80 years. The one-year, two-year, and median OS models achieved AUCs of 0.73 (95% C.I., 0.60-0.85), 0.70 (95% C.I., 0.58-0.82), and 0.73 (95% C.I., 0.58-0.82) respectively. KM survival curves showcased discrimination between low and high-risk groups in all models. External validation with our one-year model achieved AUC of 0.64 (95% C.I., 0.63-0.65) and significant risk discrimination. A sub-analysis showcased stable model performance across different tumor volumes and focality.  ConclusionsDL classifiers of PCNSL MRIs can stratify patient phenotypes beyond traditional risk paradigms. Given dissensus surrounding PCNSL treatment, DL can augment risk stratification and treatment personalization, especially with regards to WBRT decision making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Randomized dose-response trial of n-3 fatty acids in hormone receptor negative breast cancer survivors--impact on breast adipose oxylipin and DNA methylation patterns\nAbstract: BackgroundIncreasing evidence suggests the unique susceptibility of estrogen receptor and progesterone receptor negative (ERPR-) breast cancer to dietary fat amount and type. Dietary n-3 polyunsaturated fatty acids (PUFAs), such as docosahexaenoic acid (DHA) and eicosapentaenoic acid (EPA), may modulate breast adipose fatty acid profiles and downstream bioactive metabolites to counteract pro-inflammatory, pro-carcinogenic signaling in the mammary microenvironment.  ObjectiveTo determine effects of [~]1 to 5 g/d EPA+DHA over 12 months on breast adipose fatty acid and oxylipin profiles in women with ERPR(-) breast cancer, a high-risk molecular subtype.  MethodsWe conducted a 12-month randomized controlled, double-blind clinical trial of [~]5g/d vs [~]1g/d DHA+EPA supplementation in women within 5 years of completing standard therapy for ERPR(-) breast cancer Stages 0-III. Blood and breast adipose tissue specimens were collected every 3 months for biomarker analyses including fatty acids by gas chromatography, oxylipins by LC-MS/MS, and DNA methylation by reduced-representation bisulfite sequencing (RRBS).  ResultsA total of 51 participants completed the 12-month intervention. Study treatments were generally well-tolerated. While both doses increased n-3 PUFAs from baseline in breast adipose, erythrocytes, and plasma, the 5g/d supplement was more potent (n =51, p <0.001). The 5g/d dose also reduced plasma triglycerides from baseline (p =0.008). Breast adipose oxylipins at 0, 6, and 12 months showed dose-dependent increases in unesterified and esterified DHA and EPA metabolites (n =28). Distinct DNA methylation patterns in adipose tissue after 12 months were identified, with effects unique to the 5g/d dose group (n =17).  ConclusionsOver the course of 1 year, EPA+DHA dose-dependently increased concentrations of these fatty acids and their derivative oxylipin metabolites, producing differential DNA methylation profiles of gene promoters involved in metabolism-related pathways critical to ERPR(-) breast cancer development and progression. These data provide evidence of both metabolic and epigenetic effects of n-3 PUFAs in breast adipose tissue, elucidating novel mechanisms of action for high-dose EPA+DHA-mediated prevention of ERPR(-) breast cancer.  Clinicaltrials.gov identifier NCT02295059\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic value of YiDiXie\u2122-SS and YiDiXie\u2122-HS in esophageal cancer\nAbstract: BackgroundEsophageal cancer is a serious threat to human health and causes a heavy economic burden. upper gastrointestinal imaging(UGI imaging), enhanced CT, Fecal occult blood Tumor markers such as test(FOBT) and CEA, CA125 and CA19-9 are widely used in the screening or preliminary diagnosis of esophageal cancer. However, false positive results such as UGI imaging will bring unnecessary mental pain, expensive examination costs, examination injuries and other adverse consequences. However, false negative results such as UGI imaging lead to delayed treatment, and patients will have to bear the adverse consequences of poor prognosis, high treatment costs, poor quality of life, and short survival time. It is urgent to find a convenient, economical and non-invasive diagnostic method to reduce the false negative rate and false positive rate of UGI imaging. The objective of this study was to evaluate the diagnostic value of YiDiXie-SS and YiDiXie-HS in esophageal cancer.  Patients and methodsThis study included 164 subjects (malignant group, n=105; Benign group, n=59 cases). The remaining serum samples of the subjects were collected and the sensitivity and specificity of the YiDiXi -SS and YiDiXie-HS were evaluated using the YiDiXieall-cancer detection kit.  ResultsThe sensitivity of YiDiXie-SS was 99.0% (95% CI: 94.8% - 100%) and its specificity was 62.7% (95% CI: 50.0% - 73.9%).  The sensitivity of YiDiXie-HS was 92.3% (95% CI: 85.7% - 96.1%) and its specificity was 86.4% (95% CI: 75.5% - 93.0%). The sensitivity of YiDiXie-SS in UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 positive patients was 96.6% (95% CI: 82.8-99.8%) and 98.7% (95% CI: 93.1% - 99.9%), 100% (95% CI: 17.8% 100%), 100% (95% CI: 81.6% 100%), 100% (95% CI: 61.0% 100%), 100% (95%CI: 56.6%-100%); The specific degrees were 60.0% (95% CI: 23.1% 92.9%), 75.0% (95% CI: 30.1% 98.7%), 100% (95% CI: 5.1% 100%), 100% (95% CI: 43.9% - 100%), 100% (95% CI: 5.1% 100%), 50.0% (95% CI: 2.6% 97.4%). This means that the application of YiDiXie-SS, without basically increasing the missed diagnosis of malignant tumors, reduced the false positive range of UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 by 60.0% (95% CI: 23.1% - 92.9%), 75.0% (95% CI: 30.1% 98.7%), 100% (95% CI: 5.1% 100%), 100% (95% CI: 43.9% 100%), 100% (95% CI: 5.1% - 100%), 50.0% (95% CI: 2.6% 97.4%).  The sensitivity of YiDiXie-HS in UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 negative patients was 88.9% (95% CI: 56.5% - 99.4%), 92.6% (95% CI: 84.8% - 96.6%), 96.9% (95% CI: 84.3% - 99.8%), 92.6% (95% CI: 84.8% - 96.6%), 92.0% (95% CI: 84.5% - 96.1%), 91.3% (95% CI: 83.8% - 95.5%), respectively; The specific degrees were 60.0% (95% CI: 23.1% 92.9%), 87.3% (95% CI: 76.0% 93.7%), 80.0% (95% CI: 37.6% 99.0%), 89.1% (95% CI: 78.2% - 94.9%), 79.3% (95% CI: 61.6% 90.2%), 87.0% (95% CI: 75.6% 93.6%). This means that YiDiXie-HS reduced false negatives for UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 by 88.9% (95% CI: 56.5% - 99.4%), 92.6% (95% CI: 84.8% 96.6%), 96.9% (95% CI: 84.3% 99.8%), 92.6% (95% CI: 84.8% 96.6%), 92.0% (95% CI: 84.5% - 96.1%), 91.3% (95% CI: 83.8% 95.5%).  ConclusionYiDiXie-SS significantly reduced the false-positive rate of UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 without substantially increasing the delayed treatment of malignant tumors. YiDiXie -HS significantly reduced false negative rates for UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9. YiDiXie-SS and YiDiXie-HS have important diagnostic value in esophageal cancer, and are expected to solve the two problems of \"too high false positive rate such as UGI imaging\" and \"too high false negative rate such as UGI imaging\" in esophageal cancer.  Clinical trial numberChiCTR2200066840.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic value of YiDiXie\u2122-SS, YiDiXie\u2122-HS, and YiDiXie\u2122-D in Ovarian cancer\nAbstract: BackgroundOvarian cancer is a serious risk to human health and causes a heavy economic burden. Ultrasound is widely used in the diagnosis of ovarian tumors. However, false-positive ultrasound results can lead to false diagnosis, and patients will have to bear unnecessary mental pain, expensive surgery and examination costs, surgical trauma, organ removal, loss of function, and even serious complications in the perioperative period, and other adverse consequences. False-negative ultrasound results lead to delayed treatment, and patients will have to bear the consequences of poor prognosis, high treatment costs, poor quality of life, and poor survival. There is an urgent need to find convenient, cost-effective and non-invasive diagnostic methods to reduce the false-negative and false-positive rates of ovarian ultrasound. The purpose of this study was to evaluate the diagnostic value of YiDiXie-SS, YiDiXie-HS and YiDiXie-D in Ovarian cancer.  Patients and methodsThe study finally included 79 study subjects (malignant group, n=12; benign group, n=67). Remaining serum samples from the subjects were collected and tested by applying YiDiXie all-cancer detection kit to evaluate the sensitivity and specificity of YiDiXie-SS, YiDiXie-HS and YiDiXie-D, respectively.  ResultsYiDiXie-SS had a sensitivity of 100% (95% CI: 75.8% - 100%) and a specificity of 61.2% (95% CI: 49.2% - 72.0%). YiDiXie -HS had a sensitivity of 91.7% (95% CI: 64.6% - 99.6%) and a specificity of 86.6% (95% CI: 76.4% - 92.8%). The sensitivity of YiDiXie  -D was 33.3% (95% CI: 13.8% - 60.0%) and its specificity was 97.0% (95% CI: 89.8% - 99.5%). The sensitivity of YiDiXie-SS in ultrasound-positive patients was 100% (95% CI: 67.6% - 100%) and its specificity was 61.9% (95% CI: 40.9% - 79.2%). This represents a 61.9% (95% CI: 40.9% - 79.2%) reduction in the rate of false-positive ovarian ultrasound with the application of YiDiXie-SS with essentially no increase in malignant tumor under-diagnosis. The sensitivity of YiDiXie-HS in ultrasound-negative patients was 75.0% (95% CI: 30.1% - 98.7%) and its specificity was 84.8% (95% CI: 71.8% - 92.4%). This means that the application of YiDiXie-HS reduces the false negative rate of ultrasound by 75.0% (95% CI: 30.1% - 98.7%). YiDiXie -D had a sensitivity of 25.0% (95% CI: 4.4% - 59.1%) in ultrasound-positive patients and its specificity was 95.2% (95% CI: 77.3% - 99.8%). This represents a 95.2% (95% CI: 77.3% - 99.8%) reduction in the rate of ultrasound false positives with YiDiXie-SS.  ConclusionYiDiXie-SS markedly reduced the false-positive rate of ovarian ultrasound with essentially no increase in delayed treatment of malignant tumors. YiDiXie-HS substantially reduced the false-negative rate of ovarian ultrasound. YiDiXie -D substantially reduced the false-positive rate of ovarian ultrasound. The YiDiXie test has an excellent diagnostic value in ovarian cancer, and promises to solve the problems of \"high false-positive rate of ultrasound\" and \"high false-negative rate of ultrasound\" in ovarian tumors.  Clinical trial numberChiCTR2200066840.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Women with fibromyalgia: Insights into behavioral and brain imaging\nAbstract: Fibromyalgia (FM) is a chronic condition marked by widespread pain, fatigue, sleep problems, cognitive decline, and other symptoms. Despite extensive research, the pathophysiology of FM remains poorly understood, complicating diagnosis and treatment, which often relies on self-report questionnaires. This study explored structural and functional brain changes in women with FM, identified potential biomarkers, and examined their relationship with FM severity. MRI data from 33 female FM patients and 33 matched healthy controls were utilized, focusing on T1-weighted MRI and resting-state fMRI scans. Functional connectivity (FC) analysis was performed using a machine learning framework to differentiate FM patients from healthy controls and predict FM symptom severity. No significant differences were found in brain structural features, such as gray matter volume, white matter volume, deformation-based morphometry, and cortical thickness. However, significant differences in FC were observed between FM patients and healthy controls, particularly in the default mode network (DMN), somatomotor network (SMN), visual network (VIS), and dorsal attention network (DAN). The FC metrics were significantly associated with FM severity. Our prediction model differentiated FM patients from healthy controls with an area under the curve of 0.65. FC measures accurately estimated FM symptom severities with a significant correlation (r = 0.45, p = 0.007). Functional connections in the DMN, VIS, and DAN were crucial in determining FM severity. These findings suggest that integrating brain FC measurements could serve as valuable biomarkers for early detection of FM and predicting FM symptom severity, improving diagnostic accuracy and facilitating the development of targeted therapeutic strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic associations between SGLT2 inhibition, DPP4 inhibition or GLP1R agonism and prostate cancer risk: a two-sample Mendelian randomisation study\nAbstract: BackgroundEpidemiological studies have linked the use of the anti-diabetic medications, sodium-glucose co-transporter-2 inhibitors (SGLT2I), dipeptidyl peptidase-4 inhibitors (DPP4I) and glucagon-like peptide-1 receptor agonists (GLP1RA), with prostate cancer risk. However, these studies cannot infer causality.  MethodsThis was a two-sample Mendelian randomization (MR) using genome-wide association study data designed to identify causal relationships between SGLT2I, DPP4I or GLP1RA and prostate cancer. Genetic associations with HbA1c and risk of prostate cancer were extracted from IEU Open-GWAS Project database with GWAS id ukb-d-30750_irnt (UK Biobank cohort) and ebi-a-GCST006085 (European Molecular Biology Laboratorys European Bioinformatics Institute cohort), respectively. The two GWAS datasets chosen were obtained from individuals of European ancestry to minimise potential bias from population stratification. The encoding genes targeted by SGLT2I, DPP4I and GLP1RA were SGC5A2, DPP4 and GLP1R, located in Chr16: 31494323-31502181, Chr2: 162848755-162930904 and Chr6: 39016557-39059079, respectively.  ResultsA total of 31, 2 and 5 single nucleotide variants (SNVs) were used for SGC5A2, DPP4 and GLP1R. Our MR analysis results supported a causal relationship between genetic variation in SLC5A2 and DPP4 and reduced risk of prostate cancer at the Bonferroni-corrected threshold, with odds ratios (OR) [95% confidence intervals] of 0.47 [0.38-0.58] and 0.35 [0.24-0.53], but not for GLP1R (OR: 1.39 [0.93-2.07]). Sensitivity analyses by the leave-one-out method did not significantly alter the OR for SGLT2I.  ConclusionsThe two-sample MR analysis found that SGLT2 and DPP4 inhibition, but not GLP1R agonism, was associated with lower risks of developing prostate cancer.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Genome-wide Association Study Identifies Novel Genetic Variants Associated with Knee Pain in the UK Biobank (N = 441,757)\nAbstract: Knee pain is a widespread musculoskeletal condition affecting millions globally, with significant socio-economic implications. This study endeavors to identify genetic variants associated with knee pain through a comprehensive genome-wide association study (GWAS) using data from 441,757 individuals in the UK Biobank. The primary GWAS identified ten significant loci, including eight novel loci, with the most significant single nucleotide polymorphism (SNP) being rs143384 near the GDF5 gene on chromosome 20 (p = 4.68 x 10-19). In the replication study, seven loci (rs143384, rs919642, rs55760279, rs56076919, rs3892354, rs687878, rs368636424) were found to be significant in the FinnGen cohort. Further, sex-specific analyses revealed distinct genetic associations, identifying three loci (rs143384 with p = 1.70x10-15, rs56076919 with p = 1.60x10-9, rs919642 with p = 1.45x10-8) in females and four loci ( rs2899611 with p = 2.77 x 10-11, rs891720 with p = 5.55 x 10-11, rs2742313 with p = 4.19 x 10-9, rs2019689 with p = 6.51 x 10-9) in males. The phenome-wide association analysis and Mendelian randomization analysis revealed significant links between several phenotypes and knee pain such as leg pain on walking. These findings enhance our understanding of the genetic factors of knee pain, offering potential pathways for therapeutic interventions and personalized medical strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Genome-wide Association Study Identifies Novel Genetic Variants Associated with Knee Pain in the UK Biobank (N = 441,757)\nAbstract: Knee pain is a widespread musculoskeletal condition affecting millions globally, with significant socio-economic implications. This study endeavors to identify genetic variants associated with knee pain through a comprehensive genome-wide association study (GWAS) using data from 441,757 individuals in the UK Biobank. The primary GWAS identified ten significant loci, including eight novel loci, with the most significant single nucleotide polymorphism (SNP) being rs143384 near the GDF5 gene on chromosome 20 (p = 4.68 x 10-19). In the replication study, seven loci (rs143384, rs919642, rs55760279, rs56076919, rs3892354, rs687878, rs368636424) were found to be significant in the FinnGen cohort. Further, sex-specific analyses revealed distinct genetic associations, identifying three loci (rs143384 with p = 1.70x10-15, rs56076919 with p = 1.60x10-9, rs919642 with p = 1.45x10-8) in females and four loci ( rs2899611 with p = 2.77 x 10-11, rs891720 with p = 5.55 x 10-11, rs2742313 with p = 4.19 x 10-9, rs2019689 with p = 6.51 x 10-9) in males. The phenome-wide association analysis and Mendelian randomization analysis revealed significant links between several phenotypes and knee pain such as leg pain on walking. These findings enhance our understanding of the genetic factors of knee pain, offering potential pathways for therapeutic interventions and personalized medical strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Federated Multiple Imputation for Variables that Are Missing Not At Random in Distributed Electronic Health Records\nAbstract: Large electronic health records (EHR) have been widely implemented and are available for research activities. The magnitude of such databases often requires storage and computing infrastructure that are distributed at different sites. Restrictions on data-sharing due to privacy concerns have been another driving force behind the development of a large class of distributed and/or federated machine learning methods. While missing data problem is also present in distributed EHRs, albeit potentially more complex, distributed multiple imputation (MI) methods have not received as much attention. An important advantage of distributed MI, as well as distributed analysis, is that it allows researchers to borrow information across data sites, mitigating potential fairness issues for minority groups that do not have enough volume at certain sites. In this paper, we propose a communication-efficient and privacy-preserving distributed MI algorithms for variables that are missing not at random.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: \"Were here to help them if they want to come\": A qualitative exploration of hospital staff perceptions and experiences with outpatient non-attendance\nAbstract: BackgroundPatient non-attendance remains a major challenge for health services. Few studies have examined how health service providers think about, potentially address, and prioritise non-attendance within the scope of their practice. This study aimed to (1) explore healthcare professionals perspectives, beliefs, and opinions about the impact of patient non-attendance within a publicly-funded outpatient physiotherapy clinic context; (2) explore perceived barriers and facilitators associated with the implementation of non-attendance mitigation strategies; and (3) identify health service staff generated solutions to address perceived barriers and enhance facilitators.  O_TBL View this table: org.highwire.dtl.DTLVardef@f3d46forg.highwire.dtl.DTLVardef@1fff730org.highwire.dtl.DTLVardef@1bd9330org.highwire.dtl.DTLVardef@10a6257org.highwire.dtl.DTLVardef@be54db_HPS_FORMAT_FIGEXP  M_TBL C_TBL MethodsA focus group discussion and semi-structured interviews were conducted between June 2023 to January 2024 with 27 physiotherapy department clinic outpatient staff involved in operationalising clinic referral processing, appointment scheduling, or providing care to patients. Data was analysed using a hybrid inductive/deductive framework analysis approach.  ResultsParticipants indicated that non-attendance had predominantly negative implications for the health service, healthcare provider, and patient. The interconnected issue of non-attendance encompassed multiple areas and were broadly categorised into five inductively identified themes: impact of non-attendance, perceptions of value, material deprivation, service delivery and built environment, and professional role and identity. Non-attendance mitigation strategies generated by participants were deductively mapped to the theoretical domains framework (TDF) to explore behavioural determinants that may influence successful implementation. This included knowledge, reinforcement, goals, optimism, memory, attention and decision-making, environmental resources and context, and emotions.  ConclusionsStaff identified multiple strategies for reducing non-attendance; implementing many of these strategies would require additional resourcing. Research determining the effectiveness of such strategies both in the short-term and long-term following implementation into practice remains a priority for future investigation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Selective effects of dopaminergic and noradrenergic degeneration on cognition in Parkinson's disease\nAbstract: The substantia nigra and locus coeruleus are among the first brain regions to degenerate in Parkinsons disease. This has important implications for early cognitive deficits as these nuclei are sources of ascending neuromodulators (i.e., dopamine and noradrenaline) that support various cognitive functions like learning, memory, and executive function. However, because most studies of the relationship between patterns of degeneration and cognition have either studied these neuromodulator systems in isolation or studied specific cognitive domains in isolation, it is unknown if degeneration in the substantia nigra and degeneration in the locus coeruleus independently and selectively contribute to different cognitive deficits in Parkinsons disease.  To address this gap, we tested people with Parkinsons disease and older adults on tasks of positive reinforcement learning, attention/working memory, executive function, and memory to measure performance in domains of cognition specifically thought to be related to dopaminergic and noradrenergic function. Participants also underwent neuromelanin-sensitive magnetic resonance imaging which provides a measure of degeneration of dopamine neurons in the substantia nigra and of noradrenergic neurons in the locus coeruleus. Brain-behaviour relationships were evaluated by separate linear regressions predicting cognitive performance in each domain from substantia nigra and locus coeruleus neuromelanin signal intensities controlling for age, sex, and education.  As expected, Parkinsons disease patients had significantly slower learning from positive feedback and lower performance on tests of attention/working memory, executive function, and memory than controls. Parkinsons patients also had lower neuromelanin signal intensity in the substantia nigra and locus coeruleus. Examining brain-behaviour relationships, we found that reduced neuromelanin signal in the substantia nigra in Parkinsons disease patients was independently associated with impaired positive reinforcement learning, controlling for changes in the locus coeruleus, but was not associated with other domains of cognition. In contrast, reduced neuromelanin signal in the locus coeruleus was independently associated with impairments in attention/working memory and executive function, controlling for changes in the substantia nigra, but not with reinforcement learning performance. These results show that substantia nigra degeneration and locus coeruleus degeneration independently and selectively contribute to cognitive deficits and therefore suggests that individual differences in the degree of neurodegeneration in these nuclei could explain the significant heterogeneity that exists in the cognitive and behavioural manifestations of Parkinsons disease. These findings also highlight the potential value of leveraging known brain-behaviour relationships to develop performance-based measures of cognition that reflect underlying patterns of neurodegeneration.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Serum, Cell-Free HPV-Human DNA Junction Detection and HPV Typing for Predicting and Monitoring Cervical Cancer Recurrence\nAbstract: Almost all cervical cancers are caused by human papillomaviruses (HPVs). In most cases, HPV DNA is integrated into the human genome. We found that tumor-specific, HPV-human DNA junctions are detectable in serum cell-free DNA of cervical cancer patients at initial treatment. Retrospective analysis revealed these junctions were more frequently detectable in women in whom the cancer later recurred. We also found that cervical cancers caused by HPV types outside of phylogenetic clade 9 had a higher recurrence frequency than those caused by 9 types in both our study and The Cancer Genome Atlas cervical cancer database, despite the higher prevalence of 9 types including HPV16 in cervical cancer. Thus, HPV-human DNA junction detection in serum cell-free DNA and HPV type determination in tumor tissue may help predict recurrence risk. Screening serum cell-free DNA for junctions may also offer an unambiguous, non-invasive means to monitor absence of recurrence following treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Allelic effects on KLHL17 expression likely mediated by JunB/D underlie a PDAC GWAS signal at chr1p36.33\nAbstract: Pancreatic Ductal Adenocarcinoma (PDAC) is the third leading cause of cancer-related deaths in the U.S. Both rare and common germline variants contribute to PDAC risk. Here, we fine-map and functionally characterize a common PDAC risk signal at 1p36.33 (tagged by rs13303010) identified through a genome wide association study (GWAS). One of the fine-mapped SNPs, rs13303160 (r2=0.93 in 1000G EUR samples, OR=1.23, P value=2.74x10-9) demonstrated allele-preferential gene regulatory activity in vitro and allele-preferential binding of JunB and JunD in vitro and in vivo. Expression Quantitative Trait Locus (eQTL) analysis identified KLHL17 as a likely target gene underlying the signal. Proteomic analysis identified KLHL17 as a member of the Cullin-E3 ubiquitin ligase complex in PDAC-derived cells. In silico differential gene expression analysis of the GTExv8 pancreas data suggested an association between lower KLHL17 (risk associated) and pro-inflammatory pathways. We hypothesize that KLHL17 may mitigate inflammation by recruiting pro-inflammatory proteins for ubiquitination and degradation thereby influencing PDAC risk.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plaintiff experiences of the medico-legal environment in Ireland\nAbstract: IntroductionThe recent surge in clinical claims in Ireland has sparked concerns about the unsustainable trajectory of medical negligence litigation. Current evaluations have primarily focused on the financial and temporal aspects of litigation, leaving a gap in understanding the experiences of plaintiffs within the adversarial system. This study aims to fill this gap by critically exploring the experiences of those affected by medical negligence and the ensuing legal process.  MethodsA qualitative descriptive approach was employed to explore the experiences of plaintiffs following patient safety incidents and their interactions with the legal process. Semi-structured, open-ended interviews were conducted with participants who had been involved in medical negligence litigation in Ireland. Participants were eligible for inclusion if they were aged 18 years or over and were involved in medical negligence litigation in Ireland (as a plaintiff), whether the case was resolved by negotiated settlement, a form of alternative dispute resolution (e.g. mediation), or trial hearing. Maximum variation sampling was used to capture a diverse range of experiences, with sample size determined by the concept of  information power. Recruitment was facilitated by the Health Service Executive (HSE) through invitations sent by The National Open Disclosure Office. Interviews were conducted in-person or online, recorded, transcribed, and analysed thematically. Ethical approval was obtained from the Social Research Ethics Committee of University College Cork.  FindingsThis research presents the views and experiences of fifteen participants; eleven participants shared their experiences relating to an adverse event which impacted a family member (one participant spoke about two family members), nine of whom were children (including both minors and adult children), and three were a spouse. Of the twelve individuals discussed, eight were deceased. Five main themes were identified from the analysis: i) Navigating the aftermath of a patient safety event: Communication, Support and Abandonment; ii) The pathway from adverse event to litigation; iii) Experiences of the Legal System; iv) Emotional and Mental Health Impact of Litigation on Plaintiffs; v) Advocating for Change: Participant Recommendations.  DiscussionThis research highlights the profound impact of actions taken after a patient safety event on patients, families, healthcare professionals, and organisations, and the importance of Open Disclosure in meeting ethical obligations and ensuring healthcare accountability. It explores the complex relationships between financial compensation, justice-seeking, and the healthcare and legal systems. The findings contribute significant insights to the discourse on medical negligence in Ireland.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Transcranial magnetic stimulation of dorsomedial prefrontal cortex for cocaine use disorder: A pilot study\nAbstract: Cocaine use disorder (CUD) is a difficult-to-treat condition with no FDA-approved medications. Recent work has turned to brain stimulation methods to help rectify hypofrontality and dopamine reward system changes often observed in individuals with CUD. Preliminary studies using transcranial magnetic stimulation (TMS) have demonstrated promising results, but there is room for optimization of the stimulation site, stimulation pattern, and identification of relevant biomarkers of TMS effects. The current pilot study aimed to test the feasibility, safety, and preliminary effects of a double-blind, sham-controlled, cross-over, acute design using intermittent theta burst stimulation to dorsomedial prefrontal cortex (dmPFC) on electroencephalogram (EEG) as intermediate outcome assessment in CUD patients. This small pilot enrolled five individuals with moderate-to-severe CUD for feasibility and proof-of-concept. Participants completed safety, psychometric, and EEG measures before and after receiving two sessions of active or sham TMS to dmPFC on two separate days. All five participants completed all the study tasks and found the TMS to be tolerable. The side effects were minimal and consistent with an acute TMS design. Visible changes were observed in the electrical activity of the brain during a monetary guessing task, while minimal changes in psychometric measures were observed. These results indicate the feasibility and safety of the current approach and suggest that dmPFC is a viable target for treating CUD. Future work should expand upon these findings in a randomized controlled clinical trial.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Free fatty acids accelerate \u03b2-cell death in type 1 diabetes\nAbstract: Type 1 diabetes (T1D) results from autoimmune destruction of the insulin producing pancreatic {beta} cells. The bodys lipid metabolism is strongly regulated during this process but there is a need to understand how this regulation contributes to the {beta}-cell death. Here, we show that fatty acids are released from plasma lipoproteins in children during islet autoimmunity, prior to T1D onset. These fatty acids (FFAs) enhanced cytokine-mediated apoptosis in cultured insulin-producing cells by downregulating the production of nicotinamide adenosine dinucleotide (NAD) via its salvage pathway, as well as deregulated central carbon metabolism and impaired levels of ATP. Downregulation of the NAD salvage pathway and central carbon metabolism enzymes were further observed during T1D development, supporting that the pathways for NAD and energy production are compromised in vivo. Our findings show that fatty acids are released during islet autoimmunity, accelerating disease development through impaired NAD metabolism.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gut microbiome shifts in adolescents after sleeve gastrectomy with increased oral-associated taxa and pro-inflammatory potential\nAbstract: BackgroundBariatric surgery is highly effective in achieving weight loss in children and adolescents with severe obesity, however the underlying mechanisms are incompletely understood, and gut microbiome changes are unknown.  Objectives1) To comprehensively examine gut microbiome and metabolome changes after laparoscopic vertical sleeve gastrectomy (VSG) in adolescents and 2) to assess whether the microbiome/metabolome changes observed with VSG influence phenotype using germ-free murine models.  Design1) A longitudinal observational study in adolescents undergoing VSG with serial stool samples undergoing shotgun metagenomic microbiome sequencing and metabolomics (polar metabolites, bile acids and short chain fatty acids) and 2) a human-to-mouse fecal transplant study.  ResultsWe show adolescents exhibit significant gut microbiome and metabolome shifts several months after VSG, with increased alpha diversity and notably with enrichment of oral-associated taxa. To assess causality of the microbiome/metabolome changes in phenotype, pre-VSG and post-VSG stool was transplanted into germ-free mice. Post-VSG stool was not associated with any beneficial outcomes such as adiposity reduction compared pre-VSG stool. However, post-VSG stool exhibited an inflammatory phenotype with increased intestinal Th17 and decreased regulatory T cells. Concomitantly, we found elevated fecal calprotectin and an enrichment of proinflammatory pathways in a subset of adolescents post-VSG.  ConclusionWe show that in some adolescents, microbiome changes post-VSG may have inflammatory potential, which may be of importance considering the increased incidence of inflammatory bowel disease post-VSG.  What is already known on this topicBariatric surgery is highly effective in achieving weight loss in children and adolescents with severe obesity, however the underlying mechanisms are incompletely understood, and gut microbiome changes are unknown.  What this study addsSignificant gut microbiome and metabolome shifts were found several months after vertical sleeve gastrectomy in adolescents, notably with enrichment of oral-associated taxa. Using human to germ-free mice fecal transplant studies, the post-surgery changes in the gut microbiome/metabolome were shown to have inflammatory potential. Furthermore, raised fecal calprotectin and inflammatory systemic pathways were seen in a subset of adolescents post-surgery.  How this study might affect research, practice or policyThese findings may be of importance given the growing recognition of an increased incidence of inflammatory bowel disease after bariatric surgery and warrants further investigation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Generative AI for Qualitative Analysis in a Maternal Health Study: Coding In-depth Interviews using Large Language Models (LLMs)\nAbstract: Study ObjectivesIn-depth interviews are one of the most widely used approaches for qualitative studies in public health. The coding of transcripts is a critical step for information extraction and preliminary analysis. However, manual coding is often labor-intensive and time-consuming. The emergence of generative artificial intelligence (GenAI), supported by Large Language Models (LLMs), presents new opportunities to understand human languages, which may significantly facilitate the coding process. This study aims to build a computational coding framework that uses GenAI to automatically detect and extract themes from in-depth interview transcripts.  MethodsWe conducted an experiment using transcripts of in-depth interviews with maternity care providers in South Carolina. We leveraged ChatGPT to perform two tasks automatically: (1) deductive coding, which involves applying a predefined set of codes to dialogues; and (2) inductive coding, which can generate codes from dialogues without any preconceptions or assumptions. We fine-tuned ChatGPT to understand the content of the interview transcripts, enabling it to detect and summarize codes. We then evaluated the performance of the proposed approach by comparing the codes generated by ChatGPT with those generated manually by human coders, involving human-in-the-loop evaluation.  ResultsThe results demonstrated the potential of GenAI in detecting and summarizing codes from in-depth interview transcripts. ChatGPT could be utilized for both deductive and inductive coding processes. The overall accuracy of GenAI is higher than 80% and the codes it generated showed high positive associations with those generated manually. More impressively, GenAI reduced the time required for coding by 81%, demonstrating its efficiency compared to traditional methods.  DiscussionGenAI models like ChatGPT show high generalizability, scalability and efficiency in handling large datasets, and are proficient in multi-level semantic structure identification. They demonstrate promising results in qualitative coding, making it a valuable tool for supporting people in public health research. However, challenges such as inaccuracy, systematic biases, and privacy concerns must be addressed when using them in practice. GenAI-based coding results should be handled with caution and reviewed by human coders to ensure accuracy and reliability.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond Algorithms: The Impact of Simplified CNN Models and Multifactorial Influences on Radiological Image Analysis\nAbstract: This paper demonstrates that simplified Convolutional Neural Network (CNN) models can outperform traditional complex architectures, such as VGG-16, in the analysis of radiological images, particularly in datasets with fewer samples. We introduce two adopted CNN architectures, LightCnnRad and DepthNet, designed to optimize computational efficiency while maintaining high performance. These models were applied to nine radiological image datasets, both public and in-house, including MRI, CT, X-ray, and Ultrasound, to evaluate their robustness and generalizability. Our results show that these models achieve competitive accuracy with lower computational costs and resource requirements. This finding underscores the potential of streamlined models in clinical settings, offering an effective and efficient alternative for radiological image analysis. The implications for medical diagnostics are significant, suggesting that simpler, more efficient algorithms can deliver better performance, challenging the prevailing reliance on transfer learning and complex models. The complete codebase and detailed architecture of the LightCnnRad and DepthNet, along with step-by-step instructions, are accessible in our GitHub repository at https://github.com/PKhosravi-CityTech/LightCNNRad-DepthNet.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Targeted deep brain stimulation of the motor thalamus improves speech and swallowing motor functions after cerebral lesions\nAbstract: Speech and swallowing are complex motor acts that depend upon the integrity of input neural signals from motor cortical areas to control muscles of the head and neck. Lesions damaging these neural pathways result in weakness of key muscles causing dysarthria and dysphagia, leading to profound social isolation and risk of aspiration and suffocation. Here we show that Deep Brain Stimulation (DBS) of the motor thalamus improved speech and swallowing functions in two participants with dysarthria and dysphagia. First, we proved that DBS increased excitation of the face motor cortex, augmenting motor evoked potentials, and range and speed of motion of orofacial articulators in n=10 volunteers with intact neural pathways. Then, we demonstrated that this potentiation led to immediate improvement in swallowing functions in a patient with moderate dysphagia and profound dysarthria as a consequence of a traumatic brain lesion. In this subject and in another with mild dysarthria, we showed that DBS immediately ameliorated impairments of respiratory, phonatory, resonatory, and articulatory control thus resulting in a clinically significant improvement in speech intelligibility. Our data provide first-in-human evidence that DBS can be used to treat dysphagia and dysarthria in people with cerebral lesions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: CROSS-SECTIONAL ANALYSIS: INTERPRETATION OF NON-STATISTICALLY SIGNIFICANT RESULTS IN RANDOMISED CONTROLLED CLINICAL TRIALS IN REHABILITATION\nAbstract: IntroductionDespite the CONSORT guidelines, which aim to improve the quality of studies, authors often formulate conclusions based on the dichotomous distinction of the p-value, declaring differences between  statistically significant and  non-significant. This approach confuses the identification of the real efficacy of the studied treatment. To solve this problem, CONSORT guidelines recommend using confidence intervals, which offer a more complete view of possible effects. However, authors conclusions often remain based on a binary approach, confusing the absence of evidence with the evidence of absence. This error can influence clinical practice and future research, leading to the identification of  negative treatments based on  statistical insignificance, which reflects a lack of evidence of absence, not the absence of evidence.  ObjectivesTo assess the prevalence of misinterpretation of non-statistically significant results, both in the abstract and in the article, in a sample of all randomised controlled trials (RCTs) with non-statistically significant primary outcomes published in 5 rehabilitation journals with the highest impact factor (IF) published between 2019 and 2023 and to assess whether the primary outcome result is reported according to CONSORT guidelines.  MethodsWe will conduct a cross-sectional analysis of all Rcts with non-statistically significant primary outcomes in 5 general rehabilitation journals with the highest IF published between 2019 and 2023. We will determine the prevalence of trials in which non-significance is interpreted as absence of evidence, evidence of absence, or advice to use the intervention in clinical practice in the abstract and article conclusions, and the prevalence of trials that adhered to CONSORT guidelines for reporting the primary outcome.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Access to Allogeneic Cell Transplantation Based on Donor Search Prognosis: An Interventional Trial\nAbstract: ImportancePatients requiring allogeneic hematopoietic cell transplantation have variable likelihoods of identifying an 8/8 HLA-matched unrelated donor. A Search Prognosis calculator can estimate the likelihood.  ObjectiveTo determine if using a search algorithm based on donor search prognosis can result in similar incidence of transplant between patients Very Likely (>90%) vs Very Unlikely (<10%) to have a matched unrelated donor.  DesignThis interventional trial utilized a Search Prognosis-based biologic assignment algorithm to guide donor selection. Trial enrollment from June 13, 2019-May 13, 2022; analysis of data as of September 7, 2023 with median follow-up post-evaluability of 14.5 months.  SettingsNational multi-center Blood and Marrow Transplantation Clinical Trials Network 1702 study of US participating transplant centers.  ParticipantsAcute myeloid and lymphoid leukemias, myelodysplastic syndrome, Hodgkins and non-Hodgkins lymphomas, severe aplastic anemia, and sickle cell disease patients referred to participating transplant centers were invited to participate. 2225 patients were enrolled and 1751 were declared evaluable for this study. Patients were declared evaluable once it was determined no suitable HLA-matched related donor was available.  InterventionPatients assigned to the Very Likely arm were to proceed with matched unrelated donor, while Very Unlikely were to utilize alternative donors. A third stratum, Less Likely ([~]25%) to find a matched unrelated donor, were observed under standard center practices, but were not part of the primary objective.  Main OutcomeCumulative incidence of transplantation by Search Prognosis arm  ResultsEvaluable patients included 1751 of which 413 (24%) were from racial/ethnic minorities. Search prognosis was 958 (55%) Very Likely, 517 (30%) Less Likely and 276 (16%) Very Unlikely. 1171 (67%) received HCT, 384 (22%) died without HCT, and 196 (11%) remained alive without HCT. Among the 1,234 patients, the adjusted cumulative incidence (95% CI) of HCT at 6-months was 59.8% (56.7-62.8) in the Very Likely group versus 52.3% (46.1-58.5) in the Very Unlikely (P=0.113).  ConclusionsA prospective Search Prognosis-based algorithm can be effectively implemented in a national multicenter clinical trial. This approach resulted in rapid alternative donor identification and comparable rates of HCT in patients Very Likely and Very Unlikely to find a matched unrelated donor.  Trial Registration: NCT#03904134\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Providing an e-cigarette starter kit for smoking cessation and reduction as adjunct to usual care to smokers with a mental health condition: Findings from the ESCAPE feasibility study\nAbstract: BackgroundSmoking rates in the UK have declined steadily over the past decades, masking considerable inequalities, as little change has been observed among people with a mental health condition. This trial sought to assess the feasibility and acceptability of supplying an electronic cigarette (e-cigarette) starter kit for smoking cessation as an adjunct to usual care for smoking cessation, to smokers with a mental health condition treated in the community, to inform a future effectiveness trial.  MethodsThis randomised controlled feasibility trial, conducted March-December 2022, compared the intervention (e-cigarette starter kit with a corresponding information leaflet and demonstration with Very Brief Advice) with a  usual care control at 1-month follow-up. Participants were [&ge;]18 years, receiving treatment for any mental health condition in primary or secondary care in three Mental Health Trusts in Yorkshire and one in London, UK. They were also willing to address their smoking through either cessation or reduction of cigarette consumption. The agreed primary outcome measure was feasibility (consent[~]15% of eligible participants; attrition rate<30%). Acceptability, validated sustained abstinence and [&ge;]50% cigarette consumption reduction at 1-month, were also evaluated and qualitative interviews conducted to further explore acceptability in this population.  ResultsFeasibility targets were partially met; of 201 eligible participants, 43 (mean age = 45.2, SD = 12.7; 39.5% female) were recruited (21.4%) and randomised (intervention:48.8%, n=21; control:51.2%, n=22). Attrition rate was 37.2% at 1-month follow-up and was higher (45.5%) in the control group. At follow-up (n=27), 93.3% (n=14) in the intervention group and 25.0% (n=3) in the control group reported e-cigarette use. The intervention was well received with minimal negative effects. In intention-to-treat analysis, validated sustained abstinence at 1-month was 2/21 (9.5%) and 0/22 (0%) and at least 50% reduction in cigarette consumption 13/21 (61.9%) and 3/22 (13.6%), for the intervention and control group, respectively. Qualitative analysis of participant interviews (N=5) showed the intervention was broadly acceptable, but they also highlighted areas of improvements for the intervention and trial delivery.  ConclusionsOffering an e-cigarette starter kit to smokers with a mental health condition treated in the community was acceptable and largely feasible, with harm reduction outcomes (i.e. switching from cigarette smoking to e-cigarette use and substantial reduction in cigarette consumption) favouring the intervention. The findings of the study will be used to help inform the design of a main trial.  Trial RegistrationRegistry: ISRCTN  Registration number: ISRCTN17691451  Date of registration: 30/09/2021\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Electroencephalographic (EEG) Changes Accompanying Normal Breathing of Concentrated Oxygen (Hyperoxic Ventilation) by Healthy Adults: A Systematic Review\nAbstract: IntroductionDivers often increase their fraction of inspired oxygen (FiO2) to decrease their risk of decompression sickness. However, breathing concentrated oxygen can cause hyperoxia, and central nervous system oxygen toxicity (CNS-OT). This study aims to review the literature describing hyperoxic ventilations effect on the electroencephalogram (EEG), thus exploring the potential for real-time detection of impending CNS-OT seizure.  MethodsWe searched Medline, Embase, Scopus, and Web of Science for articles that reported EEG measures accompanying hyperoxic ventilation (FiO2 = 1.0) in healthy participants. We included peer-reviewed journal articles, books, and government reports with no language or date restrictions. Randomised controlled trials and cross-over studies were included; case reports were excluded. We used the Newcastle-Ottawa scale to evaluate evidence quality.  ResultsOur search strategy returned 1025 unique abstracts; we analysed the full text of 40 articles; 22 articles (16 studies) were included for review. Study cohorts were typically small, and comprised of male non-divers. We discovered a variety of EEG analysis methods: studies performed spectral analysis (n = 12), the analysis of sensory-evoked potentials (n = 4), connectivity/complexity analysis (n = 3), source localization (n = 1), and expert qualitative analyses (n = 4). Studies of severe exposures (long duration at hyperbaric pressure) typically reported qualitative measures, and studies of mild exposures typically reported quantitative measures.  ConclusionsThere is a need for a large randomised controlled trial (RCT) reporting quantitative measures to better understand hyperoxic ventilations effect on EEG, thus enabling the development of real-time monitoring of CNS-OT risk.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Right Ventricular Work and Pulmonary Capillary Wedge Pressure in Heart Failure with Preserved Ejection Fraction\nAbstract: BackgroundSymptoms of heart failure with preserved ejection fraction (HFpEF) are closely related to elevated pulmonary capillary wedge pressure (PCWP) during exercise. Understanding right ventricular (RV) myocardial work, using RV pressure-strain loops to assess RV function in HFpEF, is lacking. The study aims to evaluate the effectiveness of right ventricular myocardial work parameters in diagnosing HFpEF and their correlation with pulmonary capillary wedge pressure during exercise.  MethodsThe study included patients who underwent invasive cardiopulmonary exercise tests, measuring pressures at rest and during exercise to identify HFpEF. Echocardiography assessed left and right ventricular parameters. RV myocardial work was calculated using strain-rate and pressure curves, matched with ECG data. RV global constructive work (RV GCW), RV global work index (RV GWI), RV global wasted work (RV GWW), and RV global work efficiency (RV GWE) were analyzed and compared with invasively measured PCWP at rest and peak exercise.  ResultsForty-one patients with adequate data were enrolled, with 21 diagnosed with HFpEF. No significant differences in various echocardiographic parameters were found between HFpEF and non-HFpEF groups, except higher post-exercise PCWP and mean pulmonary artery pressure in HFpEF patients. HFpEF patients had higher RV GWW and lower RV GWE. RV GWW and RV GWE had higher predictive ability for HFpEF diagnosis compared to other echocardiographic parameters. RV GCW (r = 0.504, P = 0.001) and RV GWW (r = 0.621, P < 0.001) correlated with post-exercise {Delta}PCWP and exercise PCWP, with RV GWW independently associated with both after adjustment for confounding factors.  ConclusionsRV GWW is a novel predictive parameter that provides a better explanation of RV performance regarding post-exercise {Delta}PCWP than other standard echocardiographic parameters in HFpEF.  WHAT IS NEW?O_LIRight ventricular global wasted work (RV GWW) is identified as a novel predictive parameter in heart failure with preserved ejection fraction (HFpEF), providing a more accurate explanation of right ventricular (RV) performance regarding post-exercise changes in pulmonary capillary wedge pressure ({Delta}PCWP) compared to standard echocardiographic parameters. C_LIO_LIstudy highlights the significant correlation of RV GWW with post-exercise {Delta}PCWP and exercise PCWP, demonstrating its independent association after adjusting for confounding factors. C_LIO_LImyocardial work, assessed using RV pressure-strain loops from invasive cardiopulmonary exercise tests and echocardiography, offers valuable insights into the role of RV in exercise intolerance and dyspnea among HFpEF patients. C_LI  WHAT ARE THE CLINICAL IMPLICATIONS?O_LIRV GWW serves as a superior predictive marker for diagnosing HFpEF, independently correlating with post-exercise {Delta}PCWP. This enhances the understanding of RV contribution to exercise intolerance and dyspnea in HFpEF, potentially aiding in more accurate diagnosis and tailored management strategies. C_LIO_LIRV GWW analysis in clinical practice may improve the diagnostic precision and management of HFpEF, optimizing treatment strategies for patients with unexplained dyspnea and suspected HFpEF. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: EpiSemoLLM: A Fine-tuned Large Language Model for Epileptogenic Zone Localization Based on Seizure Semiology with a Performance Comparable to Epileptologists\nAbstract: SignificanceSeizure semiology, the study of signs and clinical manifestations during seizure episodes, provides crucial information for inferring the location of epileptogenic zone (EZ). Given the descriptive nature of seizure semiology and recent advancements in large language models (LLMs), there is a potential to improve the localization accuracy of EZ by leveraging LLMs for interpreting the seizure semiology and mapping its descriptions to the corresponding EZs. This study introduces the Epilepsy Semiology Large Language Model, or EpiSemoLLM, the first fine-tuned LLM designed specifically for this purpose, built upon the Mistral-7B foundational model.  MethodA total of 865 cases, each containing seizure semiology descriptions paired with validated EZs via intracranial EEG recording and postoperative surgery outcome, were collected from 189 publications. These collected data cohort of seizure semiology descriptions and EZs, as the high-quality domain specific data, is used to fine-tune the foundational LLM to improve its ability to predict the most likely EZs. To evaluate the performance of the fine-tuned EpiSemoLLM, 100 well-defined cases were tested by comparing the responses from EpiSemoLLM with those from a panel of 5 epileptologists. The responses were graded using the rectified reliability score (rRS) and regional accuracy rate (RAR). Additionally, the performance of EpiSemoLLM was compared with its foundational model, Mistral-7B, and various versions of ChatGPT, Llama as other representative LLMs.  ResultIn the comparison with a panel of epileptologists, EpiSemoLLM achieved the following score for regional accuracy rates (RAR) with zero-shot prompts: 60.71% for the frontal lobe, 83.33% for the temporal lobe, 63.16% for the occipital lobe, 45.83% for the parietal lobe, 33.33% for the insular cortex, and 28.57% for the cingulate cortex; and mean rectified reliability score (rRS) 0.291. In comparison, the epileptologists averaged RAR scores were 64.83% for the frontal lobe, 52.22% for the temporal lobe, 60.00% for the occipital lobe, 42.50% for the parietal lobe, 46.00% for the insular cortex, and 8.57% for the cingulate cortex; and rectified reliability score (rRS) with mean of 0.148. Notably, the fine-tuned EpiSemoLLM outperformed its foundational LLM, Mistral-7B-instruct, and various versions of ChatGPT and Llama, particularly in localizing EZs in the insular and cingulate cortex. EpiSemoLLM offers valuable information for presurgical evaluations by identifying the most likely EZ location based on seizure semiology.  ConclusionEpiSemoLLM demonstrates comparable performance to epileptologists in inferring EZs from patients seizure semiology, highlighting its value in epilepsy presurgical assessment. EpiSemoLLM outperformed epileptologists in interpreting seizure semiology with EZs originating from the temporal and parietal lobes, as well as the insular cortex. Conversely, epileptologists outperformed EpiSemoLLM regarding EZ localizations in the frontal and occipital lobes and the cingulate cortex. The models superior performance compared to the foundational model underscores the effectiveness of fine-tuning LLMs with high-quality, domain-specific samples.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: In-utero exposure to PM2.5 and adverse birth outcomes in India: Geostatistical modelling using remote sensing and demographic health survey data 2019-21\nAbstract: Rapid urbanization in India is contributing to heightened poor air quality. Yet research on the impact of poor air on adverse birth outcomes (ABOs) especially in the public health aspect is less in India. This study investigates the influence of air quality on birth weight (LBW) and preterm birth (PTB). Utilizing data from the National Family Health Survey and satellite images, the study employs various statistical analyses and spatial models to elucidate the connection between in-utero exposure to air pollution and birth outcomes, both at the individual and district levels. It was observed that approximately 13% of children were born prematurely, and 17% were born with low birth weight. Increased ambient PM2.5 concentrations during pregnancy were associated with higher odds of LBW (AOR: 1.4; 95% CI: 1.29-1.45). Mothers exposed to PM2.5 during pregnancy had a heightened likelihood of delivering prematurely (AOR: 1.7; 95% CI: 1.57-1.77) in comparison to unexposed mothers. Climatic factors such as rainfall and temperature had a greater association with ABOs. Children residing in the Northern districts of India appeared to be more susceptible to the adverse effects of ambient air pollution. Furthermore, indoor air pollution was found to be associated with LBW. Employing a distributed spline approach, the study identified a discernible upward trend in the risk of adverse birth outcomes as the level of exposure increased, particularly following an exposure level of 40 PM2.5 ug/m3. Among the spatial models employed, the MGWR spatial model exhibited the highest level of goodness of fit. In addition to addressing immediate determinants such as nutrition and maternal healthcare, it is imperative to collaboratively address distal factors encompassing both indoor and outdoor pollution to attain lasting enhancements in child health.  HighlightsO_LIAn estimated 13% of the children were preterm and 17% were low birth weight in India in 2019-21. C_LIO_LIHigh PM2.5 concentration during pregnancy was associated with LBW and PTB. C_LIO_LIChildren residing in the Northern districts of India were found to be more vulnerable to poor air quality. C_LIO_LIA rising trend in the risk of adverse birth outcomes was observed after exposure level of 40 PM2.5 ug/m3. C_LIO_LIThe MGWR spatial model demonstrated the highest level of goodness of fit. C_LI  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=96 SRC=\"FIGDIR/small/24313773v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (37K): org.highwire.dtl.DTLVardef@1f8496eorg.highwire.dtl.DTLVardef@19cf48aorg.highwire.dtl.DTLVardef@17acd5forg.highwire.dtl.DTLVardef@14149f8_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Viral transcript and tumor immune microenvironment-based transcriptomic profiling of HPV-associated head and neck squamous cell carcinoma identifies subtypes associated with prognosis\nAbstract: Human papillomavirus (HPV)-associated head and neck squamous cell carcinoma (HPV-positive HNSCC) has distinct biological characteristics from HPV-negative HNSCC. Using an AI-based analytical platform on meta cohorts, we profiled expression patterns of viral transcripts and HPV viral genome integration, and classified the tumor microenvironment (TME). Unsupervised clustering analysis revealed 5 distinct and novel TME subtypes across patients (immune-enriched, highly immune and B-cell enriched, fibrotic, immune-desert, and immune-enriched luminal). These TME subtypes were highly correlated with patient prognosis. In order to understand specific factors associated with prognosis, we used unsupervised clustering of a HPV-positive HNSCC cohort from The Cancer Genome Atlas (TCGA) (n = 53) based on HPV transcript expression, and identified 4 HPV-related subtypes (E2/E5, E6/E7, E1/E4 and L1/L2). Utilizing both viral transcript and TME subtypes, we found that the E2/E5 HPV subtype was associated with an immune-enriched TME and had a higher overall survival compared to other subtypes. The E2/E5 subtype was also enriched for samples without HPV-genome integration, suggesting that episomal HPV status and E2/E5 expression pattern may be associated with an inflamed microenvironment and improved prognosis. In contrast, E6/E7 subtype samples were associated with the fibrotic and immune-desert TME subtypes, with lower values of T-cell and B-cell gene expression signatures and lower overall survival. Both E1/E4 and L1/L2 subtypes were associated with the immune-enriched luminal subtype. Our results suggest that HPV- transcript expression patterns may drive modulation of the TME and thereby impact prognosis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reliable Online Auditory Cognitive Testing: An observational study\nAbstract: Technological advances have allowed researchers to conduct research remotely. Online auditory testing has received interest since the Covid-19 pandemic. A number of web-based developments have improved the range of auditory tasks during remote participation. Most of these studies have been conducted in young, motivated individuals who are comfortable with technology. Such studies have also used stimuli testing auditory perceptual abilities. Research on auditory cognitive abilities in real-world older adults is lacking.  In this study, we assess the reproducibility of a range of auditory cognitive abilities in older adults, with a range of hearing abilities, who took part in in-person and online experiments. Participants performed a questionnaire-based assessment and were asked to complete two verbal speech-in-noise perception tasks, for digits and sentences, and two auditory memory tasks, for different sound features. In the first part of the study, 58 Participants performed these tests in-person and online in order to test the reproducibility of the tasks. In the second part, 147 participants conducted all the tasks online in order to test if previously published findings from in-person research were reproducible.  We found that older adults under the age of 70 and those with a better hearing were more likely to take part in online testing. The questionnaire-based test had significantly better reproducibility than the behavioural auditory tests but there were no differences in reproducibility between in-person and online auditory cognitive metrics. Relationships between relationships with age and hearing thresholds in an in-person or online setting were not significantly different.  Furthermore, important relationships between auditory metrics, evidenced in literature previously, were reproducible online.  This study suggests that auditory cognitive testing may be reliably conducted online.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of Monitoring and Evaluation Systems on the Performance of Neonatal Intensive Care Unit at Yumbe Regional referral hospital; A Pre-post quasi-experimental study design\nAbstract: PurposeThis study explored the effect of implementing monitoring and Evaluation (M&E) systems on the performance of the Neonatal Intensive care Unit at Yumbe regional referral hospital.  MethodsA pretest-posttest quasi-experimental design was employed involving 236 neonates, with 103 in the pretest group (Before the implementation monitoring and evaluation systems) and 130 in the posttest group (after the implementation of monitoring and evaluation). The intervention lasted 105 days. Key performance indicators (KPIs) such as; neonatal mortality rates, length of stay, neonatal intensive cares effectiveness, morbidity rate, survival rates, and infection control were measured. Patient satisfaction as a secondary outcome was also explored through questionnaire surveys. Data collected was entered directly in Micro software, and exported to the STATA version 18 for analysis  ResultsNeonatal mortality rates significantly decreased from 19.4% in the pretest group to 7.7% in the posttest group (P<0.01). The survival rates improved from 80.6% in the pretest group to 92.3% in the posttest group. The average length of stay was reduced from 10 days (SD=4) to 8 days (SD=3) (P<0.05). Neonatal intensive care effectiveness scores improved from a mean of 2.8 to 3.5 (P<0.01). Compliance with Neonatal intensive care unit protocols increased from 70% to 80% (P<0.01). The reliability of monitoring and evaluation components was high, with Cronbachs alpha values ranging from 0.754 to 0.915  ConclusionImplementation of monitoring and evaluation systems significantly enhanced NICUs performance, reduced mortality rate, improved survival rates and improved patient satisfaction. These findings underline the importance of M&E frameworks in optimizing neonatal care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Postoperative 20% Albumin and Cardiac Surgery Associated Kidney Injury, Statistical Analysis Plan and Updated Protocol\nAbstract: BackgroundThe incidence of cardiac surgery associated acute kidney injury (CS-AKI) remains high. Patients who develop AKI after cardiac surgery are at higher risk of persistent renal dysfunction and increased long-term mortality. The risk of CS-AKI is significantly increased in patients with chronic kidney disease and in patients having prolonged bypass for complex surgery. Previous trials of albumin did not show any benefit in prevention of CS-AKI. These trials, however, did not focus on high-risk patients and used albumin as a resuscitation strategy. The aim of ALBICS-AKI is to demonstrate the effect of concentrated albumin infusion on CS-AKI in high-risk patients undergoing cardiac surgery compared with standard care.  MethodsALBICS-AKI is an investigator initiated, multicentre, randomised, open label trial. Seven centres in Australia and Italy will participate in the trial. We will randomise 620 adult patients who will undergo on-pump cardiac surgery with one of the following: an estimated glomerular filtration rate <60 ml/min/1.73m2, combined valve/s, coronary artery, or surgery involving thoracic aorta. Within 6 hours after surgery, a 20% albumin infusion will commence at 20ml/h for 15 hours. All patients will receive standard care as per institutional protocols. The primary outcome is the proportion of patients with AKI according to creatinine based KDIGO definition at hospital discharge or day 28, whichever comes first. Secondary outcomes include Major Adverse Kidney Events at day 28, AKI stage II and III, need for renal replacement therapy, and hospital mortality.  Ethics and disseminationThe trial was approved by Monash Health Lead Research Committee for Australian sites and by the Italian Medicine Agency for Italian sites. The estimated study completion date is Sep 2024. The results will be presented at major conferences and submitted for publication in peer-reviewed journals.  Trial registration numberAustralian New Zealand Clinical Trials Registry ACTRN12619001355167\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association Between Life's Essential 8 and Atherogenic Index of Plasma in Adults: Insights from NHANES 2007-2018\nAbstract: ObjectivesThis study aimed to investigate the relationship between Lifes Essential 8 (LE8) and the Atherogenic Index of Plasma (AIP).  MethodsWe conducted an analysis of data from 8,215 U.S. adults aged 20 years and older, utilizing the National Health and Nutrition Examination Survey data from 2007 to 2018. Based on LE8 scores, Cardiovascular Health (CVH) was stratified into three levels--low, moderate, and high--while AIP was categorized into four risk levels: extremely low (AIP<-0.3), low (-0.3[&le;]AIP<0.1), medium (0.1[&le;]AIP<0.24), and high (AIP[&ge;]0.24). Weighted ordinal logistic regression analysis was utilized to examine the association between CVH scores and AIP risk levels, adjusting for potential confounding variables.  ResultsA significant inverse correlation exists between CVH scores and AIP risk levels (OR=0.51, 95%CI: 0.49-0.54, P<0.001). Higher CVH scores were associated with lower AIP risk levels, while lower CVH scores corresponded to elevated AIP risk levels. Notably, improvements in specific CVH components--such as Body Mass Index and Blood Lipids--exhibited a strong relationship with reductions in AIP risk levels.  ConclusionsEnhancing CVH is vital for effectively reducing AIP risk levels, thus underscoring the critical importance of health management strategies in the prevention of cardiovascular diseases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A longitudinal study of depressive symptom trajectories and risk factors in congestive heart failure\nAbstract: BackgroundDepression is prevalent among patients with congestive heart failure (CHF) and is associated with increased mortality and healthcare utilization. However, most research has focused on high-income countries, leaving a gap in knowledge regarding the relationship between depression and CHF in low-to-middle-income countries (LMICs). This study aimed to delineate depressive symptom trajectories and identify potential risk factors for poor outcomes among CHF patients.  MethodsLongitudinal data from 783 patients with CHF from public hospitals in Karachi, Pakistan was analyzed. Depressive symptom severity was assessed using the Beck Depression Inventory (BDI). Baseline and 6-month follow-up BDI scores were clustered through Gaussian Mixture Modeling to identify distinct depressive symptom subgroups and extract trajectory labels. Further, a random forest algorithm was utilized to determine baseline demographic, clinical, and behavioral predictors for each trajectory.  ResultsFour depressive symptom trajectories were identified:  good prognosis,  remitting course,  clinical worsening, and  persistent course. Risk factors associated with persistent depressive symptoms included lower quality of life and the New York Heart Association (NYHA) class 3 classification of CHF. Protective factors linked to a good prognosis included less disability and a non-NYHA class 3 classification of CHF.  ConclusionsBy identifying key characteristics of patients at heightened risk of depression, clinicians can be aware of risk factors and better identify patients who may need greater monitoring and appropriate follow-up care.  Clinical Perspective What is new?O_LITo the best of our knowledge, this is the first study to use machine learning techniques to investigate depressive symptom trajectories in CHF patients from an LMIC. C_LIO_LIFour distinct depressive symptom trajectories were identified, ranging from good prognosis to persistent depressive symptoms. C_LIO_LIThis study highlights protective and risk factors associated with these trajectories based on patients demographics and clinical presentations at baseline. C_LI  What are the clinical implications?O_LIPersonalized interventions based on identified protective factors for high-risk CHF patients could enhance both mental health and cardiovascular outcomes. C_LIO_LIEarly detection and management of depression, particularly in patients with poor quality of life or advanced heart failure, may help reduce healthcare utilization and mortality. C_LIO_LIThis study emphasizes the importance of routine depression screening in CHF patients, especially in LMICs, to enhance overall patient care and outcomes. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Tucaresol: An Oral Candidate Drug With Two Distinct Antiviral Mechanisms.\nAbstract: Globally, approximately 39 million people are living with Human Immunodeficiency Virus, HIV, arising from approximately 86 million infections since this epidemic began in 1981. However, the number of HIV infections is unevenly distributed with two thirds of global infections confined to Sub-Saharan Africa. Due to viral drug resistance, the most effective treatment requires a triple drug combination thereby adding to the complexity and cost of therapy. As such, many people living with HIV or at risk of infection do not have access to prevention or treatment of this potentially fatal disease. There is no cure for HIV [1]. Tucaresol is an orally active clinical stage drug which functions as a host targeted antiviral agent by protection or reconstitution of CD4+ T helper immune cells. We report herein that Tucaresol also displays in-vitro activity against HIV in infected human peripheral blood mononuclear cells. Although this in-vitro antiviral activity is not potent, the excellent safety profile and bioavailability of Tucaresol, along with its low Molecular Weight, support attainment of relevant drug concentrations in man to achieve significant in-vivo activity. This is demonstrated by previously reported stabilization of viremia in a prior proof of concept phase 1b/2a HIV clinical trial [2]. It is possible that the significant in-vivo activity of Tucaresol arises from synergy between co-stimulation of CD4+ T helper cells and the direct activity against virally infected cells. A pan in-vitro viral screen of Tucaresol further revealed a weak, direct antiviral activity against human herpes virus 6B, human papillomavirus 11, measles virus and hepatitis B virus.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparative Risk of the Onset of Atrial Fibrillation after Icosapent Ethyl versus Omega-3-Acid-Ethyl-Esters Adjuvant to Statins\nAbstract: BackgroundIcosapent ethyl (ICP), an ethyl ester of eicosapentaenoic acid (EPA), and omega-3 acid ethyl esters (DHA/EPA), comprised of ethyl esters of EPA and doxosahexaenoic acid (DHA), are approved as adjunctive therapy to statins for reducing adverse cardiovascular events (CV) in patients with CV risks. However, there are concerns regarding a potential association between ICP and atrial fibrillation (AF). This study evaluated the incidence of AF onset between ICP and DHA/EPA when used as adjuvant therapy with statins.  Methods and ResultsThis retrospective study utilized administrative healthcare claims to analyze adult AF-naive patients from one year preceding their first prescription for ICP or DHA/EPA. These patients were followed for two years, spanning from2013-2021. AF incidence was assessed during active treatment with either ICP or DHA/EPA as adjunct statin therapy. A propensity score (PS) matched cohort controlled for baseline characteristics and the effect of calendar year on the use of ICP or DHA/EPA. The cumulative incidence of AF was estimated using a product-limit estimator and compared between groups using a Cox proportional hazards regression model. The PS-matched cohort included 17,638 participants with a mean age 56 years, predominantly male (65.7% ICP vs. 64.5% DHA/EPA). Over two years, the cumulative incidence of AF from ICP and DHA/EPA was 5.32% and 3.99% respectively, resulting in a HR of 1.242 (95% CI: 1.061 to 1.455).  ConclusionsIn adult AF-naive patients, ICP, when compared to DHA/EPA in conjunction with statin therapy, was associated with a significantly higher significant risk of developing AF.  RESEARCH PERSPECTIVEO_ST_ABSWhat is New?C_ST_ABSO_LIDoes icopasent ethyl (ICP), an ethyl ester of eicosapentaenoic acid (EPA) and omega-3 acid ethyl esters comprised of ethyl esters of EPA and doxosahexaenoic acid (DHA) in atrial fibrillation (AF)-naive patients taking statins increase the incidence of AF? C_LIO_LIOver two years, the cumulative incidence of AF from ICP and DHA/EPA was 5.32% and 3.99% respectively, resulting in a HR of 1.242 (95% CI: 1.061 to 1.455). C_LIO_LIIn adult AF-naive patients, ICP, when compared to DHA/EPA in conjunction with statin therapy was associated with a higher significant risk of developing AF. C_LI  What Question Should be Addressed Next?O_LIWhat should be considered as clinical and demographic factors in identifying patients at risk of atrial fibrillation prior to being prescribed ICP or DHA/EPA agents. C_LIO_LIInvestigation into the underlying mechanism of the increase in atrial fibrillation with marine omega-3 ethyl esters should continue. C_LIO_LIUnderstanding AF outcomes from ICP or DHA/EPA use including AF burden, need for AF medical or electrophysiological interventions, and health-care total costs. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Perceived barriers to research and scholarship among physicians\nAbstract: IntroductionInadequate scholarship is a common concern in graduate medical education. Many barriers to scholarship have been identified, but there are limited data on which are most important. A rank-order of barriers from learners perspectives would better enable programs to address perceived barriers.  MethodsGiven that learners are experts in their own perceptions, we applied the Delphi method of generating consensus expert opinion to construct ranked lists of physician-perceived barriers to scholarly activity at various sites. The survey was conducted within three separate health systems. Respondents were asked to identify their perceived barriers via free text and the listed barriers were consolidated by the research team. In the second round, respondents were presented with the consolidated lists and asked to rank them. In the third and final round, each respondent was shown a comparison of their own rankings to that of their peers and given an opportunity to make changes. Ranking differences between programs were compared using Rank Biased Overlap (RBO).  ResultsThe Delphi method is a straightforward method to obtain a ranked list of perceived learner barriers to scholarly activity; its primary limitation is learner engagement and, of note in our study, high dropout rates. RBO is an effective method of ranking differences between programs and specialties. Top barriers across programs included time, overwhelm with the research process, and lack of interest or energy.  DiscussionSeveral of the identified barriers may be addressed with enthusiastic mentors, streamlined administrative processes, and education. This could be done within a hospital system or on a national level through specialty organizations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Whole-exome sequencing study of opioid dependence offers novel insights into the contributions of exome variants\nAbstract: Opioid dependence (OD) is epidemic in the United States and it is associated with a variety of adverse health effects. Its estimated heritability is [~]50%, and recent genome-wide association studies have identified more than a dozen common risk variants. However, there are no published studies of rare OD risk variants. In this study, we analyzed whole-exome sequencing data from the Yale-Penn cohort, comprising 2,100 participants of European ancestry (EUR; 1,321 OD cases) and 1,790 of African ancestry (AFR; 864 cases). A novel low-frequency variant (rs746301110) in the RUVBL2 gene was identified in EUR (p=6.59x10-10). Suggestive associations (p<1x10-5) were observed in TMCO3 in EUR, in NEIL2 and CFAP44 in AFR, and in FAM210B in the cross-ancestry meta-analysis. Gene-based collapsing tests identified SLC22A10, TMCO3, FAM90A1, DHX58, CHRND, GLDN, PLAT, H1-4, COL3A1, GPHB5 and QPCTL as top genes (p<1x10-4) with most associations attributable to rare variants and driven by the burden of predicted loss-of-function and missense variants. This study begins to fill the gap in our understanding of the genetic architecture of OD, providing insights into the contribution of rare coding variants and potential targets for future functional studies and drug development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A systematic review of psychological factors influencing attitudes and intentions toward, and uptake of, Covid-19 vaccines in adolescents\nAbstract: Vaccination was a key measure to tackle the Covid-19 pandemic, however adolescents were less likely than adults to accept the vaccine. Low vaccine uptake reduces the effectiveness of vaccination campaigns and threatens global public health. Understanding why adolescents are hesitant to accept new vaccines is therefore crucial to support the development of novel vaccine uptake interventions. Prior reviews have included far fewer citations, excluded qualitative data, studies after 2022 and have not mapped adolescent Covid-19 vaccine behaviour onto psychological models. This systematic review investigated psychological factors influencing attitudes and intentions toward and uptake of Covid-19 vaccines in adolescents aged 10 to 19 years globally. It mapped results onto the COM-B framework to inform future interventions. Our search identified 25,354 citations, and included 77 in this review. The quality of studies was mixed, predominantly cross-sectional in design. According to our review, key influences on adolescent Covid-19 vaccine behaviour were: i) Reflective motivation (safety concerns, perceived susceptibility to/severity of Covid-19, perceived vaccine effectiveness, ii) Social opportunity (social norms, autonomy and prosocial attitudes), iii) Psychological capability (attitude and knowledge about vaccines). Our review provides new insights into psychological factors influencing adolescent Covid-19 vaccine behaviour, and maps factors to the COM-B model of behaviour change. To improve vaccine uptake, future vaccine interventions should support adolescents to think critically about the pros and cons of vaccines and consider external influences on their decisions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prenatal Exposure of Pesticide Mixtures and the Placental Transcriptome: Insights from Trimester-specific, Sex-Specific and Metabolite-Scaled Analyses in the SAWASDEE Cohort\nAbstract: We investigated the effect of exposure to pesticide mixtures during pregnancy on the placental transcriptome, to link these exposures and placental functions. The Study of Asian Women and their Offsprings Development and Environmental Exposures (SAWASDEE) enrolled pregnant farmworkers from Thailand (n=248), who were primarily exposed to organophosphate (OP) and pyrethroid pesticides. We measured maternal urinary levels of six non-specific OP metabolites expressed as three summary measures (dimethylalkylphosphates (DMAP), diethylalkylphosphates (DEAP), and dialkylphosphates (DAP) and three pyrethroid metabolites (3-phenoxybenzoic acid (3-PBA), cis- and trans-3-(2,2-dichlorovinyl)-2,2-dimethylcyclopropane carboxylic acid (Cis-DCCA, Trans-DCCA) during early, middle, and late pregnancy, and adjusted for urine dilution using creatinine. RNA-sequencing was used to profile the placental transcriptome from which 21 co-expression network modules were identified by Weighted Gene Co-expression Network Analysis. Quantile g-computation analysis identified an average pregnancy positive mixture exposure effect on the E2f Target Module ({beta} = 0.013, p = 0.012) and a negative mixture exposure effect ({beta} = -0.016, p = 0.008) on the Myogenesis Module. The pesticide metabolites driving the associations differed for each module, highlighting differential susceptibilities within the placental transcriptome to various pesticides. When stratifying by infant sex, the average pregnancy mixture exhibited a significant negative effect ({beta}= -0.018, P=0.016) on the Myogenesis Module only in females; other modules, such as epithelial-mesenchymal transition, though not demonstrating an overall mixture effect, did demonstrate differential impacts of the mixture by sex. Pesticide mixtures in both the second trimester ({beta} = -0.013, p = 0.015) and the third trimester ({beta} = -0.012, p = 0.028) exhibited consistently significant negative associations with the Myogenesis module. These findings underscore the importance of considering the prenatal environment more holistically, understanding the placentas susceptibility to contaminants, and incorporating sex-specific analyses to understand differential impacts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Health professionals beliefs and attitudes towards preconception care: A systematic review\nAbstract: BackgroundHealth professionals have previously identified various barriers and factors that would help facilitate preconception care services in healthcare settings. Clinically relevant preconception information and clinical practice guidelines have since been developed to aid health professionals in preconception care delivery. This systematic review aimed to 1) synthesise recent literature (past five years) describing health professionals beliefs and attitudes towards preconception care services or programmes and 2) determine if the experience of health professionals providing preconception care has changed compared to literature reviews conducted more than five years ago.  MethodsFive databases were searched between 27/01/2016 and 27/01/2022. Primary quantitative and qualitative research studies were included if they examined health professionals beliefs and attitudes towards delivering preconception care services or programmes. Study quality was assessed using the CASP Checklist (qualitative studies) and AXIS tool (quantitative studies). Data synthesis used thematic categorisation adapted from the framework approach.  ResultsTwenty-one studies were included (n=8 qualitative, n=11 quantitative, n=2 mixed-methods studies). Methodological quality was generally good for qualitative studies but varied for quantitative studies. The results covered three categories: 1) addressing preconception care health literacy (i.e. lack of knowledge, awareness, training and resources), 2) clinical practicalities of preconception car e (i.e. need for coordination of care and clarity on role responsibility), and 3) the role of the patient (i.e. need for public health education to support patient-led conversations).  ConclusionsLittle has changed regarding the barriers and facilitators to providing preconception care reported by health professionals. To improve the provision of preconception care, there is a need to co-develop professional and public preconception health education, clinical resources, and a coordinated preconception healthcare service model.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ich-Mupong, a swollen stomach: An ethnographic study of the daily lived experiences of schoolchildren in schistosomiasis high transmission areas along Lake Albert, Hoima District\nAbstract: BackgroundOur primary focus was Schistosoma mansoni infection and schoolchildren. Within communities the social environment may promote individual risk of infection for the school-aged children. There will also be demographic groups who are not targeted or reached by preventive chemotherapy campaigns. The behaviours of these other groups will interact with those of school-aged children, resulting in further infection risk through exposure-related behaviours. Furthermore, perception of the disease may significantly influence the schoolchildrens lived experience of the infection and associated disease. It is therefore crucial to document the daily experiences of schoolchildren living in schistosomiasis high transmission areas along Lake Albert, Hoima District.  MethodsAn ethnographic study explored schoolchildrens perspectives and daily life organisations that shape their risk of schistosomiaisis and their perceptions of the disease. The study was conducted between November 2022 and August 2023. It involved in-depth interviews with schoolchildren and their parents, key informant interviews, focus group discussions with schoolchildren, and participant observations. Data was analysed using a reflexive thematic analysis. Code reports were generated inductively using ATLAS.ti (Version 7).  ResultsThe study revealed a significant level of knowledge and awareness about schistosomiasis among schoolchildren. They had understanding of the risk factors, continued exposure, and experiences of illness, though they had little autonomy to address these through their own behaviour as they were influenced by the behaviour of others and macro-factors such as WASH provision and economic need. Study participants experienced individual-level effects of schistosomiasis such as educational impacts and isolation as a significant form of stigma.  ConclusionsThere is a need for continued community sensitisation and awareness campaigns to address social stigma, educational impact, and contamination and exposure-related behaviours. National and regional policies and programmes on WASH, livelihood and poverty eradication programmes need to be revisited in schistosomiasis high transmission areas to help provide alternatives and improve schoolchildrens lived experiences.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring subthreshold functional network alterations in women with phenylketonuria by higher criticism\nAbstract: ObjectivePhenylketonuria (PKU) is an inherited disorder of amino acid metabolism. Despite early dietary treatment, cognitive functioning of patients has been reported as being inferior to healthy controls. Objective of this study was to assess functional connectivity (FC) alterations in PKU in cognition-related brain networks by resting-state functional magnetic resonance imaging. We followed a hierarchical analysis approach partially based on higher criticism (HC) statistics as previously applied in a larger sister-project in fetal alcohol syndrome.  ResultsAfter exclusions for excessive head movement, 11 female young adults with early-treated PKU (age: 27.2 {+/-} 3.7 years) and 11 age-matched female healthy controls (age: 25.9 {+/-} 3.8 years) were included in the analysis. We observed effects within attention networks and the default mode network, but not in fronto-parietal networks, at the HC-based intermediate analysis level. No between-network FC differences were found. In the most detailed analysis level, we could not identify single affected functional connections. Despite statistical power limitations in this small sample, findings are in line with previously reported FC alterations in PKU and the cognitive profile in young adults with PKU, particularly with the still uncertain notion that cognitive control deficits might become less pronounced when PKU patients reach adulthood.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of Item-Level Responses to Cognitive Function Index with Tau Pathology and Hippocampal volume in The A4 Study\nAbstract: BackgroundAlzheimers Disease (AD) has a lengthy asymptomatic preclinical phase during which individuals may show pathological signs like {beta}-amyloid (A{beta}) pathology and tau tangles without noticeable objective cognitive impairments. Subjective cognitive impairment reports may offer valuable and early insights into individuals cognitive functioning and serve as indicators of early stages of cognitive decline.  ObjectiveTo investigate the associations of the item-level response to Cognitive Function Index (CFI) by participant and study partner with tau pathology and adjusted hippocampal volume (HVa).  MethodParticipants were 339 cognitively unimpaired, A{beta} positive, individuals enrolled in the Anti-Amyloid Asymptomatic Alzheimers (A4) Study who underwent tau-PET imaging. Participants and their study partners assessed subjective changes in cognition and function over the past year using the 15-item CFI questionnaire. For each CFI item, the relationship among tau, HVa, and CFI reports was investigated.  ResultParticipants were on average 72.38 (SD = 4.87) years old, 58.1% were female, and 23.6% were tau positive. Higher tauMTL was significantly associated with participant report of decline on three CFI items including depending on written notes, seeing a doctor for memory concern, and feeling lost while navigating. Higher tauMTL was associated with study partner report of decline on two different items: needing help from others to remember appointments/occasions and asking same questions. Additionally, HVa was linked to challenges with driving for participants and noticeable memory decline for study partners.  ConclusionWe showed that early changes reported on specific items of the CFI are associated with higher tauMTL and lower HVa in A{beta}+ participants. Different CFI items were associated with tau and hippocampal volume for participants and study partners, highlighting the importance of both perspective.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: First-in-human evaluation of memory-like NK cells with an IL-15 super-agonist and CTLA-4 blockade in advanced head and neck cancer\nAbstract: Cytokine induced memory-like natural killer (CIML NK) cells combined with an IL-15 super-agonist (N-803) are a novel modality to treat relapsed/refractory head and neck cancer. We report data from a phase I trial of haploidentical CIML NK cells combined with N-803 with or without ipilimumab (IPI) in relapsed/refractory head and neck cancer patients after a median of 6 prior lines of therapy. The primary endpoint was safety, which was established, with dose-limiting toxicity in 1/10 patients. A promising though transient disease control rate of 70% correlated with donor NK cell expansion, the latter occurring irrespective of IPI. High-resolution immunophenotypic and transcriptional profiling characterized the NK cells and their interacting partners in vivo. IPI was associated with contraction of Treg:Tcon, rapid recovery of recipient CD8+ T cells, and accelerated rejection of donor NK cells. These results inform evaluation of CIML NK therapy for advanced malignancies, with considerations for combination with IPI.  SignificanceCIML NK cells combined with N-803 and ipilimumab to treat head and neck cancer is safe, and associated with a more proliferative NK cell phenotype. However, the combination leads to reduced HLA mismatched NK cell persistence, resulting in an important limitation informing future NK cell combination therapies in clinical trials.  Trial RegistrationNCT04290546  FundingGateway for Cancer Research, Ted and Eileen Pasquarello Research Fund, Goldfarb and Rudkin Family Fellowship, Dr. Antins Research Fund, Massey Family Fund. MS is funded by the Sidney Farber Scholar Program, Dana Farber, and RR is a recipient of the Career Development Award from the Leukemia and Lymphoma Society and is a member of the Parker Institute for Cancer Immunotherapy at Dana-Farber Cancer Institute.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Developing a virtual Endoscopic Surgery Planning system to optimize surgical outcomes\nAbstract: ObjectivePlanning and predicting functional outcomes of endoscopic sinus surgeries (e.g., nasal airflow) based solely on visualizing Computerized Tomography (CT) or endoscopy poses a challenge to produce optimal clinical outcomes.  Study designTechnology development, retrospective case report.  MethodsA virtual surgery planning (VSP) tool is developed that can load any patients CT data and allow surgeons to remove obstructive tissue using both visual and haptic feedback endoscopically. Pre-calculated airflow resistance, wall shear stress, pressure drop are displayed on the anatomy to identify potential sites of obstruction. After each virtual surgery, changes in nasal airflow can be computed, and the process is reiterated until an optimal result is reached.  ResultsAs proof-of-concept, a series of isolated or combined procedures were performed on CT of one patient, who had olfactory losses that may involve obstructions blocking the air/odor flow to the olfactory fossa (OF). For this patient, an isolated medial partial middle turbinectomy (PMT) demonstrated the best outcome, better than traditionally performed lateral PMT, while septal body reduction worsened air/odor flow to OF.  ConclusionThis proof of concept case report demonstrates the potential usefulness of VSP in preoperative planning based on objective benchmarks and could be a valuable tool for optimizing future surgical outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Self Reported Financial Difficulties Among Patients with Multiple Myeloma and Chronis Lymphocytic Leukemia Treated at U.S. Community Oncology Clinics (Alliance A231602CD)\nAbstract: ObjectivesTo estimate the proportion and correlates of self-reported financial difficulty among patients with multiple myeloma (MM) or chronic lymphocytic leukemia (CLL).  Setting23 U.S. community and minority oncology practice sites affiliated with the National Cancer Institute Community Oncology Research Program (NCORP).  Participants521 patients ([&ge;]18 years) with MM or CLL were consented and 416 responded to a survey (completion rate=79.8%). Respondents had a MM diagnosis (74.0%), an associate degree or higher (53.4%), were White (89.2%), insured (100%) and treated with clinician-administered drugs (68.0%).  InterventionsObservational, prospective, protocol-based survey administered in 2019-2020.  Primary and secondary outcome measuresFinancial difficulty was assessed using a single-item standard measure, the EORTC QLQC30: \"Has your physical condition or medical treatment caused you financial difficulties in the past year?\" and using an  any-or-none composite measure of 22 items assessing financial difficulty, worries and the use of cost-coping strategies. Multivariable logistic regression models assessed the association between financial difficulty, diagnosis, and socioeconomic and treatment characteristics.  Results16.8% reported experiencing financial difficulty using the single-item measure and 60.3% using the composite measure. Most frequently endorsed items in the composite measure were financial worry about having to pay large medical bills related to cancer and difficulty paying medical bills. Financial difficulty using the single-item measure was associated with having MM versus CLL (adjusted odds ratio [aOR], 0.34; 95% CI, 0.13-0.84; P=.02), having insurance other than Medicare (aOR, 2.53; 95% CI, 1.37-4.66; P=.003), being non-White (aOR, 2.21; 95% CI, 1.04-4.72; P=.04), and having a high school education or below (aOR, 0.36; 95% CI, 0.21-0.64; P=.001). Financial difficulty using the composite measure was associated with having a high school education or below (aOR, 0.62; 95% CI, 0.41-0.94; P=.03).  ConclusionsU.S. patients with blood cancer report financial difficulty, especially those with low socio-economic status. Evidence-based and targeted interventions are needed.  Study Strengths and LimitationsO_ST_ABSStrengthsC_ST_ABSO_LINCORP, a program of the National Cancer Institute (NCI), is a national network for cancer clinical trials and care delivery studies that is comprised of 7 research bases and 46 community sites across the U.S., 14 of which are designated as Minority/Underserved community sites. The study had strong engagement and participation across diverse NCORP Sites across the country and their affiliates. Strong site engagement resulted in high patient recruitment and retention rates for this study (79.8%), despite coincident timing with the initial stages of the COVID-19 pandemic. C_LIO_LIThe survey tool was composed of previously validated items that were modified for this population and new questions that were evaluated for comprehension, which facilitates comparison of our findings to others previously published. Patients targeted for recruitment were treated in the community and recruitment aimed to represent the socioeconomic characteristics of the prevalent patient population. The study relied on both self-report and medical chart abstraction to establish key dependent and independent variables. C_LIO_LIThe primary outcome variable was a previously developed, and empirically tested measure, supporting study internal and external validity. We also used a secondary composite measure of financial difficulty to present a more holistic picture of how cancer diagnosis and treatment impact patients daily lives and inform decisions to delay or forego care and use cost-coping strategies. By capturing specific worries, decisions and strategies, the composite measure indicates areas where there is a need for greater patient engagement and resource provision at the site of care. C_LI  LimitationsO_LIAmong 105 participants who were not included in the final sample, the majority (n=66) were excluded from analysis because they could not be contacted within the 8-week period due to unexpectedly high recruitment volumes across sites. C_LIO_LIWhile NCORP sites from across the country participated in the study, 60% of patients recruited to the study were from the Midwest. Although this is the most representative study of financial difficulty in U.S. blood cancer patients to date, our findings may not be fully generalizable to the national CLL and MM communities due to these limitations. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pediatric Long COVID Subphenotypes: An EHR-based study from the RECOVER program\nAbstract: Pediatric Long COVID has been associated with a wide variety of symptoms, conditions, and organ systems, but distinct clinical presentations, or subphenotypes, are still being elucidated. In this exploratory analysis, we identified a cohort of pediatric (age <21) patients with evidence of Long COVID and no pre-existing complex chronic conditions using electronic health record data from 38 institutions and used an unsupervised machine learning-based approach to identify subphenotypes. Our method, an extension of the Phe2Vec algorithm, uses tens of thousands of clinical concepts from multiple domains to represent patients clinical histories to then identify groups of patients with similar presentations. The results indicate that cardiorespiratory presentations are most common (present in 54% of patients) followed by subphenotypes marked (in decreasing order of frequency) by musculoskeletal pain, neuropsychiatric conditions, gastrointestinal symptoms, headache, and fatigue.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Glucagon-Like Peptide 1 Receptor Agonists and Cardiovascular Disease Risk: Findings from Real-World Data using AI-Powered Outcomes\nAbstract: BackgroundThe SELECT trial showed cardiovascular benefits of glucagon-like peptide-1 receptor agonists (GLP-1 RAs) in obese patients with cardiovascular disease; however, real-world data (RWD) on this benefit remain limited. This study used an artificial intelligence (AI)-generated algorithm and multimodal RWD to evaluate the impact of GLP-1 RAs on cardiovascular disease risk in a population of obese patients with and without preexisting cardiovascular disease.  MethodsUsing data from the Dandelion Health RWD library, an Emulated SELECT Cohort was created to include obese patients similar to those in the SELECT trial, but with and without preexisting cardiovascular disease. An AI algorithm developed by Pheiron that used 12-lead electrocardiograms (ECGs) as a predictive biomarker for the risk of major adverse cardiovascular events (MACE) was validated and used to derive MACE risk scores for the Emulated SELECT Cohort. These outcomes were compared over time between patients who used GLP-1 RAs and non-users using inverse-probability weighted linear regression models, adjusting for key covariates.  ResultsOut-of-sample validation showed high predictive accuracy of the AI algorithm, with ROC AUCs of 0.81 for myocardial infarction (MI) and 0.75 for stroke. Increased risk scores from the algorithm were correlated with higher MACE incidence in RWD. In the Emulated SELECT Cohort of 20,795 patients, GLP-1 RA use was associated with significant attenuation of MACE risk, with reductions observed in percentile risk score for MI (4%; p<0.001) and stroke (3.6%; p<0.001) per year of use. Differences in GLP-1 RA and non-GLP-1 users were evident as early as 1.7 years, with a 15-20% difference in absolute MACE risk scores between GLP-1 RA users and non-users observed by the end of the study.  ConclusionAn AI algorithm using 12-lead ECGs accurately predicted MACE risk and could be used to model risk attenuation associated with GLP-1 RA use. Using this outcome, we find that GLP-1 RA use was associated with significant reductions in MI and stroke risk, in a broader population and within a shorter timeframe than the SELECT trial. These findings suggest potentially significant cardioprotective benefits of GLP-1 RAs in real-world settings and demonstrate a proof-of-concept for utilizing clinical AI to understand these benefits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Glucagon-Like Peptide 1 Receptor Agonists and Cardiovascular Disease Risk: Findings from Real-World Data using AI-Powered Outcomes\nAbstract: BackgroundThe SELECT trial showed cardiovascular benefits of glucagon-like peptide-1 receptor agonists (GLP-1 RAs) in obese patients with cardiovascular disease; however, real-world data (RWD) on this benefit remain limited. This study used an artificial intelligence (AI)-generated algorithm and multimodal RWD to evaluate the impact of GLP-1 RAs on cardiovascular disease risk in a population of obese patients with and without preexisting cardiovascular disease.  MethodsUsing data from the Dandelion Health RWD library, an Emulated SELECT Cohort was created to include obese patients similar to those in the SELECT trial, but with and without preexisting cardiovascular disease. An AI algorithm developed by Pheiron that used 12-lead electrocardiograms (ECGs) as a predictive biomarker for the risk of major adverse cardiovascular events (MACE) was validated and used to derive MACE risk scores for the Emulated SELECT Cohort. These outcomes were compared over time between patients who used GLP-1 RAs and non-users using inverse-probability weighted linear regression models, adjusting for key covariates.  ResultsOut-of-sample validation showed high predictive accuracy of the AI algorithm, with ROC AUCs of 0.81 for myocardial infarction (MI) and 0.75 for stroke. Increased risk scores from the algorithm were correlated with higher MACE incidence in RWD. In the Emulated SELECT Cohort of 20,795 patients, GLP-1 RA use was associated with significant attenuation of MACE risk, with reductions observed in percentile risk score for MI (4%; p<0.001) and stroke (3.6%; p<0.001) per year of use. Differences in GLP-1 RA and non-GLP-1 users were evident as early as 1.7 years, with a 15-20% difference in absolute MACE risk scores between GLP-1 RA users and non-users observed by the end of the study.  ConclusionAn AI algorithm using 12-lead ECGs accurately predicted MACE risk and could be used to model risk attenuation associated with GLP-1 RA use. Using this outcome, we find that GLP-1 RA use was associated with significant reductions in MI and stroke risk, in a broader population and within a shorter timeframe than the SELECT trial. These findings suggest potentially significant cardioprotective benefits of GLP-1 RAs in real-world settings and demonstrate a proof-of-concept for utilizing clinical AI to understand these benefits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subtyping First-Episode Psychosis based on Longitudinal Symptom Trajectories Using Machine Learning\nAbstract: Clinical course after first episode psychosis (FEP) is heterogeneous. Subgrouping longitudinal symptom trajectories after FEP would be useful for developing personalized treatment approaches, and being able to predict these trajectories at baseline would facilitate individual-level treatment planning. We utilized k-means clustering to identify distinct clusters of 411 FEP patients based on longitudinal positive and negative symptom patterns. Ridge logistic regression was then used to identify predictors of cluster membership using baseline data. Three clusters were identified, demonstrating unique demographic, clinical and treatment response profiles. Cluster 1 exhibits lower positive and negative symptoms (LS), lower antipsychotic dose, and relatively higher affective psychosis; Cluster 2 shows lower positive symptoms, persistent negative symptoms (LPPN), and intermediate antipsychotic doses; Cluster 3 presents persistently high levels of both positive and negative symptoms (PPNS), as well as higher antipsychotic doses. We effectively predicted patients cluster membership (AUC of 0.74). The most important predictive features included contrasting trends of apathy, affective flattening, and anhedonia for the LS and LPPN clusters. Global hallucination severity, positive thought disorder and manic hostility predicted PPNS. These results help parse the heterogeneity of FEP trajectories and may facilitate the development of personalized treatment approaches tailored to cluster characteristics.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of a Cardiac and Psychosocial Rehabilitation Program on Anxiety, Depression, Self-Efficacy, Quality of Life, and Exercise Capacity in Young Adults With Fontan Circulation: A Randomized Controlled Trial\nAbstract: BACKGROUNDYoung adults with Fontan circulation (FC) face psychosocial, physical, and environmental challenges and are vulnerable to emotional distress. They need holistic intervention programs to face these problems and enhance their quality of life. This study developed and evaluated a cardiac and psychosocial rehabilitation (CPR) program for young adults with FC.  METHODS AND RESULTSThirty-eight young adults with FC aged 18-23 years were prospectively recruited from an outpatient clinic and randomized into a CPR group (n = 12) that underwent eight weekly group-based sessions combining a psychosocial program based on cognitive behavioral therapy with home-based cardiac rehabilitation (CR), a CR group (n = 12) that received only home-based CR, and a usual care control group (n = 12). The study assessed CPR program effectiveness based on the Hospital Anxiety and Depression Scale, self-efficacy, quality of life, and exercise capacity testing at three time points: pre-intervention, post-intervention, and four weeks post-intervention. Participants average ages were 19.75 (2.28), 19.65 (1.79), and 20.38 (1.85) years in the CPR, CR, and control groups, respectively; 50% (CPR group) to 53.8% (CR and control groups) of the participants were male. After eight weeks, depression and anxiety decreased, whereas self-efficacy and quality of life increased in the CPR group compared with the CR and control groups. The groups showed no differences in exercise capacity.  CONCLUSIONCPR can be part of an intervention for alleviating psychological distress and improving self-efficacy in young adults with FC. Efforts should be made to increase the efficacy of home-based CR.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Socio-medical Factors Associated with Neurodevelopmental Disorders on the Kenyan Coast\nAbstract: BackgroundNeurodevelopmental disorders (NDDs) are a group of conditions with their onset during the early developmental period and include conditions such as autism, intellectual disability and attention deficit hyperactivity disorder (ADHD). Occurrence of NDDs is thought to be determined by both genetic and environmental factors, but data on the role of environmental risk factors for NDD in Africa is limited. This study investigates environmental influences on NDDs in children from Kenya. This case-control study compared children with NDDs and typically developing children from two studies on the Kenyan coast that did not overlap.  Methods and FindingsWe included 172 of the study participants from the Kilifi Autism Study and 151 from the NeuroDev Study who had a diagnosis of at least one NDD and 112 and 73 with no NDD diagnosis from each study, respectively. Potential risk factors were identified using unadjusted univariable analysis and adjusted multivariable logistic regression analysis. Univariable analysis in the Kilifi Autism Study sample revealed hypoxic-ischaemic encephalopathy conferred the largest odds ratio (OR) 10.52 (95%CI 4.04 - 27.41) for NDDs, followed by medical complications during pregnancy (gestational hypertension & diabetes, eclampsia, and maternal bleeding) OR: 3.17 (95%CI 1.61 - 6.23). In the NeuroDev study sample, labour and birth complications (OR: 7.30 (2.17 - 24.61)), neonatal jaundice (OR: 5.49 (95%CI 1.61 - 18.72)) and infection during pregnancy (OR: 5.31 (1.56 - 18.11)) conferred the largest risk associated with NDDs. In the adjusted analysis, seizures before age 3 years in the Kilifi Autism study and labour and birth complications in the NeuroDev study conferred the largest increased risk. Higher parity, the child being older and delivery at home were associated with a reduced risk for NDDs.  ConclusionRecognition of important risk factors such as labour and birth complications could guide preventative interventions, developmental screening of at-risk children and monitoring progress. Further studies examining the aetiology of NDDs in population-based samples, including investigating the interaction between genetic and environmental factors, are needed.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Relationship between blood-cerebrospinal fluid barrier integrity, cardiometabolic and inflammatory factors in schizophrenia-spectrum disorders\nAbstract: AbstractThe blood-cerebrospinal fluid barrier (BCB) builds an integral interface between the central nervous system and the periphery and appears to be impaired in a substantial proportion of individuals with schizophrenia-spectrum disorders (SSD). Even though a disruption of the BCB is associated with higher symptom severity, factors linked to BCB disruption in SSDs have been minimally investigated.  To address this gap, 57 inpatients with SSD underwent cerebrospinal fluid (CSF) and blood analyses as well as comprehensive clinical assessments. In a subgroup of 28 participants structural magnetic resonance imaging (MRI) was performed. We developed a BCB dysfunction score, employing principal component analysis of CSF/serum albumin, CSF/serum IgG ratios and total protein levels in CSF, with higher values indicating stronger abnormalities. We calculated multiple regression models to explore the associations between BCB integrity and cardiometabolic, inflammatory, brain morphometric, and clinical measures respectively.  BCB dysfunction score was negatively associated with high-density lipoprotein cholesterol and positively associated with total cholesterol, low-density lipoprotein cholesterol, and triglycerides. Furthermore, we observed a trend towards a positive association between BCB dysfunction score and treatment resistance that did not survive multiple testing correction. We did not find significant associations between the BCB composite score and any other assessed cardiometabolic, inflammatory or cerebroventricular measures.  These findings suggest that BCB integrity is associated with dyslipidemia in SSD, highlighting the interplay between cardiometabolic risk factors and brain health in SSD. Addressing cardiometabolic health in individuals with SSD might thus have implications beyond physical health, potentially influencing the integrity of the BCB and, consequently, clinical trajectories.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of epidermal melanin on peripheral pulse oximetry measurements\nAbstract: ImportancePulse oximetry is used widely to assess oxygen saturation in nearly all healthcare institutions.  ObjectiveThis study aimed to investigate the relationship between epidermal melanin concentrations, determined by colorimetry, and discrepancies between arterial blood saturation (SaO2), determined by arterial blood gas (ABG), and peripheral oxygen saturation (SpO2) determined by pulse oximetry.  Design, Setting, ParticipantsThis observational, correlational study was conducted over a one-week period in 2024 at the University of the Incarnate Word School of Osteopathic Medicine. Twenty-eight healthy adult volunteers (14 male; 14 female) with varying skin pigmentation were recruited via convenience sampling. Participants with conditions affecting oxygen saturation were excluded.  ExposureParticipants underwent non-invasive pulse oximetry to measure peripheral oxygen saturation (SpO2) and invasive arterial blood gas (ABG) analysis to measure arterial oxygen saturation (SaO2). Melanin concentrations were measured using DSM III ColorMeter on the dorsal and palmar aspects of the hand. SpO2 was measured using the Masimo MightyStat(R) Rx Fingertip Pulse Oximeter, and ABG samples were analyzed using the i-STAT(R) 1 blood analyzer.  Main Outcome(s) and Measure(s)The primary outcome was the difference between SpO2 and SaO2 across varying melanin concentrations, hypothesized before data collection.  ResultsAnalysis revealed a significant difference between SaO2 and SpO2 with a moderately positive correlation with average epidermal melanin concentrations (r = 0.432; 95% CI, 0.07 to 0.693; P = 0.022) and a moderately inverse correlation with average luminance (r = -0.492; 95% CI,- 0.731 to -0.145; P = 0.008). A strong inverse relationship was found between melanin and luminance (r = -0.85; 95% CI -0.928 to -0.698; P <0.001). PO2 emerged as the leading predictor in two regression models, explaining 50.5% of the variance when combined with melanin.  Conclusion and RelevanceTaken together, these data suggest that pulse oximetry overestimates oxygen saturation in individuals with comparatively high epidermal melanin concentrations. Future investigations that include a broader age range and participants with various comorbidities may provide a more comprehensive understanding of the impact of epidermal melanin on the accuracy of pulse oximetry readings.  Key PointsO_ST_ABSQuestionC_ST_ABSHow does epidermal melanin concentration affect the accuracy of pulse oximetry measurements compared to arterial blood gas results?  FindingsThis study found that higher epidermal melanin concentrations were associated with greater discrepancies between pulse oximetry and arterial oxygen saturation readings, suggesting that pulse oximeters may overestimate oxygen levels in individuals with darker skin tones.  MeaningHigher epidermal melanin concentrations may result in less accurate pulse oximetry measurements, potentially leading to misinterpretations of oxygen saturation in patients with darker skin tones, raising concerns about the accuracy of these devices across diverse populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gaps in protection to Anopheles exposure in high malaria endemic regencies of Papua Province, Indonesia\nAbstract: BackgroundMalaria in eastern Indonesia remains high despite significant reductions and local elimination in other parts of the country. Malaria control activities that have been implemented include early diagnosis and prompt treatment, provision of Long-lasting insecticide-treated nets (LLINs), and indoor residual spraying (IRS). To expedite malaria elimination in this region, a rapid entomological assessment combined with human behaviour observations (HBOs) were conducted in eight high malaria endemic regencies in Papua Province, Indonesia. The present study focuses on identifying gaps in protection against mosquito biting indoors and outdoors that may contribute to the sustained transmission and persistently high endemicity.  MethodsThis study was conducted alongside a rapid entomologic assessment, including human landing catches (HLCs) of adult mosquitoes. Human behavior was documented by direct observations during HLCs. HBO data focused on temporal (over the night) and spatial (domestic or peri-domestic) presence, alongside bed net usage and sleeping patterns. Household questionnaires, also conducted during entomological collections, documented data on house structure materials, practices against mosquito bites, livestock presence, as well as intervention usage.  ResultsAnalysis of human behaviors in each regency identified several indoor and outdoor gaps in protection against mosquito biting. Human exposure to mosquito bites was driven by ITN usage, IRS coverage, indoor presence without protection prior to sleeping, absence of mosquito house screens, and outdoor presence without protection.  ConclusionsData demonstrates multiple gaps in protection against mosquito exposure in all eight regencies of Papua evaluated. Indoor interventions require optimization, while current vector control activities do not presently address outdoor exposure. Measured spatial and temporal exposure may be utilized to understand protective vector interventions that may function in these spaces while also pointing to continued exposure. Additional interventions, such as community-based larval source management, may reduce exposure overall, while novel interventions like spatial repellents may fill some gaps in protection - alongside optimized case detection and treatment. Results suggest that the present strategy may be insufficient to eliminate malaria in the region, and a rethought evidence-based and adaptive strategy is required.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development and validation of a 5-year risk model using mammogram risk scores generated from screening digital breast tomosynthesis\nAbstract: Screening digital breast tomosynthesis (DBT) aims to identify breast cancer early when treatment is most effective leading to reduced mortality. In addition to early detection, the information contained within DBT images may also inform subsequent risk stratification and guide risk-reducing management. We obtained a 5-year area under the curve (AUC) = 0.78 (95% confidence interval (CI) = 0.75 - 0.80) in the internal validation. The model validated in external data (n=6,553 women; AUC = 0.77 (95% CI, 0.74 - 0.80). There was no change in the AUC when age and BI-RADS density are added to the synthetic DBT image. The model significantly outperforms the Tyrer-Cuzick model (p<0.01). Our model extends risk prediction applications to synthetic DBT, provides 5-year risk estimates, and is readily calibrated to national risk strata for clinical translation and application in the setting of US risk management guidelines. The model could be implemented within any digital mammography program.  One Sentence SummaryWe develop and externally validate a 5-year risk prediction model for breast cancer using synthetic digital breast tomosynthesis and demonstrate clinical utility by calibrating to the national risk strata.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causes of Pediatric Deaths in Lusaka, Zambia: A Quantitative Geographic Information Systems Approach\nAbstract: BackgroundWhile childhood mortality has been declining in Zambia, it remains high at 58 per 1000 live births. Importantly, many leading causes of mortality in Zambia are preventable. This study was conducted to identify clusters of childhood mortality, causes of death of recently deceased children, barriers to care, and risk factors for mortality in Lusaka, Zambia.  MethodsThis study was conducted as a prospective cohort study. Family members or lawfully authorized representatives (LARs) were interviewed when they came to pick up death certificates for recently deceased children from Lusaka Childrens Hospital. Each interview included a verbal autopsy, determination of the childs location of residence, and collection of demographic information. Demographic data was also collected from a healthy control group. Quantitative Geographic Information Systems was used to visualize mortality and evaluate for clustering.  ResultsLeading primary causes of death included malnutrition (21%), complications of chronic illnesses (16%), and central nervous system infections (13%), while the leading barriers to care were cost (58%) and difficulties with travel (53%). Compared to controls, recently deceased children came from families with significantly lower incomes (1905 Kwacha vs. 2412 Kwacha, p = 0.03) and were significantly more likely to have a history of malnutrition (16.7% vs. 1.4%, p = 0.005). Mortality was clustered in two high-population density, low-income neighborhoods in Lusaka.  ConclusionsSystems to reduce financial barriers to care and improve access to transportation could reduce childhood mortality in Lusaka. The aforementioned neighborhoods are ideal locations for public health interventions or improved healthcare services.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Qualitative Study of User Experiences in Harm Reduction Programs\nAbstract: The ongoing Canadian opioid crisis has resulted in alarming rates of overdoses and related harms. Harm reduction programs have emerged as a crucial public health strategy to mitigate these risks. The N[e]wo-Y[o]tina Friendship Centre (NYFC) offers harm reduction programs that provide a safe injection site and clean supplies to reduce substance use-associated harm. Researchers have not extensively studied the effectiveness and user experience of this program. Studies have demonstrated the effectiveness of harm reduction programs in mitigating adverse effects of drug use, such as disease transmission and overdose. This in- depth study looked at what program users went through in the NYFC harm reduction program. This was done by looking at the program environment, unexpected outcomes, reasons for seeking services, and obstacles to access. The study used a phenomenological approach, utilising semi-structured interviews with 13 participants and analysing interview data using thematic analysis2 through NVivo. The motivations for seeking services were safety, access to clean supplies, and a non-judgmental environment. Findings revealed that users valued a safe and welcoming atmosphere fostered by friendly, supportive, and non- judgmental staff. The programs positive outcomes included reduced harm, access to resources, and emotional support. Nevertheless, limited operating hours, stigma, small space, and a lack of awareness were identified as barriers to access. The study recommends improving accessibility, enhancing support systems, and addressing unanticipated outcomes like drug use enablement to optimise the programs effectiveness. This study provides valuable insights into user experience within the NYFC program. The findings inform program improvements, enhance service delivery, and contribute to a broader understanding of harm reduction strategies for addressing the opioid crisis. It emphasises the importance of user-centred approaches in developing and implementing effective harm reduction programs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Auto-segmentation of hemi-diaphragms in free-breathing dynamic MRI of pediatric subjects with thoracic insufficiency syndrome\nAbstract: PurposeIn respiratory disorders such as thoracic insufficiency syndrome (TIS), the quantitative study of the regional motion of the left hemi-diaphragm (LHD) and right hemi-diaphragm (RHD) can give detailed insights into the distribution and severity of the abnormalities in individual patients. Dynamic magnetic resonance imaging (dMRI) is a preferred imaging modality for capturing dynamic images of respiration since dMRI does not involve ionizing radiation and can be obtained under free-breathing conditions. Using 4D images constructed from dMRI of sagittal locations, diaphragm segmentation is an evident step for the said quantitative analysis of LHD and RHD in these 4D images.  MethodsIn this paper, we segment the LHD and RHD in three steps: recognition of diaphragm, delineation of diaphragm, and separation of diaphragm along the mid-sagittal plane into LHD and RHD. The challenges involved in dMRI images are low resolution, motion blur, suboptimal contrast resolution, inconsistent meaning of gray-level intensities for the same object across multiple scans, and low signal-to-noise ratio. We have utilized deep learning (DL) concepts such as Path Aggregation Network and Dual Attention Network for the recognition step, Dense-Net and Residual-Net in an enhanced encoder-decoder architecture for the delineation step, and a combination of GoogleNet and Recurrent Neural Network for the identification of the mid-sagittal plane in the separation step. Due to the challenging images of TIS patients attributed to their highly distorted and variable anatomy of the thorax, in such images we localize the diaphragm using the auto-segmentations of the lungs and the thoraco-abdominal skin.  ResultsWe achieved an average{+/-}SD mean-Hausdorff distance of [~]3{+/-}3 mm for the delineation step and a positional error of [~]3{+/-}3 mm in recognizing the mid-sagittal plane in 100 3D test images of TIS patients with a different set of [~]430 3D images of TIS patients utilized for building the models for delineation, and separation. We showed that auto-segmentations of the diaphragm are indistinguishable from segmentations by experts, in images of near-normal subjects. In addition, the algorithmic identification of the mid-sagittal plane is indistinguishable from its identification by experts in images of near-normal subjects.  ConclusionsMotivated by applications in surgical planning for disorders such as TIS, we have shown an auto-segmentation set-up for the diaphragm in dMRI images of TIS pediatric subjects. The results are promising, showing that our system can handle the aforesaid challenges. We intend to use the auto-segmentations of the diaphragm to create the initial ground truth (GT) for newly acquired data and then refining them, to expedite the process of creating GT for diaphragm motion analysis, and to test the efficacy of our proposed method to optimize pre-treatment planning and post-operative assessment of patients with TIS and other disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dynamic MR of muscle contraction during electrical muscle stimulation as a potential diagnostic tool for neuromuscular disease\nAbstract: Thanks to the rapid evolution of therapeutic strategies for muscular and neuromuscular diseases, the identification of quantitative biomarkers for disease identification and monitoring has become crucial. Magnetic resonance imaging (MRI) has been playing an important role by noninvasively assessing structural and functional muscular changes. This exploratory study investigated the potential of dynamic MRI during neuromuscular electrical stimulation (NMES) to detect differences between healthy controls (HCs) and patients with metabolic and myotonic myopathies. The study included 14 HCs and 10 patients with confirmed muscular diseases. All individuals were scanned with 3T MRI with a protocol that included a multi-echo gradient echo sequence for fat fraction quantification, multi-echo spin-echo for water T2 relaxation time calculation, and 3D phase contrast sequences during NMES. The strain tensor, buildup and release rates were calculated from velocity datasets. Results showed that strain and strain buildup rate were reduced in the soleus muscle of patients compared to HCs, suggesting these parameters could serve as biomarkers of muscle dysfunction. Notably, there were no significant differences in fat fraction or water T2 measurements between patients and HCs, indicating that the observed changes reflect alterations in muscle contractile properties that are not reflected by structural changes. The findings provide preliminary evidence that dynamic muscle MRI during NMES can detect abnormalities in muscle contraction in patients with myotonia and metabolic myopathies, warranting further research with larger, more homogeneous patient cohorts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Comparison between Evidence-Generated Transtibial Sockets and Conventional CADCAM Designs, from the Patient's Perspective\nAbstract: ObjectivePersonalised prosthetic socket design depends upon skilled prosthetists who aim to balance functional human-prosthesis coupling with safe, comfortable load transmission to skin and soft tissues. This studys objective was to assess the comfort of sockets generated from past computer aided socket design records.  DesignA crossover non-inferiority trial with embedded qualitative interview study.  SettingThree United Kingdom National Health Service clinics.  ParticipantsSeventeen people with nineteen transtibial amputations.  InterventionEvidence-Generated sockets and conventional clinician-led computer aided (Control) designs  Main MeasuresSocket Comfort Score and semi-structured interview.  ResultsEvidence-Generated sockets had no statistically-significant difference in comfort compared to clinician-led Control sockets (p=0.38, effect size=0.08), but a lower socket comfort score variability across the group. Analysis of interviews revealed themes around fitting session experiences, similarities and differences between the Evidence-Generated and Control sockets, and residual limb factors impacting perceptions of socket comfort. These provided insights into the participants experience of the study and the value of expert prosthetist input in socket design.  ConclusionsEvidence-Generated sockets demonstrated noninferiority to conventional clinical computer aided design practice in terms of socket comfort. Both quantitative and qualitative results indicated how clinician input remains essential and is valued by prosthesis users. Work is underway to incorporate the evidence-generated sockets into computer aided design software such that they can act as a digital starting point for modification by expert clinicians at fitting, potentially reducing time spent on basic design, enabling prosthetists to focus on more highly-skilled customisation and co-design with their patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: What influences non-menstruator attitudes and behaviours towards menstruation among Rohingya refugees in Bangladesh? A quantitative analysis\nAbstract: Non-menstruators play an important yet overlooked role in shaping menstrual health. They may be the family budget holders who purchase menstrual materials, receive health information outside the household, or preserve social stigmas. In response, World Vision, supported by UNICEF, implemented a programme to influence non-menstruators among the Rohingya population living in Kutupalong refugee camp, Bangladesh. The intention was to ensure non-menstruators recognise their important role in supporting family members to improve their menstrual health. We evaluated this intervention using a baseline and endline survey of 150 participants based on the Risk-Attitudes-Norms-Ability-Self-regulation (RANAS) approach to behaviour change. Based on the responses, we categorised participants into  doers and  non-doers of positive behaviours. We then performed multiple linear regression analyses and ANOVA comparison of means tests to understand how psychosocial and contextual factors influence the populations attitudes and behaviours towards menstruation before and after intervention. The regression analyses showed eight psychosocial and contextual factors that had a significant relationship with the desired behaviours. These were the block they lived in, marital status, already having learnt about menstruation from World Vision, how they were introduced to menstruation, who they discuss menstruation with, family members reaction, perceptions of their role, and their commitment. Additionally, the ANOVA comparison of means between doers and non-doers showed doers were more likely to be confident to carry out the behaviour, perceive their role as important, and discuss menstruation with family. They were also more likely to be married, older, and have first learnt about menstruation from their family. This is the first study to identify which psychosocial and contextual factors significantly influence positive non-menstruator attitudes and conducive behaviours towards menstruation and menstruators. Humanitarian organisations can use these factors to improve the design and targeting of behaviour change programmes to improve menstrual health.  HighlightsO_LIMenstrual health is often limited in refugee settings C_LIO_LINon-menstruators can enable and constrain menstrual health C_LIO_LIMenstrual health intervention among Rohingya refugees shows positive change in non-menstruator behaviour C_LIO_LIBehavioural determinants for non-menstruators related to marriage, commitment, and family reaction C_LIO_LI Doers more likely to be confident, perceive role as important, and discuss menstruation with family C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of oral contraceptive consumption timing on substrate metabolism, cognition, and exercise performance in females: a randomised controlled trial\nAbstract: The pharmacokinetic profile of oral contraceptives (OCs) results in an acute, transient increase in circulating synthetic reproductive hormones. The aim of this study was to examine the effects of acute OC ingestion on cognitive function, substrate metabolism and exercise performance. Sixteen combined OC (30{micro}g ethinyl oestradiol and 150mg Levonorgestrel) users ingested either their OC or placebo (PLA) in a randomised, double-blind, crossover manner. After 60 minutes, participants completed tests of verbal memory and verbal fluency, followed by sub-maximal treadmill exercise for 6 minutes at 60% lactate threshold (LT) and 90% LT where respiratory exchange ratio (RER), carbohydrate oxidation, fat oxidation, heart rate (HR), rating of perceived exertion (RPE), felt arousal and feeling scale were recorded. Participants then completed an incremental ramp test to exhaustion to assess time to exhaustion (TTE) and peak oxygen uptake (VO2peak), before ingesting the pill corresponding to the condition, they were not in. RER, arousal and feeling scale were all significantly lower in the OC condition compared to PLA (all P < 0.05) with no difference in HR, carbohydrate oxidation, fat oxidation, RPE, TTE or VO2peak (all P > 0.05). Verbal fluency score was significantly higher in the OC condition compared to PLA (P < 0.05), with no differences between conditions for any aspect of verbal memory (all P < 0.05). Combined OC ingestion acutely affects substrate metabolism, affective responses to exercise and verbal fluency. The timing of OC ingestion should be considered in relation to aspects of physiological function.  Key findingsO_LIIngestion of a combined oral contraceptive (OC) results in a transient increase in circulating synthetic reproductive hormones. C_LIO_LIThe altered reproductive hormone profile affects substrate metabolism and affective responses to exercise. C_LIO_LICognitive performance in a verbal fluency task is also improved post OC ingestion. C_LIO_LIThe within-day timing of OC ingestion can be manipulated to affect aspects of physiology, which may have implications for athletes, exercises and the general population, in addition to interpretation of prior research using OCs. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pre-chronic kidney disease: Serial creatinine tracks glomerular filtration rate decline above 60 mL/min\nAbstract: OBJECTIVESTo allow primary clinicians to detect decline in glomerular filtration rate above 60 milliliters per minute, signaling early kidney impairment before stage-three chronic kidney disease.  RESULTSFour patient cases show how serum creatinine referenced to an individuals historical maximum can suggest increased risk, triggering investigation to separate benign processes that alter serum creatinine from true decline in glomerular filtration rate of pre-chronic kidney disease.  DISCUSSION/CONCLUSIONSAt glomerular filtration rates above 60 milliliters per minute, serial creatinine is more reliable than estimating equations and appears practical for clinical monitoring and early intervention.  METHODSWe re-examined a standard reference that found low tubular secretion of creatinine at glomerular filtration rates above 80 milliliters per minute and suggested \"observation of subtle changes in serum creatinine levels\". We used statistics to explain why that method extends to the 80 to 60 milliliters per minute range: expanding the y-axis (to reflect accuracy of modern creatinine assays), fitting a hyperbolic curve, and showing reasonable continuity down to 60 milliliters per minute. We summarized why equations estimating glomerular filtration rate are unsuitable above 60 milliliters per minute.  ABBREVIATIONSASC = adult serum creatinine, CKD = chronic kidney disease, CrCl = creatinine clearance, eGFR = estimated GFR, GFR = glomerular filtration rate, IDMS = isotope-dilution mass spectrometry, KDIGO = Kidney Disease Improving Global Outcomes, m2 = square meters, mGFR = measured GFR, mg/dL = milligrams per deciliter, mL/min = milliliter per minute, mol/L = micromoles per liter, NSAID = nonsteroidal anti-inflammatory drugs, P30 = percentage of estimates within {+/-}30%, sCr = serum creatinine, sCr-max = maximum sCr to date, sCysC = serum cystatin C, TScr = tubular secretion of creatinine.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-gesture drag-and-drop decoding in a 2D iBCI control task\nAbstract: ObjectiveIntracortical brain-computer interfaces (iBCIs) have demonstrated the ability to enable point and click as well as reach and grasp control for people with tetraplegia. However, few studies have investigated iBCIs during long-duration discrete movements that would enable common computer interactions such as \"click-and-hold\" or \"drag-and-drop\".  ApproachHere, we examined the performance of multi-class and binary (attempt/no-attempt) classification of neural activity in the left precentral gyrus of two BrainGate2 clinical trial participants performing hand gestures for 1, 2, and 4 seconds in duration. We then designed a novel \"latch decoder\" that utilizes parallel multi-class and binary decoding processes and evaluated its performance on data from isolated sustained gesture attempts and a multi-gesture drag-and-drop task.  Main ResultsNeural activity during sustained gestures revealed a marked decrease in the discriminability of hand gestures sustained beyond 1 second. Compared to standard direct decoding methods, the Latch decoder demonstrated substantial improvement in decoding accuracy for gestures performed independently or in conjunction with simultaneous 2D cursor control  SignificanceThis work highlights the unique neurophysiologic response patterns of sustained gesture attempts in human motor cortex and demonstrates a promising decoding approach that could enable individuals with tetraplegia to intuitively control a wider range of consumer electronics using an iBCI.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: I am worth saving- A Qualitative Study of People with Alzheimers Disease Considering Lecanemab Treatment\nAbstract: ImportancePeople with Alzheimers disease (AD) now have access to disease-modifying treatment with anti-amyloid monoclonal antibodies (mAbs). Their perception of risks and benefits and approach to treatment decisions remain unknown.  ObjectiveTo understand how people with early AD consider benefits and costs of anti-amyloid mAbs and make decisions about treatment.  DesignQualitative semi-structured interviews  SettingMemory care clinics at two academic medical centers  ParticipantsPeople with biomarker or imaging-confirmed early AD referred for evaluation for treatment with anti-amyloid mAbs  Main Outcomes and MeasuresThemes identified through content analysis  ResultsAmong 22 participants, mean age was 70 years, 8 (36%) were women, 22 (100%) were White, 8 (36%) had less than a college degree, 11 (50%) had annual income less than $100,000, and 6 (27%) lived in a rural area. The analysis revealed 3 major themes and associated subthemes: 1) People with AD sought and obtained information from different sources--advocacy organizations, the Internet, and clinicians; 2) hopes, expected benefits, and the existential threat of dementia drove willingness and readiness to start lecanemab--hopes included more time feeling like themselves and doing enjoyable activities; expected benefits included stalling progression, reversing cognitive decline or cure; 3) individual traits and preferences, family factors, and degree of trust in expertise influenced how people balanced risks and benefits-- some would accept treatment at any cost; others carefully weighed risks and burdens carefully, but were motivated to pursue treatment by supportive families, insurance coverage, and trust in expertise; for a few, costs decidedly outweighed their personal benefits. People with AD desired more individualized information on risks and benefits and wanted to hear more from patients who took the medication.  Conclusions and RelevanceResults from this qualitative analysis inform clinician, health system and policy efforts to promote individualized treatment decisions for anti-amyloid mAb treatment through multimodal education and outreach, evidence-based communication skills, and adaptation of similar care models.  Key PointsO_ST_ABSQuestionC_ST_ABSHow do people with Alzheimers disease (AD) decide on treatment with newly available anti-amyloid monoclonal antibodies?  FindingsIn this qualitative analysis, people with AD considering treatment relied on multiple information sources; were motivated by hope to delay cognitive decline and preserve independence; and worried side effects would impair quality of life. Personality traits, family support, and trust in expertise determined how they balanced these tradeoffs. People with AD wanted more personalized information and to hear from others who had taken the medications.  MeaningAs access to treatment expands, these findings inform how clinicians can help people with AD make individualized treatment decisions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biological markers of brain network connectivity and pain sensitivity distinguish low coping from high coping Veterans with persistent post-traumatic headache\nAbstract: Headache is the most common type of pain following mild traumatic brain injury. Roughly half of those with persistent post-traumatic headache (PPTH) also report neck pain which is associated with greater severity and functional impact of headache. This observational cohort study aimed to identify biological phenotypes to help inform mechanism-based approaches in the management of PPTH with and without concomitant neck pain. Thirty-three military Veterans (mean (SD) = 37{+/-}16 years, 29 males) with PPTH completed a clinical assessment, quantitative sensory testing, and magnetic resonance imaging of the brain and cervical spine. Multidimensional phenotyping was performed using a Random Forest analysis and Partitioning Around Medoids (PAM) clustering of input features from three biologic domains: 1) resting state functional connectivity (rsFC) of the periaqueductal gray (PAG), 2) quality and size of cervical muscles, and 3) mechanical pain sensitivity and central modulation of pain. Two subgroups were distinguished by biological features that included forehead pressure pain threshold and rsFC between the PAG and selected nodes within the default mode, salience, and sensorimotor networks. Compared to the High Pain Coping group, the Low Pain Coping group exhibited higher pain-related anxiety (p=0.009), higher pain catastrophizing (p=0.004), lower pain self-efficacy (p=0.010), and greater headache-related disability (p=0.012). Findings suggest that greater functional connectivity of pain modulation networks involving the PAG combined with impairments in craniofacial pain sensitivity, but not cervical muscle health, distinguish a clinically important subgroup of individuals with PPTH who are less able to cope with pain and more severely impacted by headache.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Partial dependence of ultrasonically estimated fetal weight on individual biometric variables\nAbstract: ObjectivesTo assess the contribution of sonographically measured parameters, namely head circumference, biparietal diameter, abdominal circumference, and femur length, to fetal weight estimation formulas.  MethodsThe Sobol method is employed for the global sensitivity analysis of the biometric parameters.  ResultsThe Sobol sensitivity indices for the parameters of 32 known formulas are presented and discussed.  ConclusionsDepending on the formula, the indices of some parameters show substantial fluctuations, while others are insignificant for fetal weight estimation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Partial dependence of ultrasonically estimated fetal weight on individual biometric variables\nAbstract: ObjectivesTo assess the contribution of sonographically measured parameters, namely head circumference, biparietal diameter, abdominal circumference, and femur length, to fetal weight estimation formulas.  MethodsThe Sobol method is employed for the global sensitivity analysis of the biometric parameters.  ResultsThe Sobol sensitivity indices for the parameters of 32 known formulas are presented and discussed.  ConclusionsDepending on the formula, the indices of some parameters show substantial fluctuations, while others are insignificant for fetal weight estimation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating Observer Reliability and Diagnostic Accuracy of CT-LEFAT Criteria for Post-Treatment Head and Neck Lymphedema: A Prospective Blinded Comparative Analysis of Oncologist Human Inter-Rater Performance\nAbstract: BackgroundRadiation-associated lymphedema and fibrosis (LEF) is a significant toxicity following radiation therapy (RT) for head and neck cancer (HNC) patients. Recently, the CT Lymphedema and Fibrosis Assessment Tool (CT-LEFAT) was developed to standardize LEF diagnosis through fat stranding visualized on CT. This study aims to evaluate the inter-observer reliability and diagnostic accuracy of the CT-LEFAT criteria.  Materials and MethodsThis study retrospectively evaluated 26 HNC patients treated with RT that received a minimum of two contrast-enhanced CT scans. Qualitative review was conducted by five physician raters to assess the fat stranding observed on CT according to the CT-LEFAT criteria. Fleiss kappa analysis was used to assess the inter- and intra-rater reliability, and Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) analysis was used to evaluate diagnostic accuracy.  ResultsThe inter-rater reliability across the six CT-LEFAT regions generally indicated a slight to fair agreement across all raters (0.04 [&le;] kappa [&le;] 0.36). Intra-observer agreement was generally fair to moderate (overall kappa=0.44). The ROC AUC analysis varied based on aggregation method used (0.60 [&le;] average AUC [&le;] 0.70).  ConclusionThis specific use-case evaluating CT-LEFAT criteria displays limited performance. This suggests that additional materials, such as further training, refinement of imaging methods, or other processes may be required before achieving clinically-ready diagnostic performance of LEF diagnosis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Whole Genome Sequencing and single-cell transcriptomics identify KMT2D as a potential new driver for pituitary adenomas\nAbstract: The pituitary gland is a main component of the endocrine system and a master controller of hormone production and secretion. Unlike neoplastic formation in other organs, Pituitary Neuroendocrine Tumors (PitNETs) are frequent in the population (16%) and, for unknown reasons, almost exclusively benign. So far, few genes have been identified as drivers for PitNETs, such as GNAS in somatotroph tumors and USP8 in corticotroph tumors. Using whole genome sequencing, we uncover a potential novel driver, the histone methyltransferase KMT2D, in a patient in his 50s suffering from a mixed somato-lactotroph tumor. Coverage ratio between germline and tumor revealed extensive chromosomal alterations. Single-cell RNA sequencing of the tumor shows up-regulation of known tumorigenic pathways compared to a healthy reference, as well as a different immune infiltration profile compared to other PitNETs, more closely resembling the profile of carcinomas than adenomas. Genome-wide DNA methylation analysis identified 792 differentially methylated regions, including notable hypomethylation in the promoter of SPON2, an immune-related gene. Our results show that tumors considered as quiet and non-aggressive can share drivers, features, and epigenetic alterations with metastatic forms of cancer, raising questions about the biological mechanisms controlling their homeostasis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subcallosal Cingulate structural connectivity as a biomarker for chronic low back pain\nAbstract: BackgroundChronic low back pain (CLBP) poses a significant challenge, contributing significantly to the ongoing opioid crisis while also being a leading cause of disability. Although spinal cord stimulation (SCS) stands as the primary FDA-endorsed method for neuromodulatory therapy in CLBP, there remains a subset of patients unresponsive to SCS and others who experience insufficient pain relief over time. In view of the evidence suggesting the critical role of subcallosal cingulate cortex (SCC) connectivity in pain processing, in the current study we investigated the role of the baseline SCC structural as a potential neuroimaging predictive biomarker to identify patients that are likely to benefit from SCS.  MethodsDiffusion magnetic resonance imaging scans were acquired in 8 patients with CLBP (mean (SD) age = 70 (10) years; 6 female/2 male, 6 UCLA site, 2 UTSW) before their initial SCS trial. Probabilistic tractography from subject-specific anatomically defined SCC seed regions to the ventral striatum (VS), anterior cingulate cortex (ACC), uncinate fasciculus (UCF) and bilateral medial prefrontal cortex (mPFC) was used to calculate FSL structural probabilistic connectivity in the target network. To explore cross-sectional variations in SCC connectivity related to SCS trial response, we employed a general linear model (GLM) using the SCC probability of connectivity as dependent variable, and the response to the SCS trial as independent variable. We used Pearson correlation to evaluate further the relationships between the critical SCC probability of connectivity and the change in VAS score after the SCS trial. Finally, the role of depression in the treatment outcome was evaluated.  ResultsResponders to SCS had significantly lower ipsilateral SCC connectivity to mPFC (F1,8 =8.19, p = 0.03) and VS (F1,8 =17.48, p=0.01) on the left hemisphere compared to non-responders. Pearson correlation analysis showed that decreased ipsilateral SCC baseline connectivity to left mPFC (p=0.03) and VS (p=0.01) was correlated with higher improvement in VAS scores. The baseline depression severity did not significantly influence the change in VAS score following the SCS trial. On the other hand, baseline SCC-VS connectivity on the left hemisphere was a significant predictor of change in VAS score (p=0.02).  ConclusionsOur study highlights the important role of SCC connectivity that can serve as a potential biomarker for CLBP stratification and prediction to SCS treatment. These results can reshape our perspective on CLBP management and can serve as early indicator of response to the treatment providing a personalized approach based on the individuals underlying SCC connectivity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: De novo variant analysis of childhood-onset obsessive-compulsive disorder in the French-Canadian population\nAbstract: Childhood-onset obsessive-compulsive disorder (OCD) is a neuropsychiatric disorder with a strong genetic component. De novo variants (DNVs) have been shown to have a role in childhood-onset OCD, but to date, no DNV analysis has been performed in patients from a genetically isolated population. Here, we aimed to investigate the impact of rare de novo single nucleotide variants (dnSNVs) on childhood-onset OCD risk in the French-Canadian population. In a cohort of 36 French-Canadian trios comprised of 36 probands with childhood-onset OCD and 72 unaffected parents, we identified 34 dnSNVs harboured in 34 different genes. We found that four of these genes were previously associated with OCD, replicating their contribution to its risk. We also observed complete overlap between our 34 candidate genes and genes associated with 11 related neuropsychiatric disorders, supporting a shared underlying genetic susceptibility across psychopathologies. Among genes harbouring DNVs across three childhood-onset OCD cohorts, we observed an overrepresentation of genes involved in clathrin-dependent endocytosis (GO:0072583; p-adj = 0.0498) and phosphatidylinositol binding (GO:0035091; p-adj = 0.0431), offering potential biological mechanisms underlying childhood-onset OCD. No association was found between the number of dnSNVs in childhood-onset OCD probands and OCD symptom severity. Altogether, this study offers a framework for performing DNV analyses of complex disorders in genetically isolated populations. We have provided the first list of candidate childhood-onset OCD genes in the French-Canadian population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: De novo variant analysis of childhood-onset obsessive-compulsive disorder in the French-Canadian population\nAbstract: Childhood-onset obsessive-compulsive disorder (OCD) is a neuropsychiatric disorder with a strong genetic component. De novo variants (DNVs) have been shown to have a role in childhood-onset OCD, but to date, no DNV analysis has been performed in patients from a genetically isolated population. Here, we aimed to investigate the impact of rare de novo single nucleotide variants (dnSNVs) on childhood-onset OCD risk in the French-Canadian population. In a cohort of 36 French-Canadian trios comprised of 36 probands with childhood-onset OCD and 72 unaffected parents, we identified 34 dnSNVs harboured in 34 different genes. We found that four of these genes were previously associated with OCD, replicating their contribution to its risk. We also observed complete overlap between our 34 candidate genes and genes associated with 11 related neuropsychiatric disorders, supporting a shared underlying genetic susceptibility across psychopathologies. Among genes harbouring DNVs across three childhood-onset OCD cohorts, we observed an overrepresentation of genes involved in clathrin-dependent endocytosis (GO:0072583; p-adj = 0.0498) and phosphatidylinositol binding (GO:0035091; p-adj = 0.0431), offering potential biological mechanisms underlying childhood-onset OCD. No association was found between the number of dnSNVs in childhood-onset OCD probands and OCD symptom severity. Altogether, this study offers a framework for performing DNV analyses of complex disorders in genetically isolated populations. We have provided the first list of candidate childhood-onset OCD genes in the French-Canadian population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: De novo variant analysis of childhood-onset obsessive-compulsive disorder in the French-Canadian population\nAbstract: Childhood-onset obsessive-compulsive disorder (OCD) is a neuropsychiatric disorder with a strong genetic component. De novo variants (DNVs) have been shown to have a role in childhood-onset OCD, but to date, no DNV analysis has been performed in patients from a genetically isolated population. Here, we aimed to investigate the impact of rare de novo single nucleotide variants (dnSNVs) on childhood-onset OCD risk in the French-Canadian population. In a cohort of 36 French-Canadian trios comprised of 36 probands with childhood-onset OCD and 72 unaffected parents, we identified 34 dnSNVs harboured in 34 different genes. We found that four of these genes were previously associated with OCD, replicating their contribution to its risk. We also observed complete overlap between our 34 candidate genes and genes associated with 11 related neuropsychiatric disorders, supporting a shared underlying genetic susceptibility across psychopathologies. Among genes harbouring DNVs across three childhood-onset OCD cohorts, we observed an overrepresentation of genes involved in clathrin-dependent endocytosis (GO:0072583; p-adj = 0.0498) and phosphatidylinositol binding (GO:0035091; p-adj = 0.0431), offering potential biological mechanisms underlying childhood-onset OCD. No association was found between the number of dnSNVs in childhood-onset OCD probands and OCD symptom severity. Altogether, this study offers a framework for performing DNV analyses of complex disorders in genetically isolated populations. We have provided the first list of candidate childhood-onset OCD genes in the French-Canadian population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causal associations between plasma proteins and prostate cancer: a Proteome-Wide Mendelian Randomization\nAbstract: BackgroundDue to the limitations in specificity of current diagnostic methods for prostate cancer (PCa), more reliable biomarkers are needed to explore for improving early detection. Plasma proteins represent a promising source of biomarkers, therefore understanding the causal relationships between specific plasma proteins and PCa could be conductive to identify novel biomarkers and therapeutic targets for PCa prevention and treatment.  MethodsWe performed a meta-analysis of two independent genome-wide association studies (GWASs) including 94,397 individuals with PCa and 192,372 controls. A mendelian randomization (MR) supplemented by colocalization analysis was conducted, using cis-acting variants on 4,907 plasma proteins from deCODE Genetics (N=35,559) and 2,940 plasma proteins from UK Biobank Pharma Proteomics Project (UKB-PPP) (N=54,219). Then, the biological pathway analysis and druggability evaluation of the risk proteins were further performed.  ResultsFive possible susceptibility loci (JAZF1, PDILM5, WDPCP, EEFSEC, and TNS3) for PCa were identified through the meta-analysis of GWASs. Among 3,722 plasma proteins, 193 proteins were associated with PCa risk, of which 20 high-risk proteins, including KLK3, were validated in both the deCODE and UKB-PPP cohorts. Functional annotation of these genes encoding proteins confirmed enrichment of immune response, inflammatory response, cell-cell interaction and so on. Genetic colocalization and druggable genome analyses also identified several potential drug targets for PCa, such as HSPB1, RRM2B and PSCA.  ConclusionsWe identified novel variants as well as several protein biomarkers linked to PCa risk and indicated pathways associated with PCa, which offered new insights into PCa etiology and contributed to development of novel biomarkers for early detection and potential therapeutic interventions.  FundingThis work was supported by grants from Beijing Municipal Natural Science Foundation (grant No. JQ24059, No. L234038) and National Natural Science Foundation of China (grant No. 82274015).  Graphical abstractA comprehensive study design summarized as follows.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=147 SRC=\"FIGDIR/small/24312688v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (31K): org.highwire.dtl.DTLVardef@17fc0c9org.highwire.dtl.DTLVardef@49f7f9org.highwire.dtl.DTLVardef@371847org.highwire.dtl.DTLVardef@11af712_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Identifying individuals at risk for surgical supravalvar aortic stenosis by polygenic risk score with graded phenotyping\nAbstract: In a previous pathway-based, extreme phenotype study, we identified 1064 variants associated with supravalvar aortic stenosis (SVAS) severity in people with Williams syndrome (WS) and either no SVAS or surgical SVAS. Here, we use those variants to develop and test polygenic risk scores (PRS). We used the clumping and thresholding (CT) approach on the full 1064 variants and a 427-variant subset that was part of 13 biologically relevant pathways identified in the previous study. We also used a lasso approach on the full set. We were able to achieve an area under the curve (AUC) of >0.99 for the two CT PRS methods, using only 622 and 320 variants respectively when 2/3 of the initial 217 participants data were used for training and 1/3 for testing. The lasso performed less well. We then evaluated the performance of those PRS variant sets on an additional group of 138 patients with WS with intermediate severity SVAS and found a misclassification rate of <10% between the surgical and intermediate groups, suggesting potential for clinical utility of the score.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exome wide association study for blood lipids in 1,158,017 individuals from diverse populations\nAbstract: Rare coding alleles play crucial roles in the molecular diagnosis of genetic diseases. However, the systemic identification of these alleles has been challenging due to their scarcity in the general population. Here, we discovered and characterized rare coding alleles contributing to genetic dyslipidemia, a principal risk for coronary artery disease, among over a million individuals combining three large contemporary genetic datasets (the Million Veteran Program, n = 634,535, UK Biobank, n = 431,178, and the All of Us Research Program, n = 92,304) totaling 1,158,017 multi-ancestral individuals. Unlike previous rare variant studies in lipids, this study included 238,243 individuals (20.6%) from non-European-like populations.  Testing 2,997,401 rare coding variants from diverse backgrounds, we identified 800 exome-wide significant associations across 209 genes including 176 predicted loss of function and 624 missense variants. Among these exome-wide associations, 130 associations were driven by non-European-like populations. Associated alleles are highly enriched in functional variant classes, showed significant additive and recessive associations, exhibited similar effects across populations, and resolved pathogenicity for variants enriched in African or South-Asian populations. Furthermore, we identified 5 lipid-related genes associated with coronary artery disease (RORC, CFAP65, GTF2E2, PLCB3, and ZNF117). Among them, RORC is a potentially novel therapeutic target through the down regulation of LDLC by its silencing.  This study provides resources and insights for understanding causal mechanisms, quantifying the expressivity of rare coding alleles, and identifying novel drug targets across diverse populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Daily consumption of ketone ester, bis octanoyl (R)-1,3-butanediol does not impact functional and quality of life outcomes in healthy older adults, a randomized, parallel arm, double-blind, placebo-controlled study\nAbstract: BackgroundKetone bodies are metabolites produced during fasting or on a ketogenic diet that have pleiotropic effects on the inflammatory and metabolic aging pathways underpinning frailty in in vivo models. Ketone esters (KEs) are compounds that induce hyperketonemia without dietary changes and that may impact physical and cognitive function in young adults. The functional effects of KEs have not been studied in older adults.  ObjectivesOur long-term goal is to examine if KEs modulate aging biology mechanisms and clinical outcomes relevant to frailty in older adults. Here, we report the exploratory functional and quality-of-life outcome measures collected during a 12-week safety and tolerability study of KE (NCT05585762).  DesignRandomized, placebo-controlled, double-blinded, parallel-group, pilot trial of 12-weeks of daily KE ingestion.  SettingThe Clinical Research Unit at the Buck Institute for Research on Aging, California. Participants: Community-dwelling older adults ([&ge;] 65 years), independent in activities of daily living, with no unstable acute medical conditions (n = 30).  InterventionSubjects were randomly allocated (1:1) to consume 25 g daily of either KE (bis-octanoyl (R)-1,3-butanediol) or a taste, appearance, and calorie-matched placebo (PLA) containing canola oil.  MeasurementsLongitudinal change in physical function, cognitive function and quality of life were assessed as exploratory outcomes in n = 23 completers (n = 11 PLA, n = 12 KE). A composite functional outcome to describe the vigor-frailty continuum was calculated. Heart rate and activity was measured throughout the study using digital wearables.  ResultsThere were no statistically significant longitudinal differences between groups in exploratory functional, activity-based or quality of life outcomes.  ConclusionDaily ingestion of 25 g of KE did not affect exploratory functional or quality-of-life end points in this pilot cohort of healthy older adults. Future work will address these endpoints as primary and secondary outcomes in a larger trial of pre-frail older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development, External Validation, and Biomolecular Corroboration of Interoperable Models for Identifying Critically Ill Children at Risk of Neurologic Morbidity\nAbstract: ImportanceDeclining mortality in the field of pediatric critical care medicine has shifted practicing clinicians attention to preserving patients neurodevelopmental potential as a main objective. Earlier identification of critically ill children at risk for incurring neurologic morbidity would facilitate heightened surveillance that could lead to timelier clinical detection, earlier interventions, and preserved neurodevelopmental trajectory.  ObjectiveDevelop machine-learning models for identifying acquired neurologic morbidity while hospitalized with critical illness and assess correlation with contemporary serum-based, brain injury-derived biomarkers.  DesignRetrospective cohort study.  SettingTwo large, quaternary childrens hospitals.  ExposuresCritical illness.  Main Outcomes and MeasuresThe outcome was neurologic morbidity, defined according to a computable, composite definition at the development site or an order for neurocritical care consultation at the validation site. Models were developed using varying time windows for temporal feature engineering and varying censored time horizons prior to identified neurologic morbidity. Optimal models were selected based on F1 scores, cohort sizes, calibration, and data availability for eventual deployment. A generalizable created at the development site was assessed at an external validation site and optimized with spline recalibration. Correlation was assessed between development site model predictions and measurements of brain biomarkers from a convenience cohort.  ResultsAfter exclusions there were 14,222-25,171 encounters from 2010-2022 in the development site cohorts and 6,280-6,373 from 2018-2021 in the validation site cohort. At the development site, an extreme gradient boosted model (XGBoost) with a 12-hour time horizon and 48-hour feature engineering window had an F1-score of 0.54, area under the receiver operating characteristics curve (AUROC) of 0.82, and a number needed to alert (NNA) of 2. A generalizable XGBoost model with a 24-hour time horizon and 48-hour feature engineering window demonstrated an F1-score of 0.37, AUROC of 0.81, AUPRC of 0.51, and NNA of 4 at the validation site. After recalibration at the validation site, the Brier score was 0.04. Serum levels of the brain injury biomarker glial fibrillary acidic protein measurements significantly correlated with model output (rs=0.34; P=0.007).  Conclusions and RelevanceWe demonstrate a well-performing ensemble of models for predicting neurologic morbidity in children with biomolecular corroboration. Prospective assessment and refinement of biomarker-coupled risk models in pediatric critical illness is warranted.  Key PointsQuestion Can interoperable models for predicting neurological deterioration in critically ill children be developed, correlated with serum-based brain-derived biomarkers, and validated at an external site?  Findings A development site model demonstrated an area under the receiver operating characteristics curve (AUROC) of 0.82 and a number needed to alert (NNA) of 2. Predictions correlated with levels of glial fibrillary acidic protein in a subset of children. A generalizable model demonstrated an AUROC of 0.81 and NNA of 4 at the validation site.  Meaning Well performing prediction models coupled with brain biomarkers may help to identify critically ill children at risk for acquired neurological morbidity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: \"WE CAN ALL CONTRIBUTE IN OUR OWN WAY\" : KNOWLEDGE MOBILIZATION TOOLS TO PROMOTE BEST PRACTICES IN UNIVERSAL ACCESSIBILITY\nAbstract: BackgroundCities aim to enhance urban accessibility following the adoption of the United Nations Convention on the Rights of Persons with Disabilities. However, implementation faces challenges due to complex municipal legislation, lack of awareness, and organizational obstacles. Engaging stakeholders and empowering municipal employees through knowledge mobilization is crucial, as shown in a Quebec Citys partnership research process.  AimTo report the implementation strategy as implemented, explore the perception of the employees about the format and feasibility of the implementation strategy and explore the induced changes of knowledge mobilization tools on the implementation determinants of universal accessibility measures for municipal employees.  MethodsThe study used a multi-method design, involving interviews and a questionnaire with the project steering committee, made up of city employees and the research team. Three 30-minute participatory workshops were conducted for culture, communications, and public consultation administrative units.  ResultsParticipants appreciated the workshop format and video content, suggesting minor improvements for broader implementation. The tools effectively increased engagement in implementing universal accessibility measures, proving valuable for raising awareness.  Discussion and ConclusionThe study demonstrates the advantages of a collaborative approach in developing knowledge mobilization tools, enhancing municipal personnels capacity for universal accessibility measures, and highlighting the need for adaptable strategies.  Contributions to the litterature O_LIKnowledge mobilization tools created in partnership with knowledge users encourage buy-in and a positive view of the tools. C_LIO_LIAn interactive implementation strategy actively involving knowledge users promotes awareness and behavior change C_LIO_LIMunicipal organizations context being complex, the implementation strategy must be adapted to each group of people and their reality to facilitate the implementation and adoption of the tools. C_LIO_LIThe combined use of a theoretical framework and a participatory approach provides a guideline for the development of tools and implementation, while adapting to the specific context. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Supporting decision-making for individuals living with dementia and their care partners with knowledge translation: an umbrella review\nAbstract: Living with dementia requires decision-making about numerous topics including daily activities, such as advance care planning (ACP). Both individuals living with dementia and care partners require informed support for decision-making. We conducted an umbrella review to assess knowledge translation (KT) interventions supporting decision-making for individuals living with dementia and their informal care partners. Four databases were searched using 50 different search-terms, identifying 22 reviews presenting 32 KT interventions. The most common KT decision topic was ACP (N=21) which includes advanced care directives, feeding options, and placement in long-term care. The majority of KT interventions targeted care partners only (N=16), or both care partners and individuals living with dementia (N=13), with fewer interventions (N=3) targeting individuals living with dementia. Overall, our umbrella review offers insights into the beneficial impacts of KT interventions, such as increased knowledge and confidence, and decreased decisional conflicts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adherence, Adverse Events and Viral Control among Children and Adolescents with HIV in Zambia Switched to an Integrase Inhibitor Regimen\nAbstract: BackgroundBased on recent World Health Organization recommendations, there has been a large-scale transition in Sub-Saharan Africa to integrase inhibitor (II)-based antiretroviral therapy (ART) regimens.  SettingThis study was conducted at an urban referral center in Lusaka, Zambia.  MethodsThis study included 297 children and adolescents with HIV (CAWH) on ART for one year prior to enrollment and followed for 1-4 years after enrollment. ART adherence, ART regimen, and viral load were assessed periodically. Structured interviews were conducted with a subset of 95 children to assess adherence barriers and side effects.  ResultsChildren on protease inhibitor (PI)-based regimens were more likely to report adherence problems than children taking II- or Efavirenz-based regimens (10% vs. 28%, p=0.03) and noted more days with missed doses (median 1 vs. 0, p=0.02). In interviews, the most common reasons given for poor adherence included bad medication taste, not being home when medications were due, and perceived side effects. The PI group was more likely to report that taste was a problem affecting adherence (22% vs. 4%, p=0.05) and headache as an ART side effect (17% vs. 4%, p=0.05). Switching from a PI- to an II-based regimen was associated with improved adherence (72% vs. 92%, p=0.01) and an undetectable viral load (67% vs. 78%).  ConclusionsSwitching CAWH from PI-based to II-based regimens has many advantages including superior side effect profiles, adherence, and viral suppression. PI taste aversion may be a significant contributor to pediatric adherence issues. Palatability should be considered in pediatric HIV drug development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Executive Function and Adherence in Children and Adolescents Living with HIV: Evidence from the HIV-associated Neurocognitive Disorders in Zambia (HANDZ) Study\nAbstract: IntroductionExecutive function (EF) may be impaired in people with human immunodeficiency virus (HIV) infection, and poor EF may affect medication adherence. However, there is little data on EF in children with HIV in sub-Saharan Africa.  Methods208 children/adolescents with perinatally acquired HIV and 208 HIV-exposed uninfected controls were recruited in Zambia for this prospective cohort study. EF was measured using performance-based, self-report, and parental report measures. Adherence over one year of follow-up was assessed through questionnaires and viral load measurement.  ResultsChildren with HIV performed significantly worse on all three measures of EF. Lower parental rating of EF was associated with poorer antiretroviral therapy adherence (OR: 1.5, 95% CI = 1.02 - 2.2, p = 0.04).  ConclusionChildren with HIV have EF impairments which may lead to consequences like poor medication adherence and treatment failure. Interventions to improve EF or compensate for impaired EF may be necessary in this population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: National trends in drug overdose mortality in Asian American, Native Hawaiian, and Pacific Islander populations, 2018-2022\nAbstract: BackgroundDrug overdose deaths have surged over the past two decades, disproportionately impacting racial/ethnic minority populations. Yet, little is known about drug overdose patterns among Asian American and Native Hawaiian/Pacific Islander (AANHPI) populations.  MethodsWe obtained data on drug overdose deaths and population totals from the CDC WONDER Multiple Cause of Death database and American Community Survey between 2018 and 2022. We calculated crude mortality rates per 100,000, stratified by sex, US Census Division, and drug types--prescription opioids, heroin, fentanyl, cocaine, methamphetamine, and benzodiazepines. Additionally, we conducted disaggregated analyses for six Asian American subgroups (Asian Indian, Chinese, Filipino, Japanese, Korean, Vietnamese) and three NHPI subgroups (Hawaiian, Guamanian, Samoan).  ResultsIn 2022, there were 1226 drug overdose deaths among Asian Americans and 154 among NHPI individuals. The crude mortality rate for NHPI individuals (17.52 per 100,000; 95% CI: 14.76- 20.29) tripled that of Asian Americans (5.85 per 100,000; 95% CI: 5.52-6.18). Fentanyl was the leading cause of overdose deaths among Asian Americans (3.17 per 100,000; 95% CI: 2.93- 3.41), whereas methamphetamine was predominant among NHPI individuals (11.38 per 100,000; 95% CI: 9.15-13.61). Among Asian American subgroups, Japanese Americans had the highest mortality rate (9.90 per 100,000; 95% CI: 9.61-10.2), and among NHPI subgroups, Guamanians had the highest rates (43.16 per 100,000; 95% CI: 39.05-48.24).  ConclusionsThese findings underscore the urgent need for culturally competent harm reduction services, mental health and addiction treatment, and social services, addressing structural barriers that perpetuate drug overdose disparities in AANHPI communities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Milieu Interieur follow-up study - an integrative approach for studying immunological variation in an aging population\nAbstract: Human immune responses are highly variable from one individual to another, with these differences determined by both genetic and environmental factors. We previously established the Milieu Interieur cohort to define the boundaries of healthy immune responses and identify and quantify its different determinants. From this cohort of 1,000 well-defined healthy donors, we have identified multiple genetic and environmental factors that are associated with variable immune phenotypes. Crucially, these associations were observed in a healthy context, as defined by strict inclusion and exclusion criteria. To assess how such immune responses may vary over time, we initiated a 10-year follow-up clinical study of the cohort. From the original 1,000 donors, we identified and recruited 415 donors from whom we assessed recent medical history and lifestyle factors, in addition to collecting samples for measurement of diverse immune phenotypes. A comparison of 107 laboratory and serological measures over the 10-year period showed significant correlations, highlighting the quality of the data collected. By accounting for potential batch effects, our analyses revealed the profound effects of aging on health-related biomarkers and antibody levels against common pathogens. We determined that a significant proportion of the donors no longer meet the initial definition of good health, due to either physiological changes associated with aging, or disease incidence including cancer, autoimmune and cardiovascular diseases. We found that disease development over the past 10 years is associated with a biological aging score, assessed at the time of the initial recruitment. In summary, the Milieu Interieur follow-up study will provide new opportunities for studying biological mechanisms of immunosenescence and identifying factors associated with accelerated immune aging and poor health outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Where Adults with Heart Failure Die: Insights from the CDC-WONDER Database\nAbstract: ABSTRACTO_ST_ABSBACKGROUNDC_ST_ABSHeart failure (HF) is associated with high mortality rates and substantial healthcare costs. Although there is increasing emphasis on introducing palliative care for patients with HF, it is not well characterized where adults with HF spend their final days before death.  STUDY AIMThis study analyzed the locations and circumstances of death among adults with HF in the United States using data from the CDC-WONDER database.  METHODOLOGYThe study examined mortality data of individuals aged [&ge;] 20 years, with HF listed as the underlying cause of death between 1999 and 2023. The place of death was categorized as the emergency room (ER), hospice/nursing home, inpatient medical facility, or home. Multivariable logistic regression was used to determine the relationship between death location and demographic factors.  RESULTSFrom 1999 to 2023, HF-related deaths decreased from 1999 (3.60% and 143.6 AAMR) to 2010 (3.47% and 123.1 AAMR). From 2010 onwards, a gradual rise is seen, with the rate of HF deaths reaching 5.18% and 168.1 AAMR in 2023. Notably, deaths at home increased from 18.41% (50,648 of 275,132) in 1999 to 33.47% (132,470 of 395,826) in 2023 and deaths in hospice/nursing homes increased from 30.95% (85,144 of 275,132) in 1999 to 34.71% (116,634 of 336,014) in 2017 and then sudden fall was observed until 2023 to 29.54% (116,931 of 395,826). Older adults (65+) were more likely to die in inpatient facilities. Gender, ethnicity, and urbanization influenced the place of death, with males, White patients, and those residing in large metropolitan areas more likely to die in medical facilities.  CONCLUSIONSThis study highlights the changing patterns in the locations of death among HF patients, emphasizing the need for improved home and hospice care services. Addressing disparities in healthcare access and enhancing palliative care are essential for improving end-of-life experiences. Further research is needed to investigate the factors that contribute to these trends.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Two-step Bayesian Mendelian Randomization Study on Cholecystitis and Dermatitis\nAbstract: BackgroundCholecystitis is an inflammatory disease involving the gallbladder, often associated with digestive disorders and systemic immune response. This systemic immune response could potentially influence the immune status of the skin, particularly in conditions like dermatitis. Despite extensive research on dermatitis, the causal relationship between cholecystitis and dermatitis subtypes (DSs) remains unclear.  ObjectiveThe aim of this study was to investigate the causal relationship between cholecystitis and DSs.  MethodsTwo-sample Mendelian randomization (MR) was used to analyze the causal relationship between cholecystitis and DSs. We then utilized the Bayesian Weighted Mendelian Randomization (BWMR) method to validate our findings and applied bidirectional MR analysis to confirm the causal direction. After establishing the associations between traits, we delved into the underlying mechanisms of this interesting finding. Subsequently, we used 91 inflammatory proteins as mediators and performed summary data-based mendelian randomization (SMR) analysis to further investigate the pathogenesis of DSs.  ResultsMR results evidently showed that cholecystitis can significantly reduce the risk of allergic contact dermatitis (ACD) (IVW, OR=0.8834, p=0.0368) and exfoliative dermatitis (ED) (IVW, OR=0.5738, p=0.0126). BWMR also provided secondary validation of the casual associations. In the subsequent reverse direction MR analyses, reverse causality was not present, so cholecystitis had a unidirectional effect and existed as a protective factor for ACD and ED. Interestingly, cholecystitis appears to lower the risk of ACD and ED by downregulating IL-6, IL-7, and IFN-{gamma}. Additionally, the genes HCG27 and HLA-DRB5 may play a significant role in the pathogenesis of ACD.  ConclusionThis study used a two-step MR analysis of genetic summary data to investigate to what extent inflammatory proteins impact the protective role of cholecystitis on dermatitis. We also identified several proteins and genes that could serve as potential drug targets.  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=122 SRC=\"FIGDIR/small/24313850v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (28K): org.highwire.dtl.DTLVardef@140ec1org.highwire.dtl.DTLVardef@d4a81forg.highwire.dtl.DTLVardef@169af8dorg.highwire.dtl.DTLVardef@1846c59_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of Therapies Treating Sensory Processing Disorders in Children with Autism Spectrum Disorder\nAbstract: The prevalence of children being diagnosed with Autism Spectrum Disorder has risen dramatically over recent years. Many of those children suffer from sensory processing disorders (SPD). There is no standardized treatment for this disorder and the therapies available have produced confusing and conflicting results. A search was performed for relevant studies and systematic review articles that researched treatment in this area. Data was extracted and analyzed and then organized with summary conclusions of each paper. Qualitative notes were gathered on the studies and the results of the studies were compared and contrasted. Sensory integration therapy has been shown to produce significant results and most of the conflicting data can be explained scientifically. Research is still required for the duration frequency and rate of therapy. Reviews of other therapies to treat SPD have not shown enough evidence of significant positive outcomes to be recommended.  Purpose StatementThe purpose of this paper is to gather and analyze research regarding therapies for Sensory Processing Disorder in Children with Autism Spectrum Disorder. This review aims to determine the evidence of such therapies and to inform and educate practitioners regarding outcomes in their use to treat this disorder.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Who are the Speech-Language Pathologists of the future? Results of a national demographic survey of Canadian SLP students\nAbstract: Speech-language pathologists (SLPs) are experts in communication and swallowing who work with individuals across the lifespan. Prior demographic surveys in English-speaking countries (e.g., Canada and the United States) suggest that SLPs gender, racial, linguistic, and cultural and socioeconomic backgrounds may not be aligned with those of their clientele. The aim of this study is to describe the demographic characteristics of current SLP students, to gauge whether the demographic composition of future clinicians is changing and is aligned with the population they are trained to serve. We designed an anonymous online survey, in the Canadian context, that enabled us to compare current SLP student demographics with statistics available about the target population at large. This survey was disseminated to all SLP students enrolled in an accredited institution in 2024. Participants answered questions about their age, sex and gender, linguistic, racial and cultural identities, and socioeconomic status. More than half (N=525, 53%) of currently enrolled SLP students completed the survey. Results indicate that SLP students are overwhelmingly cisgender females. SLP students spoke 48 unique languages, and while most were bi or multilingual, few felt competent enough in languages other than English and French to engage in clinical service delivery. There were 151 unique racial and ethnic identities reported, with the largest proportion of students identifying as \"North American.\" Culturally most SLPs identified as \"Canadian.\" Very few students identified as Black or Indigenous racially or culturally. Most respondents reported a higher-than-average total household income. Findings suggest that the demographic composition of current SLP students is more diverse than those currently practicing, however there is still over-, and underrepresentation of certain populations. Implications for practice and suggestions for future research are discussed.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human papillomavirus vaccination at the national level in Tunisia: a cost-effectiveness analysis using a comparative modeling study.\nAbstract: Cervical cancer is one of the most prevalent cancer diseases in women caused by persistent infection with one of 13 sexually transmitted high-risk human papillomavirus (HPV) types. Vaccination can significantly reduce the prevalence of this burden in low-middle income countries. However, HPV vaccination is not included in the Tunisian immunization program. Since the economic evaluation of HPV vaccines is crucial to inform public-health decisions, the World Health Organization (WHO) recommends that a cost-effectiveness analysis of HPV vaccination is conducted before nationwide introduction. This study aimed to conduct a cost-effectiveness analysis of incorporating different HPV vaccines into the national immunisation schedule in Tunisia. The potential health and economic impacts of human papillomavirus (HPV) vaccination were evaluated through comparative modelling analysis using two published static models (UNIVAC and Papillomavirus Rapid Interface for Modelling and Economics (PRIME)). Academic literature and anecdotal evidence were included on the demographic variables, cervical cancer incidence and mortality, treatment costs, vaccine delivery costs and other model parameters.  The cost of vaccination, treatment costs saved, net costs, cases and deaths averted, life years saved, disability-adjusted life years (DALYs) prevented, and incremental cost-effectiveness ratios were predicted and reported as primary outcomes. The incremental cost-effectiveness ratios (ICERs) were estimated per disability-adjusted life years (DALYs) averted using the cost-effectiveness threshold (CET) defined by the World Health Organisation (WHO). All HPV vaccines were very cost effective (with every disability-adjusted life-year averted costing less than the cost-effectiveness threshold). The analyses were done from a health system and societal perspective. Despite model differences, the PRIME and UNIVAC models yielded similar vaccine-impact estimates.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human papillomavirus vaccination at the national level in Tunisia: a cost-effectiveness analysis using a comparative modeling study.\nAbstract: Cervical cancer is one of the most prevalent cancer diseases in women caused by persistent infection with one of 13 sexually transmitted high-risk human papillomavirus (HPV) types. Vaccination can significantly reduce the prevalence of this burden in low-middle income countries. However, HPV vaccination is not included in the Tunisian immunization program. Since the economic evaluation of HPV vaccines is crucial to inform public-health decisions, the World Health Organization (WHO) recommends that a cost-effectiveness analysis of HPV vaccination is conducted before nationwide introduction. This study aimed to conduct a cost-effectiveness analysis of incorporating different HPV vaccines into the national immunisation schedule in Tunisia. The potential health and economic impacts of human papillomavirus (HPV) vaccination were evaluated through comparative modelling analysis using two published static models (UNIVAC and Papillomavirus Rapid Interface for Modelling and Economics (PRIME)). Academic literature and anecdotal evidence were included on the demographic variables, cervical cancer incidence and mortality, treatment costs, vaccine delivery costs and other model parameters.  The cost of vaccination, treatment costs saved, net costs, cases and deaths averted, life years saved, disability-adjusted life years (DALYs) prevented, and incremental cost-effectiveness ratios were predicted and reported as primary outcomes. The incremental cost-effectiveness ratios (ICERs) were estimated per disability-adjusted life years (DALYs) averted using the cost-effectiveness threshold (CET) defined by the World Health Organisation (WHO). All HPV vaccines were very cost effective (with every disability-adjusted life-year averted costing less than the cost-effectiveness threshold). The analyses were done from a health system and societal perspective. Despite model differences, the PRIME and UNIVAC models yielded similar vaccine-impact estimates.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating and Reducing Subgroup Disparity in AI Models: An Analysis of Pediatric COVID-19 Test Outcomes\nAbstract: Artificial Intelligence (AI) fairness in healthcare settings has attracted significant attention due to the concerns to propagate existing health disparities. Despite ongoing research, the frequency and extent of subgroup fairness have not been sufficiently studied. In this study, we extracted a nationally representative pediatric dataset (ages 0-17, n=9,935) from the US National Health Interview Survey (NHIS) concerning COVID-19 test outcomes. For subgroup disparity assessment, we trained 50 models using five machine learning algorithms. We assessed the models area under the curve (AUC) on 12 small (<15% of the total n) subgroups defined using social economic factors versus the on the overall population. Our results show that subgroup disparities were prevalent (50.7%) in the models. Subgroup AUCs were generally lower, with a mean difference of 0.01, ranging from -0.29 to +0.41. Notably, the disparities were not always statistically significant, with four out of 12 subgroups having statistically significant disparities across models. Additionally, we explored the efficacy of synthetic data in mitigating identified disparities. The introduction of synthetic data enhanced subgroup disparity in 57.7% of the models. The mean AUC disparities for models with synthetic data decreased on average by 0.03 via resampling and 0.04 via generative adverbial network methods.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Automatically Identifying Event Reports of Workplace Violence and Communication Failures using Large Language Models\nAbstract: Safety event reporting forms a cornerstone of identifying and mitigating risks to patient and staff safety. However, variabilities in reporting and limited resources to analyze and classify event reports delay healthcare organizations ability to rapidly identify safety event trends and to improve workplace safety. We demonstrated how large language models can classify safety event report narratives as workplace violence and communication failures as a first step toward enabling automated labeling of safety event reports and ultimately improving workplace safety.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging large language models for systematic reviewing: A case study using HIV medication adherence research\nAbstract: BackgroundThe rapidly accumulating scientific literature in HIV presents a significant challenge in accurately and efficiently assessing the relevant literature. This study explores the potential capabilities of using large language models (LLMs), such as ChatGPT, for selecting relevant studies for a systematic review.  MethodScientific papers were initially obtained from bibliographic database searches using a Boolean search strategy with pre-defined keywords. From 15,839 unique records, three reviewers manually identified 39 relevant papers based on pre-specified inclusion and exclusion criteria. In the ChatGPT experiment, over 10% of records were randomly chosen as the experimental dataset, including the 39 manually identified manuscripts. These unique records (n=1,680) underwent screening via ChatGPT-4 using the same prespecified criteria. Four strategies were employed including standard prompting, i.e., input-output (IO), chain of thought with zero-shot learning (0-CoT), CoT with few-shot learning (FS-CoT), and Majority Voting (which integrates all three promoting strategies). Performance of the models were assessed using recall, F-score, and precision measures.  ResultsRecall scores (% of true abstracts successfully identified and retrieved by the model from all input data/records) for different ChatGPT configurations were 0.82 (IO), 0.97 (0-CoT), and both the FS-CoT and the Majority Voting prompts achieved a recall score of 1.0. F-scores were 0.34 (IO), 0.29 (0-CoT), 0.39 (FS-CoT), and 0.46 (majority voting). Precision measures were 0.22(IO), 0.17(0-CoT), 0.24(FS-CoT), and 0.30 (Majority Voting). Computational time varied with 2.32, 4.55, 6.44, and 13.30 hours for IO, 0-CoT, FS-CoT, and majority voting,respectively. Processing costs for the 1,680 unique records were approximately $63, $73, $186, and $325, respectively.  ConclusionLLMs, like ChatGPT, are viable for systematic reviews, efficiently identifying studies meeting pre-specified criteria. Greater efficacy was observed when a more sophisticated prompt design was employed, integrating IO, 0-CoT and FS-CoT prompt techniques (i.e., majority voting). LLMs can expedite the study selection process in systematic reviews compared to manual methods, with minimal cost implications.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Achievement of diabetes treatment goals in Mexico from 2016-2022: A retrospective analysis of nationally representative surveys\nAbstract: BACKGROUNDCardiovascular (CVD) risk factor reduction is a cornerstone of diabetes management. Here, we aimed to estimate the prevalence and determinants of individual and combined CVD risk factor control goals amongst individuals living with diagnosed diabetes in Mexico.  METHODSWe analyzed Mexican National Health and Nutrition Surveys from 2016-2022 including individuals aged [&ge;]20 years with diagnosed diabetes. We estimated the prevalence of glycemic, blood pressure, cholesterol, and smoking control, as well as combined control achievement according to current guidelines, as well as the prevalence of antihypertensive, statin and diabetes medication use. We also explored determinants of control achievement amongst individuals with diabetes using weighted logistic regression.  RESULTSWe analyzed data from 2,331 adults with diagnosed diabetes. Glycemic control increased over time reaching 41% (95%CI 30%-52%) by 2022. Blood pressure control remained similar over time reaching 45% (95%CI 35%-55%) in 2022, LDL-C control remained low regardless of the definition (<70 vs. <100 mg/dL), whilst smoking control was high and increased over time to 92% (95%CI 88%-96%) in 2022. Combined risk factor control achievement was low, primarily due to suboptimal LDL-C control, despite a high proportion of medication use. Control achievement was more likely in Northern Mexico, in younger individuals, those with college education or living in states with lower social lag.  CONCLUSIONSOur results suggest a need to improve comprehensive glycemic and CVD risk factor management for individuals living with diabetes in Mexico to improve diabetes care and reduce risk of adverse outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Statin use is associated with reduction in risk of de novo primary sclerosing cholangitis among patients with inflammatory bowel disease: A National Database Study\nAbstract: Background and AimsPrimary sclerosing cholangitis (PSC) is a liver disease without medical therapy that significantly increases the risk of malignancies, acute cholangitis and cirrhosis. Approximately 2-7% of patients with inflammatory bowel disease (IBD) develop PSC. No drug has been shown to prevent de novo PSC in patients with IBD. Statin use, however, has been associated with increased liver transplant-free survival. Yet, the impact of statins on development of new PSC among those with IBD is unknown.  MethodsWe conducted a retrospective cohort study of patients diagnosed with IBD with and without statin exposure using a large, representative national database. Patients were followed from the date of diagnosis of IBD. Patient demographics, co-morbidities, medications, and type of IBD were extracted. Unmatched and propensity score-matched Cox regression analyses were performed.  ResultsOur analysis included 33,813 patients with IBD of whom 8,813 were exposed to statins. PSC developed in 181 patients over a median follow-up of 3.7 years. Only nine patients (0.1%) who were exposed to statins developed PSC compared to 173 (0.69%) in the non-exposed population. In propensity score-matched analysis, statin therapy was associated with an 86% lower risk of developing PSC (HR 0.14; 95% CI 0.06-0.33, p<0.001). The findings were consistent when accounting for unmeasured confounders (E-value) in sensitivity analyses, including stratification by age group, duration of statin use, and type of statin.  ConclusionIn a propensity score-matched analysis, statin use was associated with an 86% risk reduction in new PSC diagnosis among patients with known IBD, suggesting a potential benefit as a prophylactic agent. These findings warrant prospective validation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the Spectrum: Subtype-Specific Molecular Insights into Autism Spectrum Disorder Via Integrated Transcriptomic Analysis\nAbstract: Some toddlers with autism spectrum disorder (ASD) have mild social symptoms and developmental improvement in skills, but for others, symptoms and abilities are moderately or even severely affected. Those with profound autism have the most severe social, language, and cognitive symptoms and are at the greatest risk of having a poor developmental outcome. The little that is known about the underlying biology of this important profound autism subtype, points clearly to embryonic dysregulation of proliferation, differentiation and neurogenesis. Because it is essential to gain foundational knowledge of the molecular biology associated with profound, moderate, and mild autism clinical subtypes, we used well-validated, data-driven patient subtyping methods to integrate clinical and molecular data at 1 to 3 years of age in a cohort of 363 ASD and controls representative of the general pediatric population in San Diego County. Clinical data were diagnostic, language, cognitive and adaptive ability scores. Molecular measures were 50 MSigDB Hallmark gene pathway activity scores derived from RNAseq gene expression. Subtyping identified four ASD, typical and mixed diagnostic clusters. 93% of subjects in one cluster were profound autism and 93% in a different cluster were control toddlers; a third cluster was 76% moderate ability ASD; and the last cluster was a mix of mild ASD and control toddlers. Among the four clusters, the profound autism subtype had the most severe social symptoms, language, cognitive, adaptive, social attention eye tracking, social fMRI activation, and age-related decline in abilities, while mild autism toddlers mixed within typical and delayed clusters had mild social symptoms, and neurotypical language, cognitive and adaptive scores that improved with age compared with profound and moderate autism toddlers in other clusters. In profound autism, 7 subtype-specific dysregulated gene pathways were found; they control embryonic proliferation, differentiation, neurogenesis, and DNA repair. To find subtype-common dysregulated pathways, we compared all ASD vs TD and found 17 ASD subtype-common dysregulated pathways. These common pathways showed a severity gradient with the greatest dysregulation in profound and least in mild. Collectively, results raise the new hypothesis that the continuum of ASD heterogeneity is moderated by subtype-common pathways and the distinctive nature of profound autism is driven by the differentially added profound subtype-specific embryonic pathways.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the Spectrum: Subtype-Specific Molecular Insights into Autism Spectrum Disorder Via Integrated Transcriptomic Analysis\nAbstract: Some toddlers with autism spectrum disorder (ASD) have mild social symptoms and developmental improvement in skills, but for others, symptoms and abilities are moderately or even severely affected. Those with profound autism have the most severe social, language, and cognitive symptoms and are at the greatest risk of having a poor developmental outcome. The little that is known about the underlying biology of this important profound autism subtype, points clearly to embryonic dysregulation of proliferation, differentiation and neurogenesis. Because it is essential to gain foundational knowledge of the molecular biology associated with profound, moderate, and mild autism clinical subtypes, we used well-validated, data-driven patient subtyping methods to integrate clinical and molecular data at 1 to 3 years of age in a cohort of 363 ASD and controls representative of the general pediatric population in San Diego County. Clinical data were diagnostic, language, cognitive and adaptive ability scores. Molecular measures were 50 MSigDB Hallmark gene pathway activity scores derived from RNAseq gene expression. Subtyping identified four ASD, typical and mixed diagnostic clusters. 93% of subjects in one cluster were profound autism and 93% in a different cluster were control toddlers; a third cluster was 76% moderate ability ASD; and the last cluster was a mix of mild ASD and control toddlers. Among the four clusters, the profound autism subtype had the most severe social symptoms, language, cognitive, adaptive, social attention eye tracking, social fMRI activation, and age-related decline in abilities, while mild autism toddlers mixed within typical and delayed clusters had mild social symptoms, and neurotypical language, cognitive and adaptive scores that improved with age compared with profound and moderate autism toddlers in other clusters. In profound autism, 7 subtype-specific dysregulated gene pathways were found; they control embryonic proliferation, differentiation, neurogenesis, and DNA repair. To find subtype-common dysregulated pathways, we compared all ASD vs TD and found 17 ASD subtype-common dysregulated pathways. These common pathways showed a severity gradient with the greatest dysregulation in profound and least in mild. Collectively, results raise the new hypothesis that the continuum of ASD heterogeneity is moderated by subtype-common pathways and the distinctive nature of profound autism is driven by the differentially added profound subtype-specific embryonic pathways.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the Spectrum: Subtype-Specific Molecular Insights into Autism Spectrum Disorder Via Multimodal Data Integration\nAbstract: Some toddlers with autism spectrum disorder (ASD) have mild social symptoms and developmental improvement in skills, but for others, symptoms and abilities are moderately or even severely affected. Those with profound autism have the most severe social, language, and cognitive symptoms and are at the greatest risk of having a poor developmental outcome. The little that is known about the underlying biology of this important profound autism subtype, points clearly to embryonic dysregulation of proliferation, differentiation and neurogenesis. Because it is essential to gain foundational knowledge of the molecular biology associated with profound, moderate, and mild autism clinical subtypes, we used well-validated, data-driven patient subtyping methods to integrate clinical and molecular data at 1 to 3 years of age in a cohort of 363 ASD and controls representative of the general pediatric population in San Diego County. Clinical data were diagnostic, language, cognitive and adaptive ability scores. Molecular measures were 50 MSigDB Hallmark gene pathway activity scores derived from RNAseq gene expression. Subtyping identified four ASD, typical and mixed diagnostic clusters. 93% of subjects in one cluster were profound autism and 93% in a different cluster were control toddlers; a third cluster was 76% moderate ability ASD; and the last cluster was a mix of mild ASD and control toddlers. Among the four clusters, the profound autism subtype had the most severe social symptoms, language, cognitive, adaptive, social attention eye tracking, social fMRI activation, and age-related decline in abilities, while mild autism toddlers mixed within typical and delayed clusters had mild social symptoms, and neurotypical language, cognitive and adaptive scores that improved with age compared with profound and moderate autism toddlers in other clusters. In profound autism, 7 subtype-specific dysregulated gene pathways were found; they control embryonic proliferation, differentiation, neurogenesis, and DNA repair. To find subtype-common dysregulated pathways, we compared all ASD vs TD and found 17 ASD subtype-common dysregulated pathways. These common pathways showed a severity gradient with the greatest dysregulation in profound and least in mild. Collectively, results raise the new hypothesis that the continuum of ASD heterogeneity is moderated by subtype-common pathways and the distinctive nature of profound autism is driven by the differentially added profound subtype-specific embryonic pathways.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Investigation of factors associated with delayed initiation of breastfeeding in Papua New Guinea: a cross-sectional study\nAbstract: BackgroundBreastfeeding within the first hour of birth is critical for newborn survival. However, in Papua New Guinea (PNG), about 40% of newborns are not breastfed within the first hour of birth. This study aimed to determine the prevalence and factors associated with delayed breastfeeding initiation in PNG.  MethodsThis study utilised secondary data from the 2016-2018 PNG Demographic and Health Survey (DHS), a nationally representative cross-sectional study. A total weighted sample of 4748 women aged 15-49 were included. Complex samples analysis was performed to determine the direction of association between the independent variables and delayed initiation of breastfeeding.  ResultsAbout a quarter (24.6%) of women delayed initiation of breastfeeding. Women with an unplanned pregnancy (AOR 1.32; 95% CI: 1.03 to 1.68), those who had a caesarean section (AOR 3.16; 95% CI: 1.39 to 7.17), those who did not initiate newborn skin-to-skin contact immediately after birth (AOR 1.83; 95% CI: 1.41 to 2.38), and those who watched television (AOR 1.39; 95% CI: 1.11 to 1.75), or were from the Momase region (AOR 1.31; 95% CI: 0.88 to 1.93) had higher odds of delayed breastfeeding initiation. Conversely, those who read a newspaper or magazine (AOR 0.76; 95% CI: 0.61 to 0.95), were from the Southern (AOR 0.81; 95% CI: 0.56 to 1.15) and Highlands (AOR 0.86; 95% CI: 0.58 to 1.29) regions, and gave birth at home or in the village (AOR 0.69; 95% CI: 0.49 to 0.96) had lower odds of delayed initiation of breastfeeding.  ConclusionOne in four women in this study delayed initiation of breastfeeding until after one hour after birth. Interventions to promote optimal breastfeeding require a multi-sectoral approach, as well as bolstering health workers capacity to encourage and support early initiation of breastfeeding during the antenatal and early postnatal periods.  What is known about the subjectO_LIEarly breastfeeding initiation within the first hour of birth is an important intervention to reduce childhood morbidities and mortalities. C_LIO_LIIn PNG, 40% of newborns are not breastfed immediately or within the first hour of birth. C_LI  What this study addsO_LIOne in four women in PNG delayed early initiation of breastfeeding. C_LIO_LIUnplanned pregnancy, caesarean section, no newborn skin-to-skin contact immediately after birth, and exposure to media predicted delayed initiation of breastfeeding. C_LIO_LIBirth at home or in the village reduces the likelihood of delayed initiation of breastfeeding. C_LI  How this study affects research, practice or policyO_LIThis study seeks to promote targeted breastfeeding support for mothers, particularly in rural areas. C_LIO_LIBreastfeeding advocacy and promotion programmes, strengthening health workers capacity to address factors influencing delayed initiation of breastfeeding, and promoting optimal breastfeeding practices are required. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of complex traits with common genetic variation across genomic regions containing pathogenic copy number variations\nAbstract: BackgroundCopy Number Variations (CNVs) are structural variation in the genome, which may impact complex human traits and diseases. The investigation of rare CNVs is impeded by low sample size. To understand the mechanisms through which CNVs influence human health, common variation in the genomic region of the CNV from large samples could be used as a proxy.  MethodsUtilising genome-wide association study (GWAS) summary statistics of 20 traits, we assessed the cumulative effect of common genetic variants in eight genomic regions containing pathogenic CNVs, using MAGMA gene-based analysis. We used GSA-MiXeR to estimate the fold enrichment of these CNV regions for the specific phenotypes.  ResultsThe distal and proximal regions of the 16p11.2 CNV exhibited the highest number of significant associations and were enriched for the highest number of traits: 12 of 27 significant MAGMA associations (44%) were enriched. These CNV regions also had the highest number of phenotype-associated genes related to ion transport, signalling, transcriptional regulation, development, and protein metabolism. We compared the significance of all the genomic regions and the genes in these regions and found two opposing patterns: 1) cumulative value of separate genes, resulting in the higher significance of the whole region than of the particular genes; 2) higher significance of the specific genes that drive the association of the whole region.  ConclusionsCharting the features of genomic regions encompassing CNVs might aid in clarifying CNVs role in human disease, especially pinpointing candidate genes within these regions that are associated with complex traits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Health Data Reporting Challenges in the Age of DHIS2: a Mixed-Methods Review in the Teso Sub-Region of Uganda\nAbstract: In Uganda, the complete and timely reporting of priority disease data by health centers is critical for detecting outbreaks. However, health centers face significant reporting challenges, which compromise data fidelity and public health. To assess the efficacy of existing systems, we aimed to (1) compare reporting performance among districts in the Teso region of Eastern Uganda, (2) ascertain the association between volume of outpatient department (OPD) visits and reporting rates at facilities, and (3) characterize reporting challenges. We queried Ugandas Electronic Health Management Information System database, DHIS2, regarding the completeness (reporting rate) and timeliness (reporting rate on time) of priority disease data submission within Teso from January-April 2024. We selected the 3 lowest-performing districts in both metrics and assessed reporting at all health centers within these districts. We used linear regression to determine the relationship between the aggregate number of outpatient visits per health facility and their mean reporting rates. At 7 health facilities across the 3 districts, we interviewed staff to enumerate reporting challenges. Of all 11 districts in Teso, 7 (64%) scored >80% for completeness and 2 (18%) scored >80% for submission timeliness across health facilities. The median (IQR) scores for completeness and timeliness were 83% (75-93%) and 69% (55-75%), respectively. The 3 lowest performing districts in both metrics were Soroti City, Soroti district, and Ngora district. In Soroti City, increasing number of OPD visits was associated with higher reporting rate percentages (b [slope]=0.005, p=0.01). The main reasons given for low reporting rates included limited staff trained on data entry protocols, competing responsibilities among reporting personnel, and lack of reliable internet access. The implementation of DHIS2 has improved public health and disease surveillance in Uganda, but institutional-level data reporting challenges continue to impair disease tracking. Targeted interventions to relieve such barriers is possible.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Health Data Reporting Challenges in the Age of DHIS2: a Mixed-Methods Review in the Teso Sub-Region of Uganda\nAbstract: In Uganda, the complete and timely reporting of priority disease data by health centers is critical for detecting outbreaks. However, health centers face significant reporting challenges, which compromise data fidelity and public health. To assess the efficacy of existing systems, we aimed to (1) compare reporting performance among districts in the Teso region of Eastern Uganda, (2) ascertain the association between volume of outpatient department (OPD) visits and reporting rates at facilities, and (3) characterize reporting challenges. We queried Ugandas Electronic Health Management Information System database, DHIS2, regarding the completeness (reporting rate) and timeliness (reporting rate on time) of priority disease data submission within Teso from January-April 2024. We selected the 3 lowest-performing districts in both metrics and assessed reporting at all health centers within these districts. We used linear regression to determine the relationship between the aggregate number of outpatient visits per health facility and their mean reporting rates. At 7 health facilities across the 3 districts, we interviewed staff to enumerate reporting challenges. Of all 11 districts in Teso, 7 (64%) scored >80% for completeness and 2 (18%) scored >80% for submission timeliness across health facilities. The median (IQR) scores for completeness and timeliness were 83% (75-93%) and 69% (55-75%), respectively. The 3 lowest performing districts in both metrics were Soroti City, Soroti district, and Ngora district. In Soroti City, increasing number of OPD visits was associated with higher reporting rate percentages (b [slope]=0.005, p=0.01). The main reasons given for low reporting rates included limited staff trained on data entry protocols, competing responsibilities among reporting personnel, and lack of reliable internet access. The implementation of DHIS2 has improved public health and disease surveillance in Uganda, but institutional-level data reporting challenges continue to impair disease tracking. Targeted interventions to relieve such barriers is possible.\n"}, {"role": "assistant", "content": "no"}]}
