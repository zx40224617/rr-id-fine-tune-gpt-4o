{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hyperbaric Oxygen Therapy for Long COVID: 3-Month Follow up Results from a Prospective Registry of 232 patients\nAbstract: A potential beneficial effect of hyperbaric oxygen therapy (HBOT) on complaints of long COVID was found, leading to increased demand for this treatment despite many remaining clinical questions and lack of formal guideline recommendations and reimbursement. A registry was set up in order to gain more insight into patient characteristics and (long-term) outcomes of long COVID patients undergoing HBOT. Patient-reported outcome measures were collected at baseline, after treatment and at 3-month follow up. The primary outcome measures were the mental and physical component score (MCS/PCS) of the SF-36 questionnaire 3 months after HBOT. A clinically relevant positive or negative response was defined as an increase or decrease of [&ge;]10% in MCS and/or PCS after 3 months. Secondary outcomes included the EQ-5D, severity of complaints and ability to work. In this prospective registry of 232 long COVID patients, 65% of long term-ill patients had a clinically relevant increase in quality of life. However, 15% of the patients experienced deterioration in quality of life. Symptoms that showed most improvement were predominantly in the cognitive domain. This indicates that HBOT may have a positive effect on complaints of long COVID, but alertness for worsening of the condition should be exercised.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Determinants of self-treatment with antimalarials in Ndola district, Zambia: a cross-sectional study\nAbstract: Antimalarial drug resistance has been an obstacle in the fight against malaria over the years. Antimalarial self-medication is one of the factors associated with antimalarial resistance, and is on the rise globally and has become quite common among developing populations. Self-medication is when individuals choose and use medications to treat symptoms they perceive or diagnose themselves, without the guidance of a healthcare professional. This study aimed at investigating prevalence and determinants of antimalarial drug self-medication among adults in Ndola district, Zambia. A cross-sectional study was conducted among adults in Ndola district, Zambia in June 2023. Using multistage cluster sampling, 446 participants were randomly selected and interviewed through a mobile-based structured questionnaire administered by the researchers using Kobo collect/kobo toolbox. The head of household was the primary participant. Data was then exported to Microsoft Excel, cleaned and coded, and thereafter exported to STATA version 16.1 for analysis. Chi-square tests and logistic regression analysis was used to test associations between categorical variables and to estimate the odds of antimalarial drug self-medication associated with the explanatory variables. The prevalence of antimalarial drug self-medication was 20% in this study population and the factors significantly associated were; moderate to mild illness, bad experience with hospital care, lack of knowledge about antimalarial drug resistance, and the perception that antimalarial drug self-medication was not risky. The finding that antimalarial self-medication was common in this study population is suggestive of a poor state of the health-care delivery system possibly due to inadequate manpower, stock out of drugs in health facilities, and lack of awareness about the risks of self-medication. This further suggests that there is great need for regulatory authorities to strengthen drug regulations and update the list of over-the-counter and essential medicines to ensure the safety of public health. In addition, authorities should repackage malaria sensitization messages to strongly highlight the risks of antimalarial drug self-medication.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How do socioeconomic trajectories experienced during early adulthood contribute to the development of cardiometabolic health in young adults?\nAbstract: IntroductionSocioeconomic position has been strongly associated with cardiovascular health. However, little is known about the short-term health impacts of socioeconomic exposures during early adulthood. In this study we describe distinct socioeconomic trajectories of early adulthood (age 16-24y), and assess associations of these trajectories with measures of cardiometabolic health at age 24y.  MethodsParticipants of the Avon Longitudinal Study of Parents and Children (ALSPAC), with data across age 16y to 24y (2007-2017) were included (n=7,568). Longitudinal latent class analysis identified socioeconomic trajectories, based on education and employment data across ages 16-24y. Cardiometabolic outcomes at age 24y comprised anthropometric, vascular, metabolic and cardiovascular structure and function measures. We modelled differences in cardiometabolic outcomes at age 24y across the socioeconomic trajectory classes, adjusting for childhood socioeconomic position, adolescent health behaviours and adolescent health.  ResultsFour early adulthood socioeconomic trajectories were identified: (1) Higher Education (41% of the population), (2) Extended Education (9%), (3) Part-Time Employment (21%), and (4) Early Employment (29%). Associations between socioeconomic trajectory and cardiometabolic outcomes differed by sex. Among males, the Higher Education and Extended Education classes showed a healthier cardiometabolic profile, and the Part-time Employment class the least healthy. Among females there was less clear distinction between the classes, and the pattern across different outcomes was not consistent.  ConclusionThe newly identified  Part-time Employment class showed the least healthy cardiometabolic profile, and further research should focus on this group to understand the exposures contributing to poor cardiometabolic health in this sector of the population.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association between urbanicity and depressive symptoms among Chinese middle-aged and older adults\nAbstract: BackgroundDepression is a pressing public health issue and may be affected by multifaceted urban living, yet the specific urbanicity elements associated is unclear. Using a multidimensional urbanicity scale, we explored the association between urbanicity and its components with the risk of depressive symptoms.  MethodsThis study used data from four waves of the China Health and Retirement Longitudinal Study, including 12,515 participants aged [&ge;]45 years at baseline in 2011 in 450 rural and urban communities, and 8,766 with 7 years of follow-up. Multilevel logistics regression and Cox proportional hazards regression models examined the cross-sectional and longitudinal associations between urbanicity and depressive symptoms.  ResultsLiving in areas with the highest tertile of urbanicity was associated with a 61% lower risk of depressive symptoms cross-sectionally (odds ratio (OR): 0.39, 95% confidence interval (CI): 0.30-0.50) and 33% lower risk longitudinally (hazard ratio (HR): 0.67, 95% CI: 0.58-0.77) compared to those living in areas with the lowest tertile of urbanicity. Among components, higher population density (OR: 0.92, 95% CI: 0.87-0.97), better education (OR: 0.94, 95% CI: 0.89-0.99), transportation (OR: 0.95, 95% CI: 0.92-0.98), sanitation (OR: 0.96, 95% CI: 0.93-0.98) was associated with lower odds of depressive symptoms, while greater population educational and socioeconomic diversity (OR, 1.08; 95% CI, 1.03-1.13) had opposite effect. Better economic conditions (HR: 0.94, 95% CI: 0.90-0.98) and availability of social services (HR, 0.96; 95% CI, 0.93-0.99) were longitudinally associated with reduced risk of developing depressive symptoms during 7 years of follow-up. Additionally, differences in associated components were found between urban and rural residents and between midlife and older adults.  ConclusionsOur findings underscore the complex links of urban living with depressive symptoms among middle-aged and older adults, highlighting the need to consider a multidimensional urbanicity perspective to understand the urbanicity-mental health nexus. Tailored urban planning policies should consider the associated urbanicity components, along with temporal effectiveness, urban-rural disparities, and age group differences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association between urbanicity and depressive symptoms among Chinese middle-aged and older adults\nAbstract: BackgroundDepression is a pressing public health issue and may be affected by multifaceted urban living, yet the specific urbanicity elements associated is unclear. Using a multidimensional urbanicity scale, we explored the association between urbanicity and its components with the risk of depressive symptoms.  MethodsThis study used data from four waves of the China Health and Retirement Longitudinal Study, including 12,515 participants aged [&ge;]45 years at baseline in 2011 in 450 rural and urban communities, and 8,766 with 7 years of follow-up. Multilevel logistics regression and Cox proportional hazards regression models examined the cross-sectional and longitudinal associations between urbanicity and depressive symptoms.  ResultsLiving in areas with the highest tertile of urbanicity was associated with a 61% lower risk of depressive symptoms cross-sectionally (odds ratio (OR): 0.39, 95% confidence interval (CI): 0.30-0.50) and 33% lower risk longitudinally (hazard ratio (HR): 0.67, 95% CI: 0.58-0.77) compared to those living in areas with the lowest tertile of urbanicity. Among components, higher population density (OR: 0.92, 95% CI: 0.87-0.97), better education (OR: 0.94, 95% CI: 0.89-0.99), transportation (OR: 0.95, 95% CI: 0.92-0.98), sanitation (OR: 0.96, 95% CI: 0.93-0.98) was associated with lower odds of depressive symptoms, while greater population educational and socioeconomic diversity (OR, 1.08; 95% CI, 1.03-1.13) had opposite effect. Better economic conditions (HR: 0.94, 95% CI: 0.90-0.98) and availability of social services (HR, 0.96; 95% CI, 0.93-0.99) were longitudinally associated with reduced risk of developing depressive symptoms during 7 years of follow-up. Additionally, differences in associated components were found between urban and rural residents and between midlife and older adults.  ConclusionsOur findings underscore the complex links of urban living with depressive symptoms among middle-aged and older adults, highlighting the need to consider a multidimensional urbanicity perspective to understand the urbanicity-mental health nexus. Tailored urban planning policies should consider the associated urbanicity components, along with temporal effectiveness, urban-rural disparities, and age group differences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causal effects of breast cancer risk factors across hormone receptor breast cancer subtypes: A two-sample Mendelian randomization study\nAbstract: BackgroundIt is unclear if established breast cancer risk factors exert similar causal effects across hormone receptor breast cancer subtypes. We estimated and compared causal estimates of height, body mass index (BMI), type 2 diabetes, age at menarche, age at menopause, breast density, alcohol consumption, regular smoking, and physical activity across these subtypes.  MethodsWe used a two-sample Mendelian randomization approach and selected genetic instrumental variables from large-scale risk factor GWAS. Publicly available summary-level data for the following subtypes were included: luminal A-like; luminal B/HER2-negative-like; luminal B-like; HER2-enriched-like; triple negative. We employed multiple methods to evaluate the strength of causal evidence for each risk factor-subtype association.  ResultsCollectively, our analyses indicated that increased height and decreased BMI are probable causal risk factors for all five subtypes. For the other risk factors, the strength of evidence for causal effects differed across subtypes. Heterogeneity in the magnitude of causal effect estimates for age at menopause and breast density was explained by null findings for triple negative tumours. Regular smoking was the sole risk factor for which there was no evidence for a causal effect on any subtype.  ConclusionsThis study suggests that established breast cancer risk factors differ across hormone receptor subtypes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal trajectories of psychological resilience and cognitive impairment among older adults: evidence from a national cohort study\nAbstract: BackgroundThe relationship between resilience trajectories and cognitive health is not well understood. This study aimed to identify subgroups of psychological resilience trajectories in a national sample of older adults and to examine the association with cognitive impairment over time.  MethodsThis study used data from the Chinese Longitudinal Healthy Longevity Survey (CLHLS) from 2008 to 2018, and 2,788 respondents were included in this prospective analysis. Using a group{square}based trajectory modeling approach, we identified resilience trajectory groups within a 6-year period. Cox proportional hazards models were used to assess the relationship between the resilience trajectory groups and cognitive impairment.  ResultsThree distinct trajectories of psychological resilience, including decreasing resilience group (n=131,7.1%), persistent middle resilience group (n=1,808, 58.1%), and persistent high resilience group (n=849, 34.8%). During the 6-year follow-up, compared to those with persistent high resilience, participants with persistent middle resilience (HR=1.43, 95% CI=1.14-1.79) and decreasing resilience (HR=2.46, 95% CI=1.76-3.43) remained consistent associated with a higher risk of cognitive impairment. The associations between resilience trajectories and cognitive impairment varied by lifestyle and health conditions.  ConclusionsPsychological resilience is a relatively stable trait among older adults in China, with most individuals maintaining a persistently high or middle level of resilience throughout the follow-up period; however, declining psychological resilience was significantly associated with the risk of cognitive impairment. Therefore, developing targeted interventions to strengthen psychological resilience in older adults is crucial for promoting cognitive health and successful aging, especially for those who have unhealthy lifestyles and with poorer health conditions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal trajectories of psychological resilience and cognitive impairment among older adults: evidence from a national cohort study\nAbstract: BackgroundThe relationship between resilience trajectories and cognitive health is not well understood. This study aimed to identify subgroups of psychological resilience trajectories in a national sample of older adults and to examine the association with cognitive impairment over time.  MethodsThis study used data from the Chinese Longitudinal Healthy Longevity Survey (CLHLS) from 2008 to 2018, and 2,788 respondents were included in this prospective analysis. Using a group{square}based trajectory modeling approach, we identified resilience trajectory groups within a 6-year period. Cox proportional hazards models were used to assess the relationship between the resilience trajectory groups and cognitive impairment.  ResultsThree distinct trajectories of psychological resilience, including decreasing resilience group (n=131,7.1%), persistent middle resilience group (n=1,808, 58.1%), and persistent high resilience group (n=849, 34.8%). During the 6-year follow-up, compared to those with persistent high resilience, participants with persistent middle resilience (HR=1.43, 95% CI=1.14-1.79) and decreasing resilience (HR=2.46, 95% CI=1.76-3.43) remained consistent associated with a higher risk of cognitive impairment. The associations between resilience trajectories and cognitive impairment varied by lifestyle and health conditions.  ConclusionsPsychological resilience is a relatively stable trait among older adults in China, with most individuals maintaining a persistently high or middle level of resilience throughout the follow-up period; however, declining psychological resilience was significantly associated with the risk of cognitive impairment. Therefore, developing targeted interventions to strengthen psychological resilience in older adults is crucial for promoting cognitive health and successful aging, especially for those who have unhealthy lifestyles and with poorer health conditions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interplay Between the Gut Microbiome and Typhoid Fever: Insights from Endemic Countries and a Controlled Human Infection Model\nAbstract: Typhoid fever is a systemic infection caused by Salmonella enterica serovar Typhi (S. Typhi) bacteria invading through the gut lumen. Transmission occurs through ingestion of contaminated food and water, particularly in settings with poor water, sanitation and hygiene infrastructure, resulting in over 10 million illnesses annually. It is well established that vaccines and natural infections can stimulate protective immunity against S. Typhi. As the pathogen invades through the gastrointestinal tract, it is plausible that the gut microbiome may also influence the outcome of S. Typhi exposure. There is some evidence that bacteria producing short-chain fatty acids (SCFAs) may create an environment unfavourable to invasive Salmonella, but data from humans is very limited.  To investigate the association between gut microbiome and typhoid fever, we analysed samples collected from three all-age cohorts recruited in a prospective surveillance study conducted in parallel in three settings where typhoid fever is endemic (Dhaka, Bangladesh; Blantyre, Malawi; and Kathmandu, Nepal). Cohorts consisted of acute typhoid fever patients (n=92), asymptomatic household contacts of typhoid fever patients (representing individuals who were likely exposed to S. Typhi but did not develop disease, n=97), and asymptomatic serosurvey participants with high Vi antibody titres (representing individuals who were exposed to S. Typhi and may be carriers, n=69). The stool microbiomes of each cohort were characterised using shotgun metagenomics, and bacterial composition and diversity were compared.  We identified four bacterial species and 28 metabolic gene clusters (MGCs) that were significantly lower in abundance in typhoid fever patients compared with household contacts (i.e. probably exposed), in two of the three host populations (Bangladesh and Malawi). These may represent taxa that provide protection against development of clinical infection upon exposure to S. Typhi, and include the inflammation-associated species Prevotella copri clade A and Haemophilus parainfluenzae, and seven MGCs involved in SCFA metabolism. The putative protection provided by SCFA metabolism was supported by data from a controlled human infection model conducted in a UK population, in which participants who did not develop typhoid fever following ingestion of S. Typhi had significantly higher abundance of a putative SCFA-metabolising MGC (q-value = 0.22).  This study identified the same associations between taxonomic and functional microbiota characteristics and non-susceptibility to typhoid fever across multiple cohorts. Future research should explore the potential functional role of SCFAs and inflammation-associated bacteria in resistance to S. Typhi and other enteric infections.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Tuberculosis-Associated Respiratory Disability in Children, Adolescents, and Adults: Protocol for a Systematic Review and Individual Participant Data Meta-Analysis\nAbstract: BackgroundApproximately 2% of the global population has survived tuberculosis (TB). Increasing evidence indicates that a significant proportion of pulmonary TB survivors develop TB-associated respiratory disability, commonly referred to as post-TB lung disease (PLTD) and marked by impaired respiratory function, persistent symptoms, and activity limitations. However, the prevalence, risk factors, and progression of TB-associated respiratory disability throughout the life course are not well understood. To address these gaps, we will undertake a systematic review and individual participant-level data meta-analysis (IPD-MA) focusing on TB-associated respiratory disability in children, adolescents, and adults successfully treated for pulmonary TB.  Methods and analysisWe will systematically search MEDLINE, Embase, CENTRAL, Global Index Medicus, and medRxiv for original studies investigating TB-associated respiratory disability in people of all ages who have completed treatment for microbiologically confirmed or clinically diagnosed pulmonary TB. Authors of eligible studies will be invited to contribute de-identified data and form a collaborative group. Primary outcomes will be (1) abnormal lung function based on spirometry parameters and (2) chronic respiratory symptoms. We will estimate the overall and subgroup-specific prevalence of each outcome through IPD meta-analysis. Next, we will develop clinical prediction tools assessing the risk of future TB-associated respiratory disability at (i) the start of TB treatment and (ii) end of TB treatment for those without existing signs of disability. Finally, we will use stepwise hierarchical modelling to identify epidemiological determinants of respiratory disability.  Ethics and disseminationThis study has been approved by the ethics review boards at the Rhode Island Hospital (2138217-2) and the Research Institute of the McGill University Health Centre (2024-10345). Individual study authors will be required to obtain institutional approval prior to sharing data. Results will be disseminated through open-access, peer-reviewed publications and conference presentations.  Prospero registration numberCRD42024529906  Strengths and limitations of this studyO_LIAn individual participant data meta-analysis allows for data harmonization to help overcome limitations of individual studies and aggregate meta-analysis, including small sample size, heterogeneity, and limited reporting of subgroups, such as age and other risk factors. C_LIO_LIWe will be able to identify weaknesses in current reporting and recommend standards to support high-quality data collection and facilitate pooling of data. C_LIO_LIKey limitations include authors willingness to share data, representativeness of data contributed, and missing data. C_LIO_LIWe will build an ongoing data collection platform to allow updating of evidence. C_LIO_LIResults will have implications for public health, clinical trial design, and clinical practice to support TB survivors. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Advancing Early Warning Systems for Malaria: Progress, Challenges, and Future Directions - A Scoping Review\nAbstract: BackgroundMalaria Early Warning Systems(EWS) are predictive tools that often use climatic and environmental variables to forecast malaria risk and trigger timely interventions. Despite their potential benefits, the development and implementation of malaria EWS face significant challenges and limitations. We reviewed the current evidence on malaria EWS, including their settings, methods, performance, actions, and evaluation.  MethodsWe conducted a comprehensive literature search using keywords related to EWS and malaria in various databases and registers. We included primary research and programmatic reports focused on developing and implementing Malaria EWS. We extracted and synthesized data on the characteristics, outcomes, and experiences of Malaria EWS.  ResultsAfter reviewing 5,535 records, we identified 30 studies from 16 countries that met our inclusion criteria. The studies varied in their transmission settings, from pre-elimination to high burden, and their purposes, ranging from outbreak detection to resource allocation. The studies employed various statistical and machine-learning models to forecast malaria cases, often incorporating environmental covariates such as rainfall and temperature. The most common mode used is the time series model. The performance of the models was assessed using measures such as the Akaike Information Criterion( AIC), Root Mean Square Error (RMSE), and adjusted R squared(R 2). The studies reported actions and responses triggered by EWS predictions, such as vector control, case management, and health education. The lack of standardized criteria and methodologies limited the evaluation of EWS impact.  ConclusionsThis review provides a comprehensive overview of the current status of Malaria EWS, highlighting the progress, challenges, and gaps in the field. The review informs and guides policymakers, researchers, and practitioners in enhancing EWS and malaria control strategies. The review also underscores the need for further research on the integration, sustainability, and evaluation of Malaria EWS usage and harmonized methods to ease review.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: FACILITATORS AND BARRIERS TO UPTAKE OF CHILD-FRIENDLY 3 MONTHS OF ISONIAZID AND RIFAMPICIN (3HR) FIXED DRUG COMBINATION (FDC) FOR TUBERCULOSIS PREVENTIVE THERAPY (TPT) IN NIGERIA\nAbstract: The uptake of TB preventive therapy (TPT) for child and adult contacts of index TB patients in Nigeria has been suboptimal. Nigeria introduced the 3-month isoniazid-rifampicin (3HR) shorter regimen TPT for all eligible contacts through the USAID-funded Stop TB Partnership introducing New Tools Project (iNTP). This study assesses the facilitators and barriers to the uptake of the newly introduced child-friendly 3HR TPT for child contacts of TB patients in Nigeria.  This was a cross-sectional descriptive study using mixed methods. In-depth interviews were conducted among 36 purposely selected Healthcare Workers (HCWs) and 36 caregivers of child contacts. Records of TPT-eligible child contacts (0-14 years) from April to September 2022 were retrospectively extracted. Study data were analyzed using appropriate statistical tools for qualitative and quantitative techniques.  There were 7,906 child contacts identified, of which 7,902 (99.9%) contacts were screened for TB, 1,704 (21.5%) were presumptive, 264 (15.5%) diagnosed with TB, and 6,994 were eligible for TB Preventive Therapy. Additionally, out of 6,994 eligible child contacts, 3984 (57%) were initiated on TPT with 2,982 (74,8%) enrolled on 3HR and 1,002 (25%) on 6H. Of the clients placed on 3HR, 2,499 (85%) completed treatment, 309 (10.5%) lost to follow-up, 27(0.92%) developed Tuberculosis while 48 (1.6%) interrupted treatment.  The key drivers of 3HR TPT uptake among child contacts were TPT-related health education and counseling. Access barriers to 3HR TPT elicited included stigma, poverty, transportation cost, stock out, ineffective monitoring and management of side effects issues of 3HR TPT, subpar Government funding and commitment to addressing TPT implementation challenges and inadequate knowledge among HCWs and caregivers.  In conclusion, 3HR-TPT uptake among child contacts of index TB patients was high. Enhanced provider training and intensive community health education should be sustained while identified individual, structural, and institutional barriers should be addressed to improve implementation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association Between Seasonal Respiratory Virus Activity and Invasive Pneumococcal Disease in Central Ontario, Canada\nAbstract: BackgroundIn central Ontario, influenza, respiratory syncytial virus (RSV), and invasive pneumococcal disease (IPD) follow similar seasonal patterns, peaking in winter. We aimed to quantify the independent and joint impact of influenza A, influenza B, and RSV on IPD risk at the population level.  MethodsWe used a 2:1 self-matched case-crossover study design to evaluate acute effects of respiratory virus activity on IPD risk. This design ensures that effects are not confounded by within-individual characteristics that remain constant over short periods of time. We included 3,892 IPD cases occurring between January 2000 and June 2009. Effects were measured using univariable and multivariable conditional logistic regression. Multivariable models included environmental covariates (e.g., temperature, absolute humidity, and UV index) and interaction terms between viruses.  ResultsInfluenza A activity and influenza B activity were both independently associated with increased IPD risk; however, co-circulation of influenza A and B reduced the impact of both viruses. RSV activity was positively associated with increased IPD risk only in the presence of increased influenza A or influenza B activity.  ConclusionsTo our knowledge this represents the first study to consider the impact of interactions between these viruses on IPD risk in Canada. Our findings suggest that the prevention of IPD should be considered as a potential health benefit of influenza and RSV vaccination programs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Sex differences in the trajectories of plasma biomarkers, brain atrophy, and cognitive decline relative to amyloid onset\nAbstract: INTRODUCTIONThe factors that influence the progression of Alzheimers disease (AD) after individuals become amyloid-positive are poorly understood. This study examines how sex influences the longitudinal trajectories of plasma AD and neurodegenerative biomarkers in the years following a persons estimated onset of amyloid-{beta}.  METHODSLinear mixed effects modeling investigated overall and sex-specific longitudinal trajectories of plasma biomarkers, brain volumes, and cognition relative to estimated age of amyloid onset in a cohort of 78 amyloid-positive Baltimore Longitudinal Study of Aging participants (n=45 male; follow-up time: 6.8 years [SD 3.31]). Amyloid status was ascertained with 11C-Pittsburgh compound B (PiB) PET imaging.  RESULTSAfter amyloid onset, men displayed steeper increases in pTau181, pTau231, and NfL compared to women. In this same period, men demonstrated steeper declines in brain volume and cognitive performance.  DISCUSSIONThese findings suggest that sex influences the trajectory of AD pathology, neuronal injury, and symptom progression after individuals become amyloid-positive.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Life Expectancy Exploration of Heart Failure Patients Presenting with Diabetes\nAbstract: BackgroundDiabetes is a serious medical condition marked by high blood sugar levels, leading to complications in organs like the kidney, liver, and heart. Previous research has identified diabetes as a primary risk factor for congestive heart failure (CHF), a condition where stiffened heart muscles hinder oxygenated blood circulation. Despite its severity, few studies have examined CHF prognosis in diabetic patients. This study aims to provide survival estimates and provide their comparisons among predictors, assess mortality risks based on specific variables, and reveal patient outcome patterns.  MethodsWe analyzed data from a 2015 study at Faisalabad Institute of Cardiology and Allied Hospital (FICAH), Pakistan, focusing on 125 diabetic patients with Class III or IV heart failure and left ventricular systolic dysfunction. Kaplan-Meier estimates provided survival rates, log-rank tests compared survival across variables, Cox regression models estimated hazard ratios, and cluster analysis grouped patients by characteristics and survival rates.  ResultsThe study examined 125 diabetic heart failure patients. Of these, 40(32%) were censored and the remaining 85(68%) died. The total follow-up period was 278 days, on the 120th day, 0.752[95% CI = 0.678,0,883] of the patients survived after initial diagnosis. Log-rank tests showed survival differences linked to high blood pressure, anemia and smoking. Cox regression identified age, smoking and hypertension as major mortality risk factors. Cluster analysis revealed the risk factors associated with middle aged and the older patients.  ConclusionThe overall prognosis of heart failure patients with diabetes was poor with high mortality rates, implying effective treatment and management.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Azithromycin Treatment Response as a Probe to Attribute Bacterial Aetiologies of Diarrhoea using Molecular Diagnostics: A Reanalysis of the AntiBiotics for Children with severe Diarrhoea (ABCD) Trial\nAbstract: BackgroundMulti-pathogen molecular diagnostics enable assignment of diarrhoea aetiology, but defining thresholds of pathogen quantity to accurately attribute aetiology is challenging in high-burden settings where coinfections are common. The Antibiotics for Children with severe Diarrhoea (ABCD) trial provides an opportunity to leverage the azithromycin treatment response to inform which diarrhoea episodes are bacterial.  MethodsWe analysed data from ABCD, which randomized children with watery diarrhoea to azithromycin or placebo. We quantified heterogeneity in the azithromycin treatment response by the quantity of enteric pathogens detected by qPCR as a tool for understanding aetiology.  ResultsThe heterogeneity in azithromycin treatment response was most prominent for Shigella. The risk ratio for diarrhoea on day 3 post enrolment for azithromycin compared to placebo was 13% (95% CI:3, 23) lower per log10 increase in Shigella quantity. The protective effect of azithromycin on diarrhoea at day 3 also became stronger as pathogen quantities increased for Vibrio cholerae, ST-ETEC, and tEPEC. No association between pathogen quantity and azithromycin response was observed for Campylobacter, LT-ETEC or EAEC. The associations were consistent for the outcome of 90-day hospitalisation or death.  ConclusionsThe relationships between response to azithromycin treatment and bacterial pathogen quantities observed for Shigella, Vibrio cholerae, ST-ETEC and tEPEC confirm prior evidence that these pathogens are the likely cause of diarrhoea when detected at high quantities. The lack of a similar response pattern for Campylobacter, LT-ETEC or EAEC is consistent with the limited association between pathogen quantity and diarrhoea symptoms previously observed in large studies of diarrhoea aetiology.  Key message (3 succinct bullet points, each a single sentence)O_LIWe investigated whether heterogeneity in treatment response observed in the ABCD trial, where children with diarrhoea were randomised to receive azithromycin or placebo, could be used to inform aetiological attribution of diarrhoea to bacterial enteric pathogens. C_LIO_LIThe protective effect of azithromycin on diarrhoea at day 3 and hospitalisation or death at day 90 became stronger as pathogen quantities increased for Shigella, Vibrio cholerae, ST-ETEC and tEPEC but not for Campylobacter, LT-ETEC or EAEC. C_LIO_LIThe relationships between Shigella, Vibrio cholerae, ST-ETEC and tEPEC quantity and response to antibiotic treatment confirm prior evidence that these pathogens are the likely cause of diarrhoea when detected at high quantities and could be used to inform which diarrhoea cases should be treated with antibiotics. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Analysis of C-reactive protein omics-measures associates methylation risk score with sleep health and related health outcomes\nAbstract: IntroductionDNA methylation (DNAm) predictors of high sensitivity C-reactive protein (CRP) offer a stable and accurate means of assessing chronic inflammation, bypassing the CRP protein fluctuations secondary to acute illness. Poor sleep health is associated with elevated inflammation (including elevated blood CRP levels) which may explain associations of sleep insufficiency with metabolic, cardiovascular and neurological diseases. Our study aims to characterize the relationships among sleep health phenotypes and CRP markers --blood, genetic, and epigenetic indicators-- within the Hispanic Community Health Study/Study of Latinos (HCHS/SOL).  MethodsIn HCHS/SOL, methylation risk scores (MRS)-CRP and polygenetic risk score (PRS)-CRP were constructed separately as weighted sums of methylation beta values or allele counts, respectively, for each individual. Sleep health phenotypes were measured using self-reported questionnaires and objective measurements. Survey-weighted linear regression established the association between the multiple sleep phenotypes (obstructive sleep apnea (OSA), sleep duration, insomnia and excessive sleepiness symptom), cognitive assessments, diabetes and hypertension with CRP markers while adjusting for age, sex, BMI, study center, and the first five principal components of genetic ancestry in HCHS/SOL.  ResultsWe included 2221 HCHS/SOL participants (age range 37-76 yrs, 65.7% female) in the analysis. Both the MRS-CRP (95% confidence interval (CI): 0.32-0.42, p = 3.3 x 10-38) and the PRS-CRP (95% CI: 0.15-0.25, p = 1 x 10-14) were associated with blood CRP level. Moreover, MRS-CRP was associated with sleep health phenotypes (OSA, long sleep duration) and related conditions (diabetes and hypertension), while PRS-CRP markers were not associated with these traits. Circulating CRP level was associated with sleep duration and diabetes. Associations between OSA traits and metabolic comorbidities weakened after adjusting for MRS-CRP, most strongly for diabetes, and least for hypertension.  ConclusionsMRS-CRP is a promising estimate for systemic and chronic inflammation as reflected by circulating CRP levels, which either mediates or serves as a common cause of the association between sleep phenotypes and related comorbidities, especially in the presence of diabetes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adverse events affecting recovery from seasonal influenza vaccination in the hypertensive population: A population-based pharmacovigilance analysis\nAbstract: Seasonal influenza vaccination is crucial for preventing influenza and its complications. Data from the U.S. Vaccine Adverse Event Reporting System (VAERS) indicate a higher proportion of adverse events (AEs) after influenza vaccination in hypertensive people. However, there is limited evidence on AEs in hypertensive people following seasonal influenza vaccination. We collected a total of 4647 individuals on seasonal influenza vaccination and 6380 AEs from VAERS for hypertensive people aged 18 years or older from 1 January 2013 to 23 June 2023. We conducted propensity score matching (PSM) by adjusting for the demographic characteristics of the seasonal influenza-vaccinated hypertensive population and the season of onset. Cox regression analysis was used to calculate the risk ratio of reported adverse events (AEs) that affected recovery after seasonal influenza vaccination. Most AEs were nonserious and occurred within 48 hours. The most common AEs were general disorders and administration site conditions (therapeutic and non-therapeutic responses, inflammation) and musculoskeletal and connective tissue disorders (musculoskeletal and connective tissue pain and discomfort, bursal disorders, joint-related signs, and symptoms). All three types of seasonal influenza vaccines were associated with injection site reactions (47.07% trivalent influenza vaccine [TIA], hazard ratio, HR 2.04, 95% confidence interval, CI 1.22-3.40; 20.00% quadrivalent influenza vaccine [QIA], HR 2.81, 95% CI, 1.81-4.37; 67.48% influenza vaccine, unknown manufacturer [FLUX], HR 2.83, 95% CI, 1.12-7.15) and were the AEs affecting the largest proportion of delayed recoveries in the hypertensive population. Potential AEs following seasonal influenza vaccination may affect the recovery of the hypertensive population. The majority of AEs reported were general disorders, predominantly injection site reactions, and nonserious.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Short-term and Long-Term Healthcare Costs Attributable to diagnosed COVID-19 in Ontario; Canada: A Population-Based Matched Cohort Study\nAbstract: ObjectivesEstimates of health system costs due to COVID-19, especially for long-term disability (post COVID-19 condition [PCC]) are key to health system planning, but attributable cost data remain scarce. We characterized COVID-19-attributable costs from the health system perspective.  MethodsPopulation-based matched cohort study in Ontario, Canada, using health administrative data. To assign attribution to COVID-19, individuals, defined as exposed (positive SARS-CoV-2 PCR test, 01/2020-12/2020) were matched 1:1 to an unexposed individuals (01/2016-12/2018). Historical matching was used to reduce biases due to overall reductions in healthcare during the pandemic and contamination bias. The index date was defined as the first occurrence of positive SARS-CoV-2 PCR test. We used phase-of-care costing to calculate mean attributable per-person costs (2023 CAD), standardized to 10 days, during four phases of illness: pre-index date, acute care, post-acute care (suggestive of PCC), and terminal phase (stratified by early and late deaths). Finally, we estimated total costs at 360 days by combining costs with survival estimates.  ResultsOf 165,838 exposed individuals, 159,817 were matched (mean age 40{+/-}20 years, 51% female). Mean (95%CI) attributable 10-day costs per person were $1 ($-4, $6) pre-index, $240 ($231, $249) during acute care, and $18 ($14, $21) during post-acute phases. During the terminal phase, mean attributable costs were $3,928 ($3,471, $4,384) for early deaths and $1,781 ($1,182, $2,380) for late deaths. Hospitalizations accounted for 42% to 100% of total costs. Compared to males, costs among females were lower during the acute care phase, but higher during the post-acute care phase. Mean cumulative per-person cost at 360 days was $2,553 ($2,348, $2,756); females had lower costs ($2,194 [$1,945, $2,446]) than males ($2,921 [$2,602, $3,241]).  ConclusionsSARS-CoV-2 infection is associated with substantial long-term healthcare costs, consistent with our understanding of the PCC. Understanding phase-specific costs can inform health sector budget planning, future economic evaluations, and pandemic planning.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of adverse pregnancy outcomes and impact of statin use in pregnant women with familial hypercholesterolemia\nAbstract: Background and aimsSparse data exist on the possible risk of adverse pregnancy outcomes in women with familial hypercholesterolemia (FH). We investigated associations between having a FH diagnosis and adverse pregnancy outcomes, and between statin exposure in pregnancy and adverse pregnancy outcomes among women with FH.  MethodsThis registry-based study included 3869 pregnancies among 1869 women with FH and 68225 pregnancies among 33661 women from the general population. Data on adverse pregnancy outcomes were obtained from the Medical Birth Registry of Norway with data from 1967-2018. Data on pharmacy-dispensed statins were obtained from the Norwegian prescription database (2004-2018) in 1051 women with FH. Associations were presented as odds ratio (OR) with 95% CI from logistic regression adjusted for mothers age, parity, and offsprings birth year.  ResultsWomen with FH had a higher risk of preeclampsia (OR 1.21 [1.00-1.46]), but lower risk for gestational diabetes (OR 0.58 [0.36-0.92]) and intrapartum hemorrhage during delivery (OR 0.81 [0.71-0.92]) compared to controls. No excess risk of adverse pregnancy outcome in offspring was observed for FH vs controls. Women with FH using statins in pregnancy (n=260) had a higher risk of having offspring with low (<2500 g) birth weight (OR 2.20 [1.11, 4.49]) compared to non-exposed women with FH (n=791).  ConclusionsWomen with FH had lower risk of gestational diabetes and intrapartum hemorrhage during delivery and non-significantly higher risk of preeclampsia compared to controls. No difference in adverse pregnancy outcomes in the offspring was observed. Statin exposure in pregnancy was associated with a higher risk of having offspring with low birth weight among women with FH, and this association warrants further investigations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulation of Clade Ia and Ib monkeypox virus in Kinshasa Province, Democratic Republic of the Congo, July - August 2024\nAbstract: Mpox cases have been reported in nearly all provinces of the Democratic Republic of the Congo as of August 2024. Monkeypox virus positive samples from Kinshasa, collected between July and mid-August 2024, were sequenced using a probe-based enrichment or optimized tiling sequencing protocol. With multiple introductions of both Clade Ia (7/12) and Ib (5/12), marking Kinshasa, and its Limete health zone specifically, as an area with co-circulation of both Clade I, a unique observation illustrating the growing complexity of Clade I mpox outbreaks in DRC.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulation of two lineages of Oropouche virus in the Amazon basin, Colombia, 2024\nAbstract: In early 2024, explosive outbreaks of Oropouche virus (OROV) linked to a novel viral lineage were documented in the Brazilian Amazon. Here, we report the introduction of this emerging orthobunyavirus into Colombia and its co-circulation with another OROV lineage. This investigation highlights the complex arbovirus dynamics in South America.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulation of two lineages of Oropouche virus in the Amazon basin, Colombia, 2024\nAbstract: In early 2024, explosive outbreaks of Oropouche virus (OROV) linked to a novel viral lineage were documented in the Brazilian Amazon. Here, we report the introduction of this emerging orthobunyavirus into Colombia and its co-circulation with another OROV lineage. This investigation highlights the complex arbovirus dynamics in South America.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Fetal hemoglobin enables malaria parasite growth in sickle cells but augments production of transmission stage parasites.\nAbstract: Sickle cell trait is the quintessential example of the human response to malaria, providing protection against severe disease, but leading to sickle cell disease (SCD) in the homozygous state. Fetal Hemoglobin (HbF) reduces the pathology of SCD and several mutations lead to the prolonged production of HbF into childhood and adult life. HbF has been suggested to contribute to protection against malaria. Two long-term cohorts were genotyped for three quantitative trait loci associated with HbF production and analyzed for HbF titers, malaria clinical episodes and the production of parasite stages infectious to mosquitoes, gametocytes in asymptomatic infections. Plasmodium falciparum parasites were also grown in vitro in HbSS cells with measured levels of HbF. The genetic determinants of prolonged HbF production were associated with increased HbF titers and that increased HbF afforded protection from malaria disease but increased the production of gametocytes. The presence of HbF in sickled red cells was also shown in in vitro culture to enable parasite persistence in conditions otherwise deleterious for the parasite and enabled complete maturation of gametocytes. The beneficial personal effect of HbF, whether through protection against malaria or alleviating effects of SCD, is offset by increased parasite transmissibility and disease burden for the community. These individuals represent an important reservoir of infection and need to be targeted in elimination strategies.  Key pointsO_LIIndividuals with mutations associated with fetal hemoglobin production had fewer clinical episodes but produced more gametocytes. C_LIO_LIHbF in red blood cells enables gametocyte production at tissue level oxygen partial pressures at which normally parasite lysis would occur. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Humoral Immunity after mRNA Omicron JN.1 Vaccination\nAbstract: In late June 2024, the European Medicines Agency (EMA) recommended market authorization for a monovalent COVID-19 mRNA-vaccine based on JN.1 spike. We assessed immune responses in n=42 health-care workers (median age 47 years, interquartile range, IQR 19{middle dot}5 years, 48% male), who in August 2024 were vaccinated with 30 g of the updated mRNA omicron JN.1 vaccine (bretovameran, BioNTech/Pfizer, Mainz, Germany). Humoral immune responses were analyzed directly prior to and 13 days after vaccination.  The omicron JN.1 vaccination resulted in a significant 1{middle dot}2-fold increase of anti-S IgG and 1{middle dot}2-fold increase of omicron anti-S IgG (p<0{middle dot}0001). To assess plasma neutralisation capacity, we employed a pseudovirus particle (pp) neutralisation assay including S proteins of seven SARS-CoV-2 lineages. Baseline response rates were 100% for XBB.1.5pp, 90% for JN.1pp and KP.2pp, 82% for KP.2.3pp, 92% for KP.3pp, and 72% for LB.1pp. Before JN.1 vaccination, particles bearing KP sublineage S proteins were slightly less efficiently neutralised compared with JN.1pp (median change, 1{middle dot}2-fold to 2{middle dot}6-fold), while LB.1pp neutralisation was 3-fold reduced, indicating antibody evasion. After vaccination, the response rates increased significantly for all pseudoviruses except XBB.1.5pp and KP.3pp. Thus, we observed a significant increase in neutralisation of JN.1pp, KP.2pp, KP.2.3pp, and LB.1pp, showing a median change of 2.2-fold, 3.8-fold, 3.3-fold, and 4.9-fold, respectively.  In summary, bretovameran increased anti-S IgG and strengthened neutralising responses against circulating SARS-CoV-2-variants, except for KP.3. We wish to point out that our study population exhibited high pre-vaccination omicron-related hybrid immunity and may not be representative of other populations. Our data supports the notion that the new mRNA vaccine against omicron JN.1 most likely increases protection against hospitalization and post-COVID sequelae caused by most current variants.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Steroidal Therapy plus Conventional Therapy versus Conventional Therapy alone for Tuberculous Meningitis: A systematic review and Meta-analysis\nAbstract: BackgroundTuberculosis meningitis (TBM) is the most severe form of extrapulmonary tuberculosis with a high rate of morbidity and mortality. Treatments for TBM include conventional therapy alone as well as adjunctive use of steroidal therapy.  MethodsA comprehensive search of electronic databases such as PubMed, Cochrane, and Scopus was conducted from inception to April 2024 to retrieve all randomized controlled trials (RCTs) that compared steroidal therapy plus conventional antituberculosis therapy with antituberculosis therapy alone for patients of TBM. Meta-analysis was performed using Review Manager 5.4. Dichotomous outcomes were compared using risk ratio (RR).  ResultsThere was a statistically significant decrease in risk of mortality in the Steroid group compared to the control group (RR 0.84; 95% CI 0.75, 0.94; p-value < 0.05). However, there was no statistically significant difference in the risk of neurological deficit between the two groups. There was a statistically significant reduction in the risk of adverse events in the steroidal therapy group compared to the control group (RR 0.90; 95% CI 0.83, 0.98; p-value = 0.03). Similarly, there was a significant improvement in the clinical efficacy in the steroidal therapy group compared to the control (RR 1.16; 95% CI 1.02, 1.31; p-value = 0.02).  ConclusionSteroids in addition to antituberculosis therapy significantly reduce mortality and adverse events, while improving clinical outcomes in patients of TBM. There is a need for controlled studies with longer follow-up durations to improve the robustness of the results.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Public Health Interventions for Fractional Optimal Control of Buruli Ulcer\nAbstract: Buruli Ulcer, a devastating skin disease caused by Mycobacterium Ulcerans, poses considerable public health challenges in endemic areas. This article focuses on the use of fractional optimal control theory to prevent the spread of Buruli ulcers via integrated public health interventions. We formulated a mathematical model using the Atangana-Baleanu-Caputo fractional order derivative operator. We investigated the models existence and uniqueness and presented numerical simulations using the predict-evaluate-correct-evaluate (PECE) method of Adam-Bashforth Moulton. We also study the fractional optimal control problem (FOCP) to minimize the spread of the disease in the endemic regions. We employ the Fractional Pontryagins Maximum Principle (FPMP) and implement the forward-backward method to determine the extremals of the problem. Four control strategies were implemented: promoting health education on the use of protective clothing, enhancing vaccination rates, improving treatment protocols for infected individuals, and spraying insecticides to reduce water-bug populations. After examining the optimal control dynamics of the Buruli ulcer transmission model via multiple simulations with and without control, we discover that there is a substantial decrease in the population of infected humans and the water-bug population. Hence we conclude that the best strategy to implement is by applying all the control strategies suggested.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bias from heritable confounding in Mendelian randomization studies\nAbstract: Mendelian randomization (MR) is an approach to causal inference that utilises genetic variants to obtain estimates of the causal effect of an exposure on an outcome in the presence of unobserved confounding. MR relies on a set of assumptions to obtain unbiased effect estimates, one of these assumptions is that there is no pathway from the genetic variants to the outcome that does not act through the exposure. Increasing genome-wide association study (GWAS) sample sizes for the exposure enables discovery of instrumental variables with smaller effect sizes. We illustrate through simulations how smaller effect sizes could arise from genetic variants that act through traits that have greater liability to confound an exposure-outcome relationship. When such genetic variants are selected as instruments this can bias the MR effect estimate obtained from that instrument in the same direction as the confounded observational association but with larger magnitude. Through simulation we illustrate how the total bias of the MR estimates increases across a range of standard MR estimation methods increases as the proportion of the genetic instruments that are associated with the confounder increases. However, if such heritable confounders are known and can be instrumented, the confounder free effect estimate can be obtained through applying a pre-estimation filtering to standard MR methods, removing instruments that explain more variation in that confounder than the exposure, or by estimating effects through multivariable MR. We highlight the potential for SNPs identified in GWAS to be associated with potential confounders through examination of a recent GWAS of C-Reactive Protein. Finally, we illustrate our approach through estimation of the causal effect of age at menarche on type 2 diabetes, hypothesising that the MR effect estimate may be biased by confounding due to the inclusion of genetic variants associated with early life adiposity as instruments.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the (log)book: Comparing accelerometer non-wear detection techniques in toddlers\nAbstract: BackgroundAccelerometers are increasingly used to measure physical activity and sedentary time in toddlers. Data cleaning or wear time validation can impact outcomes of interest, particularly in young children who spend less time awake. However, no study has systematically compared wear time validation strategies in toddlers. As such, the objective of this study is to compare different fully-automated methods of distinguishing wear and non-wear time (counts and raw data algorithms) to the semi-automated (counts with logbooks) criterion method in toddlers.  MethodsWe recruited 109 toddlers (age 12-35 mos) as part of the iPLAY study to wear an ActiGraph w-GT3X-BT accelerometer on the right hip for [~]7 consecutive days (removed for sleep and water activities). Parents completed a logbook to indicate monitor removal and nap times. We tested 15 nonwear detection methods grouped into 4 main categories: semi-automated logbook, consecutive 0 counts, modified consecutive 0 counts (Troiano and Choi), and raw data methods (van Hees and Ahmadi). Using logbooks as the criterion standard (all wear and wake-time only wear), we calculated the accuracy and F1 scores and compared overall wear time with a two one-sided test of equivalence.  ResultsParticipant daily wear time ranged from 556 to 684 minutes/day depending on method. Accuracy and F1 score ranged from 86 to 95%. Five methods were considered equivalent to the AllWear nonwear criterion (true wear time including sleep-time wear), with only one equivalent to the AwakeWear criterion. Mean absolute differences were lower for the AllWear criterion but ranged 49 to 192 minutes/day  ConclusionsThe 5min0count, 10min_0count, 30min_0count, Troiano60s, and Ahmadi methods provide high accuracy and equivalency when compared to semi-automated cleaning using logbooks. This paper provides insights and quantitative results that can help researchers decide which method may be most appropriate given their population of interest, sample size, and study protocol.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Risk of Cardiovascular Adverse Events and Appendicitis After COVID-19 Diagnosis in Adults in the United States: Implications of the Start of Follow-Up\nAbstract: PurposeThis study evaluated the association between coronavirus disease 2019 (COVID-19) diagnosis and adverse events (AEs), including cardiovascular AEs and appendicitis, in US adults before the introduction of COVID-19 vaccines. Real-world studies of AEs after COVID-19 suggest that diagnoses of AEs and COVID-19 frequently occur on the same day and may be a source of bias.  MethodsCohort and self-controlled risk interval (SCRI) designs were used in 2 US administrative claims data sources--Merative MarketScan(R) (ages 18-64 years) and Medicare (ages [&ge;] 65 years). AEs included stroke (nonhemorrhagic and hemorrhagic), acute myocardial infarction, myocarditis/pericarditis, deep vein thrombosis, pulmonary embolism (PE), disseminated intravascular coagulation (DIC), unusual-site and common-site thrombosis with thrombocytopenia syndrome, and appendicitis. In cohort analyses, weighted hazard ratios (HRs) and 95% confidence intervals (CIs) compared adults with a COVID-19 diagnosis and matched comparators. In SCRI analysis, relative incidences (RIs) and 95% CIs compared risk and reference windows within individuals. Analyses were performed starting follow-up on Time 0 and Day 1.  ResultsFor cardiovascular AEs, all estimates starting follow-up on Day 1 were above 1.0 in both data sources. For cohort analyses, the strongest associations were for inpatient PE in both databases: MarketScan, HR=8.65 (95% CI, 6.06-12.35), Medicare HR=3.06 (95% CI, 2.88-3.26). For SCRI analyses, the strongest association in MarketScan was for DIC: RI=32.28 (95% CI, 17.06-61.09) and in Medicare was for myocarditis/pericarditis: RI=4.53 (95% CI, 3.89-5.27). AEs diagnosed concurrently with COVID-19 (ie, on Time 0) were common; including Time 0 in follow-up/risk windows resulted in higher RIs, as well as higher HRs for some AEs. However, some AEs (eg, stroke) were more common on Time 0 in the comparator group resulting in lower HRs.  ConclusionCOVID-19 diagnoses had moderate to strong associations with cardiovascular AEs and weak or inconsistent associations with appendicitis, although estimates varied by design and methodology.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Methodological Challenges using Routine Clinical Care Data for Real-World Evidence: a Rapid Review utilizing a systematic literature search and focus group discussion\nAbstract: BackgroundThe integration of real-world evidence (RWE) from real-world data (RWD) in clinical research is crucial for bridging the gap between clinical trial results and real-world outcomes. Analyzing routinely collected data to generate clinical evidence faces methodological concerns like confounding and bias, similar to prospectively documented observational studies. This study focuses on additional limitations frequently reported in the literature, providing an overview of the challenges and biases inherent to analyzing routine clinical care data, including health claims data (hereafter: routine data).  MethodsWe conducted a literature search on routine data studies in four high-impact journals based on the Journal Citation Reports (JCR) category \"Medicine, General & Internal\" as of 2022 and three oncology journals, covering articles published from January 2018 to October 2023. Articles were screened and categorized into three scenarios based on their potential to provide meaningful RWE: (1) Burden of Disease, (2) Safety and Risk Group Analysis, and (3) Treatment Comparison. Limitations of this type of data cited in the discussion sections were extracted and classified according to different bias types: main bias categories in non-randomized studies (information bias, reporting bias, selection bias, confounding) and additional routine data-specific challenges (i.e., operationalization, coding, follow-up, missing data, validation, and data quality). These classifications were then ranked by relevance in a focus group meeting of methodological experts. The search was pre-specified and registered in PROSPERO (CRD42023477616).  ResultsIn October 2023, 227 articles were identified, 69 were assessed for eligibility, and 39 were included in the review: 11 on the burden of disease, 17 on safety and risk group analysis, and 11 on treatment comparison. Besides typical biases in observational studies, we identified additional challenges specific to RWE frequently mentioned in the discussion sections. The focus group had varied opinions on the limitations of Safety and Risk Group Analysis and Treatment Comparison but agreed on the essential limitations for the Burden of Disease category.  ConclusionThis review provides a comprehensive overview of potential limitations and biases in analyzing routine data reported in recent high-impact journals. We highlighted key challenges that significantly impact analysis results, emphasizing the need for thorough consideration and discussion for meaningful inferences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Methodological Challenges using Routine Clinical Care Data for Real-World Evidence: a Rapid Review utilizing a systematic literature search and focus group discussion\nAbstract: BackgroundThe integration of real-world evidence (RWE) from real-world data (RWD) in clinical research is crucial for bridging the gap between clinical trial results and real-world outcomes. Analyzing routinely collected data to generate clinical evidence faces methodological concerns like confounding and bias, similar to prospectively documented observational studies. This study focuses on additional limitations frequently reported in the literature, providing an overview of the challenges and biases inherent to analyzing routine clinical care data, including health claims data (hereafter: routine data).  MethodsWe conducted a literature search on routine data studies in four high-impact journals based on the Journal Citation Reports (JCR) category \"Medicine, General & Internal\" as of 2022 and three oncology journals, covering articles published from January 2018 to October 2023. Articles were screened and categorized into three scenarios based on their potential to provide meaningful RWE: (1) Burden of Disease, (2) Safety and Risk Group Analysis, and (3) Treatment Comparison. Limitations of this type of data cited in the discussion sections were extracted and classified according to different bias types: main bias categories in non-randomized studies (information bias, reporting bias, selection bias, confounding) and additional routine data-specific challenges (i.e., operationalization, coding, follow-up, missing data, validation, and data quality). These classifications were then ranked by relevance in a focus group meeting of methodological experts. The search was pre-specified and registered in PROSPERO (CRD42023477616).  ResultsIn October 2023, 227 articles were identified, 69 were assessed for eligibility, and 39 were included in the review: 11 on the burden of disease, 17 on safety and risk group analysis, and 11 on treatment comparison. Besides typical biases in observational studies, we identified additional challenges specific to RWE frequently mentioned in the discussion sections. The focus group had varied opinions on the limitations of Safety and Risk Group Analysis and Treatment Comparison but agreed on the essential limitations for the Burden of Disease category.  ConclusionThis review provides a comprehensive overview of potential limitations and biases in analyzing routine data reported in recent high-impact journals. We highlighted key challenges that significantly impact analysis results, emphasizing the need for thorough consideration and discussion for meaningful inferences.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Higher dose corticosteroids in hospitalised COVID-19 patients requiring ventilatory support (RECOVERY): a randomised, controlled, open-label, platform trial\nAbstract: BackgroundLow-dose corticosteroids (e.g. 6 mg dexamethasone) have been shown to reduce mortality for hypoxic COVID-19 patients. We have previously reported that higher dose corticosteroids cause harm in patients with hypoxia but not receiving ventilatory support (non-invasive mechanical ventilation, invasive mechanical ventilation or extra-corporeal membrane oxygenation), but the balance of efficacy and safety in patients receiving ventilatory support is uncertain.  MethodsThis randomised, controlled, open-label platform trial (Randomised Evaluation of COVID-19 Therapy [RECOVERY]) assessed multiple possible treatments in patients hospitalised for COVID-19. Eligible and consenting adult patients receiving ventilatory support were randomly allocated (1:1) to either usual care with higher dose corticosteroids (dexamethasone 20 mg once daily for 5 days followed by 10 mg once daily for 5 days or until discharge if sooner) or usual standard of care alone (which includes dexamethasone 6 mg once daily for 10 days or until discharge if sooner). The primary outcome was 28-day mortality; secondary outcomes were duration of hospitalisation and (among participants not on invasive mechanical ventilation at baseline) the composite of invasive mechanical ventilation or death. Recruitment closed on 31 March 2024 when funding for the trial ended. The RECOVERY trial is registered with ISRCTN (50189673) and clinicaltrials.gov (NCT04381936).  FindingsBetween 25 May 2021 and 9 January 2024, 477 COVID-19 patients receiving ventilatory support were randomly allocated to receive usual care plus higher dose corticosteroids versus usual care alone (of whom 99% received corticosteroids during the follow-up period). Of those randomised, 221 (46%) were in Asia, 245 (51%) in the UK and 11 (2%) in Africa. 143 (30%) had diabetes mellitus. Overall, 86 (35%) of 246 patients allocated to higher dose corticosteroids versus 86 (37%) of 231 patients allocated to usual care died within 28 days (rate ratio [RR] 0.87; 95% CI 0.64-1.18; p=0.37). There was no significant difference in the proportion of patients discharged from hospital alive within 28 days (128 [52%] in the higher dose corticosteroids group vs 120 [52%] in the usual care group; RR 1.04, 0.81-1.33]; p=0.78). Among those not on invasive mechanical ventilation at baseline, there was no significant difference in the proportion meeting the composite endpoint of invasive mechanical ventilation or death (76 [37%] of 206 vs 93 [45%] of 205; RR 0.79 [95% CI 0.63-1.00]; p=0.05).  InterpretationIn patients hospitalised for COVID-19 receiving ventilatory support, we found no evidence that higher dose corticosteroids reduced the risk of death compared to usual care, which included low dose corticosteroids.  FundingUK Research and Innovation (Medical Research Council) and National Institute of Health Research (Grant ref: MC_PC_19056), and Wellcome Trust (Grant Ref: 222406/Z/20/Z).\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A multicenter study to assess the performance of the point-of-care RT-PCR Cobas SARS-CoV-2 & Influenza A/B nucleic acid test for use on the Cobas Liat system in comparison with centralized assays across healthcare facilities in the United States\nAbstract: Non-structured abstractRespiratory diseases can share many of the same symptoms, highlighting the need for timely and accurate differentiation to facilitate effective clinical management and reduce transmission. Compared with centralized testing, molecular point-of-care tests (POCT) can provide a faster time to result.  We evaluated the RT-PCR POCT Cobas(R) SARS-CoV-2 & Influenza A/B qualitative assay for use on the Cobas Liat(R) system (the POC SARS-CoV-2 & Influenza A/B test) in nasal and nasopharyngeal swab samples from 10 diverse healthcare facilities in the US. A composite comparator design consisting of three centralized tests was used to analyze SARS-CoV-2, whilst performance versus a single centralized test was used for analysis of influenza A and B. Evaluations included performance stratified by sample type (prospective/retrospective and nasal/nasopharyngeal [paired by subject]), collection method (self/healthcare worker-collected [alternated and approximately balanced], symptom status (symptomatic/asymptomatic), and SARS-CoV-2 vaccination status, as well as assay inclusivity and system ease of use.  A total of 2,247 samples were tested. For SARS-CoV-2, the overall percent agreement (OPA) was 98.8% (95% CI: 97.9, 99.3) in nasal swab samples and 99.0% (95% CI: 98.2, 99.4) in nasopharyngeal swab samples. Regression analysis showed that Ct values from paired nasal and nasopharyngeal swab samples were highly correlated (correlation coefficient 0.83). The OPA was [&ge;]99.5% (sample type dependent) and 100.0% for influenza A and B, respectively. The POC SARS-CoV-2 & Influenza A/B test was easy to use.  These results support the use of the POCT in various sample types and by various operators in the intended-use setting.  Summary statement/importanceThis study highlights the benefits of RT-PCR POCT, namely comparable performance to centralized testing in multiple sample types and ease of use. Utilizing assays such as the POC SARS-CoV-2 & Influenza A/B test may improve timely differentiation of respiratory diseases that share similar symptoms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A multicenter study to assess the performance of the point-of-care RT-PCR Cobas SARS-2 CoV-2 & Influenza A/B nucleic acid test for use on the Cobas Liat system in comparison with 3 centralized assays across healthcare facilities in the United States\nAbstract: Non-structured abstractRespiratory diseases can share many of the same symptoms, highlighting the need for timely and accurate differentiation to facilitate effective clinical management and reduce transmission. Compared with centralized testing, molecular point-of-care tests (POCT) can provide a faster time to result.  We evaluated the RT-PCR POCT Cobas(R) SARS-CoV-2 & Influenza A/B qualitative assay for use on the Cobas Liat(R) system (the POC SARS-CoV-2 & Influenza A/B test) in nasal and nasopharyngeal swab samples from 10 diverse healthcare facilities in the US. A composite comparator design consisting of three centralized tests was used to analyze SARS-CoV-2, whilst performance versus a single centralized test was used for analysis of influenza A and B. Evaluations included performance stratified by sample type (prospective/retrospective and nasal/nasopharyngeal [paired by subject]), collection method (self/healthcare worker-collected [alternated and approximately balanced], symptom status (symptomatic/asymptomatic), and SARS-CoV-2 vaccination status, as well as assay inclusivity and system ease of use.  A total of 2,247 samples were tested. For SARS-CoV-2, the overall percent agreement (OPA) was 98.8% (95% CI: 97.9, 99.3) in nasal swab samples and 99.0% (95% CI: 98.2, 99.4) in nasopharyngeal swab samples. Regression analysis showed that Ct values from paired nasal and nasopharyngeal swab samples were highly correlated (correlation coefficient 0.83). The OPA was [&ge;]99.5% (sample type dependent) and 100.0% for influenza A and B, respectively. The POC SARS-CoV-2 & Influenza A/B test was easy to use.  These results support the use of the POCT in various sample types and by various operators in the intended-use setting.  Summary statement/importanceThis study highlights the benefits of RT-PCR POCT, namely comparable performance to centralized testing in multiple sample types and ease of use. Utilizing assays such as the POC SARS-CoV-2 & Influenza A/B test may improve timely differentiation of respiratory diseases that share similar symptoms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Divergent inflammatory and neurology-related plasma protein profiles in individuals with long COVID following primary and breakthrough SARS-CoV-2 infections.\nAbstract: Long COVID is a complex condition where symptoms persist for more than 3 months after SARS-CoV-2 infection and affects an estimated 5-30% of individuals. While the pathobiology of long COVID is still evolving, persistent inflammation has emerged as an important feature of this condition. However, it is unclear if immune responses from COVID-19 vaccination or SARS-CoV-2 re-infection exacerbate or mirror the initial inflammatory responses. To address this question, we quantified 182 inflammatory and neurology-related proteins in plasma using multiplexed affinity proteomics. Plasma samples were collected 6-9 months after first infection, but before COVID-19 vaccination from individuals who had recovered from COVID-19 (n=21) or from individuals with long COVID (n=12). This was benchmarked against plasma from unvaccinated, SARS-CoV-2 naive individuals (n=24). In addition to this cross-sectional analysis, we performed longitudinal analysis in a subset of individuals (n=34), where paired samples collected 2-4 weeks after a third COVID-19 vaccine dose and after SARS-CoV-2 breakthrough infection were available. Boruta feature selection and lasso regression models identified a distinct plasma profile in long COVID individuals, characterised by elevated IL-20, HAGH, NAAA, CLEC10A, LXN, and MCP-1 and reduced TRAIL, G-CSF, NBL1, and CCL23 protein concentrations. Notably, longitudinal analysis demonstrated that neither COVID-19 booster vaccination nor breakthrough infection replicated inflammatory and neurology-related plasma protein profiles observed after primary infection suggesting an altered immune response outcome in individuals with long COVID upon re-exposure.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Seroprevalence of chikungunya and onyong-nyong viruses in Senegal, West Africa\nAbstract: BackgroundArthritogenic alphaviruses such as chikungunya (CHIKV) and onyong-nyong (ONNV) viruses have shown capacity to cause widespread epidemics, with recurrent and sporadic outbreaks occurring throughout sub-Saharan Africa.  MethodsWe analyzed the seroprevalence for CHIKV and ONNV in 470 non-febrile subjects from three regions in Senegal (Sindia, 2018; Thies, 2018; and Kedougou, 2022/2023) using retrospective samples. We assessed the presence of anti-CHIKV IgG and neutralizing titers against CHIKV and ONNV via enzyme-linked immunosorbent assay (ELISA) and microneutralization tests, respectively, and determined risk factors of CHIKV and ONNV exposure by binary logistic regression.  ResultsThe overall seroprevalence of anti-CHIKV IgG was 24.89% (117/470). Regional seroprevalences were 14.89% (14/94) in Sindia, 28.72% (27/94) in Thies, and 26.95% (76/282) in Kedougou. Among CHIKV IgG-positive samples, 29.91% (35/117) and 39.32% (46/117) had neutralizing antibodies against CHIKV and ONNV, respectively. Of the remaining samples, 20.51% (24/117) were equivocal and 10.26% (12/117) were negative. Multivariate analysis showed that residence in Thies significantly increased the likelihood of CHIKV infection (OR, 3.878; 95% CI: 0.783-19.205), whereas prior malaria infection reduced it (aOR, 0.121; 95% CI: 0.049-0.300). Conversely, older age (OR, 7.896; 95% CI: 1.500-41.556) and residence in Kedougou (OR, 3.180; 95% CI: 0.824-12.276) were significant risk factors for ONNV infection, with prior malaria infection also linked to higher ONNV susceptibility (aOR, 6.961; 95% CI: 2.456-19.732).  ConclusionsOur study confirms significant exposure to CHIKV and ONNV across Senegal, underscoring the importance of ongoing surveillance and alphavirus testing among the population.  Author summaryArthritogenic alphaviruses, such as chikungunya (CHIKV) and onyong-nyong (ONNV) viruses have the potential to cause widespread epidemics, with recurrent and sporadic outbreaks occurring throughout sub-Saharan Africa. This study presents a retrospective evaluation of CHIKV and ONNV seroprevalence among non-febrile subjects from three regions in Senegal: Sindia, Thies, and Kedougou. Our analysis revealed regional variation in alphavirus seroprevalence, with 29.91% of subjects exhibiting neutralizing antibodies against CHIKV and 39.32% against ONNV. We identified that residence in Thies was a risk factor for CHIKV, while residence in Kedougou, a history of malaria, and older age were risk factors for ONNV. These findings suggest significant exposure to CHIKV and ONNV across Senegal, underscoring the importance of ongoing surveillance and alphavirus testing among the population.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Uncertainty quantification in epigenetic clocks via conformalized quantile regression\nAbstract: DNA methylation (DNAm) is a chemical modification of DNA that can be influenced by various factors, including age, environment, and lifestyle. An epigenetic clock is a predictive tool that measures biological age based on DNAm levels. It can provide insights into an individuals biological age, which may differ from their chronological age. This difference, known as the epigenetic age acceleration, may indicate the state of ones health and risk for age-related diseases. Moreover, epigenetic clocks are used in studies of aging to assess the effectiveness of anti-aging interventions and to understand the underlying mechanisms of aging and disease. Various epigenetic clocks have been developed using samples from different populations, tissues, and cell types, typically by training high-dimensional linear regression models with an elastic net penalty. While these models can predict mean biological age with high precision, there is a lack of uncertainty quantification which is important for interpreting the precision of age estimations and for clinical decision-making. To understand the distribution of a biological age clock beyond its mean, we propose a general pipeline for training epigenetic clocks, based on an integration of high-dimensional quantile regression and conformal prediction, to effectively reveal population heterogeneity and construct prediction intervals. Our approach produces adaptive prediction intervals not only achieving nominal coverage but also accounting for the inherent variability across individuals. By using the data collected from 728 blood samples in 11 DNAm datasets from children, we find that our quantile regression-based prediction intervals are narrower than those derived from conventional mean regression-based epigenetic clocks. This observation demonstrates an improved statistical efficiency over the existing pipeline for training epigenetic clocks. In addition, the resulting intervals have a synchronized varying pattern to age acceleration, effectively revealing cellular evolutionary heterogeneity in age patterns in different developmental stages during individual childhoods and adolescent cohort. Our findings suggest that conformalized high-dimensional quantile regression can produce valid prediction intervals and uncover underlying population heterogeneity. Although our methodology focuses on the distribution of aging in children, it is applicable to a broader range of populations to improve understanding of epigenetic age beyond the mean. This inference-based toolbox could provide valuable insights for future applications of epigenetic interventions for age-related diseases.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Medical Risk Classification For Severe COVID-19 Based On Chronic Medical Conditions: A Comparative Analysis\nAbstract: BackgroundThe European Centre for Disease Prevention and Control (ECDC) provides listings of medical conditions conferring high- or moderate-risk for severe COVID-19. In addition, individual European countries developed their own risk classifications for severe COVID-19 to select individuals recommended for annual COVID-19 vaccination. We assessed the discordance between the European and respective national medical risk classifications in assigning children and adults to risk groups for developing severe COVID-19 in populations of the Netherlands and Norway.  MethodsThis multi-country, healthcare data-linkage study covered 17.4 million inhabitants of the Netherlands and 5.6 million inhabitants of Norway by 1 January 2020. Medical conditions were defined based on ICD-10 hospital discharge codes in the European and Dutch classifications, and on ICD-10 and ICPC-2 primary care codes in the Norwegian classification. Subjects were classified as high-, moderate-, or low-risk. Discordance was calculated as the proportion of the population with a different risk status in the respective national compared to the European classification.  FindingsThe overall discordance between European and national risk classification was 12.0% in the Dutch and 13.8% in the Norwegian population. The European classification assigns more individuals to high-risk (9.0% and 9.2% of the Dutch and Norwegian populations, respectively) than the national classifications (1.5% and 3.0%, respectively). National classifications define more individuals as moderate-risk (11.3% and 12.7%, respectively) than the European classification (1.0% and 1.3%, respectively). Classification discordances most frequently involved subjects with cardiovascular disease, lung disease, and diabetes mellitus.  InterpretationThe European classification defines a substantially larger percentage of the population as high-risk for severe COVID-19 than the national classifications. This may have implications for post-pandemic vaccination programs. Further research should assess to what extent the medical conditions responsible for the classification discordances determine the risk of developing severe COVID-19.  FundingZonMw, EU, FCT, Norwegian Research Councils COVID-19 Emergency Call, iAPOGEE.  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSWe searched PubMed for English-language articles published from 1 January 2020 to 1 July 2024, using the search terms ((((\"COVID-19\"[Title] OR \"SARS-CoV-2\"[Title]) AND (\"sever*\"[Title] OR \"hospital*\"[Title] OR \"death\"[Title] OR \"decease*\"[Title]) AND (\"chronic condition*\"[Title/Abstract] OR \"comorbidit*\"[Title/Abstract]) AND (\"guideline\"[Title] OR \"classification\"[Title] OR \"system\"[Title]) AND 2020/01/01:2024/07/01[Date - Create]) NOT \"clinical trial\"[Publication Type]) NOT \"case reports\"[Publication Type]). This search identified 64 studies, but none of them assessed the impact of different medical risk classifications for severe COVID-19 or compared them across countries or to the European classification.  Added value of this studyTo the best of our knowledge, this is the first study that compared the impact of European and national medical risk classifications for severe COVID-19 by assigning the populations of the Netherlands and Norway to medical risk groups using national healthcare registries. We demonstrated important discrepancies between the European and respective national schemes in classifying high- and moderate-risk individuals in both countries. The chronic conditions responsible for the classification discordances were lung disease, cardiovascular disease, neurological disorders, diabetes mellitus, cancer, and hypertension.  Implications of all the available evidenceOur comparative analysis suggests that the choice between the European and national classifications may have important consequences for public health interventions such as vaccination campaigns. The variability in risk assignment based on chronic medical conditions underscores the absence of an international uniform approach. More research is needed to determine the extent to which each chronic medical condition impacts COVID-19 severity in the post-pandemic period, facilitating the refinement of risk classifications and supporting targeted public health interventions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Modeling the Risk of Airborne Transmission of Respiratory Viruses in Microgravity\nAbstract: Airborne transmission is the most efficient and widespread route of viral spread, posing a significant challenge in controlling major infectious diseases such as COVID-19 and influenza. In microgravity environment, such as the International Space Station (ISS), this mode of transmission requires heightened vigilance and preventive measures due to the prolonged suspension of virus-laden particles, which increases the risk of infection. Using the COVID Airborne Risk Assessment (CARA) tool, we assess the risk of airborne transmission of respiratory viruses in microgravity by simulating the emission, dispersion, and inhalation of virus-laden particles. Our findings show that the unique conditions of microgravity allow these particles to remain airborne for significantly longer periods compared to Earth, leading to a 286-fold increase in virus concentration in the air, resulting in nearly twice the probability of infection for a susceptible host. We also evaluated the effectiveness of preventive measures, and found that facemasks can reduce the risk by up to 23% while continuous HEPA filtration at five air changes per hour proves crucial for managing air quality and minimizing infection risks by reducing airborne virus concentration at 99.79%. However, when simulated the infection risk by accounting the spaceflight-induced immune suppression, we found that the infection probability increased by 12% in the condition that viral load in infected host increase for 8-fold and absence of protective measures. Although facemasks and air filtration help mitigate the risk, their effectiveness diminishes when the viral load carrying by host is high. Enhancing host immunity through vaccination or other interventions is vital, potentially reducing infection probability by up to 14.17% when combined with HEPA filtration. These findings highlight the need for robust mitigation strategies to safeguard the health of astronauts against airborne pathogens during future space missions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Loon Lens 1.0 Validation: Agentic AI for Title and Abstract Screening in Systematic Literature Reviews\nAbstract: IntroductionSystematic literature reviews (SLRs) are critical for informing clinical research and practice, but they are time-consuming and resource-intensive, particularly during Title and Abstract (TiAb) screening. Loon Lens, an autonomous, agentic AI platform, streamlines TiAb screening without the need for human reviewers to conduct any screening.  MethodsThis study validates Loon Lens against human reviewer decisions across eight SLRs conducted by Canadas Drug Agency, covering a range of drugs and eligibility criteria. A total of 3,796 citations were retrieved, with human reviewers identifying 287 (7.6%) for inclusion. Loon Lens autonomously screened the same citations based on the provided inclusion and exclusion criteria. Metrics such as accuracy, recall, precision, F1 score, specificity, and negative predictive value (NPV) were calculated. Bootstrapping was applied to compute 95% confidence intervals.  ResultsLoon Lens achieved an accuracy of 95.5% (95% CI: 94.8-96.1), with recall at 98.95% (95% CI: 97.57-100%) and specificity at 95.24% (95% CI: 94.54-95.89%). Precision was lower at 62.97% (95% CI: 58.39-67.27%), suggesting that Loon Lens included more citations for full-text screening compared to human reviewers. The F1 score was 0.770 (95% CI: 0.734-0.802), indicating a strong balance between precision and recall.  ConclusionLoon Lens demonstrates the ability to autonomously conduct TiAb screening with a substantial potential for reducing the time and cost associated with manual or semi-autonomous TiAb screening in SLRs. While improvements in precision are needed, the platform offers a scalable, autonomous solution for systematic reviews. Access to Loon Lens is available upon request at https://loonlens.com/.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pesticides and lifestyle factors are associated with disease severity of Parkinson's disease: a longitudinal study\nAbstract: ObjectiveTo longitudinally analyze the impact of the environment and lifestyle on PD motor sign severity in LRRK2 p. Gly2019Ser-related PD (LRRK2-PD) and idiopathic PD (iPD).  BackgroundThere is increasing evidence that the environment impacts disease severity. Recent studies have shown that pesticide exposure is associated with a faster disease progression. However, the relationship between smoking, caffeine, and disease severity has not yet been investigated longitudinally.  MethodsIn this longitudinal study, we included patients with iPD from the PPMI Online (N=2815) and Fox Insight (N=2319) cohorts, as well as patients with LRRK2-PD (N=81) from Fox Insight. Motor signs were assessed with the MDS-UPDRS Part II, and patients were assessed multiple times, followed up to 35 months or 60 months in the PPMI Online or Fox Insight cohort, respectively. The motor sign severity over time was analyzed by applying a linear mixed effects model. The outcome was the cumulative score of the MDS-UPDRS Part II questionnaire. Subsequently, we investigated the association between environmental exposure, lifestyle factors and motor signs. Pesticide exposure in a work setting, smoking, coffee, black tea, green tea, and caffeinated soda consumption were assessed using the validated PD-RFQ-U questionnaires. The mixed effects model included the environmental and lifestyle factors as binary (yes/no) variables.  ResultsWhen comparing LRRK2-related PD and iPD, motor signs were less severe in patients with LRRK2-PD compared to iPD ({beta}=-0.23, p=0.005). In LRRK2-PD, black tea consumption was associated with less severe motor signs ({beta}=-0.51, p=0.028). In patients with iPD, we observed that pesticide exposure was associated with more severe motor signs over time in PPMI-Online ({beta}=0.23, p=3.56x10-9). Smoking was associated with a higher motor signs score in PPMI-Online ({beta}=0.13, p=0.001). Lastly, caffeinated soda was associated with more severe motor signs in patients with iPD from PPMI-Online ({beta}=0.15, p=3.84x10-8) and Fox Insight ({beta}=0.09, p=0.031).  ConclusionsOur results provide further evidence of the importance of environment and lifestyle in PD, even after the disease onset. We suggest that pesticide exposure and lifestyle factors may affect disease severity in patients with LRRK2-PD and iPD; still, further validation is necessary.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Parenting and Family Adjustment Scales (PAFAS) questionnaire: psychometric qualities of the parenting scale in two large Brazilian birth cohorts\nAbstract: ObjectiveAnalyse the psychometric properties of the Portuguese version of the PAFAS (Parenting and Family Adjustment Scales) parenting scale, using data from two large Brazilian birth cohorts.  MethodsThe original PAFAS parenting scale, which consists of 18 items (parental inconsistency 5 items, coercive parenting 5 items, positive encouragement 3 items, and parent-child relationship 5 items) was applied in two Brazilian birth cohorts in Pelotas (ages 4 [n = 4010] and 6-7 [n = 3867]) and Rio Grande (age 3 [n = 992]). Confirmatory factor analysis was conducted, and internal consistency assessed, as well as construct validity in relation to maternal depression measured on the Edinburgh Postnatal Depression Scale.  ResultsThe model with a structure of 4 subscales showed that the global scale of parenting on the PAFAS had a good fit, but certain items did not fit well on sub-scales and were removed (2 items from parental inconsistency, 1 from coercive parenting, and 1 from positive encouragement). The original form of the parent-child relationship sub-scale was maintained. Considering the total PAFAS parenting score, we found that mothers with maternal depression had a higher likelihood of more problematic parental practices than mothers without depression.  ConclusionsA revised 14-item PAFAS parenting scale has good psychometric properties and we encourage its use in Brazilian populations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dissecting causal relationships between cortical morphology and neuropsychiatric disorders: a bidirectional Mendelian randomization study\nAbstract: Brain cortical morphology, indexed by its surface area and thickness, is known to be highly heritable. Previous research has suggested a relationship of cortical morphology with several neuropsychiatric phenotypes. However, the multitude of potential confounders makes it difficult to establish causal relationships. Here, we employ Generalized Summary-data-based Mendelian Randomization and a series of sensitivity analyses to investigate causal links between 70 cortical morphology measures and 199 neuropsychiatric, behavioral, and metabolic phenotypes. We show that total brain cortical surface area (TSA) has significant positive causal effects on 18 phenotypes. The strongest effects include TSA positively influencing cognitive performance, while reverse analyses reveal small effects of cognitive performance on TSA. Global mean cortical thickness (MTH) exhibits significant causal effects on five phenotypes, including schizophrenia. MTH reduces schizophrenia risk and bidirectional causality is found between MTH and smoking initiation. Finally, in regional analyses we detect positive influences of the transverse temporal surface area on cognitive performance and negative influences of transverse temporal thickness on schizophrenia risk. Overall, our results highlight bidirectional associations between TSA, MTH, and neuropsychiatric traits. These insights offer potential avenues for intervention studies aimed at improving brain health.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exposome-wide gene-environment interaction study of psychotic experiences in the UK Biobank\nAbstract: BackgroundA previous study successfully identified 148 out of 23,098 exposures associated with any psychotic experiences (PE) in the UK Biobank using an exposome-wide association study (XWAS). Research has shown that the polygenic risk score for schizophrenia (PRS-SCZ) is associated with PE. However, the interaction of these exposures and PRS-SCZ remains unknown.  MethodTo systematically investigate gene-environment interaction underlying PE through data-driven agnostic analyses, we conducted 1) a conditional XWAS adjusting for PRS-SCZ to estimate the main effects of the exposures and PRS-SCZ, respectively; 2) exposome-wide interaction studies (XWIS) to estimate multiplicative and additive interactions between PRS-SCZ and exposures; and 3) the correlations between PRS-SCZ and exposures. The study included 148,502 participants from UK biobank.  ResultsIn the conditional XWAS models, the significant effects of PRS-SCZ and 148 exposures on PE remained statistically significant. In the XWIS model, we found a significant multiplicative (Ms, 1.23, 95%CI, 1.10-1.37; P=4.0x10-4) and additive (RERI, 0.55; 95%CI, 0.32-0.77; SI, 0.22; 95%CI, 0.14-0.30; AP, 1.59; 95%CI, 1.30-1.91; all P < 0.05/148) interaction between PRS-SCZ and variable \"serious medical conditions or disability\" on PE. There were six additive gene-environment interactions identified for mental distress, help/treatment-seeking behaviors, vitamin D and sleep problems. In the correlation test focused on seven exposures with significant interaction with PRS-SCZ, no significant or small (r2< 0.04) gene-environment correlations were estimated.  ConclusionThese findings reveal preliminary evidence for gene-environment interaction underlying PEs and suggest that genetic vulnerability and exposures might represent intertwined pathways leading to psychosis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations between accurate measures of adiposity and fitness, blood proteins, and insulin sensitivity among South Asians and Europeans\nAbstract: ObjectiveSouth Asians (SAs) may possess a unique predisposition to insulin resistance (IR). We explored this possibility by investigating the relationship between  gold standard measures of adiposity, fitness, selected proteomic biomarkers, and insulin sensitivity among a cohort of SAs and Europeans (EURs).  MethodsA total of 46 SAs and 41 EURs completed  conventional (lifestyle questionnaires, standard physical exam) as well as  gold standard (dual energy X-ray absorptiometry scan, cardiopulmonary exercise test, and insulin suppression test) assessments of adiposity, fitness, and insulin sensitivity. In a subset of 28 SAs and 36 EURs, we also measured the blood-levels of eleven IR-related proteins. We conducted Spearman correlation to identify correlates of steady-state plasma glucose (SSPG) derived from the insulin suppression test, followed by multivariable linear regression analyses of SSPG, adjusting for age, sex and ancestral group.  ResultsSixteen of 30 measures significantly associated with SSPG, including one conventional and eight gold standard measures of adiposity, one conventional and one gold standard measure of fitness, and five proteins. Multivariable regressions revealed that gold standard measures and plasma proteins attenuated ancestral group differences in IR, suggesting their potential utility in assessing IR, especially among SAs.  ConclusionAncestral group differences in IR may be explained by accurate measures of adiposity and fitness, with specific proteins possibly serving as useful surrogates for these measures, particularly for SAs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Correlates of COVID-19 conspiracy theory beliefs in Japan: A nationally-representative cross-sectional survey\nAbstract: BackgroundThe COVID-19 pandemic was associated with an increase in conspiracy theories worldwide. However, the prevalence of COVID-19 conspiracy beliefs among Japanese has remained unclear. This study aimed to estimate the prevalence and correlates of COVID-19 conspiracy beliefs in Japan using a nationwide survey of 28,175 residents aged 16-81 years old.  MethodsA nationally representative, cross-sectional self-administered survey was conducted from September to October 2021. To assess the number of COVID-19 conspiracy beliefs, we used three questions from the Oxford Coronavirus Explanations, Attitudes, and Narratives Survey. Independent variables included general vaccine conspiracy beliefs, sociodemographic variables, information sources for COVID-19, trust in authorities, and fear of COVID-19.  ResultsAfter applying sampling weights and imputation, the estimated prevalence of holding at least one COVID-19 conspiracy belief was 24.4%. From a linear regression model, several factors were independently associated with conspiracy beliefs. Notably, people with the lowest level of education (lower secondary school) endorsed fewer COVID-19 conspiracy beliefs (B -0.089, vs. upper secondary school). Furthermore, higher socioeconomic backgrounds-such as higher income, higher wealth, and regular employment-were associated with endorsing conspiracy beliefs. Additionally, only 37.3% of respondents trusted the government of Japan, but paradoxically, trust in the government was positively associated with conspiracy beliefs (B 0.175, vs. distrust).  ConclusionsConspiracy beliefs about COVID-19 were prevalent in about a quarter of the Japanese population. Certain groups are more likely to endorse conspiracy beliefs, and targeting interventions towards these groups might be efficient in stemming the spread of conspiracy beliefs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of vaccination on SARS-CoV-2 transmission in the UK: a modelling study\nAbstract: BackgroundEfficacy and effectiveness of vaccines against SARS-CoV-2 infection, severe disease and death have been widely assessed. However, the impact of vaccination against SARS-CoV-2 transmission is far less well-characterized, and has major implications for public health, because it informs the indirect effects of vaccination in addition to its direct effects. Analysing the effects of SARS-CoV-2 vaccination on transmission is challenging, because they must be considered in tandem with the time-varying reproduction number (Rt), while also accounting for regional variability, for example due to the presence of more transmissible variants.  MethodsWe fitted a Bayesian hierarchical model to previously obtained estimates of Rt to estimate the effectiveness of vaccination with one, two and three doses on SARS-CoV-2 transmission in the UK during 2021. Vaccine effectiveness is defined as the proportional reduction in the time-varying reproduction number Rt. The model accounts for transmission at national and Lower Tier Local Authority (LTLA)-level, and uses vaccination data provided by the UK Health Security Agency (UKHSA), detailing the LTLA-specific proportions of people who have received doses one, two and three. The model also incorporates data on the proportion of wild-type, Alpha and Delta SARS-CoV-2 variants over time in each LTLA, obtained from UKHSA and the COVID-19 Genomics UK (COG-UK) Consortium.  ResultsWe find that vaccination had moderate-to-large effectiveness against transmission for dose 1 (39.30%, 95% CrI 26.64% - 48.07%), and for dose 3 (48.69%, 95% CrI 27.97% - 71.30%), but negligible effects on dose 2, likely attributable to the coincident importation and dominance of the Delta variant in the UK. Nationally, our model fitted the previously estimated values of time-series of Rt values well, largely reproducing the reproduction number averaged across LTLAs for each timepoint. This lends support to our hypothesis that the extent of vaccination (or lack thereof) was a major determinant of transmission intensity. Our model fits further reproduced well the reproduction numbers at regional level, although outliers were less well captured, implying some degree of variation that is not explained by our model.  ConclusionsTo our knowledge, our analysis is the first evidence of the effectiveness of SARS-CoV-2 vaccination against its transmission at population level. We find that vaccination is an effective tool for the control of SARS-CoV-2 transmission, in addition to its well-documented effects on disease burden and mortality. Our results allow future assessment of the impact of vaccination accounting for several circulating variants and sociodemographic factors.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The roles of lifestyle factors and genetic risk in the association between night shift work and cholelithiasis: a prospective cohort study.\nAbstract: BackgroundNight shift work has been linked to various adverse health outcomes, but its relationship with incident cholelithiasis remains unclear. This study aims to investigate the association between night shift work and the risk of cholelithiasis, assess the potential modifying effects of genetic susceptibility, and explore the mediating roles of lifestyle factors.  MethodsA total of 219,810 subjects who were either in paid employment or self-employed were included in the UK Biobank. Information on current and lifetime employment were collected. Genetic risk was quantified and stratified by a polygenic risk score (PRS) incorporating 13 known cholelithiasis-associated loci. We used Cox proportional hazard models to investigate associations between night shift work and risk of cholelithiasis. Lifestyle factors measured at baseline were explored as potential mediators.  ResultsDuring a median follow-up of 13.76 years, 6450 incidents of cholelithiasis were documented. Compared with day workers, the hazard ratio (HR) and 95% confidence interval (CI) of cholelithiasis was 1.09 (1.01, 1.17) for individuals with rarely/some night shifts and 1.18 (1.04, 1.35) for those with usual/permanent night shifts. Among the 62,558 participants who had reports on lifetime experience of night shift work, those with a higher frequency of night shifts and a longer length of each night shift were associated with an increased risk of cholelithiasis. Notably, individuals with usual/permanent night shifts and high genetic risk exhibited the highest risk of cholelithiasis (HR: 1.48, 95% CI: 1.21, 1.81), with day workers at low genetic risk serving as the reference. Mediation analysis indicated that a substantial portion (24.6%) of the association was mediated by BMI, followed by unhealthy alcohol intake (4.5%) and sedentary time (1.8%).  ConclusionsNight shift work is associated with an increased risk of cholelithiasis, with this relationship being largely mediated by lifestyle factors. These findings suggest that reducing the frequency and duration of night shifts may help mitigate the incidence of cholelithiasis among night shift workers, particularly for those with heightened genetic susceptibility.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Forecasting COVID-19, Influenza and RSV hospitalisations over winter 2023/24 in England\nAbstract: Seasonal respiratory viruses cause substantial pressure on healthcare systems, particularly over winter. System managers can mitigate the impact on patient care when they anticipate hospital admissions due to these viruses. Hospitalisation forecasts were used widely during the SARS-CoV-2 pandemic. Now, resurgent seasonal respiratory pathogens add complexity to system planning. We describe how a suite of forecasts for respiratory pathogens, embedded in national and regional decision-making structures, were used to mitigate the impact on hospital systems and patient care.  We developed forecasting models predicting hospital admissions and bed occupancy two weeks ahead for COVID-19, influenza, and RSV in England over winter 2023/24. Bed occupancy forecasts were informed by the ensemble admissions models. Forecasts were delivered in real-time at multiple scales. The use of sample-based forecasting allowed for effective reconciliation and trend interpretation.  Admission forecasts, particularly RSV and influenza, showed high skill at regional levels. Bed occupancy forecasts had well-calibrated coverage, owing to informative admissions forecasts and slower moving trends. National admissions forecasts had mean absolute percentage errors of 27.3%, 30.9% and 15.7% for COVID-19, influenza, and RSV respectively, with corresponding 90% coverages of 0.439, 0.807 and 0.779.  These real-time winter infectious disease forecasts produced by the UK Health Security Agency for healthcare system managers played an informative role in mitigating seasonal pressures. The models were delivered regularly and shared widely across the system to key users. This was achieved by producing reliable, fast, and epidemiologically informed ensembles of models. Though, a higher diversity of model approaches could have improved forecast accuracy.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Discriminatory ability of adiposity phenotypes in identifying cardiometabolic disorders in indigenous and non-indigenous African populations\nAbstract: BackgroundWhether any of the anthropometric indices are associated with cardiometabolic outcomes in indigenous Fulani African populations is not known. This study evaluates anthropometric indices in Fulani and non-autochthonous populations in predicting cardiometabolic outcomes in indigenous and non-indigenous populations.  MethodsA population-based cross-sectional study recruited 1 921 participants of similar median aged 32 (24-45) years from Fulbe (settled Fulani), Mbororo (nomadic pastoral Fulani) and the general population. Body weight (BW), height, waist circumference (WC), and hip circumference (HC) were measured and body mass index (BMI), waist-to-hip ratio (WHR), waist-to-height ratio (WHtR), Conicity Index (Cindex), body adiposity index (BAI), body roundness index (BRI) and body shape index (ABSI) were determined. The associations of anthropometric indices with cardiometabolic disorders were assessed by multivariable adjusted logistic regression and the area under the receiver-operating characteristic (ROC) curve compared the predictive abilities.  ResultsWomen had higher prevalence of MetS and the men had higher prevalence of hypertension and IFG/diabetes/hypertension while the prevalence of IFG/diabetes was similar in men and women. In women, the ROC and multivariable logistic regression analyses both showed consistent good performance of BW and BMI in identifying IFG/Diabetes in Fulbe and general population; BW, HC, BMI and BAI in Mbororo and BW, WC, HC, WHtR, and BRI in general population to predict hypertension and IFG/diabetes/hypertension. All the anthropometric indices showed good performance in all the groups to identify MetS. In men, WC, HC and BRI had good performance in all the groups while WC and BRI had good performance in all groups and HC in Fulbe and Mbororo to predict hypertension. The BW, WC, HC, BMI, WHtR, BAI and BRI showed consistent good performance in all the groups to predict MetS.  ConclusionAnthropometric indices of adiposity are important risk assessing tools for cardiometabolic disorders in indigenous as well as non-autochthonous populations varying by ethnic group and sex.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Population Genomics of Plasmodium malariae from Four African Countries\nAbstract: Plasmodium malariae is geographically widespread but neglected and may become more prevalent as P. falciparum declines. We completed the largest genomic study of African P. malariae to-date by performing hybrid capture and sequencing of 77 isolates from Cameroon (n=7), the Democratic Republic of the Congo (n=16), Nigeria (n=4), and Tanzania (n=50) collected between 2015 and 2021. There is no evidence of geographic population structure. Nucleotide diversity was significantly lower than in co-localized P. falciparum isolates, while linkage disequilibrium was significantly higher. Genome-wide selection scans identified no erythrocyte invasion ligands or antimalarial resistance orthologs as top hits; however, targeted analyses of these loci revealed evidence of selective sweeps around four erythrocyte invasion ligands and six antimalarial resistance orthologs. Demographic inference modeling suggests that African P. malariae is recovering from a bottleneck. Altogether, these results suggest that P. malariae is genomically atypical among human Plasmodium spp. and panmictic in Africa.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: COVID-19 real world data infrastructure: A big data resource for study of the impact of COVID-19 in patient populations with immunocompromising conditions\nAbstract: BackgroundWe created a United States-based real-world data resource to better understand the continued impact of the COVID-19 pandemic on immunocompromised patients, who are typically under-represented in prospective studies and clinical trials. Methods: The COVID-19 Real World Data infrastructure (CRWDi) was created by linking and harmonizing deidentified HealthVerity medical and pharmacy claims data from December 1, 2018 to December 31, 2023, with SARS-CoV-2 virologic and serologic laboratory data from major commercial laboratories and Northwell Health; COVID-19 vaccination data; and for patients with cancer, 2010 to 2021 National Cancer Institute Surveillance, Epidemiology, and End Results registry data. Results: The CRWDi dataset contains data on 5.2 million people. Four populations were included in the dataset: (1) patients with cancer (n=1,294,022); (2) patients with rheumatic conditions receiving pharmacotherapy (n=1,636,940); (3) non-cancer solid organ (n=249,797) and hematopoietic stem cell (n=30,172) transplant recipients; and (4) people from the general population including adults (>18 years of age; n=1,790,162) and pediatric patients (<18 years of age; n=198,907).  ConclusionsWe have created a complex real-world data system to address unanswered questions that have arisen during the COVID-19 pandemic. Further, by making the data broadly and freely available to academic researchers from the United States, the CRWDi real-world data system represents an important complement to existing consortia studies and clinical trials that have emerged during the healthcare crisis, and is readily reproducible for future purposing.  SummaryThe COVID-19 Real World Data infrastructure dataset contains 5.2 million deidentified patient records, with focus on immunocompromising conditions, and is freely available to approved researchers to study the impact of coronavirus disease 2019 (COVID-19) on patient morbidities and outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Epidemiological profile of patients diagnosed with covid-19 in the municipality of Sao Goncalo, Rio de Janeiro, Brazil\nAbstract: ObjectivesThe global health crisis caused by SARS-CoV-2 has led to over 760 million confirmed cases and 6.8 million deaths worldwide, primarily impacting the respiratory system with symptoms varying from mild to severe. This study aimed to analyze the interplay between vaccination status, sociodemographic profiles, comorbidities, and COVID-19 outcomes.  Study DesignObservational, cross-sectional, and analytical.  MethodsThe study analyzed data from 6,953 individuals, examining vaccination statuses, sociodemographic profiles, comorbidities, COVID-19 test results, and other relevant variables. The cohort comprised predominantly mixed-race (51%), Caucasian (38%), and Black (9.5%) individuals, with 61% being female and 60% aged between 21-50 years. Prevalent comorbidities included hypertension (18.2%), diabetes (4.9%), and obesity (0.4%).  ResultsPopulation-weighted analysis revealed significant associations between sociodemographic factors and COVID-19 test outcomes. Younger age groups, particularly 11-30 years, had higher positivity rates, which declined with age. Caucasians exhibited higher positivity rates (40.1%) compared to other ethnicities. Cramers V indicated small correlations between symptoms and test outcomes, notably with loss of taste (V = 0.11) and smell (V = 0.08). Odds ratio analysis identified hypertension as significantly associated with higher COVID-19 positivity (OR = 1.54, 95% CI: 1.28-1.83, p < 0.001), while obesity was associated with lower positivity (OR = 0.13, 95% CI: 0.02-0.63, p = 0.025). Symptoms such as fever, cough, loss of taste, loss of smell, and myalgia also showed significant associations with positive test outcomes.  ConclusionsThis study provides valuable insights into the complex interplay of sociodemographic characteristics, comorbidities, symptoms, and COVID-19 outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Accounting for partner notification in epidemiological birth-death-models\nAbstract: Phylodynamics bridges the gap between classical epidemiology and pathogen genome sequence data by estimating epidemiological parameters from time-scaled pathogen phylogenetic trees. The models used in phylodynamics typically assume that the sampling procedure is independent between infected individuals. However, this assumption does not hold for many epidemics, in particular for such sexually transmitted infections as HIV-1, for which partner notification schemes are included in health policies of many countries.  We developed an extension of phylodynamic multi-type birth-death (MTBD) models with partner notification (PN), and a simulator to generate trees under MTBD and MTBD-PN models. We proposed a non-parametric test for detecting partner notification in pathogen phylogenetic trees. Its application to simulated data showed that it is both highly specific and sensitive. For the simplest representative of the MTBD-PN family, the BD-PN model, we solved the differential equations and proposed a closed form solution for the likelihood function. We implemented it in a program, which estimates the model parameters and their confidence intervals from phylogenetic trees. It performed accurate estimations on simulated data, and detected partner notification in HIV-1 B epidemics in Zurich and the UK. Importantly, we showed that not accounting for partner notification when it is present leads to bias in parameter estimation with the BD model, while BD-PN parameter estimator performs well both in presence and in absence of partner notification.  Our PN test, MTBD-PN tree simulator and BD-PN parameter estimator are freely available at github.com/evolbioinfo/treesimulator and github.com/evolbioinfo/bdpn.  Author summaryPhylodynamic models can estimate epidemiological parameters such as the number of secondary infections Re from pathogen phylogenetic trees (i.e., genealogies, inferred from pathogen genomic sequences). These models do not account for partner notification (contact tracing), and instead assume that detection of new cases is independent between infected individuals. However, especially for sexually transmitted infections, partner notification plays an important role and is included in health policies of many countries.  We developed a phylodynamic model accounting for partner notification and a test for the detection of partner notification in pathogen phylogenetic trees. Our test and epidemiological parameter estimator showed good performance both on simulated and real data. We detected the presence of partner notification in the HIV-1 B epidemics in Zurich and the UK, and corrected the previous parameter estimates made without accounting for partner notification.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Detecting imported malaria infections in endemic settings using molecular surveillance: current state and challenges\nAbstract: The Global Technical Strategy for Malaria 2016-2030 targets eliminating malaria from at least 35 countries and reducing case incidence by 90% globally. The importation of parasites due to human mobilization presents a significant challenge to achieve elimination as it can undermine local interventions. A thorough understanding of importation is necessary to support efforts to control and further lead to elimination. Parasite genetic data is extensively deployed to investigate the space-time spread of imported infections. In this matter, this systematic review aimed to aggregate evidence on the use of parasite genetic data for mapping imported malaria and the statistical analytical methods. We discuss the advantages and limitations of the deployed genetic approaches and propose a suitable type of genetic data and statistical framework to discriminate imported malaria infections from local infections. The findings provide actionable insights for national control programs, helping them select the most suitable methods for detecting imported cases while supporting the evaluation of elimination program performance, particularly in low transmission settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adapting COVID-19 research infrastructure to capture influenza and RSV alongside SARS-CoV-2 in UK healthcare workers winter 2022/23: Evaluation of the SIREN Winter Pressures pilot study\nAbstract: BackgroundIn 2022, with high early winter respiratory virus circulation, SIREN, a prospective healthcare worker cohort study monitoring SARS-CoV-2, ran a pilot study introducing multiplex PCR testing for SARS-CoV-2, influenza A/B, and RSV to investigate winter pressures. Three pathways were trialled: (A) on-site swabbing with local laboratory testing, (B) on-site swabbing with UKHSA-commissioned laboratory testing, and (C) postal swabbing with UKHSA-commissioned laboratory testing. Here, we compare pathways in relation to recruitment, testing coverage, participant acceptability, and UKHSA SIREN research team feedback.  MethodsWe conducted a mixed methods evaluation using metrics of quality assurance and study fidelity (participant recruitment and retention; multiplex PCR testing timing and coverage), an adapted NIHR  participant in research feedback questionnaire, and thematic analysis of a UKHSA SIREN research team workshop.  ResultsWith 7,774 participants recruited, target recruitment (N=7,500) was achieved. Thirty-nine sites took part in the sub-study (4,289 participants). Thirty-three used pathway A, and six used pathway B. 3,485 participants enrolled to pathway C (27.8% of invitees). The median number of tests per participant was similar across pathways (6; 4; 5). However, sites using local laboratories showed a wide variation in the date they switched to multiplex testing (28th November 2022 to 16th March 2023). Consequently, influenza and RSV testing coverage was higher for pathways using UKHSA-commissioned laboratories (100.0% vs 45.6% at local laboratories). 1,204/7,774 (15.5%) participants completed the feedback survey. All pathways were acceptable to participants; 98.9% of postal and 97.5% of site-based participants  would consider taking part again.  ConclusionTransitioning SARS-CoV-2 PCR testing to include influenza and RSV was challenging to achieve rapidly across multiple sites. The postal testing pathway proved more agile, and UKHSA-commissioned laboratory testing provided more comprehensive data collection than local laboratory testing. This sub-study indicates that postal protocols are effective, adaptable at pace, and acceptable to participants.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Efficacy of Molnupiravir in reducing the risk of severe outcome in patients with SARS-CoV-2 infection: a real-life full-matched case-control study (SAVALO Study).\nAbstract: IntroductionMolnupiravir (MNP) is an orally administered prodrug which prevents disease progression in patients at high risk for severe COVID-19. We conducted a real-life case-control study on a cohort of outpatients, with Omicron SARS-CoV-2 infection to assess the effectiveness of MNP in reducing the occurrence of hospital admission, admission in intensive care unit (ICU) and death at day 28.  Materials and methodsCases were enrolled among SARS-CoV-2 positive subjects that sought medical care during the first five days of symptoms from January 1st, 2022, to December 31st, 2022, and received MNP. Control participants were selected from a regional database among those who tested positive during the study period and did not receive antiviral treatment for SARS-CoV-2.  Results1382 patients were included (cases: 146, controls: 1236). Vaccinated patients showed lower risk of mortality and composite outcome (at least one among hospital admission, admission in ICU and all-cause death) compared to unvaccinated ones (0.6% vs 7.8%, p<0.001 and 2% vs 7.8%, p=0.001 respectively). After full-matching propensity score, MNP-treated subjects showed a lower incidence of composite outcome, while no effect was observed on the single outcomes. In the subgroup analysis according to the vaccination status, MNP proved effective in preventing all the outcomes among unvaccinated patients, while showed to reduce the risk of ICU admission both in vaccinated and unvaccinated patients.  ConclusionsTreatment with MNP proved effective in reducing the risk of composite outcome among outpatients with SARS-CoV-2 infection. The beneficial effect of MNP treatment in reducing progression is more pronounced in unvaccinated patients.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Antibiotic De-escalation Patterns and Outcomes in Critically Ill Patients with Suspected Pneumonia as Informed by Bronchoalveolar Lavage Results\nAbstract: BackgroundAntibiotic stewardship in critically ill pneumonia patients is crucial yet challenging, partly due to the limited diagnostic yield of noninvasive infectious tests. In this study, we report an antibiotic prescription pattern informed by bronchoalveolar lavage (BAL) results, where clinicians de-escalate antibiotics based on the combination of quantitative cultures and multiplex PCR rapid diagnostic tests.  MethodsWe analyzed data from SCRIPT, a single-center prospective cohort study of mechanically ventilated patients who underwent a BAL for suspected pneumonia. We used the novel Narrow Antibiotic Therapy (NAT) score to quantify day-by-day antibiotic prescription pattern for each suspected pneumonia episode etiology (bacterial, viral, mixed bacterial/viral, microbiology-negative, and non-pneumonia control). We also analyzed and compared clinical outcomes for each pneumonia etiology, including unfavorable outcomes (a composite of in-hospital mortality, discharge to hospice, or requiring lung transplantation during hospitalization), duration of ICU stay, and duration of intubation. Clinical outcomes were compared with the Mann-Whitney U test and Fishers exact test.  ResultsWe included 686 patients with 927 pneumonia episodes. NAT score analysis indicated that an antibiotic de-escalation pattern was evident in all pneumonia etiologies except resistant bacterial pneumonia. Microbiology-negative pneumonia was treated similarly to susceptible bacterial pneumonia in terms of antibiotic spectrum. Over a quarter of the time in viral pneumonia episodes, antibiotics were completely discontinued. Unfavorable outcomes were comparable across all pneumonia etiologies. Patients with viral and mixed bacterial/viral pneumonia had longer durations of ICU stay and intubation.  ConclusionsBAL quantitative cultures and multiplex PCR rapid diagnostic tests resulted in prompt antibiotic de-escalation in critically ill pneumonia patients. There was no evidence of increased incidence of unfavorable outcomes.  Key pointsWe found that bronchoalveolar lavage-based diagnostics is associated with antibiotic de-escalation, including to no antibiotics in more than a quarter of cases where only a virus is recovered.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dutch participatory surveillance framework for evaluating evolutionary changes on SARS-CoV-2 affecting Rapid Diagnostic Test sensitivity in 2022 - 2023.\nAbstract: BackgroundRapid Diagnostic Tests (RDTs) have been pivotal in the diagnostics for SARS-CoV-2 and policies surrounding self-isolation. When self-testing policies are in place a decreased sensitivity of the virus to RDTs can give benefits for viral spread. However, to monitor for reduced sensitivity of RDTs we rely on the collection of SARS-CoV-2 positive samples from RDT negative patients. Infectieradar, a national participatory surveillance that registers influenza-like symptoms is used as a framework to study false-negative RDT results due to emergence of new virus variants.  MethodsParticipants report weekly on RDT use and symptoms linked to Acute Respiratory Illness (ARI). Each week, all RDT positive and a sample of 200 among RDT negative but symptomatic participants were invited to send in nose throat swabs (NTS). SARS-CoV-2 Ct-values are determined using RT-PCR on NTS samples for RDT positive and RDT (false) negative participants and compared. Sequencing is performed on all eligible samples for phylogenetic analysis of the SARS-CoV-2 nucleocapsid protein and the whole genome sequence. NTS samples of participants with discordant RT-PCR and RDT results are also analyzed using RDTs by professionals in the laboratory.  ResultsBetween October 2022 and October 2023, our study had 16,893 participants and we collected 1,757 self-test-positive/NTS PCR positive samples and 359 self-test-negative/NTS PCR positive samples (RDT-/PCR+). These participants were asked to take a SARS-CoV-2 RDT upon symptoms. Within SARS-CoV-2 PCR positive participants, we did not find characteristics that differ in SARS-CoV-2 RDT negative versus positive participants. There were no associations with specific changes in the N protein nor did our phylogenetic analysis show clustering of RDT negative samples.  ConclusionEvaluating brand-specific RDT performance in Dutch population and false-negative RDT analyses, led to no evidence for SARS-CoV-2 evolution affecting RDT sensitivity. The participatory surveillance program Infectieradar is a powerful tool for our national surveillance on acute respiratory illnesses, as well as for research purposes. Since this framework offered both self-testing and the gold standard of PCR testing results.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Modelling the potential spread of Clade Ib MPXV in an Asia Pacific city\nAbstract: BackgroundThe ongoing 2024 mpox outbreak in several African countries, driven by the novel Clade 1b strain, has resulted in imported cases being reported in Sweden and Thailand. The Asia Pacific (APAC) region, with little exposure to previous mpox waves, is particularly vulnerable to local transmission triggered by importation. While this highlights the importance of early preparedness, current knowledge of the viruss transmission dynamics remains too limited to effectively inform policy-making and resource planning.  MethodsA compartmental model was constructed to characterise the potential mpox transmission triggered by importation in an APAC city. Outbreaks were simulated under diverse hypothetical scenarios considering transmission mechanisms, different affected subpopulations, levels of disease transmissibility, and importation frequencies. The impacts of various non-pharmaceutical interventions (NPIs) including isolation, and vaccination strategies were projected and compared.  FindingsUp to 30% of the population would be infected in the scenario of high sexual and moderate non-sexual transmissibility in the general community, with minimal impact from importation frequency on outbreak size and healthcare burden. The sequential introduction of mandatory home isolation for diagnosed cases, pre-departure screening of international arrivals, and contact tracing were projected to lower the peak outbreak size by 35%, 0.04%, and 1.1%, respectively, while the reduction would be 30% with proper vaccination by prioritising the sexually active group. These measures would significantly decrease disease morbidity and mortality rates, thereby alleviating the diseases pressure on healthcare systems.  InterpretationThe potential mpox outbreak in the APAC setting could be alleviated through strong surveillance and timely response from stakeholders. NPIs are recommended over vaccination for outbreak management due to their demonstrated effectiveness and practicability.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic accuracy and analytical sensitivity of the novel Xpert Mpox (Cepheid) and STANDARD M10 MPX/OPX (SD Biosensor) molecular point-of-care assays for the detection of Mpox virus in skin lesion swabs and upper-respiratory swab samples\nAbstract: ObjectivesEvaluation of diagnostic accuracy of two point-of-care (POC) molecular diagnostic tests for the detection of monkeypox virus (MPXV): Xpert(R) Mpox (Cepheid, Inc., USA) and STANDARD M10 MPX/OPX (SD Biosensor, Inc., Korea).  MethodsDiagnostic accuracy of both platforms was evaluated using 53 upper-respiratory swabs (URS) and 32 skin lesions swabs (SS) collected from mpox and COVID-19 patients in the UK against the Sansure (Sansure Biotech Inc.) and the CDC reference qPCR tests. The analytical sensitivity of both platforms was assessed using a viral isolate from the lineage II, B.1.  ResultsThe limit of detection was 1x101 pfu/ml for both tests. The overall sensitivity and specificity of the Xpert(R) Mpox was 97.67% [95% CI 87.71-99.94%] and 88.57% [95% CI 73.26-96.80%] and 97.44% [95% CI 86.52-99.94%] and 74.42% [95% CI 58.83-86.48%] comparing the Sansure and CDC qPCR, respectively and for the M10 MPX/OPX was 87.80% [95% CI 73.80-95.92%] and 76.60% [95% CI 61.97-87.70%] and 94.29% [95% CI 80.84-99.30%] and 86.67% [95% CI 73.21-94.95%] with the Sansure and CDC qPCR.  ConclusionThe Xpert(R) Mpox had good diagnostic accuracy for both sample types while the M10 MPX/OPX clinical accuracy was deficient with URS. Our data supports the use of URS during the first 3 days of symptoms onset for mpox diagnosis.  HighlightsO_LIThe Xpert(R) Mpox detected Monkeypox virus (MPXV) DNA in more samples than the M10 MPX/OPX, CDC qPCR and Sansure qPCR suggesting higher sensitivity at lower viral loads. C_LIO_LIXpert(R) Mpox fulfilled the performance requirements recommended in the World Health Organisation (WHO) target product profile (TPP) using upper-respiratory swabs (URS) and skin lesion swabs (SS) but M10 MPX/OPX performance was only met when using SS. C_LIO_LIMPXV DNA was reliably detectable in SS up to 5 days after onset of symptoms. with all PCR tests C_LIO_LIThe use of URS for mpox diagnosis is not recommended for use more than 3 days after onset of symptoms. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The causal role of thyroid hormones in bipolar disorders: a two-sample Mendelian Randomization study\nAbstract: IntroductionBipolar disorder is a complex psychiatric condition with distinctions between clinical subtypes including Type 1 and 2 disorders. Several studies have proposed thyroid hormones may be involved in the etiology of bipolar disorders.  MethodsThis study employed a two-sample Mendelian Randomization (MR) approach to investigate the causal relationships between six thyroid hormone metrics (TSH, FT4, FT3, TT3, FT3/FT4, and TT3/FT4) and bipolar disorder, and Type 1 and 2 disorders, separately. Genome-wide association (GWAS) data from the Thyroidomics Consortium (up to 271,040 individuals of European ancestry) were used for thyroid function metrics. Bipolar disorder GWAS data included 41,917 cases and 371,549 controls (25,060 Type 1 and 6,781 Type 2 cases). We applied inverse variance weighted (IVW) methods for primary MR analysis, with MR Egger, weighted median, and weighted mode for sensitivity. Additional tests assessed horizontal pleiotropy and heterogeneity.  ResultsHigher FT4 levels showed a protective causal effect against bipolar disorder (OR: 0.92, 95% CI: 0.86-0.97, p=4.58x10-3) and a suggestive effect on Type 1 disorders (OR: 0.92, 95% CI: 0.86-0.99, p=3.21x10-2). Elevated FT3 (OR: 1.18, 95% CI: 1.03-1.35, p=1.55x10-2) and FT3/FT4 ratio (OR: 1.97, 95% CI: 1.02-3.82, p=4.46x10-2) had suggestive harmful effects on Type 1 disorders. Sensitivity analyses showed consistent effects, with no significant horizontal pleiotropy or heterogeneity.  ConclusionsThese findings highlight the protective role of FT4 and the potentially harmful effect of elevated FT3 in Type 1 bipolar disorder, highlighting the need for further research on thyroid hormone levels as a potential treatment strategy for Type 1 bipolar disorder.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Obstructive sleep apnea mediates genetic risk of Diabetes Mellitus: The Hispanic Community Health Study/Study of Latinos\nAbstract: ObjectiveWe sought to evaluate whether obstructive sleep apnea (OSA), and other sleep disorders, increase genetic risk of developing diabetes mellitus (DM).  Research Design and MethodsUsing GWAS summary statistics from the DIAGRAM consortium and Million Veteran Program, we developed multi-ancestry Type 2 Diabetes (T2D) polygenic risk scores (T2D-PRSs) useful in admixed Hispanic/Latino individuals. We estimated the association of the T2D-PRS with cross-sectional and incident DM in the Hispanic Community Health Study/Study of Latinos (HCHS/SOL). We conducted a mediation analysis with T2D-PRSs as an exposure, incident DM as an outcome, and OSA as a mediator. Additionally, we performed Mendelian randomization (MR) analysis to assess the causal relationship between T2D and OSA.  ResultsOf 12,342 HCHS/SOL participants, at baseline, 48.4% were normoglycemic, 36.6% were hyperglycemic, and 15% had diabetes, and 50.9% identified as female. Mean age was 41.5, and mean BMI was 29.4. T2D-PRSs was strongly associated with baseline DM and with incident DM. At baseline, a 1 SD increase in the primary T2D-PRS had DM adjusted odds ratio (OR) = 2.67, 95% CI [2.40; 2.97] and a higher incident DM rate (incident rate ratio (IRR) = 2.02, 95% CI [1.75; 2.33]). In a stratified analysis based on OSA severity categories the associations were stronger in individuals with mild OSA compared to those with moderate to severe OSA. Mediation analysis suggested that OSA mediates the T2D-PRS association with DM. In two-sample MR analysis, T2D-PRS had a causal effect on OSA, OR = 1.03, 95% CI [1.01; 1.05], and OSA had a causal effect on T2D, with OR = 2.34, 95% CI [1.59; 3.44].  ConclusionsOSA likely mediates genetic effects on T2D.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Influenza A (H3) viral aerosol shedding in nasally inoculated and naturally infected cases\nAbstract: Nasally inoculated influenza cases reported milder symptoms and shed lower viral RNA load in exhaled breath aerosols (EBA) than people with classic influenza-like illness including fever, in a previous study. Whether nasally inoculated influenza is representative of mild natural influenza infection, the majority of natural infections, is unknown. Here, we extend our previous analyses to include a broader range of community-acquired influenza cases. Previously, we reported on two groups: (A) volunteers intranasally inoculated with a dose of 5.5 log10TCID50 of influenza A/Wisconsin/67/2005 (H3N2) and (B) cases with cough and sore throat plus fever or a positive rapid antigen test recruited on a college campus in the same year (2013). Here we added two additional groups from a later study: (C) cases from a 2017-2019 surveillance cohort of college dormitory residents and their contacts, and (D) cases recruited from a university health center in 2019. All cases had an influenza A(H3) infection. Using a Gesundheit-II sampler, we collected 30-minute EBA samples. Community-acquired cases from the surveillance cohort (C) shed more EBA viral RNA and were more symptomatic than the nasally inoculated cases (A) but shed less viral RNA than the natural cases that were selected for symptoms (B) in 2013, but not (D) recruited in 2019. Despite sharing a similar symptomatic profile with the 2013 selected natural cases (B), the 2019 community-acquired cases (D) recruited post-infection showed a lower fine aerosol viral RNA load. Nasal inoculation of influenza virus did not reproduce EBA viral RNA shedding or symptoms observed in mild natural infection. Circulating strains of influenza A(H3) may differ, year-to-year in the extent to which symptomatic cases shed virus into fine aerosols. New models, including possibly aerosol inoculation, are needed to study viral aerosol shedding from the human respiratory tract.  Author SummaryIn this study, we compared influenza A (H3) viral aerosol shedding in the exhaled breath of four different groups of influenza cases: (A) volunteers given the influenza virus intranasally, naturally infected (B) college community members with classic influenza-like illness including fever recruited in 2013, (C) dormitory residents undergoing active surveillance, and (D) patients from a university health center recruited in 2019. We found that mild symptomatic cases among healthy college students (C) released more viral RNA in their exhaled breath than those nasally inoculated with influenza virus (A). We also observed that more symptomatic and medically attended cases from different flu seasons (B and D), although reporting similar symptom severity, shed different levels of viral RNA in their exhaled breath. Our findings indicate that influenza viral aerosol shedding varies from season to season. Most volunteers nasally inoculated at a high virus dose did not shed detectable viral RNA in their exhaled breath or show symptoms, suggesting that nasal inoculation may not accurately mimic natural infection. Our results highlight the need for improved models to study the spread of influenza virus in aerosol forms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Influenza A (H3) viral aerosol shedding in nasally inoculated and naturally infected cases\nAbstract: Nasally inoculated influenza cases reported milder symptoms and shed lower viral RNA load in exhaled breath aerosols (EBA) than people with classic influenza-like illness including fever, in a previous study. Whether nasally inoculated influenza is representative of mild natural influenza infection, the majority of natural infections, is unknown. Here, we extend our previous analyses to include a broader range of community-acquired influenza cases. Previously, we reported on two groups: (A) volunteers intranasally inoculated with a dose of 5.5 log10TCID50 of influenza A/Wisconsin/67/2005 (H3N2) and (B) cases with cough and sore throat plus fever or a positive rapid antigen test recruited on a college campus in the same year (2013). Here we added two additional groups from a later study: (C) cases from a 2017-2019 surveillance cohort of college dormitory residents and their contacts, and (D) cases recruited from a university health center in 2019. All cases had an influenza A(H3) infection. Using a Gesundheit-II sampler, we collected 30-minute EBA samples. Community-acquired cases from the surveillance cohort (C) shed more EBA viral RNA and were more symptomatic than the nasally inoculated cases (A) but shed less viral RNA than the natural cases that were selected for symptoms (B) in 2013, but not (D) recruited in 2019. Despite sharing a similar symptomatic profile with the 2013 selected natural cases (B), the 2019 community-acquired cases (D) recruited post-infection showed a lower fine aerosol viral RNA load. Nasal inoculation of influenza virus did not reproduce EBA viral RNA shedding or symptoms observed in mild natural infection. Circulating strains of influenza A(H3) may differ, year-to-year in the extent to which symptomatic cases shed virus into fine aerosols. New models, including possibly aerosol inoculation, are needed to study viral aerosol shedding from the human respiratory tract.  Author SummaryIn this study, we compared influenza A (H3) viral aerosol shedding in the exhaled breath of four different groups of influenza cases: (A) volunteers given the influenza virus intranasally, naturally infected (B) college community members with classic influenza-like illness including fever recruited in 2013, (C) dormitory residents undergoing active surveillance, and (D) patients from a university health center recruited in 2019. We found that mild symptomatic cases among healthy college students (C) released more viral RNA in their exhaled breath than those nasally inoculated with influenza virus (A). We also observed that more symptomatic and medically attended cases from different flu seasons (B and D), although reporting similar symptom severity, shed different levels of viral RNA in their exhaled breath. Our findings indicate that influenza viral aerosol shedding varies from season to season. Most volunteers nasally inoculated at a high virus dose did not shed detectable viral RNA in their exhaled breath or show symptoms, suggesting that nasal inoculation may not accurately mimic natural infection. Our results highlight the need for improved models to study the spread of influenza virus in aerosol forms.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations of Insomnia Symptoms and Trajectories with Incident Cardiovascular Disease: A Population-Based Cohort Study\nAbstract: BackgroundThere is limited understanding regarding associations between insomnia symptoms, particularly the trajectories of insomnia symptoms, and cardiovascular disease (CVD). We aimed to investigate the associations of insomnia symptoms and trajectories with the risk of incident CVD.  MethodsThis study used data from the Health and Retirement Study. Insomnia symptoms included non-restorative sleep, difficulty initiating sleep, early morning awakening, and difficulty maintaining sleep, classified on a scale ranging from 0 to 8. We also identified four distinct trajectories of insomnia symptoms: low, decreasing, increasing, and high insomnia symptoms. Examined outcomes included incident heart disease, stroke, and the combination of the two referred as CVD in the present study. Cox proportional hazard models were used to calculate the hazard ratio (HR) and 95% confidence interval (95% CI) after adjusting for potential confounders.  ResultsA total of 12 102 participants aged 50 years or over without CVD at baseline were included. During a median follow-up of 10.2 years, 3 962 first CVD events occurred (3 372 heart disease and 1 200 stroke). Participants experiencing one (HR, 1.16 [95% CI, 1.05-1.27]), two (HR, 1.16 [ 95% CI, 1.05-1.28]), or three to four (HR, 1.26 [95% CI, 1.15-1.38]) insomnia symptoms had a higher risk of incident CVD compared to those not experiencing any insomnia symptoms. After a median follow-up of 8.4 years after the visit 2, 2 375 first CVD events occurred (1 981 heart disease and 705 stroke). Using the trajectory with low insomnia symptoms as the reference, increasing insomnia symptoms (HR, 1.28 [95% CI, 1.10-1.50]) and high insomnia symptoms (HR, 1.32 [95% CI, 1.15-1.50]) were associated with an increased risk of incident CVD.  ConclusionsHigher insomnia symptoms and increasing insomnia symptoms over time are associated with a higher risk of CVD in the community. Public health awareness and screening for insomnia symptoms in the middle-aged and elderly population should be encouraged to reduce CVD.  Clinical PerspectiveO_ST_ABSWhat Is NewC_ST_ABSO_LIParticipants experiencing one, two, or three to four insomnia symptoms had a higher risk of incident CVD compared to those not experiencing any insomnia symptoms. C_LIO_LIHigher insomnia symptoms and increasing insomnia symptoms over time are associated with a higher risk of CVD in the community. C_LI  What Are the Clinical ImplicationsO_LIEarly prevention and mitigation of insomnia symptoms could be beneficial in reducing the population burden of CVD. C_LIO_LIClinicians can provide specific recommendations to improve sleep hygiene as part of a comprehensive approach to reducing the risk of incident CVD. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Collaborative forecasting of influenza-like illness in Italy: the Influcast experience\nAbstract: Collaborative hubs that integrate multiple teams to generate ensemble projections and forecasts for shared targets are now regarded as state-of-the-art in epidemic predictive modeling. In this paper, we introduce Influcast, Italys first epidemic forecasting hub for influenza-like illness. During the 2023/2024 winter season, Influcast provided 20 rounds of forecasts, involving five teams and eight models to predict influenza-like illness incidence up to four weeks in advance at the national and regional administrative level. The individual forecasts were synthesized into an ensemble and bench-marked against a baseline model. The ensemble forecasts consistently outperformed both individual models and baseline forecasts, demonstrating superior accuracy at national and sub-national levels across various metrics. Despite a decline in absolute performance over longer horizons, the ensemble model outperformed the baseline in all considered time frames. These findings underscore the importance of multimodel forecasting hubs in producing consistent short-term influenza-like illnesses forecasts that can inform public health preparedness and mitigation strategies.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-infection dynamics of SARS-CoV-2 and respiratory viruses in the 2022/2023 respiratory season in the Netherlands\nAbstract: ObjectivesEvaluation of the presence and effect of SARS-CoV-2 co-infections on disease severity.  MethodsWe collected both symptom data and nose- and throat samples from symptomatic people during the 2022/2023 respiratory season in a large participatory surveillance study in the Netherlands, and tested these for 18 respiratory viruses including SARS-CoV-2. We compared reported health status, symptoms and odds of having a mono respiratory viral infection or co-infection with SARS-CoV-2 and another respiratory virus.  ResultsIn total 4,655 samples were included with 22% (n=1,017) testing SARS-CoV-2 positive. Of these 11% (n=116) also tested positive for a second respiratory virus. The most frequently occurring co-infections in SARS-CoV-2 positive participants were with rhinovirus (59%; n=69), seasonal coronaviruses (15%; n=17) and adenovirus (7%; n=8). Participants with a co-infection with one of these three viruses did not report more severe disease compared to those with a SARS-CoV-2 mono-infection. The odds of experiencing SARS-CoV-2 co-infection with seasonal coronavirus or rhinovirus were lower compared to the odds of the respective non-SARS-CoV-2 mono-infection (OR: 0.16, CI 95%: 0.10 - 0.24; OR: 0.21 CI 95%: 0.17 - 0.26; respectively).  ConclusionsSARS-CoV-2 co-infections with rhinovirus, seasonal coronavirus and adenovirus are frequently observed in the general population, but are not associated with more severe disease compared to SARS-CoV-2 mono-infections. Furthermore, we found indications for inter-virus interaction with rhinovirus and seasonal coronavirus, possibly decreasing risk of co-infection.  HighlightsOur study showed viral co-infections in 11% of the SARS-CoV-2 positive participants  SARS-CoV-2 mono-infections led to more severe symptoms than the common cold mono-infections with seasonal coronavirus or rhinovirus  SARS-CoV-2 co-infections with common cold viruses did not lead to worse health status compared to SARS-CoV-2 mono-infections  Odds for mono-infection with common cold virus were higher than for co-infection with SARS-CoV-2 and the respective common cold virus\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Border control strategies for reducing importation risk of Clade Ib Mpox\nAbstract: BackgroundThe Clade Ib monkeypox virus (MPXV), newly identified in the ongoing 2024 mpox outbreak, can be more transmissible through non-sexual routes compared to the previous Clade IIb strain. With imported cases sporadically reported globally, concerns have emerged about the potential of widespread transmission in the general community after importation events. Border control measures, such as screening and quarantining of arriving travellers, may help mitigate this risk and prevent localized outbreaks in the event of global spread.  MethodsWe proposed nine border control strategies and evaluated their effectiveness in reducing importation risk using 10,000 microsimulations of individual infection profiles and PCR testing results under scenarios with varying disease prevalence levels (0.01%, 0.05%, and 0.1%) in the country of origin.  ResultsThe proposed border-control measures would reduce missed cases by 40.1% (39.1%-41.0%), 49.8% (48.8%-50.8%), and 58.1% (57.1%-59.0%) for predeparture, on-arrival, and both tests, respectively. Replacing the on-arrival test with a seven-day quarantine and post-quarantine testing would lower the count to 21.8% (20.9%-22.6%). Quarantine-only strategies showed a linear increase in effectiveness against duration, reaching a 90.4% (89.8%-91.0%) reduction with a 28-day quarantine. Disparities in distributions of missed case counts across strategies would become more pronounced at higher prevalence levels, with stringent approaches like quarantining followed by post-quarantine screening and 28-day quarantine keeping counts below two per 10,000 travellers, even at 0.1% prevalence.  ConclusionsWhen disease prevalence in the country of origin is low (0.01%), less restrictive approaches such as single on-arrival testing or a 14-day quarantine can maintain very low imported case counts of one or below. At higher prevalences, seven-day quarantining followed by post-quarantine testing, or 28-day quarantining is required to maintain similar effects. Decision makers will face balancing importation risk management and the negative impacts of such interventions to maintain safe international travel.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reconciling heterogeneous dengue virus infection risk estimates from different study designs\nAbstract: Uncovering rates at which susceptible individuals become infected with a pathogen, i.e. the force of infection (FOI), is essential for assessing transmission risk and reconstructing distribution of immunity in a population. For dengue, reconstructing exposure and susceptibility statuses from the measured FOI is of particular significance as prior exposure is a strong risk factor for severe disease. FOI can be measured via many study designs. Longitudinal serology are considered gold standard measurements, as they directly track the transition of seronegative individuals to seropositive due to incident infections (seroincidence). Cross-sectional serology can provide estimates of FOI by contrasting seroprevalence across ages. Age of reported cases can also be used to infer FOI. Agreement of these measurements, however, have not been assessed. Using 26 years of data from cohort studies and hospital-attended cases from Kamphaeng Phet province, Thailand, we found FOI estimates from the three sources to be highly inconsistent. Annual FOI estimates from seroincidence was 2.46 to 4.33-times higher than case-derived FOI. Correlation between seroprevalence-derived and case-derived FOI was moderate (correlation coefficient=0.46) and no systematic bias. Through extensive simulations and theoretical analysis, we show that incongruences between methods can result from failing to account for dengue antibody kinetics, assay noise, and heterogeneity in FOI across ages. Extending standard inference models to include these processes reconciled the FOI and susceptibility estimates. Our results highlight the importance of comparing inferences across multiple data types to uncover additional insights not attainable through a single data type/analysis.  Significance statementDengue virus infections are surging globally. Knowing who, where, and how many people are at risk of infection is crucial in determining means to protect them. Here, we compare three current approaches in measuring risk (two involving blood samples and one involving case counts) to estimate the risk of infection. Estimates derived from each method differed greatly. By accounting for rise and falls of antibodies following infections, noise in the antibody titer measurements, and heterogeneity in infection risk across ages, we reconciled the measurements. As measurements from blood samples and case counts are pillars in uncovering risk of most infectious diseases, our results signifies integrating these processes into risk measurements of pathogens beyond dengue virus.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mpox vaccination uptake in a UK community sample of gay, bisexual, and other men who have sex with men (GBMSM) the year following the 2022 Clade IIb mpox outbreak\nAbstract: Mpox is an infectious disease transmitted through close contact. It is caused by the monkeypox virus, which is endemic to some countries of West and Central Africa. A multi-country outbreak of mpox occurred in 2022, and the UK experienced rapid community transmission associated with sexual contact, mainly, but not exclusively among networks of gay, bisexual, and other men who have sex with men (GBMSM). In response to the outbreak in the UK, a reactive mpox vaccination programme was targeted to those most at risk. We explore the uptake and course completion of mpox vaccination in GBMSM taking part in an online survey in 2023. Findings from this community sample indicate vaccination uptake in around two-thirds of participants meeting mpox proxy eligibility criteria with high levels of course completion among all and eligible participants that were ever vaccinated. Vaccine non-offer was a barrier to uptake, as nearly a third of those eligible but unvaccinated reported never having received an mpox vaccine offer. Continued targeting of vaccination to GBMSM at highest risk of mpox at SHS, with community-support, will help facilitate equitable uptake of vaccination.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Decoding the Deadly Dance: NETosis Genes Predict Neonatal Sepsis Fate\nAbstract: BackgroundNeonatal sepsis, a systemic inflammatory response to infection, is a major cause of morbidity and mortality in newborns. Neutrophil extracellular trap formation (NETosis), while crucial for pathogen clearance, can contribute to organ dysfunction in sepsis. This study aimed to identify key NETosis-related genes for prognostication in neonatal sepsis.  MethodsWe analysed whole blood transcriptome datasets (GSE26440, GSE26378, GSE25504) from neonates with sepsis and controls. Differentially expressed NETosis genes (DE-NET genes) were identified, and a machine learning approach was used to select the most influential genes. A NET score model was constructed and validated using single-sample gene set enrichment analysis (ssGSEA). The models performance was evaluated using ROC analysis. The interplay between key-NET genes and the complement-coagulation (CC) system was investigated. Clinical samples were also collected for validation.  ResultsSixteen DE-NET genes were identified, and LASSO further refined these to 8 key-NET genes. The key-NET gene signature and NET score model showed excellent predictive performance (AUCs > 89%) in distinguishing survivors from non-survivors. Mediation analysis revealed that key-NET gene expression precedes and potentially drives complement-coagulation activation.  ConclusionsWe present an 8-gene prognostic model for risk stratification in neonatal sepsis, based on early blood transcript signatures in neonates. Our findings underscore the central role of NETosis in sepsis- induced coagulopathy, revealing potential therapeutic targets for intervention.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=135 SRC=\"FIGDIR/small/24313397v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (29K): org.highwire.dtl.DTLVardef@141c8ddorg.highwire.dtl.DTLVardef@1ea52f2org.highwire.dtl.DTLVardef@ebc63eorg.highwire.dtl.DTLVardef@1242a90_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rapid Decline of Mpox Antibody Responses Following MVA-BN Vaccination\nAbstract: The replication-incompetent modified vaccinia Ankara-Bavarian Nordic vaccine (MVA-BN; Jynneos) was deployed during the 2022 clade IIb mpox outbreak. On August 14, 2024, the World Health Organization declared the mpox clade Ib outbreak in the Democratic Republic of the Congo a public health emergency of international concern, which has raised the question about the durability of vaccine immunity after MVA-BN vaccination. In this study, we show that the MVA-BN vaccine generated mpox serum antibody responses that largely waned after 6-12 months.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Inhibition of HIF-2\u03b1 Pathway as a Potential Therapeutic Strategy for Endothelial Dysfunction in Post-COVID Syndrome\nAbstract: BackgroundSARS-CoV-2 infection may lead to Post-COVID Syndrome (PCS), characterized by debilitating symptoms like persistent fatigue, cardiovascular symptoms, and cognitive dysfunction. Persistent endothelial dysfunction (ED) is a potential driver of ongoing symptoms. Yet, the underlying biological mechanisms remain unclear.  MethodsIn this prospective observational study, we characterized 41 PCS patients and 24 healthy controls (HC, matched out of n = 204, recruited before the pandemic) and investigated the effect of SARS-CoV-2 Spike protein 1 (S1) and plasma from PCS patients on human retinal endothelial cells (HREC).  ResultsPlasma samples from PCS patients exhibited significantly elevated erythropoietin, VEGF and MCP-1 alongside decreased IL-6 levels compared to HC. Low Haemoglobin and Haematocrit were negatively associated with PCS severity. VEGF levels were positively correlated with Anti-S1 IgG levels in patients and upregulated on mRNA level in HREC exposed to S1. Additionally, S1 exposure promoted ROS production and transiently activated HIF-1 in HREC. Persistent activation of HIF-2 by S1 led to disrupted endothelial integrity. HREC exposed to plasma from severely affected PCS patients showed increased ROS and compromised barrier function. Treatment with Belzutifan, a HIF-2 inhibitor, restored barrier integrity in HREC exposed to S1 or PCS-plasma.  ConclusionThese findings suggest that HIF-2-mediated ED in PCS might be a potential therapeutical target for Belzutifan.  Trial registrationURL: https://www.clinicaltrials.gov; Unique identifier: NCT05635552  Novelty and significanceO_ST_ABSWhat Is Known?C_ST_ABSO_LIEndothelial dysfunction (ED) is a consequence of acute SARS-CoV-2 infection and may lead to Post-COVID syndrome (PCS) symptoms. C_LIO_LIPatients with PCS show elevated inflammation and endothelial dysfunction markers. C_LIO_LISpike proteins can persist for up to 12 months post-infection, driving ongoing inflammation and immune activation. C_LI  What New Information Does This Article Contribute?O_LILow haemoglobin (Hb) and high VEGF correlate with higher Anti-S1 IgG and low Hb is associated with higher C19-YRS severity score. C_LIO_LIPCS patients exhibit higher Erythropoietin (EPO) levels when compared to HC. C_LIO_LISpike protein 1 (S1) alone and PCS patients plasma induce endothelial dysfunction primarily through HIF-2 activation. C_LIO_LIBoth S1 and PCS plasma cause oxidative stress and disrupting endothelial integrity. C_LIO_LIInhibition of HIF-2 effectively restores endothelial barrier integrity disrupted by S1 and PCS plasma. C_LI  Persistent circulation of spike proteins can sustain chronic inflammation and immune activation in patients with PCS. Here we show that plasma from PCS patients exhibits significantly elevated levels of VEGF which positively correlates with Anti-S1 IgG. Low haemoglobin was associated with higher Anti-S1 IgG titres and correlated with a higher C19-YRS severity score. Levels of EPO were higher in PCS patients, with a more pronounced effect observed in patients with cardiovascular symptoms. In human retinal endothelial cells, both S1 and plasma from PCS patients primarily induce ED through HIF-2 activation, rather than NF-{kappa}B. Both factors lead to significant oxidative stress, evidenced by increased ROS production which in turn disrupts endothelial barrier integrity and function. Notably, Belzutifan, a HIF-2 inhibitor, can restore this compromised endothelial function, offering a potential therapeutic target for PCS.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=143 SRC=\"FIGDIR/small/24313403v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (35K): org.highwire.dtl.DTLVardef@19df9e4org.highwire.dtl.DTLVardef@80eba4org.highwire.dtl.DTLVardef@1ee6680org.highwire.dtl.DTLVardef@8b6bd3_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dissection of the 'Virgin-soil' epizootic of African swine fever in Mizoram, a Northeast state of India\nAbstract: This article aims to analyse the first-time emergence of African swine fever (ASF) in Mizoram. We collated the outbreak data and identified the time and locations of ASF emergence. To understand the impact of the outbreak, we have calculated the morbidity rate, mortality rate, case fatality rate (CFR) and overall pig depopulation rate. We identified that ASF emerged in total 178 locations in all 11 districts of Mizoram between March-July 2021, after a peak in June, and the disease continued to spread till the end of 2021 before re-emergence in March 2022. The overall morbidity rate and mortality rate of ASF between March-July 2021 in Mizoram were estimated to be 33.8% and 31.1%, while the average morbidity rate and the mortality rate of 10 districts were found to be 29.5% and 27.6% respectively. Overall CFR of ASF between March-July 2021 was estimated to be 92.1% and the average of all 11 districts was found to be 96.1%. Toward the end of 2021, the mortality rate increased by a total of 42.7% change and an average of 25.3% change. We estimated an overall 70% depopulation of susceptible pigs by disease and culling by end of 2021. This report is evidence that ASF has remained catastrophic and, keeping in view the complex nature and history of the virus on genotype adaptability associated with a high propensity for transboundary expansion, the virus continues to be a threat.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk factors for typhoid fever: A desk review\nAbstract: Background and AimTyphoid fever, a significant global health problem, demonstrates a multifaceted transmission pattern. Knowledge of the factors driving the transmission of infection is critical for developing effective control strategies and resource allocation. This comprehensive desk review aimed at synthesizing evidence from 1928 to 2023 on risk factors associated with typhoid fever transmission.  MethodWe conducted article searches in PubMed, Scopus, Google Scholar, and Semantic Scholar, using keywords related to risk, contributors, determinants, causes etc. associated with typhoid fever. We followed a registered protocol to support our search and triangulated the results.  ResultsIn all, we retrieved 1614 articles, of which 216 were reviewed. Of these articles reviewed, 106 provided data on typhoid fever risk factors. Unsurprisingly, of the total articles reviewed on risk factors, about 72% (76/106) originated from the Asian (48.1%, 51/106) and African (23.6%, 25/106) continents. A higher proportion, 47.2% (50/106) of the articles indicated risk factors related to socio-economic and housing transmission. Additional risk factors included foodborne transmissions (45.3%, 48/106), WASH: Waterborne transmissions (42.5%, 45/106), Sanitation and Hygiene practices (32.1%, 34/106), travel-related risk (16.0%, 17/106), antimicrobial agents (13.2%, 14/106), climate (13.2%, 14/106), environmental (8.5%, 9/106), typhoid carriers (10.4%, 11/106), and host risk (5.7%, 6/106) factors to disease transmission.  ConclusionThese findings highlight the necessity for targeted and combined interventions including improved sanitation infrastructure, enhanced WASH practices and the use of vaccines in endemic areas. Implementing effective strategies informed by this review can aid clinicians, public health experts, and policymakers in efficiently mitigating the burden of typhoid fever.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk factors for typhoid fever: A desk review\nAbstract: Background and AimTyphoid fever, a significant global health problem, demonstrates a multifaceted transmission pattern. Knowledge of the factors driving the transmission of infection is critical for developing effective control strategies and resource allocation. This comprehensive desk review aimed at synthesizing evidence from 1928 to 2023 on risk factors associated with typhoid fever transmission.  MethodWe conducted article searches in PubMed, Scopus, Google Scholar, and Semantic Scholar, using keywords related to risk, contributors, determinants, causes etc. associated with typhoid fever. We followed a registered protocol to support our search and triangulated the results.  ResultsIn all, we retrieved 1614 articles, of which 216 were reviewed. Of these articles reviewed, 106 provided data on typhoid fever risk factors. Unsurprisingly, of the total articles reviewed on risk factors, about 72% (76/106) originated from the Asian (48.1%, 51/106) and African (23.6%, 25/106) continents. A higher proportion, 47.2% (50/106) of the articles indicated risk factors related to socio-economic and housing transmission. Additional risk factors included foodborne transmissions (45.3%, 48/106), WASH: Waterborne transmissions (42.5%, 45/106), Sanitation and Hygiene practices (32.1%, 34/106), travel-related risk (16.0%, 17/106), antimicrobial agents (13.2%, 14/106), climate (13.2%, 14/106), environmental (8.5%, 9/106), typhoid carriers (10.4%, 11/106), and host risk (5.7%, 6/106) factors to disease transmission.  ConclusionThese findings highlight the necessity for targeted and combined interventions including improved sanitation infrastructure, enhanced WASH practices and the use of vaccines in endemic areas. Implementing effective strategies informed by this review can aid clinicians, public health experts, and policymakers in efficiently mitigating the burden of typhoid fever.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterising global risk profiles of Mpox clade Ib importation\nAbstract: The novel mpox clade Ib initially identified in the Domestic Republic of Congo has spread to its multiple neighbouring countries as well as countries beyond the African continent. We characterised the global risk of importation of mpox clade Ib, highlighting the need to ramp up surveillance capacity for early detection.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Does the choice of stepping intensity metric influence dose-response associations with mortality? A UK population cohort study of 70,174 adults\nAbstract: BackgroundResearch on the health effects of stepping intensity in free-living environments is limited and inconclusive. Inconsistent use of stepping intensity estimation metrics could explain current equivocal results. We aimed to examine and compare a range of different cadence-based metrics in terms of their multivariable-adjusted associations with all-cause (ACM) cardiovascular disease (CVD), cancer and physical-activity (PA)-related cancer mortality.  MethodsThis prospective cohort study included participants with valid wrist-worn accelerometer data from the UK Biobank. We estimated stepping intensity using ten different cadence-based metrics, including eight peak-cadence metrics (defined as averaged steps / min of the highest but not necessarily consecutive minutes) that most of whom have appeared in prior literature, plus two non-peak-cadence metrics: 1) average daily cadence, defined as steps/accelerometer wearing mins, and 2) average cadence of purposeful steps, defined as averaged steps / min of minutes with [&ge;]40 steps. We rescaled each metric into a standardised cadence scale with mean of 0 and standard deviation (SD) of 1, using (absolute-mean)/SD. We compared the dose-response associations of each stepping intensity estimation metrics with mortality outcomes using previously published modelling involving Cox-restricted-cubic-spline model, presented as overlay plots on standardised and absolute cadence scales.  ResultsAmong 70,336 participants (age [SD], 61.6 [7.8] years; female, 40,933 [58%]) followed up for a median of 8.0 years, all cadence-based metrics, besides the average cadence of purposeful steps, exhibited a comparable beneficial dose-response association with ACM/CVD/cancer mortality, with 95% CI largely overlapped (e.g., at -0.2 standardised steps/min, the hazard ratio (HR) of ACM for peak 1- and peak 30-min cadence were: 0.72, 95%CI [0.65, 0.82] and 0.66 [0.60, 0.73], respectively). The average cadence of purposeful steps only did not show dose-response associations with mortality outcomes (e.g., the HR that corresponds to the standardised median for the average cadence of purposeful steps in ACM was 0.98 [95% CI: 0.86, 1.12].  ConclusionBesides the average cadence of purposeful steps, all stepping intensity estimation metrics demonstrated comparable beneficial dose-response associations with mortality of all-cause, CVD and cancer, suggesting these cadence-based metrics may be used interchangeably for estimating associations of free-living stepping intensity with health outcomes and applied in different research scenarios accordingly.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Real-World Effectiveness of Nirsevimab Against Respiratory Syncytial Virus: A Test-Negative Case-Control Study\nAbstract: IMPORTANCENirsevimab, a long-acting monoclonal antibody, has demonstrated efficacy against RSV-related lower respiratory tract infections (LRTIs) in clinical trials. Post-licensure monitoring is essential to confirm these benefits in real-world settings.  OBJECTIVETo evaluate the real-world effectiveness of nirsevimab against medically attended RSV infections in infants and to assess how effectiveness varies by disease severity, dosage, and time since immunization.  DESIGN, SETTING, AND PARTICIPANTSThis test-negative case-control study used inpatient, outpatient, and emergency room data from the Yale New Haven Health System. Nirsevimab-eligible infants who were tested for RSV using polymerase chain reaction between October 1, 2023 and May 9, 2024 were included. Cases were infants with confirmed RSV infections; controls were those who tested negative.  EXPOSURENirsevimab immunization, verified through state immunization registries.  MAIN OUTCOMES AND MEASURESEffectiveness was estimated using multivariable logistic regression, adjusting for age, calendar month, and individual risk factors. Separate models examined effectiveness by clinical setting, disease severity, dose, and time since immunization. Broader outcomes, including all-cause LRTI and LRTI-related hospitalization, were also analyzed, with stratification by early and late respiratory seasons.  RESULTSThe analytic sample included 3,090 infants (median age 6.7 months, IQR 3.6-9.7), with 680 (22.0%) RSV-positive and 2,410 (78.0%) RSV-negative. 21 (3.1%) RSV-positive and 309 (12.8%) RSV-negative infants received nirsevimab. Effectiveness against RSV infection was 68.4% (95% CI, 50.3%-80.8%). Effectiveness was 61.6% (95% CI, 35.6%-78.6%) for outpatient visits and 80.5% (95% CI, 52.0%-93.5%) for hospitalizations. The highest effectiveness, 84.6% (95% CI, 58.7%-95.6%), was observed against severe RSV outcomes requiring ICU admission or high-flow oxygen. Although effectiveness against RSV infections declined over time, it remained significant at 55% (95% credible interval, 16%-75%) at 14 weeks post-immunization. Protective effectiveness was also observed against all-cause LRTI and LRTI-related hospitalizations during peak RSV season (49.4% [95% CI, 10.7%-72.9%] and 79.1% [95% CI, 27.6%-94.9%], respectively). However, from February to May, when RSV positivity was low, effectiveness against these broader outcomes was negligible.  CONCLUSIONS AND RELEVANCENirsevimab provided substantial protection against RSV-related outcomes for at least three months. These findings support the continued use of nirsevimab and provide evidence that may help build public confidence in the immunization program.  Key PointsO_ST_ABSQuestionC_ST_ABSWhat is the effectiveness of nirsevimab against medically attended respiratory syncytial virus (RSV) infections in infants?  Findings680 RSV test-positive cases and 2,410 RSV test-negative controls were included in this test-negative case-control study. Nirsevimabs effectiveness was 69% against RSV infections, 81% against RSV-associated hospitalization, and 85% against severe RSV disease. Effectiveness against RSV infection declined from 79% at 2 weeks post-immunization to 55% at 14 weeks post-immunization.  MeaningNirsevimab provides strong protection against a wide range of RSV outcomes, but its effectiveness diminishes over time. These data can be utilized to optimize nirsevimabs implementation and sustain its uptake.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Shortened SARS-CoV-2 shedding in saliva during early Omicron compared to wild-type pandemic phase\nAbstract: This study compared the dynamics of SARS-CoV-2 viral shedding in saliva between wild-type virus-infected and Omicron-infected household cohorts. Pre-existing immunity in participants likely shortens duration of viral shedding and lowers viral load peaks. Dense saliva sampling can be a convenient tool to study viral load dynamics.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Network biology and bioinformatics-based framework to identify the impacts of SARS-CoV-2 infections on lung cancer and tuberculosis\nAbstract: The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a coronavirus variation responsible for COVID-19, the respiratory disease that triggered the COVID-19 pandemic. The primary aim of our study is to elucidate the complex network of interactions between SARS-CoV-2, tuberculosis, and lung cancer employing a bioinformatics and network biology approach. Lung cancer is the leading cause of significant illness and death connected to cancer worldwide. Tuberculosis (TB) is a prevalent medical condition induced by the Mycobacterium bacteria. It mostly affects the lungs but may also have an influence on other areas of the body. Coronavirus disease (COVID-19) causes a risk of respiratory complications between lung cancer and tuberculosis. SARS-CoV-2 impacts the lower respiratory system and causes severe pneumonia, which can significantly increase the mortality risk in individuals with lung cancer. We conducted transcriptome analysis to determine molecular biomarkers and common pathways in lung cancer, TB, and COVID-19, which provide understanding into the association of SARS-CoV-2 to lung cancer and tuberculosis. Based on the compatible RNA-seq data, our research employed GREIN and NCBIs Gene Expression Omnibus (GEO) to perform differential gene expression analysis. Our study exploited three RNA-seq datasets from the Gene Expression Omnibus (GEO)--GSE171110, GSE89403, and GSE81089--to identify distinct relationships between differentially expressed genes (DEGs) in SARS-CoV-2, tuberculosis, and lung cancer. We identified 30 common genes among SARS-CoV-2, tuberculosis, and lung cancer (25 upregulated genes and 5 downregulated genes). We analyzed the following five databases: WikiPathway, KEGG, Bio Carta, Elsevier Pathway and Reactome. Using Cytohubbas MCC and Degree methods, We determined the top 15 hub genes resulting from the PPI interaction. These hub genes can serve as potential biomarkers, leading to novel treatment strategies for disorders under investigation. Transcription factors (TFs) and microRNAs (miRNAs) were identified as the molecules that control the differentially expressed genes (DEGs) of interest, either during transcription or after transcription. We identified 35 prospective therapeutic compounds that form significant differentially expressed genes (DEGs) in SARS-CoV-2, lung cancer, and tuberculosis, which could potentially serve as medications. We hypothesized that the potential medications that emerged from this investigation may have therapeutic benefits.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dynamic HIV risk differentiation among youth: Validation of a tool for prioritization of prevention in East Zimbabwe\nAbstract: BackgroundDifferentiating risk for HIV infection is important for providing focussed prevention options to individuals. We conducted a longitudinal study to validate a risk-differentiation tool for predicting HIV or HSV-2 acquisition among HIV-negative youth.  SettingPopulation-based household survey in east Zimbabwe.  MethodsHIV and HSV-2 status and HIV behavioural risk factors were assessed in two surveys conducted 12 months apart among young people. Associations between risk-behaviours and combined HIV/HSV-2 incident infection were estimated using proportional hazards models. We calculated the sensitivity and specificity of risk-differentiation questions in predicting HIV/HSV-2 acquisition and quantified changes between surveys among low, medium, and high-risk categories.  ResultsIn total, 44 HIV/HSV-2 seroconversions were observed in 1812 person-years of follow up (2.43/100PY, 95%CI: 1.71-3.15); 50% of incident cases reported never having had sex at baseline. Risk of HIV/HSV-2 acquisition was higher for those reporting non-regular partners (women: HR=2.71, 95% CI:1.12-6.54, men: HR=1.37, 95%CI: 0.29-6.38) and those reporting having a partner with a sexually transmitted infection (STI) (HR=7.62 (1.22-47.51). Adding a question on non-regular partnerships increased tool sensitivity from 18.2% to 38.6%, and further to 77.3% when restricted to those who had ever had sex. Individual risk category increased for 28% of men and 17% of women over 12-months.  ConclusionThe refined risk differentiation tool identified a high proportion of youth at risk of HIV acquisition. Despite this, half of incident infections were among individuals who reported no prior sexual activity. The shifting patterns of risk behaviours underscore the need for dynamic prevention engagement strategies in high HIV prevalence or incidence settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adjusting for specificity of symptoms reveals higher prevalence of asymptomatic SARS-CoV-2 infections than previously estimated\nAbstract: Accurate estimates of the prevalence of asymptomatic SARS-CoV-2 infections,{psi} , have been important for understanding and forecasting the trajectory of the COVID-19 pandemic. Two-part population-based surveys, which test the infection status and also assess symptoms, have been used to estimate{psi} . Here, we identified a widely prevalent confounding effect that compromises these estimates and devised a formalism to adjust for it. The symptoms associated with SARS-CoV-2 infection are not all specific to SARS-CoV-2. They can be triggered by a host of other conditions, such as influenza virus infection. By not accounting for the source of the symptoms, the surveys may misclassify individuals experiencing symptoms from other conditions as symptomatic for SARS-CoV-2, thus underestimating{psi} . We developed a rigorous formalism to adjust for this confounding effect and derived a facile formula for the adjusted prevalence,{psi} adj. We applied it to data from 50 published serosurveys, conducted on the general populations from 28 nations. We found that{psi} adj was significantly higher than the reported prevalence,{psi} c (P=3x10-8). The median{psi} adj was [~]60%, whereas the median{psi} c was [~]40%. In several instances,{psi} adj exceeded{psi} c by >100%. These findings suggest that asymptomatic infections have been far more prevalent than previously estimated. Our formalism can be readily deployed to obtain more accurate estimates of{psi} from standard population-based surveys, without additional data collection. The findings have implications for understanding COVID-19 epidemiology and devising more effective interventions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of Respiratory Syncytial Virus (RSV) in adults 60 years and older in Spain.\nAbstract: Respiratory illnesses frequently lead to hospitalisation in adults aged 60 and older, especially due to respiratory virus infectious (RVIs). This study investigates hospitalisation patterns and characteristics of RVIs at HM Hospitals from October 2023 to March 2024.  We retrospectively explored hospitalisations of patients aged 60 years and older with RVIs, gathering data on demographics, clinical profiles, comorbidities, and treatments. Outcomes included hospitalisation, ICU admissions, and mortality, independent factors associated with outcomes were identified using a multi-state model.  From October 2023 to March 2024, from a total of 3,258 hospitalisation, 1,933 (59.3%) were identified as positive for RVIs. Overall, SARS-CoV-2 was the most prevalent (52.6%), followed by influenza (32.7%) and RSV (11.8%). Most RVIs involved single infections (88.2%). Hospitalisation rates increased with age for SARS-CoV-2, influenza, and RSV, with SARS-CoV-2 showing the highest rate, followed by influenza and RSV.  In the multi-state model, RSV infection significantly increased ICU admission risk (HR: 2.1, 95%, p = 0.037). Age on admission (HR: 1.1, 95%, p < 0.001) and Charlson score (HR: 1.4, 95%, p = 0.001) were associated with transitioning from admission to death. ICU to death risks included age at admission (HR: 1.7, 95%, p < 0.001).  RVIs in adults 60 years and older are associated with high hospitalisation and mortality rates, primarily driven by influenza and SARS-CoV-2, followed by RSV. Age and comorbidities significantly impact disease severity, emphasising the need for targeted prevention and management strategies for RSV in this vulnerable population.  FundingThis studio received no funding.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Malaria prevalence and its associated factors amongst rural adults: Cross-sectional study in East Nusa Tenggara Province Indonesia\nAbstract: IntroductionMalaria is a global health issue including in Indonesia. Currently, most of the cases was in the rural of eastern part of the country. However, malaria risk factors amongst rural adult were less documented. This study investigated malaria risk factors amongst rural adults in East Nusa Tenggara Province (ENTP).  MethodsA community based cross-sectional study was conducted to interview 1495 rural adults in ENTP. A multi-stage cluster random sampling technique was applied to collect data on malaria history, demographic, behavioural and environmental factors of malaria of participants. Logistic regression model was applied to decide significant factors associated with malaria.  ResultsThe prevalence of malaria was 13.4%. The prevalence of malaria was significantly higher for adults with low level of malaria knowledge (Adjusted odd ratio (AOR): 2.43, 95% confidence interval (CI): 1.38 - 4.27) compared to those with high malaria knowledge level, having moderate malaria knowledge level (AOR: 1.99, 95% CI: 1.11 - 3.57) compared to those high malaria knowledge level, having no education (AOR: 2.18, 95% CI: 1.37 - 3.45) compared to those junior high school or above education level, outdoor occupation (AOR: 1.81, 95% CI: 1.22 - 2.68) compared to indoor occupation, having family size > 4 (AOR 2.08, 95% CI: 1.52 -2.87) compared to those [&le;] 4  ConclusionThe study revealed the prevalence of malaria amongst rural adults in this province was high. The study highlights the power of malaria knowledge level on the prediction of malaria prevalence amongst rural adults. Health education intervention is critical for vulnerable groups to reduce malaria prevalence in the province.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence of Chikungunya, Dengue, and West Nile arboviruses in Iran based on enzyme-linked immunosorbent assay (ELISA): A systematic review and meta-analysis\nAbstract: IntroductionArboviruses, including Chikungunya (CHIKV), Dengue (DENV), and West Nile (WNV) viruses, are significant viral threats that affect numerous people globally each year. This report explore the prevalence of these viruses in Iran through a systematic review and meta-analysis.  MethodsThe present survey was performed with a systematic review and meta-analysis method on the seroprevalence of WNV, CHIKV, and DENV using the ELISA test. Based on this, by search in Web of Science, PubMed, Scopus, Cochrane Library, Science Direct, and Google Scholar scientific databases, all relevant published papers were sorted out and reviewed. Power ratification of data was carried out with a random effects model in meta-analysis, meta-regression, I2 index, and Egger test.  ResultsTwelve published papers between 2000 and 2024 were embodied in this meta-analysis report. The seroprevalence of positive ELISA test for WNV in Iran was estimated at 12.9% (CI=95%: 7.4-18.4), and for CHIKV at 6.2% (CI=95%: 0.6-11.8). Regarding DENV, only two studies were conducted with a zero prevalence in one study, and a seroprevalence of 5.6% in another study.  ConclusionAccording to these data, WNV, CHIKV, and DENV fevers have been detected in Iran using ELISA test. Considering the seropositivity of WNV and CHIKV, and the finding of these viruses from several provinces, it could be for granted that these two viruses are ubiquitous and DENV fever is sporadic in Iran.  Author SummaryArboviruses, including Chikungunya (CHIKV), Dengue (DENV), and West Nile (WNV), pose significant health threats globally, with increasing infections reported, including in Iran. This report conducts a systematic review and meta-analysis of the seroprevalence of these viruses in Iran through ELISA testing. A total of twelve studies published from 2000 to 2024 were analyzed, revealing a seroprevalence of 12.9% for WNV and 6.2% for CHIKV, while DENV showed a mixed prevalence of 0% in one study and 5.6% in another. The results suggest that WNV and CHIKV are widespread in Iran, whereas DENV appears to be sporadic.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Antibiotic susceptibility trend estimation for India based on 2018 to 2021 data from GEARS program\nAbstract: Antimicrobial resistance (AMR) continues to be a major public threat due to dwindling supplies of effective antibiotics due to its excessive usage in humans and food producing animals. The objective of our study was to identify and predict future trends in multi-drug resistance amongst enterobacteriaceae and non-enterobacteriaceae family in India for four common broad-spectrum antibiotics. We focussed on four broad spectrum antibiotics levofloxacin, gentamicin, cefepime, and ceftazidime and classified the GEARS program study dataset into sensitive (S), intermediate(I) and resistant (R) isolates based on CLSI breakpoints. Levofloxacin (98.3%) was found to be the most susceptible broad spectrum antibiotic for treatment of non-enterobacteriaceae while it was relatively resistant (56.5%) for enterobacteriaceae treatment. As levofloxacin are among ICMR list of  alert antimicrobial agents,hospitals and clinicans can exercise greater care before prescribing them.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Protection of vaccine boosters and prior infection against mild/asymptomatic and moderate COVID-19 infection in the UK SIREN healthcare worker cohort: October 2023 to March 2024\nAbstract: ObjectiveTo estimate the protection of COVID-19 vaccine boosters against mild/asymptomatic and moderate SARS-CoV-2 infection over a 6-month period of XBB.1.5 and JN.1 variant circulation.  DesignMulti-state model applied to cohort study, adjusted for vaccination, prior infection, and demographic covariates.  SettingNational Health Services (NHS) hospitals in the UK.  ParticipantsHealthcare worker cohort including 2,867 eligible people with >6 months since a previous booster who tested fortnightly for SARS-CoV-2 between October 2023 and March 2024 and completed symptoms questionnaires.  Main outcome measuresVaccine effectiveness (VE) of vaccine boosters received in October 2023 (baseline: booster >6 months prior), and durability of protection from a recent (past 6 months) previous infection (baseline: last infection >2 years prior) against mild/asymptomatic and moderate SARS-CoV-2 infection. Mild symptoms included acute respiratory symptoms for <5 days, moderate symptoms included influenza-like illness, acute respiratory symptoms for 5+ days, or sick-leave. VE and acquired protection were estimated from the multi-state model as: 1 - adjusted hazard ratio.  InterventionsReceipt of a COVID-19 bivalent original/BA.4-5 or monovalent XBB.1.5 booster during October 2023.  ResultsHalf of eligible participants (1,422) received a booster during October 2023 (280 bivalent, 1,142 monovalent) and 536 (19%) had at least one PCR-confirmed infection over the study period. For the monovalent booster, VE against infection was 44.2% (95% confidence interval 21.7 to 60.3%) at 0-2 months, and 24.1% (-0.7 to 42.9%) at 2-4 months post-vaccination, with no evidence of protection by 4-6 months. For the bivalent booster, VE against infection was 15.1% (-55.4 to 53.6%) at 0-2 months and 4.2% (-46.4 to 37.3%) at 2-4 months. VE (monovalent or bivalent) against moderate infection was 39.7% (19.9 to 54.6%), and against mild/asymptomatic infection was 14.0% (-12.1 to 34.0%). Controlling for vaccination, compared to those with an infection >2 years prior, infection within the past 6 months was associated with 58.6% (30.3 to 75.4%) increased protection against moderate infection, and 38.5% (5.8 to 59.8%) increased protection against mild/asymptomatic infection.  ConclusionsMonovalent XBB.1.5 boosters provided short-term protection against SARS-CoV-2 infection, particularly against moderate symptoms. Vaccine formulations which target the circulating variant may be suitable for inclusion in seasonal vaccination campaigns among healthcare workers.  FundingUK Health Security Agency, Medical Research Council, NIHR HPRU Oxford, and others.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Whole genome sequencing of hepatitis B virus (HBV) using tiled amplicon (HEP-TILE) and probe-based enrichment on Illumina and Nanopore platforms.\nAbstract: Hepatitis B virus (HBV) whole genome sequencing (WGS) is currently limited as the DNA viral loads (VL) of many clinical samples are below the threshold required to generate full genomes using current sequencing methods. We developed two pan-genotypic viral enrichment methods, using probe-based capture and tiled amplicon PCR (HEP-TILE) for HBV WGS. We demonstrate using mock samples that both enrichment methods are pan-genotypic (genotypes A-J). Using clinical samples, we demonstrate that HEP-TILE amplification successfully amplifies full genomes at the lowest HBV VL tested (30 IU/ml), and the PCR products can be sequenced using both Nanopore and Illumina platforms. Probe-based capture with Illumina sequencing required VL >300,000 IU/ml to generate full length HBV genomes. The capture-Illumina and HEP-TILE-Nanopore pipelines had consensus sequencing accuracy of 100% in mock samples with known DNA sequences. Together, these protocols will facilitate the generation of HBV sequence data, enabling a more accurate and representative picture of HBV molecular epidemiology, cast light on persistence and pathogenesis, and enhance understanding of the outcomes of infection and its treatment.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Timely vaccine strain selection and genomic surveillance improves evolutionary forecast accuracy of seasonal influenza A/H3N2\nAbstract: For the last decade, evolutionary forecasting models have influenced seasonal influenza vaccine design. These models attempt to predict which genetic variants circulating at the time of vaccine strain selection will be dominant 12 months later in the influenza season targeted by vaccination campaign. Forecasting models depend on hemagglutinin (HA) sequences from the WHOs Global Influenza Surveillance and Response System to identify currently circulating groups of related strains (clades) and estimate clade fitness for forecasts. However, the average lag between collection of a clinical sample and the submission of its sequence to the Global Initiative on Sharing All Influenza Data (GISAID) EpiFlu database is [~]3 months. Submission lags complicate the already difficult 12-month forecasting problem by reducing understanding of current clade frequencies at the time of forecasting. These constraints of a 12-month forecast horizon and 3-month average submission lags create an upper bound on the accuracy of any long-term forecasting model. The global response to the SARS-CoV-2 pandemic revealed that modern vaccine technology like mRNA vaccines can reduce how far we need to forecast into the future to 6 months or less and that expanded support for sequencing can reduce submission lags to GISAID to 1 month on average. To determine whether these recent advances could also improve long-term forecasts for seasonal influenza, we quantified the effects of reducing forecast horizons and submission lags on the accuracy of forecasts for A/H3N2 populations. We found that reducing forecast horizons from 12 months to 6 or 3 months reduced average absolute forecasting errors to 25% and 50% of the 12-month average, respectively. Reducing submission lags provided little improvement to forecasting accuracy but decreased the uncertainty in current clade frequencies by 50%. These results show the potential to substantially improve the accuracy of existing influenza forecasting models by modernizing influenza vaccine development and increasing global sequencing capacity.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How does date-rounding affect phylodynamic inference for public health?\nAbstract: Phylodynamic analyses enable the inference of epidemiological parameters from pathogen genome sequences for enhanced genomic surveillance in public health. Pathogen genome sequences and their associated sampling times are the essential data in every analysis. However, sampling times are usually associated with hospitalisation or testing dates and can sometimes be used to identify individual patients, posing a threat to patient confidentiality. To lower this risk, sampling times are often given with reduced date-resolution to the month or year, which can potentially bias inference of epidemiological parameters. Here, we characterise the extent to which reduced date-resolution biases phylodynamic analyses across a diverse range of empirical and simulated datasets. We develop a practical guideline on when date-rounding biases phylodynamic inference and we show that this bias is both unpredictable in its direction and compounds with decreasing date-resolution, higher substitution rates, and shorter sampling intervals. We conclude by discussing future solutions that prioritise patient confidentiality and propose a method for safer sharing of sampling dates by translating them uniformly by a random number.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Sex-specific Mendelian Randomization-Phenome-Wide Association Study of Body Mass Index\nAbstract: BackgroundTrials of incretins are making it increasingly clear that body mass index (BMI) is linked to several diseases throughout life, but trials cannot provide a comprehensive assessment of the role of BMI in health-related attributes for men and women. To systematically investigate the role of BMI, we conducted a sex-specific Mendelian randomization-phenome-wide association study.  MethodsWe comprehensively examined the associations of genetically predicted BMI in women (n: 194,174) and men (n: 167,020) with health-related attributes from the UK Biobank with inverse variance weighting and sensitivity analysis.  ResultsBMI impacted 232 of 776 traits considered in women and 204 of 681 traits in men, after adjusting for false discovery; differences by sex were found for 105 traits. BMI was more strongly positively associated with heart disease, heart failure and hypertensive heart disease in men than women. BMI was more strongly positively associated with apolipoprotein B (ApoB), diastolic blood pressure, neuroticism, arthritis and triglycerides in women than men.  ConclusionOur study revealed that BMI might affect a wide range of health-related attributes and highlights notable sex differences in its impact, including opposite associations for certain attributes, such as ApoB and neuroticism. These findings emphasize the importance of maintaining a healthy BMI.  FundingNone\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impacts of the COVID-19 pandemic on sepsis incidence, etiology and hospitalization costs in France: a retrospective observational study\nAbstract: BackgroundSepsis is a serious medical condition that causes long-term morbidity and high mortality, annually affecting millions of people worldwide. The COVID-19 pandemic may have impacted its burden.  ObjectiveTo estimate the impact of the COVID-19 pandemic on sepsis incidence, etiology and associated hospitalization costs in metropolitan France.  MethodsThis retrospective observational study used data drawn from a cohort of hospitalized sepsis patients in Frances national healthcare database. Sepsis was identified through both explicit ICD-10 codes (E-sepsis) and implicit codes (I-sepsis). Participants included all patients aged 15 years or older hospitalized with E-sepsis or I-sepsis in metropolitan France between January 1, 2018, and December 31, 2022. Patient and hospital stay characteristics were described by sepsis type (E-sepsis, I-sepsis) and overall. The distribution of sepsis etiology was estimated for each year. Annual incidence rates were estimated overall and by sepsis type and etiology. Total and median per-stay hospitalization costs were calculated.  ResultsThe total age- and sex-standardized sepsis incidence rate per 100,000 increased slightly from 2018 (446, 95% CI 444.2 to 447.7) to 2020 (457, 95% CI 455.1 to 458.6) and then decreased in 2022 (382, 95% CI 380.2-383.7) (p <.0001). Incidence rates decreased for both E-sepsis and bacterial sepsis during the pandemic period, whereas I-sepsis incidence increased in 2020 and 2021, associated with a marked increase in viral sepsis and co-infections (p <.0001 for E- and I-sepsis). Viral sepsis represented about 10% of all sepsis cases during the pandemic, but only about 1% prior to the pandemic. Total sepsis-associated hospitalization costs and extra medication costs increased during the pandemic. Characteristics of patients and their hospital stays were overall stable over the five-year study period.  ConclusionsThe COVID-19 pandemic led to a higher burden of sepsis in French hospitals and an increase in hospital stay costs. Critically, our study highlights the need for introducing explicit viral sepsis codes within the ICD-11 classification system and for achieving a consensus on its definition in order to robustly estimate sepsis incidence.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Steroid Hormone Biosynthesis and Dietary Related Metabolites associated with Excessive Daytime Sleepiness\nAbstract: BackgroundExcessive daytime sleepiness (EDS) is a complex sleep problem that affects approximately 33% of the United States population. Although EDS usually occurs in conjunction with insufficient sleep, and other sleep and circadian disorders, recent studies have shown unique genetic markers and metabolic pathways underlying EDS. Here, we aimed to further elucidate the biological profile of EDS using large scale single- and pathway-level metabolomics analyses.  MethodsMetabolomics data were available for 877 metabolites in 6,071 individuals from the Hispanic Community Health Study/Study of Latinos (HCHS/SOL) and EDS was assessed using the Epworth Sleepiness Scale (ESS) questionnaire. We performed linear regression for each metabolite on continuous ESS, adjusting for demographic, lifestyle, and physiological confounders, and in sex specific groups. Subsequently, gaussian graphical modelling was performed coupled with pathway and enrichment analyses to generate a holistic interactive network of the metabolomic profile of EDS associations.  FindingsWe identified seven metabolites belonging to steroids, sphingomyelin, and long chain fatty acids sub-pathways in the primary model associated with EDS, and an additional three metabolites in the male-specific analysis. The identified metabolites particularly played a role in steroid hormone biosynthesis.  InterpretationOur findings indicate that an EDS metabolomic profile is characterized by endogenous and dietary metabolites within the steroid hormone biosynthesis pathway, with some pathways that differ by sex. Our findings identify potential pathways to target for addressing the causes or consequences of EDS and related sleep disorders.  FundingDetails regarding funding supporting this work and all studies involved are provided in the acknowledgments section.  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSThere is a growing recognition of the paramount importance of sleep on health and cardiometabolic disease. Excessive daytime sleepiness (EDS), one of the key common sleep treatment targets, has been linked to increased risk of mortality, hypertension, cardiovascular disease, car accidents as well as decrease in life quality, and productivity. Despite its impact on health, much remains unknown about the biological mechanisms of EDS and if those mechanisms are independent from other sleep disorders. Recent genetic evidence that shows that EDS is associated with specific genetic biomarkers supports the need to further study the underlying biology of EDS.  Added value of this studyHere, we used measurements of metabolites, the products and by-products of metabolism to identify the metabolomic profile of EDS. Metabolites are produced by the biological reactions within the body via proteins--themselves products of genes--and by the breakdown of external sources such as nutritional intake and breathing air pollutants. Therefore, metabolomics enables study of the effects of nutrition, environmental exposures, and genetics. In this study we aimed to identify the metabolites that were associated with excessive daytime sleepiness. Additionally, we mapped these metabolites into a publicly available online biological network of human metabolism pathways to obtain an understanding of our findings on a larger scale.  Implications of all the available evidenceIdentifying the metabolites and pathways related to daytime sleepiness provides insights into the biological mechanisms of EDS and suggests future research opportunities to identify targets for prevention, prediction, and treatments for EDS and potentially other sleep disorders coupled with sleepiness. In this study we found 7 such metabolites--some endogenously synthesised and some obtained from dietary sources--associated with EDS. The network analysis implicated the steroid hormone biosynthesis pathway as a shared pathway underlying those metabolites, and identified linkages to key metabolites related to sleep: melatonin and cortisol metabolism.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pediatric Kidney Injury in Communities Impacted by Chronic Kidney Disease of Unknown Etiology (CKDu): A Comprehensive Systematic Review of Epidemiologic Studies\nAbstract: BackgroundChronic kidney disease of unknown etiology (CKDu) is a tubulointerstitial disease that disproportionately affects young, primarily male, agricultural workers in Mesoamerica and South Asia who lack traditional risk factors for kidney disease. Extensive research in adult populations suggests the etiology is complex and indicates that early childhood exposures could have an integral role.  ObjectivesTo systematically identify, summarize, and compare research in children living in CKDu endemic areas or with relevant CKDu-related exposures.  MethodsA systematic literature search was conducted in six databases for studies that report kidney health outcomes of pediatric populations living in proximity to CKDu-affected areas with no limitations on geography or study design. Studies were independently screened for inclusion and underwent quality assessment using the Appraisal Tool for Cross-Sectional Studies (AXIS) or the JBI Critical Appraisal Tool for Cohort Studies based on the study design by at least two authors. Data are compared narratively and graphically.  ResultsWe included twenty peer-reviewed publications and two meeting abstracts from eight different countries. The most common study design involved cross-sectional analysis of biological specimens from children in an established CKDu endemic area. Marked decreases in estimated glomerular filtration rate were generally not identified and prevalence of albuminuria differed widely between countries. Novel urinary biomarkers frequently demonstrated subclinical kidney damage, although the specific biomarker(s) varied between studies. Epidemiologic factors associated with evidence of subclinical kidney damage in children included proximity to agriculture or agrochemicals. Despite heterogenous study outcomes, all studies concluded that there were signs of kidney injury in children living in CKDu endemic areas or with a CKDu-relevant environmental exposure.  ConclusionThis systematic review suggests that the pathophysiologic process leading to CKDu may begin prior to adulthood. Future longitudinal research aimed at elucidating the multifaceted factors and exposures impacting entire communities, including children, is imperative for disease prevention strategies.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence of common respiratory viruses in children: insights from post-pandemic surveillance\nAbstract: IntroductionThe COVID-19 pandemic has significantly affected healthcare systems worldwide, impacting the occurrence and management of respiratory illnesses. This has also influenced respiratory infections role in childhood mortality. Surveillance of common respiratory viruses in Ghana is limited, making it crucial to assess the prevalence of respiratory viral infections, particularly in children, in the post-pandemic era. This study provides data on the prevalence of respiratory viruses and the associated risk factors in children aged 5 or younger in an urban paediatric hospital setting.  MethodsThe study was a cross-sectional study with a convenience sampling method, conducted in four health facilities: Asokwa Childrens Hospital, HopeXchange Medical Centre, University Health Services-KNUST, and Kumasi South Hospital in Kumasi, Ghana, between August 2022 and June 2023. Recruitment was not done in parallel in each hospital. Oropharyngeal swabs were collected from children [&le;] 5 years old and screened by RT-qPCR for common respiratory viruses.  ResultsOut of the 303 patients enrolled in the study, 165 (54.4%) were male, and 122 (40.3%) were aged from 13 to 36 months. The median age of the patients was 19 months. The most common symptoms reported were cough (87.0%), runny nose (87.0%), and fever (72.0%). Respiratory viruses were detected in 100 (33.0%) of the samples, with 36 (12.0%) testing positive for Human metapneumovirus (HMPV), 27 (8.9%) for RSV, and 20 (6.6%) for Human Adenovirus (HAdV). In 8.0% of the cases, multiple viruses were detected, with HAdV being the most common (75.0%). Children under 6 months (AOR: 4.81, 95% CI: 1.20-24.60) had a higher risk of RSV detection compared to children aged 37 to 60 months. Furthermore, it was found that caregivers with tertiary education had a higher risk of HMPV detection (AOR: 6.91, 95% CI: 1.71-47.3).  ConclusionThe studys findings emphasize RSV infection in very young children and the potentially significant role of HMPV in causing respiratory infections among children in Ghana. Active surveillance of common respiratory viruses in healthcare facilities could enhance the management of viral respiratory infection cases in the paediatric population in Ghana.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rising prevalence of Plasmodium falciparum artemisinin resistance mutations in Ethiopia\nAbstract: Ethiopia is striving to eliminate local malaria transmission by 2030, despite a recent resurgence of malaria cases due to multiple factors. A significant contributor to this resurgence could be drug resistance, particularly the emergence of partial resistance to artemisinin (ArtR) in Ethiopia and other regions of Eastern Africa. This situation highlights the necessity for genomic surveillance to monitor relevant drug resistance markers. This study reports sentinel site-based genomic surveillance results for P. falciparum antimalarial drug resistance mutations. From 2019 to 2022, dried blood spots (DBS) were collected from febrile outpatients [&ge;]1 year of age with microscopically confirmed falciparum malaria at 12 sentinel sites across 5 regions. Molecular inversion probe (MIP) sequencing targeted mutations associated with artemisinin and partner drug resistance, including k13, mdr1, crt, dhfr, and dhps genes, along with genome-wide markers to assess the complexity of infection (COI) and parasite relatedness. A total of 1,199 falciparum-positive patients were assessed, with a median age of 20 years (IQR: 14-30) and including 463 (38.6%) females. The WHO-validated K13 R622I mutation had a high but regionally variable prevalence (15.7%, range 0-58.8%). The validated K13 A675V mutation was detected for the first time in Ethiopia in the Gambella Region (4.5%), as well as P441L and P574L mutations were detected at low frequencies in Southern and Oromia Regions, respectively. Several partner drug resistance markers were identified, with mutations in MDR1(184F), DHPS, DHFR, and CRT nearly fixed across the country. Most samples (87.2%) were monogenic infections (COI=1) and showed high genetic relatedness, particularly within the health facilities. Principal component analysis revealed regional clustering of parasites, particularly in Gambella. The prevalence of K13 R622I across the country and the presence of multiple additional ArtR markers emphasizes the urgent need for rigorous monitoring of artemisinin combination therapy (ACT) efficacy to detect partner drug resistance and ACT failure early and its impact on malaria resurgence in Ethiopia.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessing the Impact of COVID-19 on Multimorbidity: Insights from Structural Equation Modeling in Colombia\nAbstract: BackgroundMultimorbidity, the coexistence of multiple chronic diseases, poses significant challenges for healthcare systems worldwide. This study aims to assess the situation of multimorbidity in Colombia using structural equation models and to characterize multimorbidity by sex, age group, region, and health insurance regime between 2019 and 2023.  MethodsWe conducted a cross-sectional analytical study utilizing data from the Individual Health Service Provision Registry (RIPS) and other national databases, including the Unit of Payment by Capitation (UPC) Sufficiency Study Database. Structural equation models were employed to identify and analyze multimorbidity clusters among patients with two or more chronic diseases.  ResultsThe study revealed a multimorbidity prevalence of 61.5% in the general population. Hypertension emerged as the most prevalent chronic condition, frequently associated with diabetes and chronic kidney disease. Multimorbidity was more common in women and individuals affiliated with the contributory insurance regime. The study also identified significant variations in multimorbidity prevalence across different regions and age groups.  ConclusionsMultimorbidity is a prevalent issue in Colombia, with substantial variations by sex, age, and insurance regime. These findings underscore the need for tailored healthcare strategies to address the diverse needs of multimorbid patients. The results provide critical insights for health service planning and management, emphasizing the importance of continued research and policy development to mitigate the burden of chronic diseases and multimorbidity in Colombia.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mobility patterns, activity locations, and tuberculosis in Nairobi, Kenya\nAbstract: BackgroundAnnually, over 3 million people develop TB but are not diagnosed and treated. We aimed to characterize the mobility patterns and activity locations of people with TB in an urban, high-burden setting to inform future active case finding (ACF) efforts.  MethodsWe conducted a population-based TB prevalence survey in Nairobi, Kenya, in 2022. Participants aged [&ge;]15 years with TB symptoms or a suggestive chest x-ray submitted sputum for Xpert Ultra and culture. We collected data on individual activity locations and mobility and evaluated their association with the risk of pulmonary TB.  ResultsThe prevalence survey enrolled 6369 participants across nine clusters. There were significant differences in mobility patterns and activity locations between sexes and age groups. Mobility factors were not significantly associated with TB. In the adjusted analysis, age group 45-54 (OR 2.45), male sex (OR 2.95), and use of a social activity location (OR 1.96) were significantly associated with a higher risk of TB.  ConclusionsWe did not find a significant association between mobility patterns and TB but found a positive association between reported  social activity locations and TB. Identification of  social activity locations, particularly bars, provides important insight into possible venues for spatially-targeted ACF activities.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Conceptualising care pathways for neglected tropical diseases in sub-Saharan Africa: A systematic scoping review\nAbstract: BackgroundThere is a lack of synthesized evidence on how best to support care continuity for neglected tropical diseases (NTDs) in sub-Saharan Africa (SSA).  MethodsTo identify all SSA NTD care pathways, we conducted a systematic search of six scientific databases from inception to 18 February 2023. All studies were required to include care pathways for NTDs, defined at minimum as having both NTD diagnosis and treatment or referral to treatment for care continuity. Using an iterative approach to establish an understanding of care pathways relevant for NTDs, concept development drew from data extraction of variables relating to study characteristics; approaches to diagnosis, treatment, and referrals as pathway components; barriers to care and strategies for their resolution; and ethical challenges.  FindingsSearches returned 2178 studies where after de-duplication and eligibility screening, 164 were systematically reviewed. Medical referrals were used to support care continuity in 62.2% (102/164) of studies, and community health workers played roles in patient care in 22.6% (37/164) of studies. Only 6.7% (11/164) of studies explicitly mapped care pathways, none of which were for NTDs where preventive chemotherapy is the primary management strategy. The majority of studies (82.9%; 136/164) presented unmapped care pathways, which were primarily biomedical research studies that provided diagnosis and/or treatment of NTD patients (66.9%; 91/136). Of biomedical research studies, 36.3% (33/91) described strategies to support continuity of care. While there is no singular care pathway for all NTDs in SSA, we proposed a conceptual framework relevant for implementation of biomedical research.  InterpretationFurther research is needed on morbidity management of NTDs typically addressed through mass drug administration in sub-Saharan Africa. To conduct this research, there is a need for guidance on how research sponsors should collaborate with local health systems to enable continuity of care in low-income, NTD-endemic settings.  Key messagesO_ST_ABSWhat is already known on this topicC_ST_ABSProviding continuity of care for neglected tropical diseases (NTDs) in the low-income settings where NTDs are endemic is challenging due to a variety of factors, particularly for chronic NTDs requiring morbidity management.  What this study addsAll NTDs require patient care, yet NTDs are unjustifiably divided into morbidity management NTDs and preventive chemotherapy NTDs. Further research on morbidity management is needed on NTDs typically managed through mass drug administration of preventive chemotherapies. We show that implementation of biomedical research on NTDs creates distinct care pathways that connect research participants with local health systems for continuity of care. These pathways provide a conceptual framework to understand care continuity during biomedical research as a practical ethical issue that merits further exploration, and illuminates how biomedical research studies might support care continuity for NTD patients such as through provision of transport, collaboration with community health workers, or structural support to local health system service providers.  How this study might affect research, practice or policyThis research opens avenues to create tools to assist researchers in providing care in resource-constrained settings. Researchers should consider care pathways for NTDs as a tool to understand local contexts of health seeking and care delivery prior to research implementation. Through these pathways, researchers can understand potential gaps in care continuity during research implementation, and determine what support may be required to address these gaps and facilitate research activities in low-income settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clinical management, epidemiology, and recurrence of human cystic echinococcosis in a secondary care level hospital in an endemic area of the Andes in Sicuani, Cusco, Peru\nAbstract: Peru has the highest incidence of human cystic echinococcosis (CE) in South America and most cases are reported in the Central and Southern Peruvian Andes, including the Cusco region. We reviewed medical records of patients with CE admitted between 2010-2019 to a level 2 Hospital in Sicuani, to collect data on the surgical management and disease recurrence in the Canchis province of Cusco. Records of 115 patients were analyzed in detail. The median age was 25 years (IQR, 16-46) and 60% were female. Most patients (68.7%) presented with a single liver cyst. The Gharbi classification was used in 75/107 (70.1%) patients with an ultrasound and 91/142 cysts (64.8%). Thirty one (34.1%) were classified as Gharbi I, 33 (36.3%) Gharbi II, 21 (23.1%) Gharbi III, and 6 (6.6%) Gharbi IV. Pre-surgical complications were reported in 41.7%. One hundred two patients underwent surgery. In 46.1%, one cyst spillage prevention measure was documented, 5.9% had two, and one had the three recommended measures. Post-surgical cyst recurrence was reported in 16.5% at a median 32.3 months (IQR, 3.9-46.6) and readmissions in 12.7%. In the multivariable analysis, having [&ge;]3 cysts (OR 9.5, 95% CI 1.3-85.5), having two pre-surgical complications (OR 12.6, 95% CI 1.8-125.6), and receiving pre-surgical albendazole (OR 5.2, 95% CI 1.3-23.9) were associated with cyst recurrence. Advanced and complicated CE disease and post-surgical recurrence were common in Sicuani. Standardization of ultrasound staging-guided clinical management along with surgical spillage prevention measures could effectively decrease the disease burden linked to clinical care, improving outcomes and decreasing costs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Direct and indirect genetic pathways between parental neuroticism and offspring emotional problems across development: evidence from 7 cohorts across 5 European nations\nAbstract: Disentangling direct and indirect genetic pathways underlying the intergenerational transmission of emotional problems could guide preventative strategies and further the understanding of the role of parental mental health in childrens outcomes. This study aimed to estimate the extent to which genetic pathways that are direct (via child genotype) and indirect (e.g., via parental phenotype) explain the well-established association between parent and child emotional problems. We leveraged data from seven European cohort studies with a combined population of Ntrios=15,475. Polygenic scores were calculated for parental and offspring neuroticism, as it represents a dispositional trait underlying emotional problems. Emotional problems in offspring were measured using validated scales across various developmental stages from early childhood to adulthood. We used neuroticism polygenic scores within a structural equation modelling framework to distinguish between direct genetic pathways from parental genotype to offspring outcome (acting through offspring genotype), and indirect genetic pathways (acting through parental phenotype and associated environment). Standard errors for direct genetic, indirect genetic and total effects were bootstrapped and meta-analyses pooled effect estimates at three developmental stages (childhood: 3-4 years, adolescence: 11-13 years, adulthood: 18+ years). We found evidence suggesting an indirect genetic pathway between mothers and child emotional problems during early childhood (pooled estimate, mean difference in standardised child emotional problems score per 1SD increase in maternal PGS for neuroticism=0.04, 95% CI: 0.01, 0.07). This association attenuated over child development, while direct genetic pathways strengthened. High attrition rates, measurement error and low variance explained by polygenic scores may have altered precision of the estimates, influencing the interpretation of the results. However, we provide the first multi-cohort study to provide evidence for an indirect genetic pathway from maternal neuroticism to early child emotional problems. This suggests that there are likely processes other than direct genetic pathways involved in the intergenerational transmission of emotional problems, highlighting the importance of timely support to prevent and reduce emotional issues in mothers as a preventative strategy for emotional difficulties.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cohort profile: The Camden Study - a pregnancy cohort study of pregnancy complications and birth outcomes in Camden, New Jersey, USA\nAbstract: BackgroundPregnancy is a unique stage of the life course characterized by trade-offs between the nutritional, immune, and metabolic needs of the mother and fetus. The Camden Study was originally initiated to examine nutritional status, growth, and birth outcomes in adolescent pregnancies and expanded to study dietary and molecular predictors of pregnancy complications and birth outcomes in young women.  MethodsFrom 1985-2006, 4765 pregnant participants aged 12 years and older were recruited from Camden, NJ, one of the poorest cities in the U.S. The cohort reflects a population under-represented in perinatal cohort studies (45% Hispanic, 38% non-Hispanic Black, 17% White participants; 98% using Medicaid in pregnancy). Study visits, including questionnaires, dietary assessments, and biospecimen collection, occurred in early and late pregnancy as well as at delivery. Medical records were abstracted, and a subset of mothers and infants participated in a six-week postpartum visit.  ResultsOver the last five decades, the Camden Study has provided data toward the publication of numerous peer-reviewed papers. Results show that adolescent linear growth in pregnancy is associated with smaller birth size, possibly due to impaired hemodynamics. In the context of preterm birth and other perinatal outcomes, analyses of nutritional data have demonstrated the importance of micronutrients (e.g., folate, iron, zinc), as well as glucose/insulin dynamics and prenatal supplement use. More recent analyses have begun to unpack the biochemical pathways in pregnancy that may be shaped by race as an indicator for systemic racism.  ConclusionsThe Camden Study data and biorepositories are well-positioned to support future research aimed at better understanding perinatal health in under-represented women and infants. Linkages to subsequent health and administrative records and the potential for recontacting participants over 18-39 years after initial participation may provide key insights into the trajectories of maternal and child health across the life course.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence, intensity and risk factors of soil-transmitted helminthiasis after five effective rounds of preventive chemotherapy across three implementation units in Ondo State, Nigeria\nAbstract: BackgroundRoutine epidemiological data are essential for monitoring the effectiveness of preventive chemotherapy (PC), optimizing resource allocation, and addressing the evolving needs in the elimination of soil-transmitted helminthiasis (STH). This study assesses the prevalence, intensity, and associated risk factors of STH following five rounds of albendazole-based PC in three implementation units (IUs) in Ondo State, Nigeria.  MethodologyFresh stool samples were collected from 2,093 children aged 5-14 years across 45 systematically selected schools in three IUs: Ese-Odo, Irele, and Ile-Oluji. The samples were analyzed using the Kato-Katz technique. Additionally, standardized questionnaires were administered to gather data on demographics and access to water, sanitation, and hygiene (WASH) resources. Data analysis was conducted using R software version 4.3.2, with a 95% confidence interval.  Principal Findings/ConclusionsThe parasitological data indicated a significant decline in the aggregated prevalence of STH across the three IUs. In Ese-Odo, the prevalence decreased to 25.8% (95% CI: 23.0-29.0) from 39% at baseline (d = -34%, p = 0.00). In Irele, prevalence dropped to 9.7% (95% CI: 7.6-12.0) from 51.3% at baseline (d = -81%, p = 0.00), and in Ile-Oluji, prevalence was reduced to 6.4% (95% CI: 4.6-8.7) from 23% at baseline (d = -72.2%, p = 0.00). The most prevalent STH species was Ascaris lumbricoides, with infection rates of 25.5%, 9.4%, and 6.4% in Ese-Odo, Irele, and Ile-Oluji, respectively, followed by Trichuris trichiura in Ese-Odo (2.7%) and Irele (0.4%), while hookworm infections were detected only in Irele (0.7%). The majority of infections were of low intensity in Ese-Odo (91.0%), Irele (96.8%), and Ile-Oluji (100%). Access to improved sanitation (17.7%, 54.9%, and 58.2%, p < 0.05), improved water sources (24.5%, 66.1%, and 69.8%, p < 0.05), and handwashing facilities (9.0%, 39.6%, and 25.4%) was suboptimal across Ese-Odo, Irele, and Ile-Oluji, respectively. Open defecation rates were high in Ese-Odo (54.2%), Irele (36.3%), and Ile-Oluji (34.3%). In Ese-Odo, significant risk factors for STH infection included the use of hand-pump boreholes (AOR: 2.44, 95% CI: 1.23-4.88, p = 0.01), unprotected dug wells (AOR: 3.25, 95% CI: 0.96-11.36, p = 0.06), ventilated improved pit latrines (AOR: 3.95, 95% CI: 1.13-16.1, p = 0.04), pit latrines without a slab (AOR: 2.19, 95% CI: 1.27-3.8, p = 0.01), and failure to use soap after defecation, both when soap was available (AOR: 12.09, 95% CI: 1.86-112.97, p = 0.01) and when soap was unavailable (AOR: 8.19, 95% CI: 1.73-76.65, p = 0.04). In Irele, access to protected dug wells was marginally significant (AOR: 1.79, 95% CI: 0.96-3.21, p = 0.06), while in Ile-Oluji, access to river water emerged as a significant risk factor (AOR: 7.97, 95% CI: 1.81-58.58, p = 0.02). The use of rainwater was found to be protective across all three IUs. These findings demonstrate significant progress in reducing STH prevalence across the three IUs following PC interventions. However, the data underscore the need for enhanced efforts to improve access to and use of WASH facilities to achieve STH elimination.  Authors SummaryThe World Health Organization (WHO) recommends reducing soil-transmitted helminthiasis (STH) prevalence to below 20% and moderate-to-heavy infections to less than 2% in treated areas to achieve elimination targets. Endemic countries, including Nigeria, have implemented mass albendazole administration to at-risk populations to meet these goals. After a decade of such interventions in Nigeria, reassessing the infection status is essential for determining whether to adjust or discontinue the program. This study analyzed stool samples from 2,093 children across three implementation units (IUs) in Ondo State. The results indicated significant reductions in STH prevalence to below 20% in two of the three IUs, with no heavy infections reported in any IU. While these findings demonstrate the effectiveness of the PC interventions, the study also identified poor access to water, sanitation, and hygiene (WASH) resources, highlighting the need for improvements in these areas to sustain progress and prevent infection resurgence.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparative Effectiveness of the mRNA-1273 and BNT162b2 COVID-19 Vaccines Among Adults With Underlying Medical Conditions: A Systematic Literature Review and Pairwise Meta-Analysis Using GRADE\nAbstract: IntroductionThis systematic literature review and pairwise meta-analysis evaluated the comparative effectiveness of mRNA-1273 versus BNT162b in patients with at least one underlying medical condition at high risk for severe COVID-19.  MethodsMEDLINE, Embase, and Cochrane databases were searched for relevant articles from January 1, 2019 to February 9, 2024. Studies reporting effectiveness data from at least two doses of mRNA-1273 and BNT162b2 vaccination in adults with medical conditions at high risk of developing severe COVID-19 according to the US Centers for Disease Control and Prevention were included. Outcomes of interest were SARS-CoV-2 infection (overall, symptomatic, and severe), hospitalization due to COVID-19, and death due to COVID-19. Risk ratios (RRs) were calculated with random effects models. Subgroup analyses by specific medical conditions, number of vaccinations, age, and SARS-CoV-2 variant were conducted. Heterogeneity between studies was estimated with chi-square testing. The certainty of evidence was assessed using the Grading of Recommendations, Assessments, Development, and Evaluations framework.  ResultsSixty-five observational studies capturing the original/ancestral-containing primary series to Omicron-containing bivalent original-BA4-5 vaccinations were included in the meta-analysis. mRNA-1273 was associated with significantly lower risk of SARS-CoV-2 infection (RR, 0.85 [95% CI, 0.79-0.92]; I2=92.5%), symptomatic SARS-CoV-2 infection (RR, 0.75 [95% CI, 0.65-0.86]; I2=62.3%), severe SARS-CoV-2 infection (RR, 0.83 [95% CI, 0.78-0.89]; I2=38.0%), hospitalization due to COVID-19 (RR, 0.88 [95% CI, 0.82-0.94]; I2=38.7%), and death due to COVID-19 (RR, 0.84 [95% CI, 0.76-0.93]; I2=1.3%) than BNT162b2. Findings were generally consistent across subgroups. Evidence certainty was low or very low because sufficiently powered randomized controlled trials are impractical in this heterogeneous population.  ConclusionMeta-analysis of 65 observational studies showed that vaccination with mRNA-1273 was associated with a significantly lower risk of SARS-CoV-2 infection and COVID-19-related hospitalization and death than BNT162b2 in patients with medical conditions at high risk of severe COVID-19.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Improved resolution of influenza vaccination responses with high-throughput live virus microneutralisation\nAbstract: Influenza remains a significant threat to human and animal health. Assessing serological protection against influenza has relied upon haemagglutinin inhibition assays, which are used to gauge existing immune landscapes, seasonal vaccine decisions and in systems vaccinology studies. Here, we adapt our high-throughput live virus microneutralisation assay for SARS-CoV-2, benchmark against haemagglutinin inhibition assays, and report serological vaccine responsiveness in a cohort of older (>65yo) community dwelling adults (n=73), after the adjuvanted 2021-22 Northern Hemisphere quadrivalent vaccine. We performed both assays against all four viruses represented in the vaccine (A/Cambodia/H3N2/2020, A/H1pdm/Victoria/2570/2019, B/Yamagata/Phuket/2013, BVIC/Washington/02/201), using sera drawn on days 0 [range: d-28 to d0], 7 [d6-10] and 182 [d161-196] with respect to vaccination. We found population-level concordance between the two assays (Spearmans correlation coefficient range 0.48-0.88; all P[&le;]1.4 x 10-5). The improved granularity of microneutralisation was better able to estimate fold-changes of responses, and quantify the inhibitory effect of pre-existing antibody. Our high-throughput method offers an alternative approach to assess influenza-specific serological responses with improved resolution.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Systematic Review of Air Pollution Exposure and Brain Structure and Function during Development\nAbstract: ObjectivesAir pollutants are known neurotoxicants. In this updated systematic review, we evaluate new evidence since our 2019 systematic review on the effect of outdoor air pollution exposure on childhood and adolescent brain structure and function as measured by magnetic resonance imaging (MRI).  MethodsUsing PubMed and Web of Science, we conducted an updated literature search and systematic review of articles published through March 2024, using key terms for air pollution and functional and/or structural MRI. Two raters independently screened all articles using Covidence and implemented the risk of bias instrument for systematic reviews informing the World Health Organization Global Air Quality Guidelines.  ResultsWe identified 222 relevant papers, and 14 new studies met our inclusion criteria. Including six studies from our 2019 review, the 20 publications to date include study populations from the United States, Netherlands, Spain, and United Kingdom. Studies investigated exposure periods spanning pregnancy through early adolescence, and estimated air pollutant exposure levels via personal monitoring, geospatial residential estimates, or school courtyard monitors. Brain MRI occurred when children were on average 6-14.7 years old; however, one study assessed newborns. Several MRI modalities were leveraged, including structural morphology, diffusion tensor imaging, restriction spectrum imaging, arterial spin labeling, magnetic resonance spectroscopy, as well as resting-state and task-based functional MRI. Air pollutants were associated with widespread brain differences, although the magnitude and direction of findings are largely inconsistent, making it difficult to draw strong conclusions.  ConclusionPrenatal and childhood exposure to outdoor air pollution is associated with structural and functional brain variations. Compared to our initial 2019 review, publications doubled--an increase that testifies to the importance of this public health issue. Further research is needed to clarify the effects of developmental timing, along with the downstream implications of outdoor air pollution exposure on childrens cognitive and mental health.  HighlightsO_LIAir pollutants have emerged as ubiquitous neurotoxicants C_LIO_LIThis field of study has grown substantially in the last 5 years C_LIO_LIExclusion of highly exposed populations poses a barrier to result generalizability C_LIO_LILongitudinal investigations are needed to understand developmental impacts of AP C_LIO_LIAdditional research should aim to clarify which children may be most vulnerable C_LI    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=174 SRC=\"FIGDIR/small/24313629v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (69K): org.highwire.dtl.DTLVardef@721773org.highwire.dtl.DTLVardef@61a94eorg.highwire.dtl.DTLVardef@1b260e7org.highwire.dtl.DTLVardef@1f80484_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOGraphical AbstractC_FLOATNO C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of Health Technology Use and Digital Health Engagement on Clinical Trial Participation: Findings from the Health Information National Trends Survey\nAbstract: BackgroundClinical trials are critical to scientific advances and medical progress, although awareness and participation remain low in the general population. The existing literature indicates that clinical trial knowledge and participation is multifactorial. Yet, little is known about the association between clinical trial participation with health technology use and digital health engagement to search for health information, interact with medical providers, and seek health supports.  ObjectiveExamine the multivariate association between clinical trial knowledge and participation with past-year health technology use and digital health engagement with medical providers.  DesignCross-sectional data from a federal surveillance system.  ParticipantsA total of 3,865 US adult respondents from the Health Information National Trends Survey 5, Cycle 4 conducted in 2020.  Main MeasuresThe two outcomes were clinical trial knowledge (no knowledge, a little knowledge, a lot of knowledge) and participation (never invited, invited did not participate, invited and participated). There were four binary indicators of health technology use for the following purposes in the past year: searching for health or medical information, communicating with a doctors office, looking up medical test results, and making medical appointments. There were four binary indicators of digital health engagement in the past year: sharing health information on social media, participating in a health forum or support group, watching health-related videos on YouTube, and awareness of ClinicalTrials.gov.  Key ResultsSurvey-weighted multivariate regression models demonstrated that awareness of ClinicalTrials.gov had the largest associations with clinical trial knowledge and participation. Digital technology use to engage with medical providers and electronic health records was associated with clinical participation, although the vast majority of respondents had never been invited.  ConclusionsFindings from this study can inform the design of large-scale digital health campaigns and quality improvement programs focused on increasing clinical trial participation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interpreting epidemiological surveillance data: A modelling study from Pune City\nAbstract: Routine epidemiological surveillance data represents one of the most continuous and comprehensive sources of data during the course of an epidemic. This data is used as inputs to epidemiological forecasting models as well as for public health decision making such as imposition and lifting of lockdowns and quarantine measures. However, such data is generated during testing and contact tracing and not through randomized sampling which makes it unclear how representative such data is of the epidemic itself. Using the BharatSim simulation framework, we build an agent-based epidemiological model with a detailed algorithm of testing and contact tracing representative of actual strategies employed in Pune city to generate synthetic surveillance data. We simulate the impact of different public health strategies, availability of tests and contact tracing efficiencies on the resulting surveillance data as well as on the course of the epidemic. The fidelity of the resulting surveillance data in representing the real-time state of the epidemic and in decision-making is explored in the context of Pune city.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interpreting epidemiological surveillance data: A modelling study from Pune City\nAbstract: Routine epidemiological surveillance data represents one of the most continuous and comprehensive sources of data during the course of an epidemic. This data is used as inputs to epidemiological forecasting models as well as for public health decision making such as imposition and lifting of lockdowns and quarantine measures. However, such data is generated during testing and contact tracing and not through randomized sampling which makes it unclear how representative such data is of the epidemic itself. Using the BharatSim simulation framework, we build an agent-based epidemiological model with a detailed algorithm of testing and contact tracing representative of actual strategies employed in Pune city to generate synthetic surveillance data. We simulate the impact of different public health strategies, availability of tests and contact tracing efficiencies on the resulting surveillance data as well as on the course of the epidemic. The fidelity of the resulting surveillance data in representing the real-time state of the epidemic and in decision-making is explored in the context of Pune city.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and determinants of modern contraception use among persons with disabilities in low- and middle-income countries: a systematic review and meta-analysis\nAbstract: BackgroundPersons with disabilities should require the same level of access to contraception as the general population. However, the extent of contraception use among this group is underexplored in low- and middle-income countries (LMICs).  ObjectiveThis study aimed to determine the prevalence of modern contraception use among persons with disabilities in LMICs and identify the key determinants.  MethodsIn June 2024, we conducted a systematic search across six databases to identify studies on disability and modern contraception in LMICs. The primary outcomes were the prevalence of modern contraception use and its determinants among persons with disabilities. Summary estimates were calculated using fixed or random-effects meta-analysis, depending on the level of heterogeneity.  ResultsA total of 19 studies were identified, with 11 included in the meta-analysis. The pooled prevalence of modern contraception use among persons with disabilities was 31.4% (95% CI: 26.5, 36.2), with significant heterogeneity across respondent characteristics. Five factors were significantly associated with higher contraception use: age over 25 years, having some level of education, being in a higher wealth quintile, adequate knowledge of family planning, and being in a formal marital relationship.  ConclusionThis study reveals a significantly lower prevalence of modern contraception use among persons with disabilities in LMICs. Improving access to education, addressing social norms, and strengthening healthcare systems may contribute to increase contraception access and uptake among persons with disabilities in LMICs.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of a booster dose of aerosolized or intramuscular adenovirus type 5 vectored COVID-19 vaccine in adults with hybrid immunity against COVID-19: a multicenter, partially randomized, platform trial in China\nAbstract: BackgroundThe primary objective of this research was to assess if a booster dose with COVID-19 vaccines containing ancestral strain could still provide significant protection against symptomatic SARS-CoV-2 infection in a predominantly hybrid-immune population during the period of omicron variant dominance.  MethodsWe did a multicenter, partially randomized, platform trial to evaluate the effectiveness of a booster dose of an aerosolized or intramuscular adenovirus type 5 vectored COVID-19 vaccine (Ad5-nCoV) in adults, after the national-wide omicron circulating at the end of year 2022 in China. Participants who were willing to receive a COVID-19 booster dose were randomly assigned to receive one of the booster doses. While, those participants who refused to take a booster dose but consented to participate COVID-19 surveillance were included in a control group. Both participants receiving a booster dose or not were monitored for symptomatic COVID-19 during a six-month surveillance period.  ResultsBetween May 23, 2023, and August 28, 2023, 4089 eligible participants were equally randomized to receive a booster dose of aerosolized Ad5-nCoV through oral inhalation at 0.1mL (IH Ad5-nCoV, n=2039) or intramuscular injection of Ad5-nCoV at 0.5 mL (IM Ad5-nCoV, n=2050). While, 2008 participants were enrolled in the blank-control group. A total of 79 COVID-19 cases were confirmed, with 22 (0.006%) in the IH Ad5-nCoV group, 23 (0.007%) in the IM Ad5-nCoV group, and 34 (0.01%) in the control group. Adjusted effectiveness of IH Ad5-nCoV and IM Ad5-nCoV from 14 days after the vaccination were 51.6% (95% CI 9.0 to 74.3) and 38.1% (95% CI - 9.6 to 65.1), respectively.  InterpretationSignificant protection against symptomatic COVID-19 caused by the Omicron variant, during the ongoing pandemic of evolving COVID-19 variants, was found to be provided by boosting with the ancestral strain-containing vaccine IH Ad5-nCoV, but not by boosting with IM Ad5-nCoV.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Modeling the effects of COVID-19 mobility disruptions on RSV transmission in Seattle, Washington\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSIntroductionC_ST_ABSRespiratory Syncytial Virus (RSV) infection is a major cause of acute respiratory hospitalizations in young children and older adults. In early 2020 most countries implemented non-pharmaceutical interventions (NPIs) to slow the spread of SARS-CoV-2. COVID-19 NPIs disrupted the transmission of RSV on a global scale, and many locations did not experience widespread re-circulation until late 2020 or 2021. Here, we use a mechanistic transmission model informed by cellphone mobility data to determine which aspects of population behavior had the greatest influence on post-pandemic RSV rebound in Seattle, Washington.  MethodsWe used aggregated mobile device location data to characterize within-city mixing, visitor in-flows, and foot traffic to points of interest in Seattle. We fit an age-structured epidemiological model to data on weekly RSV hospitalizations, allowing for reductions in transmission due to declines in mobility during the pandemic. We compared model fits to observed data to assess which mobility behaviors best capture RSV dynamics during the first two post-pandemic waves in Seattle.  ResultsIn Seattle, COVID-19 NPIs perturbed RSV seasonality from 2020 to 2022. Seattle experienced a small out-of-season outbreak in Summer 2021 and an atypically large and early wave in Fall 2022. RSV transmission models incorporating mobility network connectivity (measured as the average shortest path length between Seattle neighborhoods) or the inflow of visitors from outside of Seattle best captured the timing and magnitude of the first two post-pandemic waves. Models including foot traffic to schools or child daycares or within-neighborhood movement produced poor fits to observed data.  ConclusionsOur results suggest that case importations from other regions and local spread between neighborhoods had the greatest influence on the timing of RSV reemergence in Seattle. These findings contribute to the understanding of behavioral factors underlying RSV epidemic spread and can inform the timing of preventative measures, such as the administration of immunoprophylaxis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neuroinflammatory Disorders of the Central Nervous System Associated with Monkeypox Virus Infection: A Systematic Review and Call to Action\nAbstract: BackgroundThe Monkeypox virus, a zoonotic pathogen of the Orthopoxvirus genus, has shown a marked global spread, resulting in cases of neuroinflammatory disorders. This systematic review aims to summarize the central nervous system manifestations linked to monkeypox virus infection.  MethodsWe conducted a systematic review according to PRISMA guidelines. Databases such as PubMed, EMBASE, Cochrane Library, and Web of Science were searched up to September 2024. Inclusion criteria focused on monkeypox virus-positive patients with confirmed central nervous system inflammatory disorders, including encephalitis, meningitis, myelitis, and related neuroimmune diseases.  ResultsFrom 770 screened articles, 38 studies were included. Of the 20 reported monkeypox virus-infected cases with central nervous system involvement, the most common manifestations were encephalitis (40%), encephalomyelitis (30%), and meningoencephalitis (10%). Additional rarer presentations included Guillain-Barre syndrome (5%) and transverse myelitis (5%). The mean age of affected individuals was 27.9{+/-}13.69 years, and 75% were male. Fever, fatigue, and myalgia were the predominant systemic symptoms, with neurological complications often appearing within 4.6{+/-}2.5 days post-infection. Diagnoses were confirmed by quantitative reverse transcription polymerase chain reaction, magnetic resonance imaging, and cerebrospinal fluid analysis. Treatment strategies varied, with antivirals (e.g., tecovirimat) and immunomodulatory therapies (e.g., methylprednisolone, immunoglobulins, and rituximab) utilized.  ConclusionsMonkeypox virus infection is associated with severe neuroinflammatory disorders, with varying outcomes from complete recovery to mortality. Increased awareness, comprehensive diagnostic approaches, and targeted therapeutic interventions are critical in managing these cases. Further research is required to elucidate the mechanisms of neuroinflammation in the monkeypox virus and establish standardized treatment protocols.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: First imported Cases of MPXV Clade Ib in Goma, Democratic Republic of the Congo: Implications for Global Surveillance and Transmission Dynamics\nAbstract: The ongoing national mpox outbreak in the Democratic Republic of the Congo has resulted in more >30,000 suspected cases in the country from January 2023 to August 2024. While these historic case totals have been driven by primarily by zoonosis, the emergence of Clade Ib monkeypox virus (MPXV), which is connected to more sustained human-to-human transmission, has been associated with increasing public health impacts in eastern DRC. First identified in South Kivu province, Clade Ib MPXV has been identified in multiple non-endemic East African countries for the first time. In DRC, there have been concerns over broader Clade Ib expansion in the country that could further complicate containment and mitigation responses. Here, we report the first introductions of Clade Ib into North Kivu province, including within internal displacement camps, with suspected close contact transmission that includes non-intimate contacts and children. These findings demonstrate that mpox case investigations and community messaging campaigns should include considerations for non-sexual contact-mediated transmission of Clade Ib that includes children <15 years.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Multi-City COVID-19 Categorical Forecasting Model Utilizing Wastewater-Based Epidemiology\nAbstract: The COVID-19 pandemic highlighted shortcomings in forecasting models, such as unreliable inputs/outputs and poor performance at critical points. As COVID-19 remains a threat, it is imperative to improve current forecasting approaches by incorporating reliable data and alternative forecasting targets to better inform decision-makers.  Wastewater-based epidemiology (WBE) has emerged as a viable method to track COVID-19 transmission, offering a more reliable metric than reported cases for forecasting critical outcomes like hospitalizations. Recognizing the natural alignment of wastewater systems with city structures, ideal for leveraging WBE data, this study introduces a multi-city, wastewater-based forecasting model to categorically predict COVID-19 hospitalizations.  Using hospitalization and COVID-19 wastewater data for six US cities, accompanied by other epidemiological variables, we develop a Generalized Additive Model (GAM) to generate two categorization types. The Hospitalization Capacity Risk Categorization (HCR) predicts the burden on the healthcare system based on the number of available hospital beds in a city. The Hospitalization Rate Trend (HRT) Categorization predicts the trajectory of this burden based on the growth rate of COVID-19 hospitalizations. Using these categorical thresholds, we create probabilistic forecasts to retrospectively predict the risk and trend category of six cities over a 20-month period for 1, 2, and 3 week forecasting windows.  We also propose a new methodology to measure forecasting model performance at change points, or time periods where sudden changes in outbreak dynamics occurred. We also explore the influence of wastewater as a predictor for hospitalizations, showing its inclusion positively impacts the models performance. With this categorical forecasting study, we are able to predict hospital capacity risk and disease trends in a novel and useful way, giving city decision-makers a new tool to predict COVID-19 hospitalizations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deep Learning Models for Predicting the Nugent Score to Diagnose Bacterial Vaginosis\nAbstract: The Nugent score is a commonly used tool for diagnosing bacterial vaginosis; however, its accuracy depends on the skills of laboratory technicians. We aimed to evaluate the performance of deep learning models in predicting the Nugent score, with the goal of improving diagnostic consistency and accuracy. A total of 1,510 vaginal images collected from a hospital in Japan between 2021 and 2023 were assessed. Each image was annotated by laboratory technicians into one of four categories based on the Nugent score--normal vaginal flora, absence of vaginal flora, altered vaginal flora, or bacterial vaginosis. Deep learning models were developed to predict these categories, and their performance was evaluated by comparing the predicted scores with technician annotations. A high magnification model was further optimized and evaluated using an independent test set of 106 images to assess its performance relative to that of the technicians. The deep learning models demonstrated an accuracy of 84% at low magnification and 89% at high magnification in predicting the Nugent score categories. After optimization, the high magnification model achieved 94% accuracy, surpassing the average 92% accuracy of the technicians. The agreement between deep learning model predictions and technician annotations was 92% for normal vaginal flora, 100% for absence of vaginal flora, 91% for altered vaginal flora, and 100% for bacterial vaginosis. The deep learning models demonstrated accuracy comparable to that of laboratory technicians, which indicates their potential utility in improving the diagnostic accuracy of bacterial vaginosis.  IMPORTANCEBacterial vaginosis is a global health issue affecting women, causing symptoms such as abnormal vaginal discharge and discomfort. The Nugent score is the standard method for diagnosing bacterial vaginosis and is based on manual interpretation of Gram-stained vaginal smears. However, this method relies on the skill and experience of trained professionals, leading to variability in results and challenges in facilities with limited access to such experts. This poses significant challenges for settings with limited access to experienced technicians. The deep learning models developed in this study predict the Nugent score with high accuracy; thus, they can be used to standardize the diagnosis of bacterial vaginosis, reduce observer variability, and enable reliable diagnosis even in settings without experienced personnel. Although larger scale validation is needed, our results suggest that deep learning models may represent a new approach for the diagnosis of bacterial vaginosis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integration of Group A Streptococcus Rapid Tests with the Open Fluidic CandyCollect Device\nAbstract: The CandyCollect device is a lollipop-inspired open fluidic oral sampling device designed to provide a comfortable user sampling experience. We demonstrate that the CandyCollect device can be coupled with a rapid antigen detection test (RADT) kit designed for Group A Streptococcus (GAS). Through in vitro experiments with pooled saliva spiked with Streptococcus pyogenes we tested various reagents and elution volumes to optimize the RADT readout from CandyCollect device samples. The resulting optimized protocol uses the kit-provided reagents and lateral flow assay (LFA) while replacing the kits pharyngeal swab with the CandyCollect device, reducing the elution solution volume, and substituting the tube used for elution to accommodate the CandyCollect device. Positive test results were detected by eye with bacterial concentrations as low as the manufacturers \"minimal detection limit\" - 1.5x105 CFU/mL. LFA strips were also scanned and quantified with image analysis software to determine the signal-to-baseline ratio (SBR) and categorize positive test results without human bias. We tested our optimized protocol for integrating CandyCollect and RADT using CandyCollect clinical samples from pediatric patients (n=6) who were previously diagnosed with GAS pharyngitis via pharyngeal swabs tested with RADT as part of their clinical care. The LFA results of these CandyCollect devices and interspersed negative controls were determined by independent observers, with positive results obtained in four of the six participants on at least one LFA replicate. Taken together, our results show that CandyCollect devices from children with GAS pharyngitis can be tested using LFA rapid tests.  Table of Contents/Abstract Figure  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=152 SRC=\"FIGDIR/small/24312510v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (44K): org.highwire.dtl.DTLVardef@da56a5org.highwire.dtl.DTLVardef@6e84b8org.highwire.dtl.DTLVardef@1cb5a9dorg.highwire.dtl.DTLVardef@1aa07ac_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Co-circulating pathogens of humans: A systematic review of mechanistic transmission models\nAbstract: Historically, most mathematical models of infectious disease dynamics have focused on a single pathogen, despite the ubiquity of co-circulating pathogens in the real world. We conducted a systematic review of 311 published papers that included a mechanistic, population-level model of co-circulating human pathogens. We identified the types of pathogens represented in this literature, techniques used, and motivations for conducting these studies. We also created a complexity index to quantify the degree to which co-circulating pathogen models diverged from single-pathogen models. We found that the emergence of new pathogens, such as HIV and SARS-CoV-2, precipitated modeling activity of the emerging pathogen with established pathogens. Pathogen characteristics also tended to drive modeling activity; for example, HIV suppresses the immune response, eliciting interesting dynamics when it is modeled with other pathogens. The motivations driving these studies were varied but could be divided into two major categories: exploration of dynamics and evaluation of interventions. Finally, we found that model complexity quickly increases as additional pathogens are added. Future potential avenues of research we identified include investigating the effects of misdiagnosis of clinically similar co-circulating pathogens and characterizing the impacts of one pathogen on public health resources available to curtail the spread of other pathogens.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hospital-onset bacteraemia and fungaemia as a novel automated surveillance indicator: results from four European university hospitals\nAbstract: BackgroundConventional manual surveillance of healthcare-associated infections is labour-intensive and therefore often restricted to areas with high-risk patients. Fully automated surveillance of hospital-onset bacteraemia and fungaemia (HOB) may facilitate hospital-wide surveillance.  AimTo develop an algorithm and minimal dataset (MDS) required for automated surveillance of HOB and apply it to real-life routine data in four European hospitals.  MethodsThrough consensus discussion a HOB definition with MDS suitable for automated surveillance was developed and applied in a retrospective multicentre observational study including all admitted adult patients (2018-2022). HOB was defined as a positive blood culture with a recognised pathogen two or more days after hospital admission. For common commensals, two blood cultures with the same commensal within two days were required. Annual HOB rates were calculated per 1,000 patient days for the hospital and for intensive care units (ICU) and non-ICU.  ResultsHOB rates were comparable between the four hospitals (1.0 to 2.2 per 1,000 patient days). HOB rates were substantially higher in ICU than non-ICU across the four hospitals, and HOB with common commensals accounted for 14.8-28.2% of all HOB. HOB rates per 1,000 patient days were rather consistent over time, but were higher in 2020 and 2021. HOB caused by Staphylococcus aureus accounted for 8.4-16.0% of all HOB.  ConclusionAutomated HOB surveillance using a common definition was feasible and reproducible across four European hospitals. Future studies should investigate clinical relevance and preventability of HOB, and focus on strategies to make the automated HOB metric an actionable infection control tool.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Climate variation and serotype competition drive dengue outbreak dynamics in Singapore\nAbstract: Dengue poses a rapidly increasing threat to global health, with Southeast Asia as one of the worst affected regions. Climate-informed early warning systems can help to mitigate the impact of outbreaks; however, prediction of large outbreaks with sufficient lead time to guide interventions remains a challenge. In this work, we quantify the role of climatic variation and serotype competition in shaping dengue risk in Singapore using over 20 years of weekly case data. We integrated these findings into an early warning system framework able to predict dengue outbreaks up to 2 months ahead. While a climate-informed model improved predictive power by 54% compared to a seasonal baseline, including additional serotype information increased predictive performance to 60%, helping to explain interannual variation. By incorporating serotype competition as a proxy for population immunity, this work advances the field of dengue prediction and demonstrates the value of long-term virus surveillance.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging an Online Dashboard to Inform on Infectious Disease Surveillance: A case Study of COVID-19 in Kenya.\nAbstract: A multi-pronged approach to combating the COVID-19 pandemic in Kenya resulted in the formation of multidisciplinary research initiatives including genomic sequencing, syndromic surveillance, sero-surveillance, vaccination, and mathematical modelling. These initiatives generated an overwhelming amount of data that posed a challenge to researchers and public health officials, to effectively manage, analyse and promptly interpret for immediate pandemic response. As a result, there was demand for a platform to collate and integrate these datasets with interpretable findings to aid in pandemic management. In response, we developed a web-based dashboard, and integrated multidisciplinary datasets collected by the Ministry of Health-Kenya (MoH-K) and other research organizations, to support surveillance and monitoring of COVID-19 in Kenya. The developed dashboard combines genomics, epidemiological, seroprevalence, modelling, vaccination, syndromic and phylogenetic data and provides real-time updates to the public and health sector experts. The dashboard provides temporal trends of reported COVID-19 cases, fatalities, variants, and vaccination, in addition to summary reports from multiple cross-sectional seroprevalence studies and ongoing facility-based inpatient syndromic surveillance from 15 health facilities across Kenya. This is the first detailed interactive dashboard in Kenya that combines multiple datasets from a disease outbreak to provide valuable insights to researchers, health policy makers, the media and public not only during pandemic but also during routine surveillance. This resource is a model for digital platform for infectious disease surveillance and for informing public health planning and intervention.  Dashboard Linkhttps://kcd.kemri-wellcome.org/\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A next generation CRISPR diagnostic tool to survey drug resistance in Human African Trypanosomiasis.\nAbstract: The WHO aims to eliminate the gambiense form of human African trypanosomiasis (HAT) by 2030. With the decline of reported cases, maintaining efficient epidemiological surveillance is essential, including the emergence of drug-resistant strains. We have developed new highly specific diagnostic tools using Specific High-Sensitivity Reporter Enzymatic UnLOCKing (SHERLOCK) technology for monitoring the presence of drug-resistant genotypes that (1) are already circulating, such as the AQP2/3(814) chimera providing resistance to pentamidine and melarsoprol, or (2) could emerge, such as TbCPSF3 (N232H), associated to acoziborole resistance in lab conditions. The melarsoprol - pentamidineAQP2/3(814) SHERLOCK assay detected RNA from both cultured parasites and field isolated strains from gHAT patients in relapse following treatment. The acoziborole CPSF3(SNV)SHERLOCK assay discriminated between wild-type CPSF3 RNA and CPSF3 with a single A-C mutation that confers resistance to acoziborole in vitro.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Surveillance and control of neglected zoonotic diseases: methodological approaches to studying Rift Valley Fever, Crimean-Congo Haemorrhagic Fever and Brucellosis at the human-livestock-wildlife interface across diverse agricultural systems in Uganda\nAbstract: Background Zoonoses are of public health importance with most major emerging diseases originating in animal populations. Rift Valley Fever (RVF), Crimean-Congo Haemorrhagic Fever (CCHF) and Brucellosis are circulating in Uganda causing frequent outbreaks, but gaps exist in the understanding of transmission dynamics, community perspectives and effective mitigation strategies of these diseases. With increasing human-livestock-wildlife interaction in Uganda's biodiverse cattle corridor, this study protocol outlines an integrated One Health model to determine the burden of RVF, CCHF and Brucellosis, identify key vectors and reservoirs and assesses the impact of social and policy factors on disease distribution. Methods A series of mixed-methods cross-sectional and longitudinal surveys across six conservation areas experiencing high human-livestock-wildlife interaction spanning Uganda's Cattle Corridor: Queen Elizabeth National Park, Bwindi-Mgahinga Impenetrable Forest, Lake Mburo-Nakivaale, Murchison Falls, Kidepo Valley and Pian Upe Game Reserve. In selected villages household surveys comprise questionnaires, focus-group discussions and in-depth interviews to determine drivers of disease risk with blood-sampling of human population. Questionnaires provide detail on livestock practices and blood-sampling is conducted on cattle, sheep, pigs and goats. Targeted sampling of vectors in these localities including mosquitos, ticks and small mammals using environmental traps and on-host collection. Specimens taken from nearby large wildlife include blood sampling and nasal swabs. Serological testing using indirect ELISA and molecular testing using real-time PCR was conducted to determine disease status of RVF, CCHF and Brucellosis across humans, livestock and wildlife with eco-epi modelling and qualitative analyses used to inform risks and drivers of disease. Results Baseline survey data and blood specimens were obtained from 2894 humans residing in 1602 households across 96 villages in 6 conservation areas of Uganda. A further 379 community members participated in focus group discussions and key informant interviews with 978 reformed and active poachers across 4 conservation areas. 3692 livestock were sampled including 1925 cattle, 1409 goats, 282 sheep and 76 pigs from 358 herds. Vector data were collected for 18236 ticks, 53480 mosquitoes and 768 rodents. 241 large wildlife were sampled including buffalo, kobs, zebras, waterbucks, topi and hartebeest. 127 Community One Health Volunteers (COHVs) were enlisted to monitor and detect outbreaks in the study sites. Conclusions This paper outlines a comprehensive One Health approach to studying neglected zoonotic diseases integrating molecular epidemiology, social sciences and community participatory approaches involving humans, livestock, vectors and wildlife across 6 conservation areas in Uganda. It will inform interventions to enhance the surveillance and control of RVF, CCHF and Brucellosis including strengthening outbreak preparedness and response.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Surveillance and control of neglected zoonotic diseases: methodological approaches to studying Rift Valley Fever, Crimean-Congo Haemorrhagic Fever and Brucellosis at the human-livestock-wildlife interface across diverse agricultural systems in Uganda\nAbstract: Background Zoonoses are of public health importance with most major emerging diseases originating in animal populations. Rift Valley Fever (RVF), Crimean-Congo Haemorrhagic Fever (CCHF) and Brucellosis are circulating in Uganda causing frequent outbreaks, but gaps exist in the understanding of transmission dynamics, community perspectives and effective mitigation strategies of these diseases. With increasing human-livestock-wildlife interaction in Uganda's biodiverse cattle corridor, this study protocol outlines an integrated One Health model to determine the burden of RVF, CCHF and Brucellosis, identify key vectors and reservoirs and assesses the impact of social and policy factors on disease distribution. Methods A series of mixed-methods cross-sectional and longitudinal surveys across six conservation areas experiencing high human-livestock-wildlife interaction spanning Uganda's Cattle Corridor: Queen Elizabeth National Park, Bwindi-Mgahinga Impenetrable Forest, Lake Mburo-Nakivaale, Murchison Falls, Kidepo Valley and Pian Upe Game Reserve. In selected villages household surveys comprise questionnaires, focus-group discussions and in-depth interviews to determine drivers of disease risk with blood-sampling of human population. Questionnaires provide detail on livestock practices and blood-sampling is conducted on cattle, sheep, pigs and goats. Targeted sampling of vectors in these localities including mosquitos, ticks and small mammals using environmental traps and on-host collection. Specimens taken from nearby large wildlife include blood sampling and nasal swabs. Serological testing using indirect ELISA and molecular testing using real-time PCR was conducted to determine disease status of RVF, CCHF and Brucellosis across humans, livestock and wildlife with eco-epi modelling and qualitative analyses used to inform risks and drivers of disease. Results Baseline survey data and blood specimens were obtained from 2894 humans residing in 1602 households across 96 villages in 6 conservation areas of Uganda. A further 379 community members participated in focus group discussions and key informant interviews with 978 reformed and active poachers across 4 conservation areas. 3692 livestock were sampled including 1925 cattle, 1409 goats, 282 sheep and 76 pigs from 358 herds. Vector data were collected for 18236 ticks, 53480 mosquitoes and 768 rodents. 241 large wildlife were sampled including buffalo, kobs, zebras, waterbucks, topi and hartebeest. 127 Community One Health Volunteers (COHVs) were enlisted to monitor and detect outbreaks in the study sites. Conclusions This paper outlines a comprehensive One Health approach to studying neglected zoonotic diseases integrating molecular epidemiology, social sciences and community participatory approaches involving humans, livestock, vectors and wildlife across 6 conservation areas in Uganda. It will inform interventions to enhance the surveillance and control of RVF, CCHF and Brucellosis including strengthening outbreak preparedness and response.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reactogenicity and immunogenicity against MPXV of the intradermal administration of Modified V Vaccinia Ankara compared to the standard subcutaneous route.\nAbstract: The recent resurgence of Mpox in central Africa has been declared again a Public Health Emergency of International Concern (PHEIC) requiring coordinated international responses. Vaccination is a priority to expand protection and enhance control strategies, but the vaccines need exceeds the currently available doses. Intradermal administration of one-fifth of the standard Modified-Vaccinia-Ankara (MVA-BN) dose was temporarily authorized during the 2022 PHEIC. Studies conducted before 2022 provided evidence about the humoral response against the Vaccinia virus (VACV) after vaccination but not against the Mpox virus (MPXV). Moreover, no data are available on the T-cell response elicited by MVA-BN administered subcutaneously or intradermally. Here, we compare the two vaccine administration routes according to reactogenicity and immunogenicity based on data from 943 vaccine recipients during the 2022 vaccination campaign in Rome, Italy. We found that the intradermal route elicited slightly higher titers of MPXV-specific IgG and nAbs than the subcutaneous one. At the same time, no differences in cellular response were detected. MVA-BN was globally well tolerated despite higher reactogenicity for the intradermal than the subcutaneous route, especially for the reactions at the local injection site. The intradermal dose-sparing strategy was proven safe and immunogenic and would make vaccination available to more people.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Metagenomic detection of Mimiviridae reads in upper respiratory tract samples of SARS-CoV-2 patients\nAbstract: The upper respiratory tract (URT) virome is crucial in respiratory health and response to pathogens. While common respiratory viruses are well-studied, the presence and potential impact of giant DNA viruses, such as Mimiviridae, in the human URT remain underexplored. This study employed a whole genome metagenomics approach to profile the URT virome of 48 SARS-CoV-2-positive patients from central India. Mimiviridae reads were detected in two elderly male patients with severe acute respiratory infection (SARI) or influenza-like illness (ILI), contributing to 24% and 44% of the total virome in their samples. The dominant species were Acanthamoeba polyphaga mimivirus and Moumouvirus. Although Mimiviridae are not traditionally associated with human respiratory infections, their presence in SARS-CoV-2 patients raises questions about their potential role in co-infections and disease severity, particularly in individuals with ongoing respiratory infections. These findings underscore the need to investigate further giant viruses clinical significance, transmission, and pathogenicity in humans. Future research should focus on their epidemiology and the development of improved diagnostic tools to assess their contribution to human health.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Metagenomic detection of Mimiviridae reads in upper respiratory tract samples of SARS-CoV-2 patients\nAbstract: The upper respiratory tract (URT) virome is crucial in respiratory health and response to pathogens. While common respiratory viruses are well-studied, the presence and potential impact of giant DNA viruses, such as Mimiviridae, in the human URT remain underexplored. This study employed a whole genome metagenomics approach to profile the URT virome of 48 SARS-CoV-2-positive patients from central India. Mimiviridae reads were detected in two elderly male patients with severe acute respiratory infection (SARI) or influenza-like illness (ILI), contributing to 24% and 44% of the total virome in their samples. The dominant species were Acanthamoeba polyphaga mimivirus and Moumouvirus. Although Mimiviridae are not traditionally associated with human respiratory infections, their presence in SARS-CoV-2 patients raises questions about their potential role in co-infections and disease severity, particularly in individuals with ongoing respiratory infections. These findings underscore the need to investigate further giant viruses clinical significance, transmission, and pathogenicity in humans. Future research should focus on their epidemiology and the development of improved diagnostic tools to assess their contribution to human health.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biomarkers of atrial fibrillation-related pathways and left atrial structure and function in an overweight and obese population\nAbstract: BackgroundExploring longitudinal associations of blood biomarkers with left atrial (LA) structure and function can enhance our understanding of atrial fibrillation (AF) etiopathogenesis.  MethodsWe studied 532 participants of the PREDIMED-Plus trial, a multicenter randomized trial in overweight and obese adults with metabolic syndrome. At baseline, 3 and 5 years after randomization, participants underwent transthoracic echocardiography and provided blood for serum biomarker measurements [propeptide of procollagen type I (PICP), high-sensitivity (hs) troponin T (hsTnT), hs C-reactive protein (hsCRP), 3-nitrotyrosine (3-NT), and N-terminal propeptide of B-type natriuretic peptide (NT-proBNP)]. Outcomes of interest included LA peak systolic longitudinal strain (LA PSLS), LA volume index (LAVi), LA function index (LAFi), and LA stiffness index (LASi). We performed cross-sectional and longitudinal analyses to evaluate relationships between log-transformed biomarkers and echocardiographic measurements using multiple linear regression and mixed models.  ResultsThe participants in this analysis had a mean age of 65.0 (SD 4.8) years, and 40% were females. At baseline, increased NT-proBNP and hsTnT were associated with larger LAVi and worse LA function as measured by the LAFi, LASi, and LA PSLS. Longitudinally, higher NT-proBNP, but not higher hsTnT, was associated with increased LAVi and worsening LA function. Over 5 years, 1 unit increase in log(NT-proBNP) was associated with steeper decline in LA PSLS (-0.19%, 95% CI -0.35%, -0.02%) and greater increase in LAVi (0.28 mL/m2, 95% CI 0.10, 0.45) each year. PICP, hsCRP, and 3-NT did not show consistently significant associations with LA outcomes at baseline and through 5 years.  ConclusionIn an overweight and obese population, higher NT-proBNP was associated with LA volume enlargement and worsening LA function over 5 years. The implications of these findings for the prevention and prediction of AF warrant further investigation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Explicit solution of the SVIR (Susceptible-Vaccinated-Infectious-Recovered) epidemic model\nAbstract: An explicit solution of an initial value problem for the Susceptible-Vaccinated-Infectious-Recovered (SVIR) epidemic model is obtained, and various properties of the explicit solution are investigated. It is shown that the parametric form of the explicit solution satisfies some linear differential system including a positive solution of an integral equation. In this paper integral equations play an important role in establishing the explicit solution of the SVIR epidemic model, in particular, the number of infected individuals can be represented in a simple form by using a positive solution of an integral equation. Uniqueness of positive solutions of the SVIR epidemic model is also investigated, and it is shown that the explicit solution is a unique solution in the class of positive solutions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Public communication and outreach by mosquito programs in the United States\nAbstract: Blood feeding female mosquitoes cause itchy welts and can transmit pathogens that cause diseases such as chikungunya, malaria, West Nile encephalitis, and Zika. Mosquito control programs conduct mosquito, pathogen, and epidemiological surveillance, carry out source reduction, treat mosquito habitats with larvicides or adulticides, and disseminate information to the public. Here, 100 organizations (e.g., private/public mosquito control programs, national professional mosquito/pest control associations) in the United States were asked to complete a survey (N=39 respondents) about their public communication and outreach efforts. Results indicate most programs (N=27, 69%) have dedicated personnel for public communication. A checklist was constructed to compare communication strategies between a subset of program websites and Facebook pages. Recommendations for improving public communication and outreach strategies for mosquito control programs are discussed.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Employment Trajectories During the Menopause Transition: Experiences of Women with Early and Surgical Menopause\nAbstract: This study examines the labour market trajectories of women experiencing early and surgical menopause over a 10-year period surrounding their final menstruation or surgery, representing for most women the menopause transition. We also investigate the potential mediating role of hormone therapy (HT) in early postmenopause (within 5 years of menopause onset or surgery) in these relationships. Using data from the English Longitudinal Study of Aging (ELSA), we employ sequence and cluster analysis, followed by mediation analysis. Our findings indicate that women with early menopause, compared to those who undergo menopause at 45 or older, are less likely to have flexible working arrangements (part-time work or self-employment) compared to full-time work during this sensitive period. However, they are equally likely to exit the labour market as to work full-time, indicating distinct experiences. Surgical menopause, compared to natural menopause, is associated with an increased risk of labour market exit, particularly for women aged 45 or older at the time of surgery, potentially due to higher comorbidities and increased age-related precarity. HT use appears to mitigate the risk of labour market exit for women with both early and surgical menopause, although other factors (e.g., health) may play a more significant role in this transition out of work. We advocate for further research on the impact of early and surgical menopause on womens labour market circumstances and for workplace policies that consider the diverse experiences of women with early and surgical menopause, including their increased risk of chronic conditions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Female Infertility and Neurodevelopmental Disorders in Children: associations and evidence for familial confounding in Denmark\nAbstract: IMPORTANCEExisting research suggests the impact of infertility on the risk of neurodevelopmental disorders in children, however, studies to date have failed to separate the impact of male and female infertility, often blurring the lines with proxies that encompass all forms of infertility. Moreover, while both health conditions co-occurring with infertility and genetic factors operating upstream have been suggested to influence the association between infertility and child outcomes, their roles and potential impact on observed associations remain unclear.  OBJECTIVEThe objectives of this study are to investigate the relationship between female infertility and autism in the child, differentiating it from the effects of male and the couple infertility; consider the role of various maternal and birth factors in the association; and examine the effects of shared familial confounders on the association.  DESIGN SETTING AND PARTICIPANTSDanish population-based cohort study, including all singleton live births in Denmark 1998-2015, their parents and parents siblings. The cohort was followed up until December 31, 2016.  EXPOSURESThe exposure was a history of female infertility in the mother and the mothers sister. We examined four definitions of female infertility based on the ICD-10 codes derived from the Danish National Patient Register - any female infertility; specified female infertility; female exclusive infertility; and female or male infertility.  MAIN OUTCOME AND MEASURESThe outcome was diagnosis of autism spectrum disorder (ASD) in the Danish Psychiatric Central Research Register or the national patient register. A multivariable Cox regression model was used to estimate the associations between female infertility and autism, accounting for childs sex, year of birth, maternal age, education level, chronic comorbidities, and pregnancy and birth complications. The effects of shared familial factors on the association were analyzed using exposure information from the childs maternal aunt.  RESULTSThe cohort included 1,131,899 mother-child pairs, among which 18,374 children with ASD diagnosis. History of female infertility in the mother (all definitions) was significantly associated with autism in the child, with the association remaining robust after adjustment for covariates (HRadj=1.14 (95% CI, 1.03-1.26) for specified infertility). The diagnosis of infertility in a childs maternal aunt was also significantly linked to the childs autism risk, even after adjustment for maternal infertility (HRadj=1.10 (95% CI, 1.00-1.20).  CONCLUSIONS AND RELEVANCEin This population-based birth cohort study, we found a slightly higher risk of autism in children born to mothers with a history of infertility, with the association remaining consistent across various definitions of female infertility and robust to adjustments for demographic, child, and maternal factors. The study suggests for the first time that shared familial factors, possibly both genetic and non-genetic, could be influencing both female infertility and the risk of autism in children, indicating a need for further investigation into these familial effects.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Climate Change and Malaria: A Call for Robust Analytics\nAbstract: Mosquito ecology and malaria parasite development in mosquitoes display marked sensitivity to weather, in particular to temperature and precipitation. Therefore, climate change is expected to profoundly affect malaria epidemiology in its transmission, spatiotemporal distribution and consequent disease burden. However, malaria transmission is also complicated by other factors (e.g. urbanisation, economics, genetics, drug resistance) which together constitute a highly complex, dynamical system, where the influence of any single factor is highly uncertain.  In this study, we therefore aim to re-evaluate the evidence underlying the widespread belief that climate change will increase worldwide malaria transmission. We firstly review the different types of studies that have contributed to this evidence-base: i) studies that project changes in transmission due to inferred relationships between environmental and mosquito entomology; ii) studies that focus on either mechanistic transmission or time series models to estimate the effects of malaria control strategies on prevalence, and iii) regression-based studies that look for associations between environmental variables and malaria prevalence. We then employ a simple statistical model to show that environmental variables alone do not account for the observed spatiotemporal variation in malaria prevalence.  Our review raises several concerns about the robustness of the analyses used for advocacy around climate change and malaria. We find that, while climate changes effect on malaria is highly plausible, empirical evidence is much less certain. Future research on climate change and malaria must become integrated into malaria control programs, and understood in context as one factor among many affecting malaria. Our work outlines gaps in modelling that we believe are priorities for future research.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Statin uses and skeletal muscle-related phenotypes: insights from epidemiological and Mendelian randomization analyses\nAbstract: BackgroundThe association between statin use and skeletal muscle-related side effects is always controversial. This study aimed to comprehensively investigate the associations between statin use and muscle-related phenotypes including sarcopenia, sarcopenic obesity, serum lactate dehydrogenase (LDH), and musculoskeletal pain symptoms among adults with indications for statin use for secondary prevention (cardiovascular disease, diabetes, or hyperlipidemia).  MethodsThis cross-sectional study included 22,549 patients aged [&ge;]20 years with cardiovascular disease, diabetes, or hyperlipidemia. Weighted generalized linear regression analysis and propensity score matching methods were used to estimate the associations between the use of statins or other lipid-lowering agents and skeletal muscle-related phenotypes. Mendelian randomization (MR) analysis was additionally used to verify the causal relationship between statin use and skeletal muscle-related phenotypes.  ResultsThe weighted mean age was 59 years, 50.3% were male, and 37.6% (n=8,481) received statin treatment. In the unadjusted model, compared with adults without any lipid-lowering drugs, statin use was associated with a higher likelihood of sarcopenia (appendicular skeletal muscle mass [ASM]/Body mass index [BMI] OR 1.35 (95%CI 1.12 to 1.62, p < 0.001), ASM/weight [Wt] OR 1.86 (95%CI 1.62 to 2.13, p < 0.001), max HGS {beta} -3.01 (95% CI -3.97 to -2.06, p < 0.001), relative HGS {beta} -0.23 (95% CI -0.30 to -0.17, p < 0.001) and combined HGS {beta} -5.90 (95% CI -7.86 to -3.93, p < 0.001)), sarcopenic obesity (ASM/height squared [Ht2] and body fat percentage definition [OR 1.36 (95% CI 1.13 to 1.63, p < 0.001]). After multivariable adjustment or propensity score match, the independent associations of statin use with sarcopenia, sarcopenic obesity, HGS, LDH, and musculoskeletal pain became nonsignificant. Stepwise regression suggested that age was the predominant confounding factor for the associations. MR analysis also revealed no significant causality between statin use and skeletal muscle-related phenotypes.  ConclusionsOur epidemiological and MR analyses did not support the causality between statin use and skeletal muscle-related phenotypes. A higher likelihood of skeletal muscle-related adverse phenotypes in statin users may be attributed to age. Future studies should further explore the biological factors that may affect statin-related muscle phenotypes to provide evidence for the safety of statins.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Summary Estimates Derived from a Multi-state Non-Markov Framework to Characterize the Course of Heart Disease\nAbstract: Multi-state Markov models have been used to model the course of chronic disease. However, they are unsuitable to chronic disease where past and present states interplay and affect future states, and the estimated transition probabilities are time-specific which are not straightforward for public health interpretation. We have proposed a multi-state non-Markov framework that splits disease states into substates conditioning on past states. As the substates track past states and indicate multimorbidity, the estimated transition rates can be used to derive two summary estimates: Disease path which shows path of state transition, and multimorbidity-adjusted life year (MALY) which represents the adjusted life year in full health. In this paper, we showed the derivation of the two summary estimates and applied them to characterize the course of heart disease using data from the Atherosclerosis Risk in Communities Study (ARIC) study. The course of heart disease was modeled in five states, namely, healthy, at metabolic risk, coronary heart disease (CHD), heart failure, and mortality. In this mid- to old-age population, the estimated MALY was 24.13 (95% CI: 16.55, 32.06) years. For healthy participants at baseline, the most likely disease paths were: \"Healthy [-&gt;] at metabolic risk [-&gt;] mortality\" (37%), \"Healthy [-&gt;] mortality\" (21%), \"Healthy [-&gt;] at metabolic risk [-&gt;] heart failure [-&gt;] mortality\" (19%), and \"Healthy [-&gt;] at metabolic risk [-&gt;] CHD [-&gt;] mortality\" (8%). The MALY was higher among women than men and higher among Whites than Blacks. The distribution of disease path was similar across sex and race subgroups. In summary, MALY and disease path characterize the disease course in a summary manner and have potential use in chronic disease prevention.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Childhood conduct problems, potential snares in adolescence and problematic substance use in Brazil\nAbstract: ObjectiveExamine whether the relationship between childhood conduct problems and substance use in adulthood is explained through potential snares (police arrest, gang membership, school non-completion) in a Brazilian population-based birth cohort.  MethodData were analyzed from 4,599 young people from the 1993 Pelotas Birth Cohort in Brazil. The exposure was conduct problems at age 11 years. Outcomes included hazardous alcohol consumption and illicit drug use (age 22 years). Mediators included police arrest (by age 18 years), gang membership (ages 18 and 22 years), and school non-completion (by age 22 years). We performed counterfactual mediation using the parametric g-computation formula to estimate the indirect effect via all three mediators simultaneously.  ResultsAfter adjusting for confounders (including comorbidity), conduct problems were weakly associated with police arrest [OR (95% CI)=1.45 (0.97, 2.16)] and school non-completion [OR (95% CI)=1.46 (1.22, 1.74)], but not with gang membership. Police arrest and gang membership were associated with illicit drug use [OR (95% CI)=3.84 (2.46, 5.99); OR (95% CI)=7.78 (4.30, 14.10), respectively] and with hazardous alcohol use [OR (95% CI)=1.60 (1.08, 2.38); OR (95% CI)=1.88 (1.07, 3.30)]. However, there was no association between school non-completion and either outcome after confounder adjustment. There was little evidence for an indirect effect of conduct problems on hazardous alcohol use and illicit drug use via all three mediators after confounder adjustment.  ConclusionThe indirect effects of childhood conduct problems on substance use in early adulthood via police arrest, gang membership, and school non-completion were very small, after accounting for confounders and comorbidity.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Latent class growth mixture modelling of HbA1C trajectories identifies individuals at high risk of developing complications of type 2 diabetes mellitus in the UK Biobank\nAbstract: AimsGlycated Hemoglobin A1c (HbA1c) is widely used for the diagnosis and management of type 2 diabetes mellitus (T2D), with regular testing in primary care recommended every three to six months. We aimed to identify distinct, long-term HbA1c trajectories following a T2D diagnosis and investigate how these glycaemic control trajectories were associated with health-related traits and T2D complications.  MethodsA cohort of 12,435 unrelated individuals of European ancestry with T2D was extracted from the UK Biobank data linked to primary care records. Latent class growth mixture modelling was applied to identify classes with similar HbA1c trajectories over the 10-years following T2D diagnosis. We tested for associations of HbA1c class membership with sociodemographic factors, biomarkers, polygenic scores, and T2D-related outcomes, using logistic regression and Cox proportional hazards models.  ResultsSix HbA1c trajectory classes were identified. The largest class (76.8%) maintained low and stable HbA1c levels over time. The other five classes demonstrated higher and more variable trajectories and included: two with parabolic shapes (starting low and distinguished by the height of their peaks), two with high initial HbA1c levels that declined over time (one rapidly, one slowly), and one class with a rapid increase in HbA1c five years after diagnosis. Younger age at T2D diagnosis, higher fasting glucose levels, higher random glucose levels, and higher body mass index polygenic score were associated with membership of these five classes. These classes were also more likely to be prescribed glucose-lowering medication at diagnosis and had fewer primary care visits in the month and year prior to diagnosis. Relative to the low and stable class, these five showed increased risks of T2D complications, including stroke (HR=1.55 [1.31-1.84]), kidney disease (HR=1.39 [1.27-1.53]), all-cause mortality (HR=1.36 [1.23-1.51]), and progression to combination therapy (HR=3.22 [3.04-3.41]) or insulin (HR=3.21 [2.89-3.55]).  ConclusionIndividuals with T2D who show higher and more variable HbA1c trajectories are at increased risk of developing T2D-related complications. Early identification of patients at risk, based on factors such as age at diagnosis and previous healthcare utilisation could improve patient outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Temporal trends in the occurrence, mortality, and cost of brain disorders in Denmark\nAbstract: BackgroundBrain disorders, including neurological and mental disorders, are common and burdensome diseases.  AimTo examine temporal trends in occurrence, mortality, and cost of brain disorders in Denmark for the period of 2015-2021.  MethodsWe conducted a nationwide population-based cohort study using individual-level data recorded in the Danish health registries during 2011-2021. We computed the prevalence of any brain disorder and 25 individual brain disorders for each year from 2015 to 2021 and the incidence for the periods 2011-2015 and 2016-2021 by combining hospital diagnoses and filled prescriptions for relevant medications. We computed one-year hazard ratios (HRs) for mortality by comparing individuals with brain disorders to matched controls without. We also calculated attributable direct and indirect costs (i.e., lost productivity) of brain disorders.  ResultsThe prevalence of any brain disorder in Denmark was 33.2% in 2015, increasing to 35.2% in 2021. The three most prevalent conditions were depression (13.5% in 2021), sleep disorders (13.5% in 2021), and headache (7.9% in 2021). The incidence rate of any brain disorder was 1,792 and 1,634 per 100,000 person-years in 2011-2015 and 2016-2021, respectively. The one-year HR of mortality for any brain disorder was 5.5 (95% confidence internal [CI]: 5.4; 5.6) for 2011-2015 and 5.3 (95% CI: 5.2; 5.3) for 2016-2021. The total attributable direct costs for individuals with any brain disorder were {euro}7.5 billion in both 2015 and 2021. In 2021, the total attributable indirect costs were highest for depression ([~]{euro}3.5 billion) and lowest for neuromuscular disorders ([~]{euro}53.5 million). Total indirect costs increased from {euro}17.7 billion in 2015 to {euro}23.2 billion in 2021. In 2021, the total indirect costs were highest for depression ([~]{euro}14 billion) and lowest for other neurodegenerative disorders ([~]{euro}60 million).  ConclusionBrain disorders remain common, with a fivefold higher one-year mortality compared to persons without brain disorders. While total direct costs were similar in 2015 and 2021, total indirect costs increased over this period.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Overview and evaluation of a nationwide hospital-based surveillance system for Influenza and COVID-19 in Switzerland (CH-SUR): 2018-2023\nAbstract: BackgroundIn 2018, a hospital-based surveillance system for influenza (CH-SUR) was established in six tertiary care hospitals in Switzerland. From March 2020 onwards, this surveillance system was expanded to include more institutions, as well as COVID-19.  AimTo evaluate quantitatively and qualitatively the surveillance system CH-SUR.  MethodsAll patients admitted to one of the participating centres for more than 24 hours and who had a laboratory-confirmed influenza virus or SARS-CoV-2 infection were included in CH-SUR. For all cases, we evaluated the quality of the CH-SUR data, including timeliness and completeness of reporting. A qualitative survey among CH-SUR stakeholders assessed perceived importance, understanding, reliability and adaptability of CH-SUR.  ResultsUp to 20 centres participated in CH-SUR. Between December 2018 and October 2023, 7,375 cases of influenza were reported and between March 2020 and October 2023, 49,235 cases of COVID-19 were reported to CH-SUR. During the COVID-19 pandemic, time to data entry and completeness improved over time; the median delay of data entry in CH-SUR was 5 days (IQR=2-23) for COVID-19 and 4 days (IQR=2-15) for influenza during the period 2018-2023. The completeness of variables was high (99.4%), with the exception of COVID-19 or annual influenza vaccination status (respectively 15% and 72% of \"Unknown\" responses). Stakeholders perceived the system as important, relevant, understandable and adaptable.  ConclusionCH-SUR has provided critical epidemiological and clinical information on hospitalised influenza and COVID-19 cases across Switzerland during the pandemic. Our evaluation highlighted the importance and relevance of this system among CH-SUR stakeholders, as well as its importance for preparedness and response to future infectious disease outbreaks.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Overview and evaluation of a nationwide hospital-based surveillance system for Influenza and COVID-19 in Switzerland (CH-SUR): 2018-2023\nAbstract: BackgroundIn 2018, a hospital-based surveillance system for influenza (CH-SUR) was established in six tertiary care hospitals in Switzerland. From March 2020 onwards, this surveillance system was expanded to include more institutions, as well as COVID-19.  AimTo evaluate quantitatively and qualitatively the surveillance system CH-SUR.  MethodsAll patients admitted to one of the participating centres for more than 24 hours and who had a laboratory-confirmed influenza virus or SARS-CoV-2 infection were included in CH-SUR. For all cases, we evaluated the quality of the CH-SUR data, including timeliness and completeness of reporting. A qualitative survey among CH-SUR stakeholders assessed perceived importance, understanding, reliability and adaptability of CH-SUR.  ResultsUp to 20 centres participated in CH-SUR. Between December 2018 and October 2023, 7,375 cases of influenza were reported and between March 2020 and October 2023, 49,235 cases of COVID-19 were reported to CH-SUR. During the COVID-19 pandemic, time to data entry and completeness improved over time; the median delay of data entry in CH-SUR was 5 days (IQR=2-23) for COVID-19 and 4 days (IQR=2-15) for influenza during the period 2018-2023. The completeness of variables was high (99.4%), with the exception of COVID-19 or annual influenza vaccination status (respectively 15% and 72% of \"Unknown\" responses). Stakeholders perceived the system as important, relevant, understandable and adaptable.  ConclusionCH-SUR has provided critical epidemiological and clinical information on hospitalised influenza and COVID-19 cases across Switzerland during the pandemic. Our evaluation highlighted the importance and relevance of this system among CH-SUR stakeholders, as well as its importance for preparedness and response to future infectious disease outbreaks.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genomic recombination of rapidly evolving mpox Ib strains compounds the challenges of the 2024 outbreak\nAbstract: The World Health Organization recently declared the 2024 mpox virus (MPXV Ib) outbreak a public health emergency of international concern. We report that in 2023-2024, MPXV clade Ib genomes are diverging at a faster rate than clade IIb (2022), primarily due to an unusually high incidence of recombination. Phylogenetic analysis revealed that Ib strains have diverged into four lineages, and they have evolved into 14 subgroups based on nine tandem repeat (TR) polymorphisms. These findings confirms that TRs in MPXV Ib are mutating at a significantly higher frequency compared to the 2022 outbreak (clade IIb, 11 subgroups). Linkage disequilibrium analysis also identified 10 recombination clusters among all 4 lineages, with recombination incidence in Ib being twice as high as in IIb. This suggests that a higher rate of superinfection is contributing to ongoing recombination among populations infected with clade Ib. Prompt action is necessary to prevent the emergence of more lethal mpox strains.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of Ghanas COVID-19 policy responses and lessons learnt for the future: A multi-methods evaluation\nAbstract: Ghana implemented various mitigating policies in response to the COVID-19 outbreak. This study examined the effectiveness of these policies to contribute to the ongoing discussions on proactive and pre-emptive interventions for similar future outbreaks.  A mix of qualitative and quantitative methods were used for the analysis. Data were drawn from multiple sources, including peer-reviewed and grey literature, and academic experts from Ghanaian universities. The data from the literature informed a questionnaire that was sent to independent academic experts to explore their opinions on whether the policies met their intended objectives. The experts opinions were collected on a 5-point Likert scale and from an open-ended question using an online data collection platform, Qualtrics. The data were evaluated using narrative synthesis, descriptive statistics and thematic analysis.  We identified and evaluated eight key COVID-19 policy responses in Ghana: (1) partial lockdown of epicentres; (2) COVID-19 public awareness campaigns; (3) ban on public gatherings; (4) COVID-19 vaccination; (5) border closures; (6) entry border COVID-19 screening; (7) incentives for healthcare workers (HCWs); and (8) the Ghana Alleviation and Revitalisation of Enterprises Support (GCARES). Two policies - the COVID-19 awareness campaigns and border closure - effectively improved public awareness of COVID-19 and helped to reduce COVID-19 case importation (median score [&ge;]4).  Ghanas COVID-19 public awareness campaigns and border closure policies could serve as a valuable model for informing proactive interventions to address future infectious disease outbreaks.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mapping and sequencing of cases from an ongoing outbreak of Clade Ib monkeypox virus in South Kivu, Eastern Democratic Republic of the Congo between September 2023 to June 2024\nAbstract: BackgroundIn September 2023, an mpox outbreak was reported in the eastern part, South Kivu Province, of Democratic Republic of the Congo. This outbreak is still ongoing and expanding to other regions and countries. Here, we describe the epidemiological and genomic evolution of the outbreak from September 2023 to June 2024.  MethodsConsenting patients with mpox-like symptoms admitted to the Kamituga and the Kamanyola hospitals were recruited to the study. Samples from throat, lesions, breast milk and placenta were collected for PCR testing and sequencing. For the patients from Kamituga hospital, data on place of residence and possible exposures were collected by interviews. The location and numbers of employees were collected for all bars with sex workers. Where possible, exposures were linked to the genomic sequencing data for cluster analysis.  FindingsIn total, 670 (suspected) mpox cases were admitted to the Kamituga hospital. There were slightly more female than male cases (351/670 [52,4%] versus 319/670, [47,6%], and cases were reported from 17 different health areas. The majority of cases were reported in Mero (205/670 [30,6%]), followed by Kimbangu (115/670 [17,2%]), Kabukungu (105/670 [16,7%]), and Asuku (73/670 [10.9%]). During this period, 7 deaths occurred and 8 out of 14 women who were pregnant had fetal loss. Three healthcare workers acquired mpox infection when caring for patients. In depth case ascertainment showed that 83,4% of patients reported recent visits to bars for (professional) sexual interactions as a likely source of infection. Whole genome sequencing resulted in the generation of 58 genome sequences. Three main clusters characterized by specific mutations were identified and several miniclusters of 2 or more sequences with over two shared mutations. No clear link between sequence cluster, bar or health area was observed. The more recent sequences from Kamanyola were related to the sequences in Kamituga and confirmed to be Clade Ib. However, relatively long branches were observed and one of the sequences clustered with publicly released sequences from travelers in Kenya, Uganda, Sweden and Thailand, indicating more undocumented ongoing spread for cluster A than for the other clusters. Most observed mutations were APOBEC-3 related mutations indicative of ongoing human-to-human transmission.  InterpretationThese data suggests that the rapid transmission of monkeypox virus until June 2024 was mostly related to interactions with professional sex workers (PSW) within densely populated health areas. The expanding number of cases and the recent expansion to 29 other nearby health zones of South -Kivu as well as Rwanda, Burundi, Uganda and Kenya stresses the need for cross border surveillance and collaboration. Urgent enhanced response action is needed, including case finding, diagnostic capacity building, health education programmes focussing on sex workers, and possibly vaccination to limit further escalation and stop this outbreak.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Humoral Immune Responses in German Dialysis Patients after mRNA Omicron JN.1 Vaccination\nAbstract: To assess the effect of the updated mRNA JN.1 omicron vaccine (bretovameran, BioNTech/Pfizer, Mainz, Germany) in an immunocompromised and elderly population, we measured humoral immune responses after mRNA omicron JN.1 vaccination in 37 haemodialysis patients before and 21 days after vaccination.  We observed a 3-fold change in anti-S IgG, and a 4{middle dot}7-fold change in anti-S omicron IgG. Memory B cells (MBC) exclusively binding the receptor binding domain (RBD) of JN.1 displayed a median frequency of 0{middle dot}11% before vaccination and changed significantly 3{middle dot}9-fold to a median of 0{middle dot}43%. Cross reactive JN.1 RBD and Wuhan-Hu-1 S-binding MBCs and MBCs only binding to Wuhan-Hu-1 S changed 2{middle dot}3-fold and 1{middle dot}8-fold, respectively. Using a vesicular stomatitis virus-based pseudovirus particle (pp) neutralisation assay, baseline response rates were 86% for XBB.1.5pp, 78% for JN.1pp, 73% for and KP.2pp, 65% for KP.2.3pp and KP.3pp, and 68% for LB.1pp. After vaccination, the response rates for all pseudoviruses increased significantly, and we observed a mean increase in neutralisation of XBB.1.5pp, JN.1pp, KP.2pp, KP.2.3pp, KP.3pp, and LB.1pp of 8{middle dot}3-fold, 18{middle dot}7-fold, 22{middle dot}5-fold, 18{middle dot}7-fold, 25{middle dot}5-fold, and 23{middle dot}5-fold, respectively. In summary, our report provides first evidence for a firm humoral immune response in dialysis patients after mRNA omicron JN.1 vaccination.  Our data suggest that the vaccine could be highly effective at enhancing protection of vulnerable populations against evolving SARS-CoV-2 variants.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integrating Clinical Research with Electronic Health Records to Improve Diversity in Research: Findings from an Urban Hospital System\nAbstract: BackgroundThe under-representation of racial, ethnic, and other minority populations in clinical research has threatened the validity of novel therapeutic interventions and exacerbated the longstanding inequities in health outcomes. Despite attention and mandates across institutions and federal agencies to address these disparities, effective and actionable strategies have remained a subject of debate in the existing literature. Thus, the need for comprehensive and rigorous methods to assess diversity in study population samples as well as strategies for improved recruitment and retention has been made clear.  ObjectiveExamine the distribution of research participant demographics at Norton Healthcare (NHC) and compare to applicable benchmarks from the overall NHC patient population and local census.  DesignSuccessive-independent samples comparison of EPIC electronic health records (EHR) and census data from Jefferson County.  ParticipantsA total of 2,053 adult research participants enrolled at NHC from 2020 - 2024.  Main MeasuresDemographic data were reported as frequency and percentage across the three benchmarks. The z-test for independent proportions was used to compare the research participant demographics to the NHC patients and Jefferson County during a consistent time period. Temporal trends in research participant demographics were also examined.  Key ResultsApart from being relatively older, the NHC research participant population closely resembled the NHC patient population. A similar age-related pattern emerged as well as an over-representation of White individuals in the research participant group when compared to the census data. When looking at research participant demographic trends overtime, increases in White, Black and older cohorts were noted while decreases were observed in Hispanic/Latinx and younger cohorts. Trends related to participant sex remained stable.  ConclusionsThe findings from this study will inform future strategies for setting enrollment goals and facilitate the creation of tools and metrics to evaluate appropriate standards for diversity in clinical research study population samples.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cohort profile: design, sociodemographic characteristics, chronic disease risk factors, and baseline hypertension and diabetes care cascades of the open, prospective Community-Based chronic disease Care Lesotho (ComBaCaL) cohort\nAbstract: PurposeThe open, prospective Community-Based chronic Care Lesotho (ComBaCaL) cohort is the first study to comprehensively investigate socioeconomic indicators, common chronic diseases and their risk factors in a remote rural setting in Lesotho. It serves as a platform for implementing nested trials using the Trials within Cohorts (TwiCs) design to assess community-based chronic care interventions. Here, we present the cohorts sociodemographic and chronic disease risk factor profile, including self-reported HIV prevalence and hypertension and diabetes care cascades.  ParticipantsSince February 2023, Community Health Worker (CHWs) supported by a clinical decision support and data collection application, have enrolled inhabitants from 103 randomly selected rural villages in Butha-Buthe and Mokhotlong districts in North-East Lesotho. As of May 31, 2024, the cohort includes 5008 households with 14735 participants (55% female, median age 19 years). The cohorts socioeconomic status is low with an International Wealth Index of 26, a monthly household income of 42.4 USD and low levels of formal education. Among the 7917 adult participants, 42.5% are overweight or obese, with higher rates among women, and 33.1% smoke tobacco, with higher rates among men. Self-reported HIV prevalence is 15.1% with a 98.4% treatment rate. Hypertension prevalence is 17% with a 56% control rate and diabetes prevalence is 4% with a 39% control rate.  Findings to dateThe cohorts low socioeconomic status is linked to multiple health risks including insufficient access to clean energy, essential healthcare services, adequate sanitary facilities and secure food supply. Besides the expected high HIV prevalence, we found significant hypertension, diabetes and cardiovascular risk factor prevalences. While treatment and control rates for diabetes and hypertension are higher than in similar settings, they remain below global targets.  Future plansOngoing cluster-randomized TwiCs, which will be completed in 2025, are assessing the effectiveness of community-based, CHW-led care interventions for diabetes and hypertension. CHWs will continue to closely monitor the cohort and integrate additional measurements such as HIV testing. This will provide further insights into the dynamics and interactions of chronic diseases and inform the development of future nested trials on innovative community-based prevention and care interventions.  RegistrationNCT05596773  Strengths and limitations- Comprehensive Data Collection: The ComBaCaL cohort offers comprehensive data on sociodemographics, chronic disease risk factors, and hypertension and diabetes care cascades within a large, representative sample of the rural population in Lesotho. - Community-Based Approach: Data is captured by local Community Health Workers residing in the study villages using a tailored clinical decision support and data collection application. This approach allows for continuous data collection, remote monitoring by study staff, and data verification, ensuring nearly complete village enrolment and high data quality. - Efficient study design: The cohort utilizes the Trials within Cohorts (TwiCs) design, which allows for the efficient implementation of multiple randomized nested trials to assess the effectiveness of innovative health interventions. - Reliance on self-reported data: Assessments other than hypertension and diabetes screening outcomes rely on self-reported data, which may have limited correlation with objective assessments. - Limitations in data scope: Clinical data on chronic conditions other than hypertension and diabetes remain limited and anthropometric and behavioural risk factor data for children has not yet been collected.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The potential global impact and cost-effectiveness of next-generation influenza vaccines: a modelling analysis\nAbstract: BackgroundNext-generation influenza vaccines (NGIVs) are in development and have the potential to achieve greater reductions in influenza burden, with resulting widespread health and economic bene[fi]ts. Understanding the prices at which their market can be sustained and which vaccination strategies may maximise impact and cost-effectiveness, particularly in low- and middle-income countries, can provide a valuable tool for vaccine development and investment decision-making at a national and global level. To address this evidence gap, we projected the health and economic impact of NGIVs in 186 countries and territories.  Methods and FindingsWe inferred current influenza transmission parameters from World Health Organization (WHO) FluNet data in regions de[fi]ned by their transmission dynamics, and projected thirty years of influenza epidemics, accounting for demographic changes. Vaccines considered included current seasonal vaccines, vaccines with increased efficacy, duration, and breadth of protection, and universal vaccines, de[fi]ned in line with the WHO Preferred Product Characteristics. We estimated cost-effectiveness of different vaccination scenarios using novel estimates of key health outcomes and costs.  NGIVs have the potential to substantially reduce influenza burden: compared to no vaccination, vaccinating 50% of children aged under 18 annually prevented 1.3 (95% uncertainty range (UR): 1.2-1.5) billion infections using current vaccines, 2.6 (95% UR: 2.4-2.9) billion infections using vaccines with improved efficacy or breadth, and 3.0 (95% UR: 2.7-3.3) billion infections using universal vaccines. In many countries, NGIVs were cost-effective at higher prices than typically paid for existing seasonal vaccines. However, cross-subsidy may be necessary for improved vaccines to be cost-effective in lower income countries.  This study is limited by the availability of accurate data on influenza incidence and influenza-associated health outcomes and costs. Furthermore, the model involves simplifying assumptions around vaccination coverage and administration, and does not account for societal costs or budget impact of NGIVs. How NGIVs will compare to the vaccine types considered in this model when developed is unknown. We conducted sensitivity analyses to investigate key model parameters.  ConclusionsThis study highlights the considerable potential health and economic bene[fi]ts of NGIVs, but also the variation in cost-effectiveness between high-income and low- and middle-income countries. This work provides a framework for long-term global cost-effectiveness evaluations, and contributes to a full value of influenza vaccines assessment to inform recommendations by WHO, providing a pathway to developing NGIVs and rolling them out globally.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Tracing SARS-CoV-2 Clusters Across Local-scales Using Genomic Data\nAbstract: Understanding local-scale transmission dynamics of SARS-CoV-2 is crucial for planning effective prevention strategies. This study analyzed over 26,000 genomes and their associated metadata collected between January and October 2021 to explore the introduction and dispersal patterns of SARS-CoV-2 in Greater Houston, a major metropolitan area noted for its demographic diversity. We identified more than a thousand independent introduction events, resulting in clusters of varying sizes, with earlier clusters presenting larger sizes and posing greater control challenges. Characterization of the sources of these introductions showed that domestic origins were more significant than international ones. Further examination of locally circulating clusters across different subregions of Greater Houston revealed varied transmission dynamics. Notably, subregions that served as primary viral sources sustained the local epidemic effectively, evidenced by: (1) a smaller proportion of new cases driven by external viral importations, and (2) longer persistence times of circulating lineages. Overall, our high-resolution spatiotemporal reconstruction of the epidemic in Greater Houston enhances understanding of the heterogeneous transmission landscape, providing key insights into regional response strategies and public health planning.  Significance StatementThe growing recognition of genome sequencing as critical for outbreak response has led to a rapid increase in the availability of sequence data. In this context, we put forward an analytical workflow within the Bayesian phylodynamic framework to identify and trace imported SARS-CoV-2 clusters using large-scale genome datasets. By utilizing metrics such as the Source-Sink Score, Local Import Score, and Persistent Time, our approach characterizes transmission patterns in each subregion and elucidates transmission heterogeneity. As new variants continue to emerge, the insights provided by our analysis are crucial for addressing the challenges of current and future pandemics effectively.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Molecular Detection of Multi-drug resistant tuberculosis in clinical isolates from two urban centres in Malawi\nAbstract: IntroductionSuboptimal chemotherapy allows Mycobacterium tuberculosis to develop drug resistance owing to development of resistant mutants in the mycobacterial population. Early diagnosis of TB and identification of drug-resistance is of particular importance in human immunodeficiency virus (HIV)-infected individuals, as delay of therapy and subsequent development of drug-resistant TB can be devastating due to compromised immune systems.  MethodologyWe conducted a cross-sectional evaluation study using presumptive M. tuberculosis positive clinical isolates at two urban sites in Malawi (Blantyre and Lilongwe) to assess the presence of mutant genes on first and second line TB drugs using Line Probe Assay (LPA) and the gold standard drug susceptibility test (DST)  ResultsFor the Lilongwe site, the incidence of MDR-TB by Line Probe Assay (LPA) was found to be 14.06% (95% CI: 8%-20%) whereas that for Rif mono-resistance was 6.25% (95% CI: 2%-10%). Contrastingly, MDR-TB by DST was 23.44% (95 CI:16% - 21%) while mono-resistance was 6.25% (95% CI:2% -10). There was a substantial agreement on the detection of MDR-TB (kappa statistic was 0.75 with 95% CI of 0.62-0.88). Blantyre site, at 9.5% confidence interval, the point estimate for MDR-TB was 0% while for INH mono-resistance TB was 3.3%.  ConclusionsThere is high incidence of MDR-TB among patients whose samples are sent to the Lilongwe site than previously thought. A short turnaround time to diagnosis, and the ability to simultaneously detect rifampicin and isoniazid resistance, makes LPA a reliable tool for the early detection of multidrug-resistant tuberculosis.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Performance evaluation of nine reference centers for effective surveillance of Leishmania-infected Phlebotomine sand flies and basis for technical recommendations\nAbstract: BackgroundLeishmaniasis, caused by Leishmania protozoan parasites transmitted by Phlebotomine sand flies, is a significant public health concern in the Mediterranean basin. Effective monitoring of Leishmania-infected sand flies requires standardized tools for comparing their distribution and infection prevalence. Consistent quantitative PCR (qPCR) conditions and efficient DNA extraction protocols are crucial for reliable results over time and across regions. However, there is currently a lack of technical recommendations for Leishmania DNA detection, which needs to be addressed. This study aimed to compare various DNA extraction protocols and conduct a qPCR based External Quality Assessment (EQA) through a multicenter study involving nine reference laboratories.  Methodology/Principal findingsEQA samples were prepared using Leishmania infantum and L. major strains, at different concentration from 101 to 104 parasites/mL and distributed to participating centers. All centers, except one, detected all Leishmania concentrations, demonstrating diagnostic proficiency. The ability to detect low concentrations highlighted the robustness of the qPCR assay used, although Cq value variations suggested differences in sensitivity due to technical capabilities and/or extraction kit performances.  Reported comparative analysis of seven DNA extraction methods identified the EZ1 DSP Virus(R) Kit and QIAamp(R) DNA mini-kit as the most efficient, supporting their use for standardized protocols. The study also evaluated the impact of lyophilization and shipment conditions, finding no compromise in Leishmania detection, despite slight Cq value variations. In addition to EQA samples, experimentally infected sand fly have been included to mimic sample field condition. All centers detected positive samples, with variable Cq values, reflecting differences in individual infection load.  Conclusion and significanceOverall, the study underscores the importance of standardized protocols and continuous quality assurance to maintain high diagnostic validity, crucial for effective surveillance of leishmaniasis, especially in field settings with low infection densities. Continuous training and calibration are essential to ensure uniform diagnostic performance across laboratories, enhancing epidemiological surveillance and disease control strategies.  Author SummaryLeishmaniasis is a disease caused by Leishmania parasites, transmitted by sand flies, and poses a major health risk in the Mediterranean region. Monitoring the spread of nfected sand flies is crucial for controlling the disease. This study focused on improving the methods used to detect Leishmania in sand flies by comparing different DNA extraction techniques and assessing the accuracy of these methods across nine reference laboratories. All centers, except one, efficiently detected all Leishmania concentrations, demonstrating proficiency in diagnostic protocols. Moreover, we found that two specific DNA extraction kits, the EZ1 DSP Virus(R) Kit and QIAamp(R) DNA mini-kit, were the most effective for Leishmania detection. We also tested how sample preparation and shipping conditions affected the results, ensuring that our methods would work in real-world settings. Even under these conditions, the detection methods proved reliable. This work helps to standardize the detection of Leishmania, making surveillance more accurate and consistent. Continuous training and calibration are essential to ensure uniform diagnostic performance across laboratories, enhancing epidemiological surveillance and disease control strategies\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: DNA methylation age acceleration is associated with incident cognitive impairment in the Health and Retirement Study\nAbstract: BackgroundDNA methylation clocks have emerged as promising biomarkers for cognitive impairment and dementia. Longitudinal studies exploring the link between DNA methylation clocks and cognitive decline have been constrained by limited sample sizes and a lack of diversity.  ObjectiveOur study aimed to investigate the longitudinal associations between DNA methylation clocks and incident cognitive impairment using a larger sample size encompassing a US nationally representative sample from the Health and Retirement Study.  MethodsWe measured DNA methylation age acceleration in 2016 by comparing the residuals of DNA methylation clocks, including GrimAge, against chronological age. Cognitive decline was determined by the change in Langa-Weir cognition status from 2016 to 2018. Using multivariable logistic regression, we evaluated the link between DNA methylation age acceleration and cognitive decline, adjusting for cell-type proportions, demographic, and health factors. We also conducted an inverse probability weighting analysis to address potential selection bias from varying loss-to-follow-up rates.  ResultsThe analytic sample (N=2,713) at baseline had an average of 68 years old, and during the two years of follow-up, 12% experienced cognitive decline. Participants who experienced cognitive decline during follow-up had higher baseline GrimAge (mean = 1.2 years) acceleration compared to those who maintained normal cognitive function (mean = -0.8 years, p < 0.001). A one-year increase in GrimAge acceleration was associated with 1.05 times higher adjusted and survey-weighted odds of cognitive decline during follow-up (95% CI: 1.01-1.10). This association was consistent after accounting for loss-to-follow-up (OR = 1.07, 95% CI: 1.04-1.11).  ConclusionOur study offers insights into DNA methylation age acceleration associated with cognitive decline, suggesting avenues for improved prevention, diagnosis, and treatment.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: High Seroprevalence to Aedes-borne arboviruses in Ethiopia: a Cross-sectional Survey in 2024\nAbstract: Aedes-borne diseases infect millions of people each year. In the last decade several arbovirus outbreaks have been reported in Ethiopia. Arbovirus diagnosis and surveillance is lacking and the true burden is unknown. In this study we conducted a seroprevalence survey using a commercially available test kit that that tests for immunological responses to IgM and IgG for dengue (DENV), Zika (ZIKV), and chikungunya (CHIKV) viruses in Dire Dawa city, eastern Ethiopia. We found a high IgG seroprevalence for DENV (76%), CHIKV (44%), and ZIKV (38%), and <20% IgM seropositivity across all viruses. As a comparison, we conducted serosurveillance in Addis Ababa, the national capital with no reported history of arbovirus outbreaks. The highest seropositivity we found was to IgM for DENGV at approximately 3%. Our results suggest both past and recent widespread exposure to these arboviruses, underscoring the need for improved surveillance and public health interventions in Ethiopia.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: High Seroprevalence to Aedes-borne arboviruses in Ethiopia: a Cross-sectional Survey in 2024\nAbstract: Aedes-borne diseases infect millions of people each year. In the last decade several arbovirus outbreaks have been reported in Ethiopia. Arbovirus diagnosis and surveillance is lacking and the true burden is unknown. In this study we conducted a seroprevalence survey using a commercially available test kit that that tests for immunological responses to IgM and IgG for dengue (DENV), Zika (ZIKV), and chikungunya (CHIKV) viruses in Dire Dawa city, eastern Ethiopia. We found a high IgG seroprevalence for DENV (76%), CHIKV (44%), and ZIKV (38%), and <20% IgM seropositivity across all viruses. As a comparison, we conducted serosurveillance in Addis Ababa, the national capital with no reported history of arbovirus outbreaks. The highest seropositivity we found was to IgM for DENGV at approximately 3%. Our results suggest both past and recent widespread exposure to these arboviruses, underscoring the need for improved surveillance and public health interventions in Ethiopia.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Wastewater surveillance overcomes socio-economic limitations of laboratory-based surveillance when monitoring disease transmission: the South African experience during the COVID-19 pandemic\nAbstract: Wastewater and environmental surveillance has been promoted as a communicable disease surveillance tool because it overcomes inherent biases in laboratory-based communicable disease surveillance. Yet, little empirical evidence exists to support this notion, and it remains largely an intuitive, though highly plausible hypothesis. Our interdisciplinary uses WES data to show evidence for underreporting of SARS-CoV-2 in the context of measurable and statistically significant associations between economic conditions and SARS-CoV-2 incidence and testing rates. We obtained geolocated, anonymised, laboratory-confirmed SARS-CoV-2 cases, wastewater SARS-CoV-2 viral load data and socio-demographic data for Gauteng Province, South Africa. We spatially located all data to create a single dataset for sewershed catchments served by two large wastewater treatment plants. We conducted epidemiological, persons infected and principal component analysis to explore the relationships between variables. Overall, we demonstrate the co-contributory influences of socio-economic indicators on access to SARS-CoV-2 testing and cumulative incidence, thus reflecting that apparent incidence rates mirror access to testing and socioeconomic considerations rather than true disease epidemiology. These analyses demonstrate how WES provides valuable information to contextualise and interpret laboratory-based epidemiological data. Whilst it is useful to have these associations established for SARS-CoV-2, the implications beyond SARS-CoV-2 are legion for two reasons, namely that biases inherent in clinical surveillance are broadly applicable across pathogens and all pathogens infecting humans will find their way into wastewater albeit in varying quantities. WES should be implemented to strengthen surveillance systems, especially where economic inequalities limit interpretability of conventional surveillance data.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Self-reported health 50 years later among Children and Adolescents who experienced The Scorched Earth tactics in Finnmark county, Norway, in World War II, 1944/45\nAbstract: BackgroundMost of Finnmark county in Norway was burned down during World War II by the German troops on order from Hitler, the scorched earth tactic. More than 50 000 were evacuated, but 23 000 disobeyed and stayed the winter 1944/45 in caves, turf huts and underneath boats. The purpose of this study was to examine among those being children and adolescents at that time, the effect of place of residence, nutrition and self-reported health consequences of wartime experiences on current self-reported health 50 years later.  Material and methodsIn connection with the cardio-vascular screening study in Finnmark 1996/97 nine questions regarding health status and experiences during World War II were included in a questionnaire. Altogether 3.471 persons born between 1925 and 1944 responded to the questions: 64% response rate. The dependant variables in the analysis were current self-reported health.  ResultsIn a multivariate analysis those who reported reduction in health due to the war had a higher risk of having poor self-reported health at time of screening; OR=2.7 (95% confidence interval 2.1-3.5). Place of residence 1944/45 in Finnmark was a borderline significant risk factor, while lack of food was associated with reduced self-reported health.  ConclusionDespite the long period of time between World War II and the present screening, a relation between the experience from the war and having a poor self-evaluated health status today was found. The study indicates long-term health consequences of warfare on the civilian population, but due to the cross-sectional design further prospective studies are necessary.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Seroprevalence of teratogenic viruses among women of childbearing age in Botswana.\nAbstract: BackgroundTeratogenic viruses are viruses than can cross the placenta and infect a growing foetus, resulting in malformations and birth defects. Some of the commonly known teratogenic viruses include cytomegalovirus (CMV), rubella, herpes simplex and varicella zoster (VZV) viruses. Most birth defects associated with these infections affect the central nervous system and sensory organs leading to symptoms that include mental retardation, hearing loss and blindness. The economic burden caused by congenital birth defects is high, as many affected children require special care, therapeutic and educational services. Despite the risk posed by teratogenic viruses during pregnancy, there is no national screening for active CMV, Rubella or VZV infection during pregnancy in Botswana and most African countries. Furthermore, data on the seroprevalence of these viruses among women of childbearing age is limited.  Methods and settingThis cross-section study used eighty-nine (89) residual plasma samples from Scottish Livingstone Hospital Laboratory in Molepolole-Botswana. Samples were from women between the ages 15-49 years. Samples were tested for antibodies against rubella, VZV and CMV using enzyme linked immunosorbent assay.  ResultsOur results show a high seroprevalence of rubella IgG antibodies (97%), even though a small proportion (3%) of women are still susceptible. There was also a high seroprevalence of CMV IgG (100%) which was accompanied by an equally high CMV IgM of 98%. Seroprevalence of VZV IgG was low (63%) and 3% of the samples showed active VZV infection.  ConclusionsTeratogenic viruses are a concern in the population. This calls for preventative measures which include prompt screening and vaccination of susceptible eligible women to prevent congenital abnormalities in children.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessing Variation in First-Line Type 2 Diabetes Treatment across eGFR Levels and Providers\nAbstract: ObjectiveThe purpose of this study is to assess variation in first-line type 2 diabetes treatment empirically using a large clinical dataset. Since metformin, the guideline-recommended first-line treatment, is contraindicated for severe chronic kidney disease, we examine variation in this treatment decision on two axes--across estimated glomerular filtration rate (eGFR) measurements from the patient and across preferences from the prescribing provider.  Study Design and SettingUsing a large insurance claims dataset, we conducted a retrospective cohort study of patients who were newly initiated on a type 2 diabetes treatment (metformin versus a DPP-4 inhibitor or sulfonylurea). Three years of observation prior to treatment were required, and patients with type 1 or gestational diabetes or without eGFR results were excluded. To test whether the choice of treatment is significantly dependent on eGFR level, we performed a chi-squared test for association between eGFR level and treatment decision. 2) To test whether practice variation exists among providers that cannot be explained by treatment guidelines, we fitted restricted cubic spline models to predict treatment from patient age, eGFR, sex, history of heart failure, and treatment date. Then, we performed a generalized likelihood ratio test (GLRT) to assess whether a model that included provider-specific random effects is a better fit than a model without these random effects.  ResultsAmong 10,643 eligible patients, the choice of metformin versus a DPP-4 inhibitor or a sulfonylurea was significantly associated with eGFR level (p < 0.0001). Among the 2,271 patients seen by 173 providers with at least 10 patients in the cohort, a GLRT found significant variation exists across providers even after accounting for age, eGFR, sex, history of heart failure, and treatment date (p < 0.0001).  ConclusionOur study found significant variation in first-line type 2 diabetes treatments--some that can be explained by treatment guidelines and some that may be due to provider preferences. Further studies can help elucidate whether such variation across providers is appropriate. The data-driven approaches in our study can also be applied to other disease areas to characterize variation in real-world clinical practice and potential opportunities for improvement.  What is New?Key Findings  O_LIWe used a large health insurance claims dataset to show that first-line type 2 diabetes treatment is significantly associated with estimated glomerular filtration rate (eGFR). C_LIO_LIWe established empirically that significant variation exists in how providers choose between metformin and DPP-4 inhibitors or sulfonylureas for first-line type 2 diabetes treatment, even after accounting for eGFR, age, sex, history of heart failure, and treatment date. C_LI  What this adds to what is known?O_LIWe proposed a new statistical approach to test for variation in treatment decisions across all providers while accounting for patient characteristics. C_LIO_LIWe applied this approach to establish that providers may consider eGFR levels differently when prescribing first-line type 2 diabetes treatments. C_LI  What is the implication and what should change now?O_LIFurther work is needed to understand whether the provider variation we discovered for initial type 2 diabetes treatment is appropriate, and if not, how to remove this variation by reaching out to providers or improving treatment guidelines C_LIO_LIOur proposed statistical approach can be applied to determine whether provider variation exists for other diseases after accounting for patient characteristics relevant to the specific disease. C_LI    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=118 SRC=\"FIGDIR/small/24313155v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (31K): org.highwire.dtl.DTLVardef@197215aorg.highwire.dtl.DTLVardef@10eccbdorg.highwire.dtl.DTLVardef@a3aa95org.highwire.dtl.DTLVardef@1144174_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genomic Surveillance for Enhanced Healthcare Outbreak Detection and Control\nAbstract: BackgroundCurrent methods are insufficient alone for outbreak detection in hospitals. Real-time genomic surveillance using offers the potential to detect otherwise unidentified outbreaks. We initiated and evaluated the Enhanced Detection System for Healthcare-associated Transmission (EDS-HAT), a real-time genomic surveillance program for outbreak detection and mitigation.  MethodsThis study was conducted at UPMC Presbyterian Hospital from November 2021 to October 2023. Whole genome sequencing (WGS) was performed weekly on healthcare-associated clinical bacterial isolates to identify otherwise undetected outbreaks. Interventions were implemented in real-time based on identified transmission. A clinical and economic impact analysis was conducted to estimate infections averted and net cost savings.  ResultsThere were 3,921 bacterial isolates from patient healthcare-associated infections that underwent WGS, of which 476 (12.1%) clustered into 172 outbreaks (size range 2-16 patients). Of the outbreak isolates, 292 (61.3%) had an identified epidemiological link. Among the outbreaks with interventions, 95.6% showed no further transmission on the intervened transmission route. The impact analysis estimated that, over the two-year period, 62 infections were averted, with gross cost savings of $1,011,146, and net savings of $695,706, which translates to a 3.2-fold return on investment. Probabilistic sensitivity analysis showed EDS-HAT was cost-saving and more effective in 98% of simulations.  ConclusionReal-time genomic surveillance enabled the rapid detection and control of outbreaks in our hospital and resulted in economic benefits and improvement in patient safety. This study demonstrates the feasibility and effectiveness of integrating genomic surveillance into routine infection prevention practice, offering a paradigm shift in healthcare outbreak detection and control.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Population-level Impact of HPV Vaccination On the Incidence of Genital Warts in Sweden\nAbstract: BackgroundSweden introduced HPV vaccination in 2006, administered through opportunistic, subsidized, catch-up and school-based programs. Notably, genital warts (GW) are the first observable clinical outcome following infection by HPV-6/11, targeted by vaccination. We aim to gain knowledge of the population incidence of GW in Sweden and evaluate its change throughout vaccination programs.  MethodsThis ecological study used Swedish registers to obtain national population data and cases of genital warts from 2006-2018 in men and women aged 15-44. We used Poisson models to evaluate GW incidence change after vaccination in reference to a pre-vaccination period, stratified by age and sex. As well as, to estimate incidence change of GW in birth cohorts eligible for different vaccination programs compared to a pre-vaccination cohort. Finally, we estimated GW cases averted in each vaccinated cohort.  ResultsThe incidence of GW decreased during periods following HPV vaccination. In 2016-2018, over a decade after vaccination availability, incidence decreased by 89% (95% CI 83-93), 73% (95% CI 71-75), 50% (95% CI 43-56) and 20% (95% CI 10-28) in women aged 15-19, 20-24, 25-29 and 30-34, respectively. A similar reduction was observable in men, although of lesser magnitude. We estimated 18,890 and 12,343 GW cases averted among vaccinated cohorts of women and men, respectively.  ConclusionsWe report on population-level decreases of GW incidence in women and men following increased vaccination coverage. Cohorts eligible for school-based vaccination recorded the largest decrease in GW incidence in Sweden to date. For the period under study, decreases among men could be attributed to herd effects.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessing COVID-19 infection probabilities in response to alternate vaccine boosting frequencies for multiple-sclerosis patients undergoing disease-modifying therapy with beta-interferon, dimethyl fumarate, natalizumab, or teriflunomide\nAbstract: Multiple sclerosis patients treated with disease-modifying therapies experience varying immune responses to COVID-19 vaccinations. However, guidance regarding the impact of treatments on infection risks remains sparse. Integrating vaccine-based and long-term coronavirus infection-based antibody data, we calculated cumulative probabilities of breakthrough infection for untreated multiple sclerosis patients and patients treated with interferon, dimethyl fumarate, natalizumab, or teriflunomide undergoing alternative Pfizer-BioNTech BNT162b2 booster frequencies. Annual boosters appear to effectively reduce risks for untreated multiple sclerosis patients. For treated patients, booster vaccinations likely provide protection that is nearly equivalent to that obtained in untreated patients, with moderate treatment-specific increases and decreases in immunity.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: COVID-19 Vaccine effectiveness among Healthcare Workers during the Omicron Period in the country of Georgia, January - June 2022\nAbstract: IntroductionUnderstanding COVID-19 vaccine effectiveness (VE) in healthcare workers (HCWs) is critical to inform vaccination policies. We measured COVID-19 VE against laboratory-confirmed symptomatic infection in HCWs in the country of Georgia from January - June 2022, during a period of Omicron circulation.  MethodsWe conducted a cohort study of HCWs in six hospitals in Georgia. HCWs were enrolled in early 2021. Participants completed weekly symptom questionnaires. Symptomatic HCWs were tested by RT-PCR and/or rapid antigen test (RAT). Participants were also routinely tested, at varying frequencies during the study period, for SARS-CoV-2 by RT-PCR or RAT, regardless of symptoms. Serology was collected quarterly throughout the study and tested by electrochemiluminescence immunoassay for SARS-CoV-2 antibodies. We estimated absolute and relative VE of a first booster dose compared to a primary vaccine series as (1-hazard ratio)*100 using Cox proportional hazards models.  ResultsAmong 1253 HCWs, 141 (11%) received a primary vaccine series (PVS) and a first booster, 855 (68%) received PVS only, and 248 (20%) were unvaccinated. Most boosters were BNT162b2 (Comirnaty original monovalent) vaccine (90%) and BIBP-CorV vaccine (Sinopharm) (9%). Most PVS were BNT162b2 vaccine (68%) and BIBP-CorV vaccine (24%). Absolute VE for a first booster was 40% (95% Confidence Interval (CI) -56 - 77) at 7- 29 days following vaccination, -9% (95% CI -104 - 42) at 30 - 59 days, and - 46% (95% CI -156 - 17) at [&ge;] 60 days. Relative VE of first booster dose compared to PVS was 58% (95% CI 1 - 82) at 7- 29 days following vaccination, 21% (95% CI -33 - 54) at 30 - 59 days, and -9% (95% CI -82 - 34) at [&ge;] 60 days.  ConclusionIn Georgia, first booster dose VE against symptomatic SARS-CoV-2 infection among HCWs was moderately effective but waned very quickly during Omicron. Increased efforts to vaccinate priority groups in Georgia, such as healthcare workers, prior to periods of anticipated high COVID-19 incidence are essential.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How floods may affect the spatial spread of respiratory pathogens: the case of Emilia-Romagna, Italy in May 2023\nAbstract: The negative impact of floods on public health has been increasing, as climate change makes these events more frequent and intense. Floods are known to cause direct injury and favor the spread of many waterborne and vector-borne pathogens. Their effect on the circulation of respiratory pathogens, like influenza and SARS-CoV-2, is, however, still unclear. In this study, we quantify this effect through the analysis of large-scale behavioral data coupled to mathematical models of epidemic spread. We focus on the devastating floods occurred in Italy in 2023 and measure how they impacted human contact patterns within and between communities. We find a substantial increase in contacts occurring 3 weeks after the floods, both among residents of the affected areas and between them and those living in distant, unaffected areas of Italy. Then, through mathematical simulations, we determine that these disrupted contact patterns can carry a circulating pathogen to previously unaffected geographic areas, as well as increasing infection counts across the country. Our findings may help set up protocols to use large-scale human contact data to contain epidemic outbreaks before, during and in the aftermath of floods.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Using machine learning to forecast peak health care service demand in real-time during the 2022-23 winter season: a pilot in England, UK\nAbstract: During winter months, there is increased pressure on health care systems in temperature climates due to seasonal increases in respiratory illnesses. Providing real-time short-term forecasts of the demand for health care services helps managers plan their services.  During the Winter of 2022-23 we piloted a new forecasting pipeline, using existing surveillance indicators which are sensitive to increases in respiratory syncytial virus (RSV). Indicators including telehealth cough calls and ED bronchiolitis attendances, both in children under 5 years. We utilised machine learning techniques to train and select models that would best forecast the timing and intensity of peaks up to 28 days ahead. Forecast uncertainty was modelled usings a novel gamlss approach which enabled prediction intervals to vary according to the level of the forecast activity.  The winter of 2022-23 was atypical because the demand for healthcare services in children was exceptionally high, due to RSV circulating in the community and increased concerns around invasive Group A streptococcal (GAS) infections. However, our short-term forecasts proved to be adaptive forecasting a new higher peak once the increasing demand due to GAS started. Thus, we have demonstrated the utility of our approach, adding forecasts to existing surveillance systems.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A quantitative approach to evidence triangulation: development of a framework to address rigour and relevance\nAbstract: Triangulation is an approach to strengthening causal inference by integrating evidence from multiple sources. Most studies using triangulation have qualitatively examined whether different studies agree upon the presence of a causal effect, rather than estimated the effect by quantitatively integrating results. Here, we develop a framework for quantitative triangulation. We first address how to relate study specific research questions to an overall target causal question (relevance), and then assess the directions and magnitudes of bias in each study (rigour), before combining the results using meta-analysis adjusted for the biases.  We illustrate our framework by triangulating evidence from randomized controlled trials (RCTs), Mendelian randomization (MR) and conventional multivariable regression (MVR) to estimate the effect of beta-carotene on coronary heart disease (CHD) and cardiovascular disease (CVD). Five RCTs and one MR study showed little evidence of a causal relationship between beta-carotene and CHD (relative risk (RR)=1.00 with 95% CI=0.98 to 1.01 and RR=1.02 with 95% CI=0.98 to 1.07, respectively). 13 MVR studies indicated that high intake of beta-carotene reduces CHD risk (RR=0.83 with 95% CI0.76 to 0.91). After applying our framework, the three study designs agreed that there is little evidence of an effect of beta-carotene intake on the risk of CHD (RR=1.01 with 95% CI=0.99 to 1.02). Findings were similar for CVD.  Our framework shows how to address rigour and relevance quantitatively when triangulating evidence from different study designs. We highlight the importance of explicitly defining the target and study-specific research questions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Application and Significance of SIRVB Model in Analyzing COVID-19 Dynamics\nAbstract: In the summer of 2024, COVID-19 positive cases spiked in many countries, but it is no longer a deadly pandemic thanks to global herd immunity to the SARS-CoV-2 viruses. In our physical chemistry lab in spring 2024, students practice kinetic models, SIR (Susceptible, Infected, and Recovered) and SIRV (Susceptible, Infected, Recovered, Vaccinated) using COVID-19 positive cases and vaccination data from World Health Organization (WHO). In this report, we further introduce virus breakthrough to the existing model updating it the SIRVB (Susceptible, Infectious, Recovered, Vaccinated, Breakthrough) model. We believe this is the simplest model possible to explain the COVID-19 kinetics in all countries in the past four years. Parameters obtained from such practice correlate with many indices of different countries. These models and parameters have significant value to researchers and policymakers in predicting the stages of future outbreaks of infectious diseases.  TOC  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=147 SRC=\"FIGDIR/small/24314129v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (34K): org.highwire.dtl.DTLVardef@10a8433org.highwire.dtl.DTLVardef@16d4137org.highwire.dtl.DTLVardef@1d49f55org.highwire.dtl.DTLVardef@28a008_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Natural history of a parasite-induced biliary cancer\nAbstract: Pathogens are major drivers of cancer globally. Quantifying the relationship between infection and carcinogenesis is therefore crucial for developing preventative programs. The foodborne trematode Opisthorchis viverrini is a primary cause of biliary cancer (cholangiocarcinoma) and infects 12 million people in Southeast Asia. In tumours from patients exposed to O. viverrini we found that the earliest chromosomal amplification of driver genes occurred at 30 years old on average, two to four decades before cancer diagnosis, and disproportionately contained FGFR2, TP53 and PTEN genes. We fitted transmission models to parasitological data from Thailand spanning 27 years (n = 11,517) finding that, for people born between 1960-1989, first exposure occurred at two years old and by 30 years individuals had been cumulatively infected with a median of 72 worms. Trematodes are long-lived and our analysis quantifies the average lifespan of O. viverrini as 13 years (90% credible interval [CrI] 6-23 years) within human hosts. Finally, we calculate the lifetime probability of diagnosis with cholangiocarcinoma as 1.2% (90% CrI 1.0-1.4%) given prior exposure to the parasite.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Natural history of a parasite-induced biliary cancer\nAbstract: Pathogens are major drivers of cancer globally. Quantifying the relationship between infection and carcinogenesis is therefore crucial for developing preventative programs. The foodborne trematode Opisthorchis viverrini is a primary cause of biliary cancer (cholangiocarcinoma) and infects 12 million people in Southeast Asia. In tumours from patients exposed to O. viverrini we found that the earliest chromosomal amplification of driver genes occurred at 30 years old on average, two to four decades before cancer diagnosis, and disproportionately contained FGFR2, TP53 and PTEN genes. We fitted transmission models to parasitological data from Thailand spanning 27 years (n = 11,517) finding that, for people born between 1960-1989, first exposure occurred at two years old and by 30 years individuals had been cumulatively infected with a median of 72 worms. Trematodes are long-lived and our analysis quantifies the average lifespan of O. viverrini as 13 years (90% credible interval [CrI] 6-23 years) within human hosts. Finally, we calculate the lifetime probability of diagnosis with cholangiocarcinoma as 1.2% (90% CrI 1.0-1.4%) given prior exposure to the parasite.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: CRISPR-Cas12a2-based rapid and sensitive detection system for target nucleic acid\nAbstract: Infectious diseases are extremely important public health issues, where the design of effective, rapid, and convenient detection platforms is critical. In this study, we used conventional PCR coupled with SuCas12a2, a novel Cas12 family RNA-targeting nuclease, to develop a detection approach. SuCas12a2 possesses collateral cleavage activity and cuts the additional single-stranded RNA (ssRNA) added to the reaction system once the ternary complex RNA-SuCas12a2-CRISPR RNA (crRNA) is formed. SuCas12a2 is specifically activated, where the cleaved fluorescent-labeled probes release fluorescent signals, with the strength of the fluorescent signal being proportional to the concentration of nucleic acids specifically bound to crRNA. Simultaneous transcription and SuCas12a2 detection can be performed in a single tube by introducing the T7 promoter sequence into the forward primer. Entamoeba histolytica was used to evaluate the performance of the platform. PCR-SuCas12a2 has excellent capabilities, including high specificity with no cross-reactivity from other species and ultra-sensitivity that achieves a detection of one copy per reaction. There were five samples from amoebiasis patients confirmed by indirect immunofluorescence assay that were used as proof specimens, where the PCR-SuCas12a2 assay demonstrated 100% specificity. Furthermore, we replaced conventional PCR with recombinase polymerase amplification (RPA) to simplify the procedure for producing amplicons harboring the T7 promoter sequence. The sensitivity of the RPA-SuCas12a2 assay was 102 copies per reaction, which was inferior to PCR-SuCas12a2, and demonstrated 100% specificity. The technique shows robust performance and suggests great potential for point-of-care testing of other pathogens to facilitate effective management and control of the spread of diseases.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=134 SRC=\"FIGDIR/small/24314102v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (66K): org.highwire.dtl.DTLVardef@8a0281org.highwire.dtl.DTLVardef@aa8962org.highwire.dtl.DTLVardef@2196d0org.highwire.dtl.DTLVardef@1344331_HPS_FORMAT_FIGEXP  M_FIG Figure abstract  C_FIG\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Preventive interventions for post Covid-19 condition: systematic review update\nAbstract: BackgroundPost COVID-19 condition (PCC) can affect individuals regardless of the severity of their initial illness, and its impact on daily life can be significant. There are uncertainties about whether treatments in the acute or post-acute phase of infection can prevent PCC. We report an update to a previous systematic review on the effects of interventions to prevent PCC.  MethodsWe updated our previous peer-reviewed searches on February 9, 2024. We searched bibliographic databases and grey literature resources to identify trials and comparative observational studies reporting on any intervention provided during the acute (symptom onset to 4 weeks) or post-acute phase (4-8 weeks) of COVID-19 and our primary outcome of incidence of PCC, ascertained at 3 months or longer following infection and capturing, at a minimum, symptoms of fatigue, dyspnea and one or more aspects of cognitive function. Non-recovery from COVID-19 was included if necessary. Secondary outcomes included fatigue, breathlessness/dyspnea, post-exertional malaise, health-related quality of life, psychopathology, cognitive impairment, hospitalization, return to work/education, and adverse effects of the intervention. For screening we employed artificial intelligence to prioritize records and modified our methods to rely on single-reviewer screening after 50% of citations were screened in duplicate. Study selection and risk of bias assessments were conducted independently by two reviewers and data extraction relied on verification of another reviewers work. We grouped studies by intervention type and timing, and by acute-care setting, and performed meta-analysis where appropriate. Sensitivity analyses were conducted for the primary outcome, excluding studies with high risk of bias, using non-recovery as a proxy outcome, and evaluating the outcome at more than 12 months of follow-up. We assessed the certainty of evidence using GRADE.  ResultsTwenty-four studies (5 randomized and 19 non-randomized), all among adults, were included. The acute care setting in nine studies was outpatient and in 15 studies was in-patient; all but one intervention was administered during the acute-phase of illness. The use of convalescent plasma in outpatient acute COVID-19 care probably does not reduce the risk of PCC (relative risk [RR]: 0.93, 95% CI: 0.77-1.12; 1 RCT; moderate certainty). There was low-certainty evidence suggesting that probiotics (RR [95% CI]: 0.32 [0.13-0.78]; 1 RCT) and metformin (0.50 [0.25-0.99]; 1 RCT among individuals with a BMI [&ge;]25 kg/m2) reduce PCC to a small-to-moderate extent in outpatients, while ivermectin (outpatients), antivirals (outpatients), steroids (in-patients), and therapeutic-dose heparin (vs. prophylactic dose; in-patients) may not be effective. Evidence was very low certainty for several other acute-phase pharmacologic intervention and post-acute outpatient assessment and referrals. For outpatient antiviral treatment, while overall PCC risk may not decrease, there might be a slight reduction in psychopathology. Similarly, inpatient antiviral use may not prevent PCC but may offer a small reduction in prolonged general malaise after light exertion. Therapeutic-dose heparin may slightly reduce the risk of cognitive impairment compared to prophylactic-dose heparin among in-patients. The findings remained consistent across all these sensitivity analyses.  ConclusionsEvidence suggests that PCC can be prevented to some extent among outpatients with the use of probiotics and metformin during the acute phase of COVID-19. Effects from interventions used among in-patients and within the post-acute phase are uncertain at this time. Evidence on commonly recommended interventions including rehabilitation or multidisciplinary care was lacking.  Protocol registrationCRD42024513247\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The molecular basis for prognosis of isoniazid resistance in Mycobacterium tuberculosis\nAbstract: Tuberculosis (TB), a disease that kills 1.5 million people every year, is a major global public health concern. The emergence of drug resistance in M. tuberculosis, the obligate pathogen of TB is a major challenge. The emergence of resistance seems to follow an order that might be exploited for novel therapeutic strategies. In most cases resistance to isoniazid (INH) emerges first, followed by rifampicin, then either pyrazinamide or ethambutol, and finally followed by resistance to second-line drugs. For this reason, it is thought that prevention of emergence of INH resistance may help the prevention of resistance to other drugs. In this manuscript we present the prognostic potential of specific mutations in predicting the emergence of the three most common canonical INH resistance (katG315, inhA-15, and inhA-8) with the hope that majority of resistance cases can be predicted and avoided. Here we present evidence that resistance to INH occurs in steps that in most cases follow specific evolutionary trajectory. Identifying these steps can therefore be used to predict and avoid the most common INH resistance mechanism. In our approach, we used genomic and phenotypic data from over 16,000 samples collected by two large databases, the TB Portals and the CRyPTIC consortium. We used classical sensitivity and specificity values as well as a deep learning neural models to identify promising predictive mutations using TB Portals data. We then tested the prognostic potential of the identified mutations using the CRyPTIC consortium data. Here we report two mutations (Rv1258c 581 indel & mshA A187V) as those carrying the highest potential for predicting the emergence of the three canonical mutations (accuracy of 73% and specificity of 96%). Our results point to a stepwise evolutionary trajectory toward the emergence of the three canonical mutations. Furthermore, the high negative predictive values provide an opportunity for clinicians to continue using INH in new regiments designed for nonresponsive patients whose samples do not contain the two precursor mutations. Finally, we present testable hypotheses describing the role of the precursor mutations in emergence of the three canonical mutations and the predicted trajectories. Mutagenesis experiments can confirm these hypotheses. Additional time course samples and analysis will undoubtedly uncover additional prognostic markers for other trajectories toward high-level INH resistance.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging Illumina iSeq100 for Whole Genome Sequencing of Salmonella Typhi: a practical approach for resource-limited setting\nAbstract: Bacterial whole genome sequencing helps to improve our understanding of epidemiology and pathogenesis of bacterial infections and allows comprehensive investigation on virulence, evolution and resistance mechanisms. Nepal, in recent times, has seen some increase in sequencing capabilities but faces numerous hurdles for optimum utilization. However, these hurdles can be alleviated with use of Illumina iSeq100. Therefore, this study aimed at performing whole genome sequencing of bacteria isolated utilizing the iSeq100 platform.  For this study, 6 banked Salmonella enterica serovar Typhi bacterial isolates were selected. These isolates were extracted for DNA, confirmed by qPCR and then, their libraries were prepared. The libaries were checked and loaded in Illumina iSeq100 at loading concentration of 200pM. The consensus was generated from the raw genomic data by reference-based assembly, mapping onto S. Typhi CT18. These consensus genomes and coverage parameters were compared to data from using HiSeq. The raw reads were also evaluated using pathogenwatch (v22.3.8) to observe for genotype, mutations and resistance genes.  The coverage parameters (coverage width and depth) of the genomes from this study were compared to same genomes sequenced using Illumina HiSeq. The average coverage width (96.81%) and depth (63.75x) of genomes sequenced in iSeq100 were comparable to that of HiSeq (width: 98.72% and depth: 69.87x). When the genomes sequenced from Illumina iSeq100 and HiSeq were compared, the genotypes detected, number of SNPs and genetic determinants of AMR genes were identical.  The data from bacterial whole genome sequencing using the Illumina iSeq100 is equally informative when compared to other high-end sequencers. Therefore, the primary goal of this study is to advocate for optimum utlisation of iSeq100 while still ensuring a high standard of quality. This optimum utilization will create capacity to fill critical surveillance gaps.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging Illumina iSeq100 for Whole Genome Sequencing of Salmonella Typhi: a practical approach for resource-limited setting\nAbstract: Bacterial whole genome sequencing helps to improve our understanding of epidemiology and pathogenesis of bacterial infections and allows comprehensive investigation on virulence, evolution and resistance mechanisms. Nepal, in recent times, has seen some increase in sequencing capabilities but faces numerous hurdles for optimum utilization. However, these hurdles can be alleviated with use of Illumina iSeq100. Therefore, this study aimed at performing whole genome sequencing of bacteria isolated utilizing the iSeq100 platform.  For this study, 6 banked Salmonella enterica serovar Typhi bacterial isolates were selected. These isolates were extracted for DNA, confirmed by qPCR and then, their libraries were prepared. The libaries were checked and loaded in Illumina iSeq100 at loading concentration of 200pM. The consensus was generated from the raw genomic data by reference-based assembly, mapping onto S. Typhi CT18. These consensus genomes and coverage parameters were compared to data from using HiSeq. The raw reads were also evaluated using pathogenwatch (v22.3.8) to observe for genotype, mutations and resistance genes.  The coverage parameters (coverage width and depth) of the genomes from this study were compared to same genomes sequenced using Illumina HiSeq. The average coverage width (96.81%) and depth (63.75x) of genomes sequenced in iSeq100 were comparable to that of HiSeq (width: 98.72% and depth: 69.87x). When the genomes sequenced from Illumina iSeq100 and HiSeq were compared, the genotypes detected, number of SNPs and genetic determinants of AMR genes were identical.  The data from bacterial whole genome sequencing using the Illumina iSeq100 is equally informative when compared to other high-end sequencers. Therefore, the primary goal of this study is to advocate for optimum utlisation of iSeq100 while still ensuring a high standard of quality. This optimum utilization will create capacity to fill critical surveillance gaps.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gaps and Opportunities for Data Systems and Economics to Support Priority Setting for Climate-Sensitive Infectious Diseases in Sub-Saharan Africa: A Rapid Scoping Review\nAbstract: Climate change alters risks associated with climate-sensitive infectious diseases (CSIDs) with pandemic potential. This poses additional threats to already vulnerable populations, further amplified by intersecting social factors, such as gender and socioeconomic status. Currently, critical evidence gaps and inadequate institutional and governance mechanisms impact on the ability for African States to prevent, detect and respond to CSIDs. The aim of this study was to explore the role of data systems and economics to support priority setting for CSID preparedness in sub-Saharan Africa.  We conducted a rapid scoping review to identify existing knowledge and gaps relevant to economics and data systems. A literature search was performed across six bibliographic databases in November 2023. A list of 14 target pathogens, identified by the World Health Organization as Public Health Emergencies of International Concern or R&D Blueprint Pathogens, was adopted and compared to a database of CSIDs to determine relevant inclusion criteria. Extracted data were synthesised using bibliometric analysis, thematic topic categorisation, and narrative synthesis to identify research needs, evidence gaps, and opportunities for priority setting.  We identified 68 relevant studies. While African author involvement has been increasing since 2010, few studies were led by senior authors from African institutions. Data system studies (n = 50) showed broad coverage across CSIDs and the WHO AFRO region but also a high degree of heterogeneity, indicating a lack of clearly defined standards for data systems related to pandemic preparedness. Economic studies (n = 18) primarily focused on COVID-19 and Ebola and mostly originated from South Africa. Both data system and economic studies identified limited data sharing across sectors and showed a notable absence of gender sensitivity analyses. These significant gaps highlight important opportunities to support priority setting and decision-making for pandemic preparedness, ultimately leading to more equitable health outcomes.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Diversity of the Plasmodium falciparum Reticulocyte Binding protein Homologue-5 which is a potential Malaria Vaccine Candidate: Baseline data from areas of varying malaria endemicity in Mainland Tanzania.\nAbstract: BackgroundThe limited efficacy of the two malaria vaccines, RTS,S/AS01 and R21/Matrix M, which were recently approved vaccines by the World Health Organization, highlights the need for alternative vaccine candidate genes beyond these pre-erythrocytic-based vaccines. Plasmodium falciparum Reticulocyte Binding Protein Homologue 5 (Pfrh5) is a potential malaria vaccine candidate, given its limited polymorphism compared to other parasites blood stage antigens. This study evaluated the genetic diversity of the Pfrh5 gene among parasites from regions with varying malaria transmission intensities in Mainland Tanzania, to generate baseline data for this potential malaria vaccine candidate.  MethodsThis study utilized secondary data of 697 whole-genome sequences from Mainland Tanzania, which were generated by the MalariaGEN Community Network. The samples which were sequenced to generate the data were collected between 2010 and 2015 from five districts within five regions of Mainland Tanzania, with varying endemicities (Morogoro urban district in Morogoro region, Muheza district in Tanga region, Kigoma-Ujiji district in Kigoma region, Muleba district in Kagera region, and Nachingwea district in Lindi region). The genetic diversity of the Pfrh5 gene was assessed using different genetic metrics, including Wrights fixation index (FST), Wrights inbreeding coefficient (Fws), Principal Component analysis (PCA), nucleotide diversity ({pi}), haplotype network, haplotype diversity (Hd), Tajimas D, and Linkage disequilibrium (LD).  ResultsOf the sequences used in this study (n=697), 84.5% (n = 589/697) passed quality control and 313 (53.1%) were monoclonal, and these monoclonal sequences were used for haplotype diversity and haplotype network analysis. High within-host diversity (Fws <0.95) was reported in Kigoma-Ujiji (60.7%), Morogoro urban (53.1%), and Nachingwea (50.8%), while Muleba (53.9%) and Muheza (61.6%) had low within host diversity (Fws[&ge;]0.95). PCA did not show any population structure across the five districts and the mean FST value among the study populations was 0.015. Low nucleotide diversity values were observed across the study sites with the mean nucleotide diversity of 0.00056. A total of 27 haplotypes were observed among the 313 monoclonal samples. The Pf3D7 was detected as Hap_1, and it was detected in 16/313 (5.1%) sequences, and these sample sequences were from Muheza (62.5%, n=10/16), Kigoma-Ujiji (18.8%, n=3/16), and Muleba (18.8%, n=3/16). Negative Tajimas D values were observed among the parasite populations in all the study sites.  ConclusionIn this study, we observed low levels of polymorphism in the pfrh5 gene, as it exhibited low nucleotide and haplotype diversity, a lack of population structure and negative Tajimas D values as signatures of purifying selection. This study provides an essential framework of the diversity of the Pfrh5 gene to be considered in development of the next generation malaria vaccines. Robust and intensive studies of this and other candidate genes are required for characterization of the parasites from areas with varying endemicity, and are crucial to support the prioritization of the Pfrh5 gene for potential inclusion in a broadly cross-protective malaria vaccine.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Year-long assessment of the immune response elicited by MVA-BN vaccine\nAbstract: BackgroundModified-Vaccinia-Ankara Bavarian Nordic (MVA-BN) vaccine has been recommended to tackle the mpox epidemic 2022-2023 and its resurgence in 2024.  Although its effectiveness has been estimated to range between 36-86%, the persistence of protection is still unknown.  Aims of this study is to assess the immune response one year after vaccination with MVA-BN.  MethodsObservational prospective study at the National Institute for Infectious Diseases in Rome. All people at high risk for mpox infection who received MVA-BN as pre-exposure prophylaxis were enrolled. People previously primed with smallpox vaccination received a single-dose course of MVA-BN, while non-primed received a two-dose course. Blood samples were collected at the time of each dose and one, six and 12 months after vaccination. MPXV-specific IgG and neutralizing antibody (nAb) titers were assessed by immunofluorescence and plaque neutralization tests, respectively. Interferon-{gamma} producing T-cell specific response to the MVA-BN vaccine was analyzed by ELISpot assay. Antibody titers at pre- and post-vaccination were compared using the Friedman tests. Mann Whitney test was used to compare antibody titers in PLWH vs PLWoH. Wilcoxon and Mann-Whitney non-parametric tests were used to compare T-cells specific response to the MVA-BN vaccine for intra and inter-group differences, respectively.  ResultsFifty high-risk people were included. All were men, with 94% self-reporting having sex with men. The median age was 50 years (IQR 45-57), and 21 (42%) were people living with HIV (PLWH), all on antiretroviral therapy, and 71% with a CD4 cell count higher than 500 L. 25 (50%) have been primed with previous smallpox vaccination.  In non-primed people, anti-MPXV IgG titers significantly increased from T1 to T3 and, despite a slight reduction, were still higher than T1 up to T4 and then gradually decreased until T5, when 64% of sera were still reactive. MPXV-nAb titers peaked at T3 and then dropped, with 56% and 32% of sera reactive at T4 and T5, respectively. IFN-{gamma} production by MVA-BN-specific T-cells progressively rose across time, peaked at T3, and remained significantly higher than the baseline after 6 and 12 months from vaccination. A single-dose course of MVA-BN vaccination in smallpox-primed participants elicited an early increase in IgG and nAb titers, which remained significantly higher than baseline after 6 and 12 months. MPXV-nAbs were detected in 80% and 72% of vaccinees at T4 and T5, respectively. A similar improvement and maintenance were observed for the MVA-BN-specific T-cell response. No evidence for a difference in both humoral and cellular responses was found between PLWH and PLWoH in our cohort.  ConclusionsOne year after vaccination, our data showed the persistent detectability of low levels of nAb against MPXV in one-third of non-primed individuals. At the same time, humoral response was still detectable in most previously vaccinated participants. Concurrently, the MVA-BN-specific T-cell response was robust and persistent.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Emergence to dominance: Estimating time to dominance of SARS-CoV-2 variants using nonlinear statistical models\nAbstract: Background/ObjectiveRelative proportion of cases in a multi-strain pandemic like the COVID-19 pandemic provides insight on how fast a newly emergent variant dominates the infected population. However, the behavior of relative proportion of emerging variants is an understudied field. We investigated the emerging behavior of dominant COVID-19 variants using nonlinear statistical methods and calculated the time to dominance of each variant.  MethodWe used a phenomenological approach to model national- and regional-level variant share data from the national genomic surveillance system provided by the Centers for Disease Control and Prevention to determine the best model to describe the emergence of two recent dominant variants of the SARS-CoV-2 virus: XBB.1.5 and JN.1. The proportions were modeled using logistic, Weibull, and generalized additive models. Model performance was evaluated using the Akaike Information Criteria (AIC) and the root mean square error (RMSE).  FindingsThe Weibull model performed the worst out of all three approaches. The generalized additive model approach slightly outperformed the logistic model based on fit statistics, but lacked in interpretability compared to the logistic model. These models were then used to estimate the time elapsed from emergence to dominance in the infected population, denoted by the time to dominance (TTD). All three models yielded similar TTD estimates. The XBB.1.5 variant was found to dominate the population faster compared to the JN.1 variant, especially in HHS Region 2 (New York) where the XBB.1.5 was believed to emerge. This research expounds on how emerging viral strains transition to dominance, informing public health interventions against future emergent COVID-19 variants and other infectious diseases.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Validation of a Difference-in-Differences Investigation Tool (DiD IT) for quantifying local outbreaks\nAbstract: The Difference-in-Differences Investigation Tool ( DiD IT) is a new tool used to estimate the impact of local threats to public health in England.  DiD IT is part of a daily all hazards syndromic surveillance service. We present a validation of the  DiD IT tool, using synthetic injects to assess how well it can estimate small, localised increases in the number of people presenting to health care. Furthermore, we assess how control settings within  DiD IT affect its performance.   DiD IT was validated across ten different syndromic indicators, chosen to cover a range of data volumes and potential public health threats. Injects were added across different times of year and days of week, including public holidays. Also, different size of injects were created, including some with an impact spread to neighbouring locations or spread over several days. The control settings within  DiD IT were tested by varying the control location and periods, using, for example a  washout period or excluding nearest neighbours. Performance was measured by comparing the estimates for excess counts produced by  DiD IT with the actual synthetic injects added.   DiD IT was able to provide a positive estimate in 99.8% of trials, with a mean absolute error of 1.5. However, confidence intervals for the central estimate could not be produced in 42.5% of trials. Furthermore, the 95% confidence intervals for the central estimates only included the actual inject count within 62.8% of the intervals. Unsurprising, mean errors were slightly higher when synthetic injects were not concentrated in one location on one day but were spread across neighbouring areas or days. Selecting longer control periods and using more locations as controls tended to lower the errors slightly. Including a washout period or excluding neighbouring locations from the controls did not improve performance.  We have shown that  DiD IT is accurate for assessing the impact of local incidents but that further work is needed to improve the how the uncertainty of these estimates are communicated to users.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integrating Kolmogorov-Arnold Networks with Ordinary Differential Equations for Efficient, Interpretable and Robust Deep Learning: A Case Study in the Epidemiology of Infectious Diseases\nAbstract: In this study, we extend the universal differential equation (UDE) framework by integrating Kolmogorov-Arnold Network (KAN) with ordinary differential equations (ODEs), herein referred to as KAN-UDE models, to achieve efficient and interpretable deep learning for complex systems. Our case study centers on the epidemiology of emerging infectious diseases. We develop an efficient algorithm to train our proposed KAN-UDE models using time series data generated by traditional SIR models. Compared to the UDE based on multi-layer perceptrons (MLPs), training KAN-UDE models shows significantly improves fitting performance in terms of the accuracy, as evidenced by a rapid and substantial reduction in the loss. Additionally, using KAN, we accurately reconstruct the nonlinear functions represented by neural networks in the KAN-UDE models across four distinct models with varying incidence rates, which is robustness in terms of using a subset of time series data to train the model. This approach enables an interpretable learning process, as KAN-UDE models were reconstructed to fully mechanistic models (RMMs). While KAN-UDE models perform well in short-term prediction when trained on a subset of the data, they exhibit lower robustness and accuracy when real-world data randomness is considered. In contrast, RMMs predict epidemic trends robustly and with high accuracy over much longer time windows (i.e., long-term prediction), as KAN precisely reconstructs the mechanistic functions despite data randomness. This highlights the importance of interpretable learning in reconstructing the mechanistic forms of complex functions. Although our validation focused on the transmission dynamics of emerging infectious diseases, the promising results suggest that KAN-UDEs have broad applicability across various fields.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Harnessing multi-output machine learning approach and dynamical observables from network structure to optimize COVID-19 intervention strategies\nAbstract: The COVID-19 pandemic has necessitated the development of accurate models to predict disease dynamics and guide public health interventions. This study leverages the COVASIM agent-based model to simulate 1331 scenarios of COVID-19 transmission across various social settings, focusing on the school, community, and work contact layers. We extracted complex network measures from these simulations and applied deep learning algorithms to predict key epidemiological outcomes, such as infected, severe, and critical cases. Our approach achieved an R2 value exceeding 95%, demonstrating the models robust predictive capability. Additionally, we identified optimal intervention strategies using spline interpolation, revealing the critical roles of community and workplace interventions in minimizing the pandemics impact. The findings underscore the value of integrating network analytics with deep learning to streamline epidemic modeling, reduce computational costs, and enhance public health decision-making. This research offers a novel framework for effectively managing infectious disease outbreaks through targeted, data-driven interventions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Social determinants of injection drug use-associated bacterial infections and treatment outcomes: systematic review and meta-analysis\nAbstract: BackgroundIndividual injecting practices (e.g., intramuscular injecting, lack of skin cleaning) are known risk factors for injection drug use-associated bacterial and fungal infections; however, social contexts shape individual behaviours and health outcomes. We sought to synthesize studies assessing potential social determinants of injecting-related infections and treatment outcomes.  MethodsWe searched five databases for studies published between 1 January 2000 and 18 February 18 2021 (PROSPERO CRD42021231411). We included studies of association (aetiology), assessing social determinants, substance use, and health services exposures influencing development of injecting-related infections and treatment outcomes. We pooled effect estimates via random effects meta-analyses.  ResultsWe screened 4,841 abstracts and included 107 studies. Several factors were associated with incident or prevalent injecting-related infections: woman/female gender/sex (adjusted odds ratio [aOR] 1.57, 95% confidence interval [CI] 1.36-1.83; n=20 studies), homelessness (aOR 1.29, 95%CI 1.16-1.45; n=13 studies), cocaine use (aOR 1.31, 95%CI 1.02-1.69; n=10 studies), amphetamine use (aOR 1.74, 95%CI 1.39-2.23; n=2 studies), public injecting (aOR 1.40, 95%CI 1.05-1.88; n=2 studies), requiring injecting assistance (aOR 1.78, 95%CI 1.40-2.27; n=8 studies), and use of opioid agonist treatment (aOR 0.92, 95%CI 0.89-0.95; n=9 studies). Studies assessing outcomes during treatment (e.g., premature hospital discharge) or afterward (e.g., rehospitalization; all-cause mortality) typically had smaller sample sizes and imprecise effect estimates.  ConclusionsInjecting-related infections and treatment outcomes may be shaped by multiple social contextual factors. Approaches to prevention and treatment should look beyond individual injecting practices towards addressing the social and material conditions within which people live, acquire and consume drugs, and access health care.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A decade of shifting cholera burden in Africa and its implications for control: a statistical mapping analysis\nAbstract: BackgroundThe World Health Organization declared a global cholera emergency in 2023 due to an increase in cholera outbreaks, with most cholera-associated deaths reported in Africa. Characterizing large-scale burden patterns can help with monitoring progress in cholera control and targeting interventions.  MethodsWe modeled the mean annual incidence of suspected cholera for 2011-2015 and 2016-2020 on a 20 km by 20 km grid across Africa using a global cholera database and spatial statistical models. We then examined how 2011-2020 incidence is associated with post-2020 cholera occurrence and investigated the potential reach of prospective interventions when prioritized by past incidence.  FindingsAcross 43 African countries mean annual incidence rates remained steady at 11 cases per 100,000 population through both periods. Cholera incidence shifted from Western to Eastern Africa, and we estimated 125,701 cases annually (95% CrI: 124,737-126,717) in 2016-2020. There were 296 million (95% CrI: 282-312 million) people living in high-incidence second-level administrative (ADM2) units ([&ge;] 10 cases per 100,000 per year) in 2020, of which 135 million experienced low incidence (<1 per 100,000) in 2011-2015. ADM2 units with sustained high incidence in Central and Eastern Africa from 2011-2020 were more likely to report cholera in 2022-2023, but cases were also reported in sustained low ADM2 units. Targeting the 100 million highest burden populations had potential to reach up to 63% of 2016-2020 mean annual cases but only 37% when targeting according to past 2011-2015 incidence.  InterpretationBy revealing the changing spatial epidemiology of cholera in Africa, these 10-year subnational estimates may be used to project OCV demand, characterize the potential of targeting interventions based on past burden, and track progress towards disease control goals.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characteristics of High Impact Chronic Low back Pain patients in a digital cohort of 1376 patients across the United States\nAbstract: Background ContextThere are a number of risk factors-from biological, psychological, and social domains-for non-specific chronic low back pain (cLBP). Many cLBP treatments target risk factors on the assumption that the targeted factor is not just associated with cLBP but is also a cause (i.e, a causal risk factor). In most cases this is a strong assumption, primarily due to the possibility of confounding variables. False assumptions about the causal relationships between risk factors and cLBP likely contribute to the generally marginal results from cLBP treatments.  PurposeThe objectives of this study were to a) using rigorous confounding control compare associations between modifiable causal risk factors identified by Mendelian randomization (MR) studies with associations in a cLBP population and b) estimate the association of these risk factors with cLBP outcomes.  Study Design/SettingCross sectional analysis of a longitudinal, online, observational study.  Patient Sample1,376 participants in BACKHOME, a longitudinal observational e-Cohort of U.S. adults with cLBP that is part of the NIH Back Pain Consortium (BACPAC) Research Program.  Outcome MeasuresPain, Enjoyment of Life, and General Activity (PEG) Scale.  MethodsFive risk factors were selected based on evidence from MR randomization studies: sleep disturbance, depression, BMI, alcohol use, and smoking status. Confounders were identified using the ESC-DAG approach, a rigorous method for building directed acyclic graphs based on causal criteria. Strong evidence for confounding was found for age, female sex, education, relationship status, financial strain, anxiety, fear avoidance and catastrophizing. These variables were used to determine the adjustment sets for the primary analysis. Potential confounders with weaker evidence were used for a sensitivity analysis.  ResultsParticipants had the following characteristics: age 54.9 {+/-} 14.4 years, 67.4% female, 60% never smokers, 29.9% overweight, 39.5% obese, PROMIS sleep disturbance T-score 54.8 {+/-} 8.0, PROMIS depression T-score 52.6 {+/-} 10.1, Fear-avoidance Beliefs Questionnaire 11.6 {+/-} 5.9, Patient Catastrophizing Scale 4.5 {+/-} 2.6, PEG 4.4 {+/-} 2.2. In the adjusted models alcohol use, sleep disturbance, depression, and obesity were associated with PEG, after adjusting for confounding variables identified via a DAG constructed using a rigorous protocol. The adjusted effect estimates- the expected change in the PEG outcome for every standard deviation increase or decrease in the exposure (or category shift for categorical exposures) were the largest for sleep disturbance and obesity. Each SD increase in the PROMIS sleep disturbance T-score resulted in a mean 0.77 (95% CI: 0.66, 0.88) point increase in baseline PEG score. Compared to participants with normal BMI, adjusted mean PEG score was slightly higher by 0.37 points (95% CI: 0.09, 0.65) for overweight participants, about 0.8 to 0.9 points higher for those in obesity classes I and II, and 1.39 (95% CI: 0.98, 1.80) points higher for the most obese participants. Each SD increase in the PROMIS depression T-score was associated with a mean 0.28 (95% CI: 0.17, 0.40) point increase in baseline PEG score, while each SD decrease in number of alcoholic drinks per week resulted in a mean 0.12 (95%CI: 0.01, 0.23) increase in baseline PEG score in the adjusted model.  ConclusionsSeveral modifiable causal risk factors for cLBP - alcohol use, sleep disturbance, depression, and obesity- are associated with PEG, after adjusting for confounding variables identified via a DAG constructed using a rigorous protocol. Convergence of our findings for sleep disturbance, depression, and obesity with the results from MR studies, which have different designs and biases, strengthens the evidence for causal relationships between these risk factors and cLBP (1). The estimated effect of change in a risk factors on change in PEG were the largest for sleep disturbance and obesity. Future analyses will evaluate these relationships with longitudinal data.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Chronic Low Back Pain Causal Risk Factors Identified by Mendelian Randomization: a Cross-Sectional Cohort Analysis\nAbstract: Background ContextThere are a number of risk factors-from biological, psychological, and social domains-for non-specific chronic low back pain (cLBP). Many cLBP treatments target risk factors on the assumption that the targeted factor is not just associated with cLBP but is also a cause (i.e, a causal risk factor). In most cases this is a strong assumption, primarily due to the possibility of confounding variables. False assumptions about the causal relationships between risk factors and cLBP likely contribute to the generally marginal results from cLBP treatments.  PurposeThe objectives of this study were to a) using rigorous confounding control compare associations between modifiable causal risk factors identified by Mendelian randomization (MR) studies with associations in a cLBP population and b) estimate the association of these risk factors with cLBP outcomes.  Study Design/SettingCross sectional analysis of a longitudinal, online, observational study.  Patient Sample1,376 participants in BACKHOME, a longitudinal observational e-Cohort of U.S. adults with cLBP that is part of the NIH Back Pain Consortium (BACPAC) Research Program.  Outcome MeasuresPain, Enjoyment of Life, and General Activity (PEG) Scale.  MethodsFive risk factors were selected based on evidence from MR randomization studies: sleep disturbance, depression, BMI, alcohol use, and smoking status. Confounders were identified using the ESC-DAG approach, a rigorous method for building directed acyclic graphs based on causal criteria. Strong evidence for confounding was found for age, female sex, education, relationship status, financial strain, anxiety, fear avoidance and catastrophizing. These variables were used to determine the adjustment sets for the primary analysis. Potential confounders with weaker evidence were used for a sensitivity analysis.  ResultsParticipants had the following characteristics: age 54.9 {+/-} 14.4 years, 67.4% female, 60% never smokers, 29.9% overweight, 39.5% obese, PROMIS sleep disturbance T-score 54.8 {+/-} 8.0, PROMIS depression T-score 52.6 {+/-} 10.1, Fear-avoidance Beliefs Questionnaire 11.6 {+/-} 5.9, Patient Catastrophizing Scale 4.5 {+/-} 2.6, PEG 4.4 {+/-} 2.2. In the adjusted models alcohol use, sleep disturbance, depression, and obesity were associated with PEG, after adjusting for confounding variables identified via a DAG constructed using a rigorous protocol. The adjusted effect estimates- the expected change in the PEG outcome for every standard deviation increase or decrease in the exposure (or category shift for categorical exposures) were the largest for sleep disturbance and obesity. Each SD increase in the PROMIS sleep disturbance T-score resulted in a mean 0.77 (95% CI: 0.66, 0.88) point increase in baseline PEG score. Compared to participants with normal BMI, adjusted mean PEG score was slightly higher by 0.37 points (95% CI: 0.09, 0.65) for overweight participants, about 0.8 to 0.9 points higher for those in obesity classes I and II, and 1.39 (95% CI: 0.98, 1.80) points higher for the most obese participants. Each SD increase in the PROMIS depression T-score was associated with a mean 0.28 (95% CI: 0.17, 0.40) point increase in baseline PEG score, while each SD decrease in number of alcoholic drinks per week resulted in a mean 0.12 (95%CI: 0.01, 0.23) increase in baseline PEG score in the adjusted model.  ConclusionsSeveral modifiable causal risk factors for cLBP - alcohol use, sleep disturbance, depression, and obesity- are associated with PEG, after adjusting for confounding variables identified via a DAG constructed using a rigorous protocol. Convergence of our findings for sleep disturbance, depression, and obesity with the results from MR studies, which have different designs and biases, strengthens the evidence for causal relationships between these risk factors and cLBP (1). The estimated effect of change in a risk factors on change in PEG were the largest for sleep disturbance and obesity. Future analyses will evaluate these relationships with longitudinal data.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Chronic Low Back Pain Causal Risk Factors Identified by Mendelian Randomization: a Cross-Sectional Cohort Analysis\nAbstract: Background ContextThere are a number of risk factors-from biological, psychological, and social domains-for non-specific chronic low back pain (cLBP). Many cLBP treatments target risk factors on the assumption that the targeted factor is not just associated with cLBP but is also a cause (i.e, a causal risk factor). In most cases this is a strong assumption, primarily due to the possibility of confounding variables. False assumptions about the causal relationships between risk factors and cLBP likely contribute to the generally marginal results from cLBP treatments.  PurposeThe objectives of this study were to a) using rigorous confounding control compare associations between modifiable causal risk factors identified by Mendelian randomization (MR) studies with associations in a cLBP population and b) estimate the association of these risk factors with cLBP outcomes.  Study Design/SettingCross sectional analysis of a longitudinal, online, observational study.  Patient Sample1,376 participants in BACKHOME, a longitudinal observational e-Cohort of U.S. adults with cLBP that is part of the NIH Back Pain Consortium (BACPAC) Research Program.  Outcome MeasuresPain, Enjoyment of Life, and General Activity (PEG) Scale.  MethodsFive risk factors were selected based on evidence from MR randomization studies: sleep disturbance, depression, BMI, alcohol use, and smoking status. Confounders were identified using the ESC-DAG approach, a rigorous method for building directed acyclic graphs based on causal criteria. Strong evidence for confounding was found for age, female sex, education, relationship status, financial strain, anxiety, fear avoidance and catastrophizing. These variables were used to determine the adjustment sets for the primary analysis. Potential confounders with weaker evidence were used for a sensitivity analysis.  ResultsParticipants had the following characteristics: age 54.9 {+/-} 14.4 years, 67.4% female, 60% never smokers, 29.9% overweight, 39.5% obese, PROMIS sleep disturbance T-score 54.8 {+/-} 8.0, PROMIS depression T-score 52.6 {+/-} 10.1, Fear-avoidance Beliefs Questionnaire 11.6 {+/-} 5.9, Patient Catastrophizing Scale 4.5 {+/-} 2.6, PEG 4.4 {+/-} 2.2. In the adjusted models alcohol use, sleep disturbance, depression, and obesity were associated with PEG, after adjusting for confounding variables identified via a DAG constructed using a rigorous protocol. The adjusted effect estimates- the expected change in the PEG outcome for every standard deviation increase or decrease in the exposure (or category shift for categorical exposures) were the largest for sleep disturbance and obesity. Each SD increase in the PROMIS sleep disturbance T-score resulted in a mean 0.77 (95% CI: 0.66, 0.88) point increase in baseline PEG score. Compared to participants with normal BMI, adjusted mean PEG score was slightly higher by 0.37 points (95% CI: 0.09, 0.65) for overweight participants, about 0.8 to 0.9 points higher for those in obesity classes I and II, and 1.39 (95% CI: 0.98, 1.80) points higher for the most obese participants. Each SD increase in the PROMIS depression T-score was associated with a mean 0.28 (95% CI: 0.17, 0.40) point increase in baseline PEG score, while each SD decrease in number of alcoholic drinks per week resulted in a mean 0.12 (95%CI: 0.01, 0.23) increase in baseline PEG score in the adjusted model.  ConclusionsSeveral modifiable causal risk factors for cLBP - alcohol use, sleep disturbance, depression, and obesity- are associated with PEG, after adjusting for confounding variables identified via a DAG constructed using a rigorous protocol. Convergence of our findings for sleep disturbance, depression, and obesity with the results from MR studies, which have different designs and biases, strengthens the evidence for causal relationships between these risk factors and cLBP (1). The estimated effect of change in a risk factors on change in PEG were the largest for sleep disturbance and obesity. Future analyses will evaluate these relationships with longitudinal data.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Angiotensin-converting enzyme inhibition and Alzheimer's disease: Findings from proteome-wide Mendelian randomization and a large prospective cohort study\nAbstract: BackgroundWe aimed to provide clinically translatable insights for drug discovery, repurposing, and vigilance for preventing Alzheimers disease (AD) by integrating genetic and \"real-world\" drug use data.  MethodsProteome-wide Mendelian randomization (MR) analysis was conducted to identify plasma proteins causally related to AD risk using the largest summary-level data to date, followed by colocalization and multi-omic validation analyses (on the gene expression, alternative splicing, and DNA methylation levels in blood and brain, respectively) to prioritize potential druggable targets. We also replicated our MR findings using additional genetic data and, where appropriate, performed multivariable MR for the prioritized findings. Conventional observational analysis using the data from UK Biobank, a large prospective cohort, was performed to provide further clinical implications for our genetic findings.  ResultsMR analysis identified 15 plasma proteins with putative causal effects on AD risk. Of them, inhibition of angiotensin-converting enzyme (ACE) was found to increase the risk of AD (OR 1.10, 95% CI 1.08-1.14), which was likely independent of blood pressure as suggested by multivariable MR. Observational analysis in UK Biobank showed a higher incidence (HR 1.24, 95% CI 1.01-1.52) of AD among regular users of ACE inhibitors (ACEI), compared with the counterpart angiotensin receptor blocker users.  ConclusionsIn addition to expanding the understanding of druggable targets for AD prevention, our findings highlighted the potential risk of AD associated with the use of ACEIs, a widely prescribed antihypertensive medication, suggesting the need for caution in clinical practice and further research on the effect of antihypertensives on neurodegenerative diseases.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Novel antibiotic resistance genes from the hospital effluent are disseminated into the marine environment in Norway\nAbstract: Hospital effluent comprises feces of many individuals, including patients undergoing antibiotic treatment. Although, hospital effluent is an important source for contamination of the environment with antibiotic resistance genes (ARGs) and pathogens, how hospital effluent in a low resistance setting contributes to antimicrobial resistance (AMR) in the environment is largely understudied. The aim of our study was to understand the microbiota and resistome of hospital effluent, and its role in the spread of AMR in the marine environment in Norway. We further aimed at describing/characterizing novel resistance factors from hospital effluent and the receiving sewage treatment plant (STP). 24-hour composite samples of the hospital effluent and the influent and effluent of the receiving STP were collected at two sampling time-points (February and April 2023) in Bergen city, Norway. Isolation of Escherichia coli and Klebsiella spp. was performed, using ECC and SCAI plates with cefotaxime, tigecycline or meropenem, followed by antibiotic susceptibility testing, using EUVSEC3 plates. Whole-genome sequencing of selected strains (n=36) and shotgun metagenomics of sewage samples (n=6) were performed, using Illumina NovaSeq. ARGs were identified with USEARCH, and known and novel ARGs were assembled with fARGene. All E. coli strains (n=66) were multidrug-resistant (MDR), while 92.3% of the Klebsiella spp. strains (n=55) showed MDR phenotype. The sequenced strains carried multiple clinically important ARGs, including carbapenemases such as NDM-5 (n=3) and KPC-3 (n=3). We obtained 238 Gigabases of sequence data from which we identified 676 unique ARGs with >200 ARGs shared across samples. We assembled 1,205 ARGs using fARGene, 365 gene sequences represented novel ARGs (< 90% amino acid (aa) identity). Both known and novel ARGs (n=54) were shared between the hospital effluent and the treated effluent of the receiving STP. We show that hospital effluent in Norway has a high diversity of both known and novel ARGs. Our study demonstrates that hospital effluent is a source of clinically relevant pathogens, as well as known and novel ARGs, reaching the marine environment in Norway through treated sewage.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Implementing portable, real-time 16S rRNA sequencing in the healthcare sector enhances antimicrobial stewardship\nAbstract: BackgroundAntimicrobial resistance (AMR) poses a significant global health challenge, resulting in over 1.27 million deaths in 2019 and projected to cause up to 10 million deaths annually in the future. To address this issue, the healthcare sector requires rapid and accurate bacterial identification, which is currently not readily available for effective antimicrobial stewardship. In a UK national first, we implemented 16S ribosomal RNA (rRNA) sequencing using Oxford Nanopore Technology (ONT) in an NHS setting to enhance diagnostic capabilities, aiming to reduce antibiotic misuse and improve patient outcomes.  MethodsWe implemented 16S rRNA sequencing via ONT, running samples from seven NHS hospitals across Cheshire and Merseyside. We focused on samples from sterile sites, such as \"pus\", \"fluid\", and \"tissue\", typically collected from critical care units. The assay was validated against traditional methods including Sanger sequencing and MALDI-TOF, with a turnaround time of 24-72 hours. Clinical impact was measured by analysing changes in antibiotic regimens and patient outcomes based on 16S assay results over a period of several months post-launch.  FindingsONT 16S rRNA sequencing significantly impacted antibiotic treatment in 34.2% of cases, reducing patient stays and outperforming traditional methods by detecting additional bacterial organisms and identifying bacteria missed by reference labs. It provided species- level identification and confirmed non-infectious conditions in 5.4% of cases, aiding alternative treatment decisions. Its speed, cost-effectiveness, and minimal training requirements contributed to its successful integration into clinical practice.  InterpretationThe integration of ONT 16S sequencing into routine NHS diagnostics has significantly improved antimicrobial stewardship by offering a faster, more sensitive, and accurate bacterial identification method. Earlier use of this assay in cases where routine cultures are likely to fail could enhance patient outcomes further by enabling timely, targeted antibiotic therapies, reducing hospital stays, and curbing unnecessary antibiotic use.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Implementing portable, real-time 16S rRNA sequencing in the healthcare sector enhances antimicrobial stewardship\nAbstract: BackgroundAntimicrobial resistance (AMR) poses a significant global health challenge, resulting in over 1.27 million deaths in 2019 and projected to cause up to 10 million deaths annually in the future. To address this issue, the healthcare sector requires rapid and accurate bacterial identification, which is currently not readily available for effective antimicrobial stewardship. In a UK national first, we implemented 16S ribosomal RNA (rRNA) sequencing using Oxford Nanopore Technology (ONT) in an NHS setting to enhance diagnostic capabilities, aiming to reduce antibiotic misuse and improve patient outcomes.  MethodsWe implemented 16S rRNA sequencing via ONT, running samples from seven NHS hospitals across Cheshire and Merseyside. We focused on samples from sterile sites, such as \"pus\", \"fluid\", and \"tissue\", typically collected from critical care units. The assay was validated against traditional methods including Sanger sequencing and MALDI-TOF, with a turnaround time of 24-72 hours. Clinical impact was measured by analysing changes in antibiotic regimens and patient outcomes based on 16S assay results over a period of several months post-launch.  FindingsONT 16S rRNA sequencing significantly impacted antibiotic treatment in 34.2% of cases, reducing patient stays and outperforming traditional methods by detecting additional bacterial organisms and identifying bacteria missed by reference labs. It provided species- level identification and confirmed non-infectious conditions in 5.4% of cases, aiding alternative treatment decisions. Its speed, cost-effectiveness, and minimal training requirements contributed to its successful integration into clinical practice.  InterpretationThe integration of ONT 16S sequencing into routine NHS diagnostics has significantly improved antimicrobial stewardship by offering a faster, more sensitive, and accurate bacterial identification method. Earlier use of this assay in cases where routine cultures are likely to fail could enhance patient outcomes further by enabling timely, targeted antibiotic therapies, reducing hospital stays, and curbing unnecessary antibiotic use.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cross omics risk scores of inflammation markers are associated with all-cause mortality: The Canadian Longitudinal Study on Aging\nAbstract: Inflammation is a critical component of chronic diseases, aging progression, and lifespan. Omics signatures may characterize inflammation status beyond blood biomarkers. We leveraged genetics (Polygenic-Risk-Score; PRS), metabolomics (Metabolomic-Risk-Score; MRS), and epigenetics (Epigenetic-Risk-Score; ERS) to build multi-omics-multi-marker risk scores for inflammation status represented by the level of circulating C-reactive protein (CRP), interleukin 6 (IL6), and tumor necrosis factor alpha (TNFa). We found that multi-omics risk-scores generally outperformed single-omics risk scores in prediction of all-cause mortality in the Canadian Longitudinal Study on Aging. Compared with circulating inflammation biomarkers, some multi-omics risk scores had a higher HR for all cause-mortality when including both score and circulating IL6 in the same model (1-SD IL6 MRS-ERS: HR=1.77 [1.15-2.72] vs. 1-SD circulating IL6 HR=1.11 [0.75,1.66]; 1-SD IL6 PRS-MRS: HR=1.32 [1.21,1.45] vs. 1-SD circulating IL6 HR=1.31 [1.12, 1.53]; 1-SD PRS-MRS-ERS: HR=1.62 [1.04, 2.53] vs. 1-SD circulating IL6: HR=1.16 [0.77, 1.74]). In the Nurses Health Study (NHS), NHS II, and Health Professional Follow-up Study with available omics, 1-SD of IL6 PRS and 1-SD IL6 PRS-MRS had HR=1.13 [1.00,1.27] and HR=1.13 [1.01,1.27], among individuals >65years without mutual adjustment of the score and circulating IL6. Our study demonstrated that some multi-omics scores for inflammation markers may characterize important inflammation burden for an individual beyond those represented by blood biomarkers and improve our prediction capability for aging process and lifespan.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Engineered antibodies targeted to bacterial surface integrate effector functions with toxin neutralization to provide superior efficacy against bacterial infections\nAbstract: Anti-bacterial monoclonal antibody (mAb) therapies either rely on toxin neutralization or opsonophagocytic killing (OPK). Toxin neutralization protects the host from toxin-induced damage, while leaving the organism intact. OPK inducing antibodies clear the bacteria but leave the released toxins unencountered. Infection site targeted anti-toxin antibodies (ISTAbs) that we report here addresses this binary paradigm by combining both functionalities into a single molecule. ISTAbs consist of cell wall targeting (CWT) domains of bacteriophage endolysins fused to toxin neutralizing mAbs (IgG). CWT governs specific binding to the surface of bacteria while the IgG variable domain neutralizes the toxins as they are released. The complex is then cleared by phagocytic cells. As proof of concept, we generated several ISTAb prototypes targeting major toxins from two Gram-positive spore forming pathogens that have a high clinical significance; Clostridium difficile, causative agent of the most common hospital-acquired infection, and Bacillus anthracis, a Category A select agent pathogen. Both groups of ISTAbs exhibited potent toxin neutralization, binding to their respective bacterial cells, and induction of opsonophagocytosis. In mice infected with B. anthracis, ISTAbs exhibit significantly higher efficacy than parental IgG in both pre- and post-challenge models. Furthermore, ISTAbs fully protected against B. anthracis infection in a nonhuman primate (NHP) aerosol challenge model. These findings establish that as a platform technology, ISTAbs are broadly applicable for therapeutic intervention against several toxigenic bacterial pathogens.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Lipid Fingerprinting by MALDI Biotyper Sirius Instrument Fails to Differentiate the Three Subspecies of the Mycobacterium abscessus Complex\nAbstract: The number of patients suffering from Mycobacterium abscessus complex (MABC) pulmonary diseases is steadily increasing. MABC consists of three subspecies, and it is recommended that the three subspecies be distinguished because of their differing macrolide susceptibilities. Unfortunately, current methods are inefficient due to their high cost, complexity, and time requirements. The third-generation Bruker MALDI Biotyper (MBT) Sirius has the capability to detect phospholipids and glycolipids using negative-ion mode. Mycobacterial cell walls are rich in lipids, and if lipid structure diversity can serve as species-specific fingerprints, this method may provide an alternative for microbial identification. This study aimed to examine the accuracy of discriminating between the three MABC subspecies by lipid profiling. Our best model failed to differentiate the three subspecies. Even in the two-dimensional space of the most significant peaks, M. abscessus and M. massiliense could not be separated. The agreement rate between lipid fingerprint-based and WGS-based identification was, at most, 47.2% for negative-ion mode. Even after applying recent machine learning algorithms to detect variables and create predictive models, accuracy remained at 50%. Our results suggest that using lipid fingerprinting alone to differentiate the three MABC subspecies is currently inadequate. Further advancements and standardization of MALDI-TOF MS-based methods are necessary for the routine differentiation of MABC subspecies in clinical settings.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PPAR-\u03b3 signaling and risk of bacterial enteric infection: insight from thiazolidinedione users in a US population-based study\nAbstract: The ongoing antimicrobial resistant crisis heralds the need for new therapeutics against enteric infection. In mouse models, colon epithelial peroxisome proliferator-activated receptor-{gamma} (PPAR-{gamma}) signaling limits oxygen and nitrate luminal bioavailability, thereby preventing bacterial pathogen colonization. However, whether this mechanism operates similarly in humans remains uncertain. To investigate, we used the cloud-based TriNetX Analytics Platform which aggregates health records from 117 million patients across 66 US healthcare organizations, to assess the risk of bacterial enteric infection among diabetic patients prescribed thiazolidinediones, a class of PPAR-{gamma} agonists. Among 85,117 thiazolidinedione users, we observed a 22-49% lower risk of bacterial enteric infections compared to users of other anti-diabetes medications. This reduction in risk was consistent across high-risk individuals, regardless of sex or age. Similar results were replicated in high-risk patients when thiazolidinedione users were directly compared to those on DPP-4 inhibitors. These findings support the potential protective role of PPAR-{gamma} signaling against bacterial enteric infection and call for further clinical investigation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: High diversity of Escherichia coli causing invasive disease in neonates in Malawi poses challenges for O-antigen based vaccine approach\nAbstract: Escherichia coli is an important cause of neonatal sepsis and the third most prevalent cause of neonatal infection in sub-Saharan Africa, often with negative outcomes. Development of maternally administered vaccines is under consideration, but to provide adequate protection, an understanding of serotypes causing invasive disease in this population is essential. We describe the genomic characteristics of a collection of neonatal E. coli isolates from a tertiary hospital in Blantyre, Malawi, with specific reference to potential protection by vaccines under development. Neonatal blood or cerebrospinal fluid cultures from 2012-2021 identified 205 E. coli isolates, and 170 could be recovered for sequencing. There was very high diversity in sequence types, LPS O-antigen-type and fimbrial H-type, which all showed temporal fluctuations and previously undescribed diversity, including ten putative novel O-types. Vaccines in clinical trials target the O-antigen but would only protect against one third (33.7%) of neonatal sepsis cases in this population (EXPEC9V, in clinical trials). An O-antigen based vaccine would require 30 different O-types to protect against 80% of infections. Vaccines against neonatal sepsis in Africa are of considerable potential value, but their development requires larger studies to establish the diversity and stability over time of relevant O-types for this population.  Data summaryAll sequencing data is freely available under the sequencing project IDs ERP120687 (short read data; accessions in Supplementary Table 1) and PRJNA1121524 (long-read data; accessions in Supplementary Table 2), detailed per-isolate information is provided in Supplementary Table 3. Blood culture and CSF data used to show the trends and numbers of E. coli cases per year is available in Supplementary Table 4.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Detection of Mpox and other Orthopoxviruses using a Lateral Flow Device as a Point of Care diagnostic.\nAbstract: IntroductionIn 2022 the WHO declared the worldwide outbreak of mpox to be a public health emergency of international concern (PHEIC). The causative monkeypox virus (MPXV) belonged to Clade IIb and transmitted through sexual contact with a low case fatality rate (0.1%), which together with underdetection, all contributed to a rapid global spread particularly within the MSM (men who have sex with men) community. As MPXV Clade II remains circulating worldwide, a new outbreak of the more fatal Clade I disease has been declared in Central and East Africa and remains uncontrolled in part due to the lack of Point of Care (POC) diagnostics for rapid decisions on treatment and self-isolation.  AimTo address the lack of POC solutions for mpox we have designed and evaluated an orthopoxvirus-specific lateral flow device (LFD) that could be used for diagnosis of mpox.  ResultsUsing an LFD comprising four monoclonal antibodies against the A27 protein we demonstrate sensitivity to 3x105 pfu/ml. This sensitivity is expected to be sufficient for detection of MPXV from lesion sites and may also be sufficient for other sample types such as saliva and urine. However, sample collection buffer may have a detrimental impact on sensitivity for clinical material.  ConclusionPoint of care (POC) diagnosis of mpox may be possible using a LFD to reduce delays arising from sample shipment to centralised laboratory testing facilities.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ruminant-dense environments increase risk of Shiga toxin-producing Escherichia coli independently of ruminant contact\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWCattle and other domestic ruminants are the primary reservoirs of O157 and non-O157 Shiga toxin-producing Escherichia coli (STEC). Living in areas with high ruminant density has been associated with excess risk of infection, which could be due to both direct ruminant contact and residual environmental risk, but the role of each is unclear. We investigated whether there is any meaningful risk to individuals living in ruminant-dense areas if they do not have direct contact with ruminants. Using a Bayesian spatial framework, we investigated the association between the density of ruminants on feedlots and STEC incidence in Minnesota from 2010 to 2019, stratified by serogroup and season, and adjusting for direct ruminant contact. For every additional head of cattle or sheep per 10 acres, the incidence of O157 STEC infection increased by 30% (IRR 1.30; 95% CrI 1.18, 1.42) or 135% (IRR 2.35; 95% CrI 1.14, 4.20), respectively, during the summer months. Sheep density was also associated with O157 STEC risk during winter (IRR 4.28; 95% CrI 1.40, 8.92). The risk of non-O157 STEC infection was only elevated in areas with goat operations during summer (IRR 19.6; 95% CrI 1.69, 78.8). STEC risk associated with ruminant density was independent of direct ruminant contact across serogroups and seasons. Our findings demonstrate that living in a ruminant-dense area increases an individuals risk of O157 and non-O157 STEC infection even without direct ruminant contact, indicating that prevention efforts need to extend to community strategies for averting indirect transmission from local ruminant populations.  IO_SCPLOWMPORTANCEC_SCPLOWSTEC are zoonotic enteric bacteria responsible for 2.5 million illnesses each year. Infections in young children can be especially devastating, causing hemolytic uremic syndrome (HUS), a debilitating and sometimes fatal form of acute kidney injury. STECs primary reservoirs are cattle and other domestic ruminants, and transmission can occur through food, water, animal contact, and person-to-person. Living near ruminants poses a significant risk of STEC infection; however, the proportion of that risk due to direct ruminant contact or other routes of transmission is unknown. Our research demonstrates that direct ruminant contact is a substantial risk irrespective of location, and that individuals living in ruminant-rich regions are at high risk of STEC infection regardless of whether they come into contact with ruminants. These findings indicate a need for multi-pronged prevention efforts that emphasize control of contamination in the environments surrounding ruminant populations, in addition to biosafety precautions when contacting ruminants directly.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Variation and Regulation of MICA Alters Natural Killer Cell-Mediated Immunosurveillance in Early-Onset Colorectal Cancer\nAbstract: The incidence of colorectal cancer (CRC) among individuals under age 50, or early-onset CRC (EOCRC), has been rising over the past few decades for unclear reasons, and the etiology of the disease remains largely unknown. Known genetic risk factors do not explain this increase, pointing to possible environmental and as-yet unidentified genetic contributors and their interactions. Previous research linked genetic variation on chromosome 6 to increased CRC risk. This region harbors multiple immune genes, including the gene encoding Major Histocompatibility Complex (MHC) class I polypeptide-related sequence A (MICA). MICA is a polygenic ligand for the Natural Killer Group 2D receptor (NKG2D), a receptor expressed on Natural Killer (NK) cells and other lymphocytes. Given that intra-tumoral NK cell infiltration correlates with favorable CRC outcomes, we hypothesized that germline genetic variation in MICA could influence CRC risk. In a discovery set of 40,125 cases and controls, we show that the minor G allele at Chr6:31373718C>G (hg19) is associated with increased risk for CRC (odds ratio (OR) = 1.09, 95% confidence interval (CI) 1.04 - 1.15, p = 0.0009). The effect is stronger in EOCRC (OR = 1.26, 95% CI 1.08 - 1.44, p = 0.0023) than in those 50 and over (OR = 1.07, 95% CI 1.02 - 1.13; p = 0.012) (Ratio of ORs = 1.32, 95% CI 1.14 - 1.52, p = 0.0002). In an independent validation set of 77,983 cases and controls, the adjusted interaction by age-of-onset was significant at OR = 1.15 (95% CI 1.03 - 1.34, p = 0.0150) with a higher risk in EOCRC. Expression quantitative trait locus analysis in normal colonic epithelia showed that MICA RNA expression decreases linearly with each additional copy of the minor G allele (p = 3.345 x 10e-18). Bulk RNA analysis of the tumor immune microenvironment revealed that tumors from patients with CG or GG genotypes have lower resting and activated NK cell infiltration as compared to tumors from patients with CC genotype. Multiplex immunofluorescence analysis demonstrated that patients with a G allele (i.e. CG or GG genotype, but not CC genotype) have a statistically significant decrease in the number of NK cells in tumor compared to adjacent normal colonic mucosa. Taken together, population-based epidemiologic, molecular, genetic, cellular and immunologic evidence demonstrate that MICA genotype is associated with increased risk of EOCRC and reduced number of NK cells in colorectal tumors, suggesting that patients with a G allele have altered NK cell-mediated immunosurveillance. These novel findings suggest that EOCRC may have a previously unrecognized innate immune-mediated etiology which merits further investigation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of Immunoadsorption on clinical presentation and immune alterations in COVID-19-associated ME/CFS\nAbstract: Autoreactive antibodies (AAB) are currently being investigated as causative or aggravating factors during post-COVID. In this study we analyze the effect of immunoadsorption therapy on symptom improvement and the relationship with immunological parameters in post-COVID patients exhibiting symptoms of Myalgic Encephalomyelitis/Chronic Fatigue Syndrome (ME/CFS). This observational study includes 12 post-COVID patients exhibiting a predominance of ME/CFS symptoms alongside increased concentrations of autonomic nervous system receptors (ANSR) autoantibodies and neurological impairments. We found that following immunoadsorption therapy, the ANSR autoantibodies were nearly eliminated from the patients blood. The removal of IgG antibodies was accompanied by a decrease of pro-inflammatory cytokines including IL4, IL2, IL1{beta}, TNF and IL17A serum levels, and a significant reduction of soluble spike protein. Notably, a strong positive correlation between pro-inflammatory cytokines and ASNR-AABs {beta}1, {beta}2, M3, and M4 was observed in spike protein-positive patients, whereas no such correlation was evident in spike protein-negative patients. 30 days post-immunoadsorption therapy, patients exhibited notable improvement in neuropsychological function and a substantial amelioration of hand grip strength was observed. However, neither self-reported symptoms nor scores on ME/CSF questionnaires showed a significant improvement and a rebound of the removed proteins occurring within a month.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Severe infection among young infants in Dhaka, Bangladesh: effect of case definition on incidence estimates\nAbstract: IntroductionHeterogeneity in definitions of severe infection, sepsis and serious bacterial infection (SBI) in young infants limits the comparability of randomized controlled trials (RCTs) of infection prevention and treatment interventions. To inform the design of severe infection prevention RCTs for young infants in low-resource settings, we estimated the incidence of severe infection in an observational cohort of Bangladeshi infants aged 0-60 days and examined the effect of variations in case definitions on incidence estimates.  MethodsIn 2020-2022, 1939 infants born generally healthy were enrolled at two hospitals in Dhaka, Bangladesh. Severe infection cases were identified through up to 12 scheduled community health worker home visits from 0-60 days of age or through caregiver self-referral. The primary severe infection case definition combined physician documentation of standardized clinical signs and/or diagnosis of sepsis/SBI and either a positive blood culture or parenteral antibiotic treatment for [&ge;]5 days. Incidence rates were estimated for the primary severe infection definition, the World Health Organization (WHO) definition of possible SBI, blood culture- confirmed infection, and five alternative severe infection definitions.  ResultsSevere infection incidence per 1000 infant-days was 1.2 (95% CI 0.97-1.4) using the primary definition, 0.84 (0.69-1.0) using the WHO definition of possible SBI, and 0.026 (0.0085- 0.081) using blood culture-confirmed infection. One-third of cases met the primary criteria for severe infection through physician diagnosis of sepsis/SBI rather than the standardized clinical signs and 85% were identified following caregiver self-referral despite frequent scheduled study visits.  ConclusionSevere infection incidence in young infants varied considerably by case definition. Using a clinical sign-based severe infection definition may miss a substantial proportion of cases identified by physician diagnosis of sepsis/SBI. In settings where health facilities are accessible, and caregivers seek care for infant illness, frequently scheduled home assessments by study personnel to identify severe infection in infants may not be necessary.  What is already known on this topicO_LIResearchers aiming to design a randomized controlled trial (RCT) for severe infection prevention or treatment in young infants require a clinically precise and feasible case definition of severe infection. C_LIO_LIThere is no consensus definition of severe infection for neonates or young infants. A previous systematic review of neonatal sepsis definitions used in RCTs identified a diverse range, including culture-confirmed sepsis, a combination of clinical signs and culture-confirmation, and a combination of clinical signs and laboratory investigation results. C_LIO_LIIncidence estimates of various severe infection case definitions that can be operationalized in low- and middle-income countries (LMICs) are needed to determine the feasibility of using these definitions in severe infection prevention and treatment RCTs for young infants in these settings. C_LI  What this study addsO_LIWe provide incidence estimates of severe infection in young infants born generally healthy in Dhaka, Bangladesh, during the first 60 days of age using case definitions based on different combinations of clinical signs, antibiotic treatment and microbiologic criteria. C_LIO_LIWe demonstrate that the incidence estimates of severe infection in young infants vary considerably depending on whether a permissive or stringent case definition is adopted. C_LIO_LIWe also demonstrate that in this study, most severe infection cases were identified following caregiver self-referral rather than during scheduled home assessments by study personnel. C_LI  How this study might affect research, practice or policyO_LIOur findings may inform the design of future severe infection prevention RCTs in young infants in LMICs by 1) providing incidence estimates of various candidate case definitions, and 2) supporting the planning of optimal outcome surveillance systems that balance the identification of severe infection cases with operational costs. C_LI\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development of Machine Learning-Based Mpox Surveillance Models in a Learning Health System\nAbstract: We developed machine learning and deep learning models to identify mpox cases from clinical notes as part of a learning health system initiative. Lasso regression outperformed deep learning models, excelled in minimizing false positives, and may prove helpful for flagging missed or delayed diagnoses as part of continuous quality improvement.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development of Machine Learning-Based Mpox Surveillance Models in a Learning Health System\nAbstract: We developed machine learning and deep learning models to identify mpox cases from clinical notes as part of a learning health system initiative. Lasso regression outperformed deep learning models, excelled in minimizing false positives, and may prove helpful for flagging missed or delayed diagnoses as part of continuous quality improvement.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deep learning reveals diverging effects of altitude on aging\nAbstract: Aging is influenced by a complex interplay of multifarious factors, including an individuals genetics, environment, and lifestyle. Notably, high altitude may impact aging and age-related diseases through exposures such as hypoxia and ultraviolet radiation. To investigate this, we mined summary exposure value as a measure of risk exposure levels, and disability-adjusted life years (DALYs) as a measure of disease burden from the Global Health Data Exchange (GHDx) for each subnational region of Ethiopia, a country with considerable differences in the living altitude. We conducted a cross-sectional clinical trial involving 227 highland and 202 lowland dwellers from the Tigray region in Northern Ethiopia to gain a general insight into the biological aging at high altitudes. Notably, we observed significantly lower risk exposure rates and a reduced disease burden in higher-altitude regions of Ethiopia. When assessing biological aging using facial photographs, we found a faster rate of aging with increasing elevation, likely due to greater UV exposure. Conversely, analysis of nuclear morphologies of peripheral blood mononuclear cells in blood smears (PBMCs) with five different senescence predictors revealed a significant decrease in DNA damage-induced senescence in both monocytes and lymphocytes with increasing elevation. Overall, our findings suggest that disease and DNA damage-induced senescence decreases with altitude in agreement with the idea that oxidative stress may drive aging.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Arsenic exposure is associated with elevated sweat chloride concentration and airflow obstruction among adults in Bangladesh: a cross sectional study\nAbstract: Arsenic is associated with lung disease and experimental models suggest that arsenic-induced degradation of the chloride channel CFTR (cystic fibrosis transmembrane conductance regulator) is a mechanism of arsenic toxicity. We examined associations between arsenic exposure, sweat chloride concentration (measure of CFTR function), and pulmonary function among 285 adults in Bangladesh. Participants with sweat chloride [&ge;] 60 mmol/L had higher arsenic exposures than those with sweat chloride < 60 mmol/L (water: median 77.5 {micro}g/L versus 34.0 {micro}g/L, p = 0.025; toenails: median 4.8 {micro}g/g versus 3.7 {micro}g/g, p = 0.024). In linear regression models, a one-unit {micro}g/g increment in toenail arsenic was associated with a 0.59 mmol/L higher sweat chloride concentration, p < 0.001. We found that toenail arsenic concentration was associated with increased odds of airway obstruction (OR: 1.97, 95%: 1.06, 3.67, p = 0.03); however, sweat chloride concentration did not mediate this association. Our findings suggest that sweat chloride concentration may be a novel biomarker for arsenic exposure and also that arsenic likely acts on the lung through mechanisms other than CFTR dysfunction.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Antibody response to Plasmodium vivax in the context of Epstein-Barr virus (EBV) co-infection: A 14-year follow-up study in the Amazon rainforest\nAbstract: BackgroundTo develop an effective vaccine against Plasmodium vivax, the most widely dispersed human malaria parasite, it is critical to understand how coinfections with other pathogens could impact malaria-specific immune response. A recent conceptual study proposed that Epstein-Barr virus (EBV), a highly prevalent human herpesvirus that establishes lifelong persistent infection, may influence P. vivax antibody responses. Here, it was investigated whether EBV could impact the longevity of humoral immune response to P. vivax.  Methodology/principal findingsA 14-year follow-up study was carried out among long-term P. vivax-exposed Amazonian individuals (272, median age 35 years), and included 9 cross-sectional surveys at periods of high and low malaria transmission. The experimental approach focused on monitoring antibodies to the major blood-stage P. vivax vaccine candidate, the Duffy binding protein region II (DBPII-Sal1), including a novel engineered DBPII-based vaccine targeting conserved epitopes (DEKnull-2). In parallel, the status of EBV infection was determined over time by the detection of circulating EBV DNA (EBV-DNAemia) and EBV-specific antibodies to lytic (VCAp18) or latent (EBNA1) antigens. Regardless of the malaria transmission period, the results demonstrated that one or multiple episodes of EBV-DNAemia did not influence the longevity of DBPII immune responses to both strain-specific (Sal-1) or strain-transcending (DEKnull-2) antibodies. Also, the average time in which DBPII-responders lost their antibodies was unrelated to the EBV serostatus. Considering all malaria cases detected during the study, there was a predominance of P. vivax mono-infection (76%), with a positive association between malaria infection and detectable EBV-DNAemia.  Conclusions/significanceIn an immunocompetent P. vivax-exposed adult population neither sporadic episodes of EBV-DNAemia nor antibody responses to lytic/latent EBV antigens influence the longevity of both strain-specific and strain-transcending DBPII immune responses. Further studies should investigate the role of acute P. vivax infection in the activation of EBV replication cycle.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Antibody response to Plasmodium vivax in the context of Epstein-Barr virus (EBV) co-infection: A 14-year follow-up study in the Amazon rainforest\nAbstract: BackgroundTo develop an effective vaccine against Plasmodium vivax, the most widely dispersed human malaria parasite, it is critical to understand how coinfections with other pathogens could impact malaria-specific immune response. A recent conceptual study proposed that Epstein-Barr virus (EBV), a highly prevalent human herpesvirus that establishes lifelong persistent infection, may influence P. vivax antibody responses. Here, it was investigated whether EBV could impact the longevity of humoral immune response to P. vivax.  Methodology/principal findingsA 14-year follow-up study was carried out among long-term P. vivax-exposed Amazonian individuals (272, median age 35 years), and included 9 cross-sectional surveys at periods of high and low malaria transmission. The experimental approach focused on monitoring antibodies to the major blood-stage P. vivax vaccine candidate, the Duffy binding protein region II (DBPII-Sal1), including a novel engineered DBPII-based vaccine targeting conserved epitopes (DEKnull-2). In parallel, the status of EBV infection was determined over time by the detection of circulating EBV DNA (EBV-DNAemia) and EBV-specific antibodies to lytic (VCAp18) or latent (EBNA1) antigens. Regardless of the malaria transmission period, the results demonstrated that one or multiple episodes of EBV-DNAemia did not influence the longevity of DBPII immune responses to both strain-specific (Sal-1) or strain-transcending (DEKnull-2) antibodies. Also, the average time in which DBPII-responders lost their antibodies was unrelated to the EBV serostatus. Considering all malaria cases detected during the study, there was a predominance of P. vivax mono-infection (76%), with a positive association between malaria infection and detectable EBV-DNAemia.  Conclusions/significanceIn an immunocompetent P. vivax-exposed adult population neither sporadic episodes of EBV-DNAemia nor antibody responses to lytic/latent EBV antigens influence the longevity of both strain-specific and strain-transcending DBPII immune responses. Further studies should investigate the role of acute P. vivax infection in the activation of EBV replication cycle.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The post-pandemic hospital and mortality burden of COVID-19 compared with influenza: A national cohort study in Denmark, May 2022 to June 2024\nAbstract: BackgroundIn the post-pandemic period, COVID-19 continues to cause significant numbers of hospitalisations and deaths. We describe this burden and compare it to the burden of influenza in the first two post-pandemic years in Denmark.  MethodsA cohort study including residents in Denmark from May 16, 2022, to June 7, 2024. Data were obtained from national registries, including information on Polymerase chain reaction (PCR) test-positive COVID-19 and influenza admissions, mortality within 30 days of admission, sex, age, COVID-19 and influenza vaccination, comorbidity, and living in long-term care facility for elderly. Negative binomial regression was used to estimate adjusted incidence rate ratios (aIRRs) to compare rates of admissions between COVID-19 and influenza. To assess severity of COVID-19 among hospitalized patients, we used Cox proportional hazard models to estimate adjusted hazard ratios (aHR) of 30-day mortality between COVID-19 and influenza.  ResultsAmong 5,899,170 individuals, admissions with COVID-19 (n=24,687) were more frequent than admissions with influenza (n=8,682; aIRR 2.01, 95%CI 1.37-2.95), in particular during the first year (p=0.01), in the summer (p<0.001) and among people above 65 years of age (p<0.001). The number of deaths were also higher (COVID-19, n=2,393; influenza, n=522). Among patients, the risk of mortality of COVID-19 was higher than influenza in the 12-30 days following admission (0-11 days, aHR 1.08, 95%CI 0.94-1.25; 12-30 days, aHR 1.50, 95%CI 1.21-1.84), in particular among non-vaccinated for both COVID-19 and influenza (aHR 1.81, 95%CI 1.25-2.62), while it was similar to influenza among patients without comorbidities (aHR 1.07, 95%CI 0.63-1.80).  ConclusionCOVID-19 represented a greater disease burden than influenza, with more hospitalisations and deaths, and more severe disease primarily among non-vaccinated and comorbid patients. These results highlight the continued need for attention and public health efforts to mitigate the impact of SARS-CoV-2.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Suicide Death Predictive Models using Electronic Health Record Data\nAbstract: In the realm of medical research, particularly in the study of suicide risk assessment, the integration of machine learning techniques with traditional statistics methods has become increasingly prevalent. This paper used data from the UNC EHR system from 2006 to 2020 to build models to predict suicide-related death. The dataset, with 1021 cases and 10185 controls consisted of demographic variables and short-term informa-tion, on the subjects prior diagnosis and healthcare utilization. We examined the efficacy of the super learner ensemble method in predicting suicide-related death lever-aging its capability to combine multiple predictive algorithms without the necessity of pre-selecting a single model. The study compared the performance of the super learner against five base models, demonstrating its superiority in terms of cross-validated neg-ative log-likelihood scores. The super learner improved upon the best algorithm by 60% and the worst algorithm by 97.5%. We also compared the cross-validated AUCs of the models optimized to have the best AUC to highlight the importance of the choice of risk function. The results highlight the potential of the super learner in complex predictive tasks in medical research, although considerations of computational expense and model complexity must be carefully managed.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations of Smoking Status and Leisure-time Physical Activity with Waist Circumference Change Ten-year Follow-up among Twin Adults\nAbstract: BACKGROUNDThis follow-up study investigated the associations of smoking status and leisure-time physical activity (LTPA) with weight circumference (WC) change.  METHODSIn the FinnTwin16 cohort, 3,431 twins (47% men) reported smoking status, LTPA, and WC in early adulthood and 10 years later. Regression models were conducted to investigate associations of smoking status and of LTPA change (metabolic equivalent tasks [MET]-h/week) with WC change (cm) during the follow-up. Within-pair associations were analyzed using linear mixed fixed-effect regression among 800 same-sexed (409 identical) pairs.  RESULTSDuring the 10-year follow-up, 40% (n=454) quit smoking. Among those who quit smoking, the mean WC increase was 7.4 cm (SD 8.2) and the mean LTPA decrease was -0.02 MET-h/week (SD 35.8). Compared to individuals continuing daily smoking, only quitters who smoked daily at baseline ({beta} 1.87; 95% CI 0.68, 3.06) increased their WC. This association was not robust after shared familial influences were controlled for. Each additional MET-h/week lowered the risk for WC increase among individuals who smoked occasionally ({beta} -0.054; -0,08, -0.003), quitters who smoked daily ({beta} -0.05; -0.06, -0.02) and those who had never smoked ({beta} -0.04; -0.05, -0.03). In the analyses among identical twin pairs, LTPA was associated with less WC increase among those who quit occasional smoking or had never smoked. For quitters from daily smoking, this association approached significance, but no association remained for those continuing smoking.  CONCLUSIONSSmoking cessation seems to be associated with WC increase, but familial confounding is involved in this process. LTPA may inhibit post-cessation WC increase.  KEY MESSAGESThis will be published as a summary box after the abstract in the final published article.  What is already known on this topic1. Individuals quitting smoking tend to gain weight, but less is known of post-cessation abdominal obesity and the role of leisure-time physical activity in this process.   What this study adds2. Smoking cessation associates with moderate increase in waist circumference among those who quit daily smoking, but shared familial influences are involved in this process. 3. Increase in leisure-time physical activity may prevent post-cessation waist circumference increase.   How this study might affect research, practice, or policy4. More research is needed to unravel genetic and epigenetic mechanisms underlying post-cessation waist circumference increase. 5. In practice, individuals who quit smoking should be encouraged to be physically active.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Detection of diphtheria toxin-producing Corynebacterium ramonii in wounds of an urban, inner-city population in Vancouver, Canada, 2019-2023\nAbstract: We conducted a retrospective chart review and whole-genome sequencing of specimens with presumptive Corynebacterium ulcerans in Vancouver from July 2019 to July 2023. WGS confirmed 8/14 wound culture isolates as C. ramonii. Two distinct clusters of C. ramonii were identified with clinical presentations similar to cutaneous C. diphtheriae.  Article SummaryTwo distinct clusters of C. ramonii were identified in Vancouver, BC with clinical presentations similar to cutaneous C. diphtheriae.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Synergizing Health Strategies: Exploring the Interplay of Treatment and Vaccination in an Age-Structured Malaria Model\nAbstract: Malaria remains a persistent global challenge, particularly prevalent in tropical regions of Africa, Asia, and South America. According to the World Health Organizations (WHO) World Malaria Report 2023, there were approximately 249 million reported malaria cases in 2022 across 85 endemic countries, resulting in over half a million deaths. Progress towards global malaria eradication through antimalarial drugs has been slow, with case numbers increasing since 2015. Dihydroartemisinin (DHA), artesunate, and artemether, derivatives of artemisinin, are crucial components of modern antimalarial treatment. However, resistance to these drugs and their partners in Artemisinin Combination Therapy (ACT) has emerged in Southeast Asia, Africa, and South America. In 2021, the WHO recommended widespread use of the RTS,S malaria vaccine among children in endemic regions. To address these challenges, we develop an extended SEIR age-structured model incorporating malaria vaccination for children, drug-sensitive and drug-resistant strains, and interactions between human hosts and mosquitoes. Our research focuses on evaluating how malaria vaccination coverage influences disease prevalence and transmission dynamics. We derive the basic, intervention, and invasion reproduction numbers for both strains and conduct sensitivity analysis to identify key parameters affecting infection prevalence. Our findings reveal that model outcomes are primarily influenced by scale factors that reduce transmission and natural recovery rates for the resistant strain, as well as by drug treatment and vaccination efficacies, and mosquito death rates. Numerical simulations indicate that while treatment reduces the malaria disease burden, it also increases the proportion of drug-resistant cases. Conversely, higher vaccination efficacy correlates with lower infection cases for both strains. These results suggest that a synergistic approach, involving both vaccination and treatment, could effectively decrease the overall proportion of the population that is infected.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Epidemiological Analysis of Confirmed Mpox Cases in Burundi, July to September 2024\nAbstract: This study analyzes mpox cases in Burundi from July to September 2024, following the 34 introduction of Clade Ib. During this time, 25.4% of 607 samples tested positive via PCR. 35 Children under 15 comprised 55.2% of cases, with a higher proportion of female children testing 36 positive. Geographic analysis demonstrates case concentration in Bujumbura Mairie (59.1%). 37 These findings highlight the importance of age- and sex-specific interventions for outbreak 38 containment and the need for targeted public health strategies in Burundi.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Predictive Time Series Modeling of Malaria Incidence in India: A 20-Year Retrospective and 5-Year Forecast.\nAbstract: This study presents a predictive time series analysis of malaria incidence in India, utilizing a two-decade dataset. Malaria, caused by Plasmodium species and transmitted by Anopheles mosquitoes, poses a significant public health challenge in the WHO South-East Asia Region. We employed linear regression and ARIMA modeling techniques to analyze historical incidence data, ensuring rigorous data cleaning for accuracy. Results indicate a statistically significant declining trend in malaria cases, with projections suggesting continued decreases in malaria cases over the next five years. These findings highlight the effectiveness of current malaria elimination strategies in India and underscore the necessity for sustained public health interventions. Ultimately, this study emphasizes the importance of data-driven approaches for understanding and forecasting malaria trends, contributing to the goal of malaria eradication by 2030.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The transmission blocking activity of artemisinin-combination, non-artemisinin, and 8-aminoquinoline antimalarial therapies: a pooled analysis of individual participant data.\nAbstract: Background Interrupting human-to-mosquito transmission is important for malaria elimination strategies as it can reduce infection burden in communities and slow the spread of drug resistance. Antimalarial medications differ in their efficacy in clearing the transmission stages of Plasmodium falciparum (gametocytes) and in preventing mosquito infection. Here we present a combined analysis of six trials conducted at the same study site with highly consistent methodologies that allows for a direct comparison of the gametocytocidal and transmission-blocking activities of fifteen different antimalarial regimens or dosing schedules. Methods and findings Between January 2013 and January 2023, six clinical trials with transmission endpoints were conducted at the Clinical Research Centre of the Malaria Research and Training Centre of the University of Bamako in Mali. These trials tested Artemisinin-Combination Therapies (ACTs), non-ACT regimens and combinations with 8-aminoquinolines. Participants were males and non-pregnant females, between 5-50 years of age, who presented with P. falciparum mono-infection and gametocyte carriage by microscopy. Blood samples were taken before and after treatment for thick film microscopy, infectivity assessments by mosquito feeding assays and molecular quantification of gametocytes. Mixed-effects generalized linear models were fit with individual-specific random effects and fixed effects for time points, treatment groups and their interaction. Models quantified changes in mosquito infection rates and gametocyte densities within treatment arms over time and between treatments. In a pooled analysis of 422 participants, we observed substantial differences between ACTs in gametocytocidal and transmission-blocking activities, with artemether-lumefantrine (AL) being significantly more potent at reducing mosquito infection rates within 48 hours than dihydroartemisinin-piperaquine (DHA-PPQ), artesunate-amodiaquine (AS-AQ) and pyronaridine-artesunate (PY-AS) (p<0.0001). The addition of single low dose primaquine (SLD PQ) accelerated gametocyte clearance and led to a significantly greater reduction in mosquito infection rate within 48-hours of treatment for each ACT, while an SLD of the 8-aminoaquinoline tafenoquine (TQ) showed a delayed but effective response compared to SLD primaquine. Finally, our findings confirmed considerably higher post-treatment transmission after sulfadoxine-pyrimethamine plus amodiaquine (SP-AQ) compared to most ACTs, with a significantly lower relative reduction in mosquito infection rate at day 7 compared to DHA-PPQ, AS-AQ, and AL (p<0.0001). Therefore, adding an SLD PQ to SP-AQ may be beneficial to block malaria transmission in community treatment campaigns. Conclusions We found marked differences among ACTs and single low-dose 8-aminoquinoline drugs in their ability and speed to block transmission. The findings from this analysis can support treatment policy decisions for malaria elimination and be integrated into mathematical models to improve the accuracy of predictions regarding community transmission and the spread of drug resistance under varying treatment guidelines.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Burden of Latent Tuberculosis Infection among Healthcare Workers of Primary Health Centres and its Association with Clinical Laboratory Parameters\nAbstract: Objectives Healthcare workers (HCWs) are at high risk of latent tuberculosis infection (LTBI) due to their continued occupational exposure. The incidence of LTBI among the HCWs has seldom been investigated. Primary health centres (PHCs) provide effective and affordable medical care largely for the local population. The HCWs of PHCs who are likely to have increased occupational exposure have an increased risk of reactive as well as LTBI, and contribute to overall TB transmission than the general population. Methods A cross-sectional study (March-April 2024) was carried out to assess the burden of LTBI among the HCWs of PHCs (n=64) across Chennai, India. Blood samples were analyzed for gamma interferon using a QuantiFERON-TB Gold Plus assay. A complete baseline health profile, including complete blood count, blood glucose, liver and renal functions, and ferritin levels was estimated to identify potential biomarkers that are independently associated with LTBI. Results The present study revealed an LTBI prevalence of 25.3% (n=99) among PHC workers. The red cell distribution width was significantly associated with LTBI positivity among different biochemical and haematological parameters analyzed. Factors such as individuals age, underlying comorbid conditions (30.3%; n=30), and longer employment duration (28%; n=28) were significantly associated with IGRA positivity. IGRA positivity was significantly associated with decreased RDW-SD in females, overweight, and participants with O blood group. Conclusions The study reported a high prevalence of LTBI among HCWs of PHCs, which necessitates their periodical screening for the elimination of TB.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of family planning counseling delivered during maternal healthcare on postpartum modern contraceptive uptake in low- and middle-income countries: a systematic review and meta-analysis\nAbstract: Background: Postpartum modern contraception is crucial for preventing unintended pregnancies, reducing short inter-pregnancy intervals, and improving maternal and child health outcomes. Family planning counseling, when engaging with maternal healthcare services, may enhance modern contraceptive uptake in the postpartum period. However, evidence in low- and middle-income countries (LMICs) has yielded conflicting findings. We aimed to explore the effects of family planning counseling delivered as part of maternal healthcare on postpartum modern contraceptive uptake in LMICs. Methods: The following six databases were searched in April 2024: PubMed, Web of Science, Embase, Global Health, Medline, and Scopus. Studies that examined the association between family planning counseling and modern contraception uptake in the postpartum period were included. The findings of the included studies were summarized narratively and through a random-effects meta-analysis when data supported. Trim and fill estimates and subgroup analyses were conducted to address publication bias and heterogeneity, respectively. Results: A total of 61 studies were included, of which 42 studies were considered for quantitative synthesis and the remaining 19 studies included in a narrative synthesis. We found that women who received family planning counseling during maternal healthcare visits were 2.75 times (95% CI, 2.11-3.58) more likely to use modern contraception during the postpartum period compared to those who did not receive family planning counseling. Although we observed significant publication bias and heterogeneity, addressing these issues through trim and fill estimation and subgroup analyses, respectively, produced estimates consistent with the summary findings. A narrative synthesis of an additional 19 studies also supports the effectiveness of family planning counseling during maternal healthcare visits on postpartum modern contraception uptake. Conclusion: Integrating family planning counseling into maternal healthcare can significantly increase modern contraceptive use in the postpartum period, as such effectively reducing unintended and short interval pregnancy as well as adverse maternal and child health outcomes. Policymakers should prioritize training healthcare providers and developing standardized protocols for effective counseling.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: SARS-CoV-2 Omicron XBB infections boost cross-variant neutralizing antibodies, potentially explaining the observed delay of the JN.1 wave in some Brazilian regions\nAbstract: The SARS-CoV-2 JN.1 lineage emerged in late 2023 and quickly replaced the XBB lineages, becoming the predominant Omicron variant worldwide in 2024. We estimate the epidemiological impact of this SARS-CoV-2 lineage replacement in Brazil and we further assessed the cross-reactive neutralizing antibody (NAb) responses in a cohort of convalescent Brazilian patients infected during 2023. We analyzed the evolution of SARS-CoV-2 lineages and severe acute respiratory infection (SARI) cases in Brazil between July 2023 and March 2024. We evaluated the cross-reactive NAb responses to the JN.1 variant in a cohort of convalescent Brazilian patients, both before and after infection with XBB.1* lineages. JN.1 replaced XBB with similar temporal dynamics across all country regions, though its epidemiological impact varied between locations. The Southeastern, Southern, and Central-Western regions experienced a brief XBB wave around October 2023, shortly before the introduction of JN.1, without any immediate upsurge of SARI cases during viral lineage replacement. By contrast, the Northeastern and Northern regions did not experience an XBB wave in the latter half of 2023 and displayed a rapid surge in SARI cases driven by the emergence of the JN.1. We found that recent XBB infections in the Brazilian population significantly boosted cross-reactive NAb levels against JN.1. The XBB wave observed in the second half of 2023 in some Brazilian states likely acted as a booster for population immunity, providing short-term protection against JN.1 infections and delaying the rise of SARI cases in certain regions of the country.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gut colonization of Enterococcus species is associated with COVID-19 disease in Uganda\nAbstract: Background: Infection with the COVID-19-causing pathogen SARS-CoV-2 is associated with disruption in the human gut microbiome. The gut microbiome enables protection against diverse pathogens and exhibits dysbiosis during infectious and autoimmune disease. Studies based in the United States and China have found that severe COVID-19 cases have altered gut microbiome composition when compared to mild COVID-19 cases. We present the first study to investigate the gut microbiome composition of COVID-19 cases in a population from Sub-Saharan Africa. Given the impact of geography and cultural traditions on microbiome composition, it is important to investigate the microbiome globally and not draw broad conclusions from homogenous populations. Results: We used stool samples in a Ugandan biobank collected from COVID-19 cases during 2020-2022. We profiled the gut microbiomes of 114 symptomatic individuals who tested positive for SARS-CoV-2 along with 76 household contacts who did not present any symptoms of COVID-19. The inclusion of healthy controls enables us to generate hypotheses about bacterial strains potentially related to susceptibility to COVID-19 disease, which is highly heterogeneous. Comparison of the COVID-19 patients and their household contacts revealed decreased alpha diversity and blooms of Enterococcus and Eggerthella in COVID-19 cases. Conclusions: Our study finds that the microbiome of COVID-19 individuals is more likely to be disrupted, as indicated by decreased diversity and increased pathobiont levels. This is either a consequence of the disease or may indicate that certain microbiome states increase susceptibility to COVID-19 disease. Our findings enable comparison with cohorts previously published in the Global North, as well as support new hypotheses about the interaction between the gut microbiome and SARS-CoV-2 infection.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Design and evaluation of an automated real-time SOFA score calculator in an electronic health record system, for early sepsis diagnosis\nAbstract: Background: In patients with infections, the Sequential Organ Failure Assessment (SOFA) score should be used to diagnose sepsis. However, manual SOFA calculation is time consuming. Thus, we developed an automated real-time SOFA score application that has been fully implemented into the major electronic health record (EHR) system (TakeCare) in Stockholm. We aimed to describe the method and evaluate its performance for detection of sepsis. Method: We developed an automated SOFA application that presents a total score (SOFATotal) over time and a baseline score (SOFAChronic) based on outpatient data prior to hospital admission. We evaluated its performance on 583 sepsis alert patients in an emergency department, including 472 with sepsis according to manually calculated SOFA (SOFAManual). SOFATotal at 30 minutes and 3 hours, and quick-SOFA (qSOFA) were compared with SOFAManual for detection of sepsis. The acute SOFA score (SOFAAcute) was calculated by subtracting SOFAChronic from SOFATotal. Results: SOFATotal at 3 hours showed moderate-good agreement with SOFAManual (R2 = 0.76). Areas under receiver operating characteristic curves for sepsis detection were 0.83 at 30 minutes, 0.94 at 3 hours for SOFATotal, and 0.67 for qSOFA. Among patients with SOFAChronic [&ge;]1 (21% of cases), SOFATotal of [&ge;]2 was observed in 90% of cases (mortality 13.5%), although SOFAAcute of [&ge;]2 was noted in 63% (mortality 16.7%). Conclusion: The automated SOFA score demonstrated effectiveness in early sepsis detection, outperforming qSOFA, but adjustments for chronic baseline scores were necessary to avoid over-diagnosis. Further studies on broader patient populations would be useful to validate its clinical use.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Vaccine failure mode determines population-level impact of vaccination campaigns during epidemics.\nAbstract: Vaccines are a crucial tool for controlling infectious diseases, yet rarely offer perfect protection. \"Vaccine efficacy\" describes a population-level effect measured in clinical trials, but mathematical models used to evaluate the impact of vaccination campaigns require specifying how vaccines fail at the individual level, which is often impossible to measure. Does 90% efficacy imply perfect protection in 90% of people and no protection in 10% (\"all-or-nothing\"), or that the per-exposure risk is reduced by 90% in all vaccinated individuals (\"leaky\"), or somewhere in between? Here we systematically investigate the role of vaccine failure mode in controlling ongoing epidemics. We find that the difference in population-level impact between all-or-nothing and leaky vaccines can be substantial when R0 is higher, vaccines efficacy is intermediate, and vaccines slow but can't curtail an outbreak. Comparing COVID-19 pandemic phases, we show times when model predictions would have been most sensitive to assumptions about vaccine failure mode. When determining the optimal risk group to prioritize for limited vaccines, we find that modeling a leaky vaccine as all-or-nothing (or vice versa) can change the recommended target group. Overall, we conclude that models of vaccination campaigns should include uncertainty about vaccine failure mode in their design and interpretation.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Estimating the trend of COVID-19 in Norway by combining multiple surveillance indicators\nAbstract: Background: Estimating the trend of new infections was crucial for monitoring risk and for evaluating strategies and interventions during the COVID-19 pandemic. The pandemic revealed the utility of new data sources and highlighted challenges in interpreting surveillance indicators when changes in disease severity, testing practices or reporting occur. Aim: To estimate the trend in new COVID-19 infections by combining estimates of growth rates from all available surveillance indicators in Norway. Methods: We estimated growth rates from ten different surveillance indicators in Norway by using a negative binomial regression method and aligned the growth rates in time to hospital admissions by maximising correlations. Using a meta-analysis framework, we calculated overall growth rates and reproduction numbers, including assessments of the heterogeneity between indicators. Results: The estimated growth rates reached a maximum of 25% per day in March 2020, but afterwards they were between -10% and 10% per day. The correlations between the growth rates estimated from different indicators were between 0.5 and 1.0. Growth rates from indicators based on wastewater, panel and cohort data can give up to 14 days earlier signals of trends compared to hospital admissions, while indicators based on positive lab tests can give signals up to 7 days earlier. Conclusions: Combining estimates of growth rates from multiple surveillance indicators provides a good description of the COVID-19 pandemic in Norway. This is a powerful technique for a holistic understanding of the trends of new COVID-19 infections and the technique can easily be adapted to new data sources and situations.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development, Testing, and Calibration of LINCS: A New Microsimulation Model of Maternal and Fetal Cytomegalovirus Infection\nAbstract: Background: Congenital cytomegalovirus (cCMV) is a leading cause of birth defects and the most common cause of non-genetic sensorineural hearing loss in children. There is a lack of decision modeling frameworks that can project cytomegalovirus (CMV) related patient outcomes and inform health policy. We created, tested, and calibrated a model of CMV acquisition and transmission in pregnancy using linked mother-infant dyads. Methods: We developed the Linking INfants and Mothers in Cytomegalovirus Simulation (LINCS) dyad-level Monte-Carlo microsimulation model of CMV infection among pregnant people and fetuses throughout pregnancy. We parameterized the model with data from the existing literature, implemented rigorous code testing procedures, and calibrated a key set of parameters to match model output to external data on cCMV prevalence and symptom risk. Results: A fully parameterized model for CMV among pregnant people and fetuses was developed, and the model code was confirmed to perform as specified. The calibration procedure identified parameter sets that generated model output closely matching the target values from the available data on cCMV prevalence and symptom risk. Conclusions: The LINCS model's ability to simulate the natural history of CMV infection during pregnancy was described and demonstrated, and the model was tested and calibrated to ensure proper functioning. Base case parameters were derived for CMV infection natural history to be used in future decision analyses of CMV testing and treatment strategies.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal co-development of mental and cardio-metabolic health from childhood to young adulthood\nAbstract: Objective: Depressive symptoms and cardio-metabolic risk factors often co-occur. However, our understanding of the potential mechanisms and temporal dynamics underlying their co-development remains elusive. Method: This population-based cohort study examined bidirectional longitudinal associations between depressive symptoms and cardio-metabolic risk factors from age 10 to 25 years, using prospective data from the ALSPAC Study. Participants with at least one (of six) follow-up measurement for each outcome were included in the analyses. We measured depressive symptoms through self- as well as parent-reports, and assessed several cardio-metabolic risk factors (including adiposity measures, lipid profiles and inflammation). Results: Among our 7970 (47% male) participants, we found bidirectional, within-person associations between self-reported depressive symptoms and adiposity (i.e., fat/lean mass index, but not body mass index), across the study period. Adiposity was more stable over time ({beta} [range] = 0.75 [0.54; 0.84]), compared to depressive symptoms (0.26 [0.12; 0.38]), and it had a stronger prospective (i.e., cross-lagged) association with future depressive symptoms (0.07 [0.03, 0.13]) compared to that between depressive symptom and future adiposity (0.04 [0.03, 0.06]). The magnitude of these associations reached its peak between 14 and 16 years. We did not find evidence of cross-lagged associations in either direction between depressive symptoms and waist circumference, insulin, triglycerides, LDL cholesterol or C-reactive protein. Conclusions: These findings suggest a bidirectional relationship between depressive symptoms and cardio-metabolic risk factors, particularly adiposity (i.e., fat/lean mass). Adiposity showed a stronger prospective association with future depressive symptoms, than vice versa, however their relationship revealed more reciprocal than previously thought.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Female Sex Worker Preferences for HIV Pre-Exposure Prophylaxis Delivery in Uganda: A Discrete Choice Experiment\nAbstract: Background Cisgender female sex workers (FSWs) in sub-Saharan Africa have a high risk of HIV acquisition, highlighting the need for innovative approaches to expand coverage of evidence-based HIV prevention methods, including oral pre-exposure prophylaxis (PrEP). Our study aimed to identify FSWs preferences for a PrEP delivery model with structured choices for delivery location, services offered, and adherence support. Methods We conducted a discrete choice experiment (DCE) among FSWs [&ge;]18 years recruited from the Most At-Risk Population Initiative (MARPI) clinic in Kampala, Uganda, between October and November 2023. FSWs were recruited using consecutive sampling. To determine the most effective PrEP delivery method for FSWs, we created eight choice sets, each with three alternative combinations of PrEP service attributes and an opt-out using a D-efficient experimental design. Participants were presented with three alternatives, the fourth being an opt-out (no model selected), and asked to make selections based on four distinct attributes: the PrEP provider, place of delivery, delivery channel, and support services. We assessed FSW preferences and attribute trade-offs using a panel data mixed model and identified the preferred PrEP delivery model using the highest median utility score. Results Overall, 203 participants completed the DCE. The median age was 24 years (interquartile range [IQR] 20-32). Most FSWs preferred receiving PrEP from a healthcare worker at the clinic with short message service (SMS) reminders for adherence support (median utility score 0.87; interquartile range [IQR] 0.82, 0.94). This preference remained consistent across all age groups, with a median utility score of 0.88 for ages 15-19, 0.87 for ages 20-24, and 0.85 for ages [&ge;]25. Conclusion FSWs preferred to receive PrEP care directly from providers at healthcare facilities and highlighted the need for additional support in the form of SMS reminders to improve adherence and prevent HIV acquisition. This preferred model, if implemented, could increase prevention coverage and inform future approaches to delivering PrEP through the Uganda National PrEP Program.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Chagas Disease Screening: Awareness, Practices and Perceived Barriers Among Health Care Providers in Connecticut\nAbstract: Background. An estimated 288,000 people in the United States are infected with Chagas disease. Despite published recommendations for healthcare providers, the neglected nature of this disease persists, in part due to gaps in knowledge and low levels of Chagas disease awareness among healthcare providers. A survey was emailed to healthcare providers to assess knowledge of Chagas disease, screening practices, and provider-perceived barriers to screening.  Methods. The survey link was emailed to healthcare providers and department heads. Providers answered a series of questions categorized either as knowledge (K), practice (P), or perceived barriers (B), which were then scored by category. The analysis included Spearmans rho test to measure the strength of the correlation coefficient between K and P scores and between K and B scores, Kruskal-Wallis tests to see if average K, P, and B scores were equal across specialty groups, and Pairwise Wilcoxon Rank Sum Tests to assess for a significant difference between average scores of cardiology, infectious disease, and the \"other specialties\" category.  Results. 92 providers consented to complete the survey, 88 of whom fit the inclusion criteria of either affiliation with Yale University or YNHH. Infectious disease scored highest on average in knowledge and practices and reported lower provider-perceived barriers (0.66{+/-}0.183, 0.35{+/-}0.247, 0.42{+/-}0.365). No specialty received higher than 0.66{+/-}0.183 on average for knowledge or screening practices. Average perceived barriers to screening were highest in the \"other\" specialty category (0.76{+/-}0.303). There was a significant positive association between knowledge scores and screening practice scores and a significant negative association between knowledge scores and perceived barriers to screening.  Conclusions. This study revealed a knowledge deficit among healthcare providers in various specialties, which was associated with less frequent adherence to recommended screening practices for Chagas disease, as well as higher provider-perceived barriers to screening. This information can inform provider education initiatives so that patients at risk for Chagas disease may be better served in Connecticut and throughout the United States.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mendelian randomization, lipids and coronary artery disease: trade-offs between study designs and assumptions\nAbstract: Background. Mendelian randomization (MR) studies have been described as naturally occurring randomized controlled trials (RCTs). However, MR often deviates from appropriate RCT design principles and relies heavily on two-sample approaches. We used data from the Million Veteran Program (MVP) to empirically evaluate the impact of study design choices and use of one- versus two-sample MR in a study of lipids and coronary artery disease. Methods. Our MR study included MVP participants of European descent with no history of coronary artery disease or contraindications to low-density lipoprotein cholesterol (LDL-C)-related therapies. We sequentially modified the eligibility criteria, study duration and follow-up to reflect common study design decisions for MR. In all designs, we used one- and two-sample approaches to estimate 10-year risks of coronary artery disease per 39 mg/dL increase in LDL-C or 15.6 mg/dL increase in high-density lipoprotein cholesterol (HDL-C). Results. For LDL-C, one-sample estimates varied across designs (odds ratios from 1.50 [95% CI: 1.34,1.68] to 2.23 [95% CI: 1.93,2.59]) and were most sensitive to the inclusion of prevalent outcome events in the analysis. Odds ratios obtained via two-sample MR were attenuated (1.13 [95% CI: 1.01,1.26] to 1.30 [95% CI: 1.15,1.46]). For HDL-C, we observed inverse or null relationships and estimates were qualitatively similar across all designs (odds ratios from 0.76 [95% CI: 0.68,0.86] to 0.93 [95% CI: 0.65,1.34]). Conclusions. MR estimates can, in practice, be impacted by decisions in study design due to trade-offs between different biases, and investigators should evaluate the sensitivity of their estimates to different design decisions.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Postpartum hormonal contraceptive use and risk of depression\nAbstract: Importance: Hormonal contraceptive (HC) use is associated with depression. It is, however, unknown whether this is also true in the postpartum period where women have a heightened depression risk and are routinely offered to start HC. Objective: To determine if HC initiation postpartum is associated with depression development within 12 months postpartum. Design: A cohort study based on Danish register data. Setting: Nationwide population-based. Participants: All primiparous women in Denmark who gave birth from 1997 through 2022. Women were excluded if they had a depression within 24 months prior to delivery, had multiple birth or stillbirth, or a diagnosis of breast cancer or liver tumor. Exposure: HC initiation within 12 months postpartum treated as a time-varying exposure. HC types were categorized as combined oral contraceptives (COCs), combined non-oral contraceptives (CNOCs), progestogen-only pills (POPs), and progestogen-only non-oral contraceptives (PNOCs). Main Outcome and Measure: Depression defined as filling an antidepressant prescription or receiving a hospital depression diagnosis. Adjusted hazards ratios (HRs) and average absolute risks of depression within 12 months postpartum were estimated using Cox regression and a G-formula estimator. Results: Of 610,038 first-time mothers, 41% initiated HC within 12 months postpartum (mean [SD] age; 27.6 [4.3] years for HC users vs. 29.6 [4.8] years for non-users). HC initiation was associated with subsequent depression with a HR of 1.49 (95% CI, 1.42;1.56) compared to no use resulting in an increase in the 12-month absolute risk from 1.36% (1.32;1.39) to 1.54% (1.50;1.57).The HR for COC was 1.72 (1.63;1.82); CNOC 1.97 (1.64;2.36); PNOC 1.40 (1.25;1.56). POP exposure was associated with an initially reduced instantaneous risk but it was increased late postpartum. Investigating the impact of timing of initiation showed that the earlier COC was initiated postpartum the higher the associated rate ratio of depression. Conclusions and Relevance: HC initiation postpartum was associated with 49% higher instantaneous depression risk resulting in an increase in 12-month risk from 1.36% to 1.54% in the observed population. Such associated risk was higher the earlier it was initiated postpartum, at least for COC. This raises the question if depression incidence postpartum is inflated by routine HC initiation after childbirth.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Time-varying consideration of health behaviours explains over 90% of the inequality in mortality associated with socioeconomic status\nAbstract: Background Applying survival analysis techniques to epidemiological inference within research into ageing offers opportunities to estimate the association between exposure and outcome in longitudinal data. This study used Cox regression to investigate how socioeconomic inequality in mortality can be explained by exposure to various factors including smoking, diet, alcohol and physical activity. This study seeks to complement and extend previous work which found that the contribution of the socioeconomic gradient to inequalities in health was underestimated by baseline analysis. Methods Data was obtained from Whitehall II, a British longitudinal cohort study, which investigated social determinants of health. Analysis is based on 11 waves of data collected over 32 years on 10,308 civil servants aged between 35 and 90. Socioeconomic position was defined by baseline employment grade (1-3). During the follow-up 2,427 participants died. Extensive experimental analysis was conducted using a vast number of health behaviours. Cox regression produced an age-and-sex-adjusted hazard ratio for the socioeconomic inequality in mortality. Health behaviours (smoking, physical activity, alcohol consumption, and diet) were then added as covariates to determine the extent to which they statistically explain this inequality, and how this differed from the last similar analysis from 2009. This was done at baseline and longitudinally. The health behaviours were then combined linearly, nonlinearly and new health behaviours were added. Results Adding the above health behaviours as covariates statistically explained the socioeconomic gradient in mortality at baseline from 42% to 2009, to 51% to 2021. Longitudinal consideration increased the explanatory power, when all health behaviours were added as time-varying covariates, from 51% to 87%. Adding more variables in the form of a more comprehensive diet score statistically explained the gradient further, to 91%. The nonlinear model of smoking and exercise most accurately predicted mortality and had a 13% higher explanatory power when explaining the gradient compared to the linear model in longitudinal data. Conclusion In the Whitehall II study, socioeconomic position and mortality showed an association. There is a gain in explanatory power of the set of health behaviours at baseline when follow-up is extended by 12 years, from 42% to 51%. When changes in behaviour over the 32 years of follow-up were also accounted for, this association was now significantly explained by over 90%, compared with 51% when considered at baseline. We suggest that reverse causation is partly responsible for the almost complete explanation of the social gradient in mortality by health behaviours. These results would therefore lead us to question why health behaviours are socially patterned in the way that has been observed, which would be significant for targeting health behaviours in lower socioeconomic statuses.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of a Next Generation Sequencing Assay for Hepatitis B Antiviral Drug Resistance on the Oxford Nanopore System\nAbstract: Background: Next-generation sequencing (NGS) for Hepatitis B virus (HBV) antiviral resistance (AVR) testing is a highly sensitive diagnostic method, able to detect low-level mutant subpopulations. Our clinical virology laboratory previously transitioned from DNA hybridization (INNO-LiPA) to NGS, initially with the GS Junior System and subsequently the MiSeq. The Oxford Nanopore Technology (ONT) sequencing system was evaluated for HBV resistance testing, with regards to sequencing accuracy and turn-around time. Methods: We performed amplicon sequencing of the HBV polymerase gene from patient plasma and external quality assessment (EQA) samples on the MiSeq Reagent Nano Kit v2 and GridION ONT with R10.4.1 flowcells. Mutational analysis and genotyping were performed by DeepChekAssay-HBV (version 2.0). Results: A total of 49 patient samples and 15 EQA samples were tested on both the MiSeq and ONT. There was high agreement for both patient and EQA samples between the MiSeq and ONT systems, with regards to total drug resistance mutations detected and total patient sample agreement, 68/70 (97%) and 47/49 (96%), respectively. Conclusion: The ONT NGS platform provided accurate HBV AVR results, with improved turn-around times. Sequencing error rates at AVR codons were below 1%.\n"}, {"role": "assistant", "content": "yes"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The impact of service wait times on General Practitioners' treatment of adolescent depression and anxiety\nAbstract: BackgroundGeneral Practitioners (GPs) play a key role in the treatment of adolescent depression and anxiety, but their capacity to provide effective care may be compromised by long wait times.  AimTo examine the treatments and recommendations of GPs for adolescent patients with depression and/or anxiety in Australia, their referral practices to specialist care and estimated wait times for these, and the perceived impact of long wait times on GPs, their patients and their treatment.  Design, Setting and MethodsAn online survey of 192 GPs in Australia who treated adolescents (12 to 17 years old) with depression and/or anxiety.  ResultsGPs frequently referred adolescents with depression and/or anxiety to psychologists. The estimated wait time for psychologists (M: 57 days, SD: 47.9) was four times the proposed acceptable wait time (M: 16.7 days, SD: 27.0). The frequency of medication prescribing almost doubled during the wait time when compared to routine practice (14.6% versus 8.3%, respectively). Almost all GPs (81.8%) increased their level of care due to long wait times but had limited training in youth mental health and knowledge on appropriate strategies to do so effectively.  ConclusionThe findings signify the discrepancies between the preferences of GPs for treatment availability in Australia and what they see as the experience for many adolescents with depression and/or anxiety who are referred to specialist care. Greater training, improved communication between referrer and referred services, and digital interventions may help GPs to reduce the negative impacts of long wait times on their adolescent patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: From peas to people - using quantitative traits to aid genetic discovery in depression\nAbstract: A key component of Mendels work is what we now refer to as pleiotropy - when variation in one gene gives rise to variation in multiple phenotypes.  This study focuses on aiding genetic discovery in depression by revisiting the depressed phenotype and developing a quantitative trait in a large mixed family and population study, using analyses built upon the theory which underpins Mendels pleiotropic observations - the relationship between phenotypic variation and genetic variation.  Measures of genetic covariation were used to evaluate and rank ten measures of mood, personality, and cognitive ability as endophenotypes for depression. The highest-ranking traits were subjected to principal component analysis, and the first principal component used to create multivariate measures of depression.  Four traits fulfilled most endophenotype criteria, however, only two traits (neuroticism and the general health questionnaire) consistently ranked highest across all measures of covariation. As such, three composite traits were derived incorporating two, three, or four traits.  Composite traits were compared to the binary classification of depression and to their constituent univariate traits in terms of their coheritability, their ability to identify risk loci in a genome-wide association analysis, and phenotypic variance explained by polygenic profile scores for depression.  Association analyses of binary depression, univariate traits, and composite traits yielded no genome-wide significant results. However, composite traits were more heritable and more highly correlated with depression than their constituent traits, suggesting that analysing candidate endophenotypes in combination captures more of the heritable component of depression and may in part be limited by sample size in the current study.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mapping the Psychopathic Brain: Divergent Neuroimaging Findings converge onto a Common Brain Network\nAbstract: Psychopathy is a personality disorder characterized by a constellation of interpersonal, affective, lifestyle, and antisocial features. However, its neural underpinnings remain poorly understood because functional neuroimaging studies have produced disparate findings. Here, we tackled this lack of replication by investigating whether peak coordinates of studies on psychopathy could in fact map onto a common functional connectivity network. An updated meta-analysis of 23 functional neuroimaging studies (534 cases vs 594 controls) first revealed no significant regional spatial convergence. However, using functional connectomes of 1,000 healthy participants, we demonstrated that the heterogeneous study findings do indeed converge onto a common brain network with a replicability reaching up to 85.2% across studies. We subsequently showed strong associations between this Psychopathy Network and a lesion network of 17 lesion sites causally linked to antisocial behaviors, as well as its association with neurotransmission systems and genetic markers previously implicated in the pathophysiology of psychopathy. Taken together, our study highlights the importance of examining the neural correlates of psychopathy from a network perspective, which can be validated using a multilevel approach, encompassing neural, genetic and neurochemical data. Ultimately, this approach may pave the way for novel and more personalised treatments.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Healthy Human Global Project - Hong Kong : a community-based cross-sectional study of a healthy Asian population\nAbstract: Immune responses are highly variable from one individual to another, with this variability determined by factors such as age, sex, genetics and environment, which also affect physical and mental well-being. Systems immunology studies have been applied to human cohort studies to better understand these effects, but most are performed in Western populations of mostly European ancestry, neglecting the vast majority of human global diversity. To overcome this limitation, we established the Healthy Human Global Project - Hong Kong (HHGP-HK) cohort to allow the study of immune variability in a healthy Asian population. Taking inspiration from the established French Milieu Interieur study we adapted inclusion and exclusion criteria to identify healthy donors, and to facilitate cross comparison between the two cohorts we collected similar demographic, medical and lifestyle information. To study the effects of age and sex, donors were stratified for both ranging from 20-79 years. We report here significant age and sex effects on multiple clinical laboratory measures, many of which were consistently observed in the Milieu Interieur cohort. C-reactive protein and liver enzymes were two exceptions perhaps reflecting different environmental effects between the two cohorts. We applied biological aging, physiological, and mental health scores to our cohort which highlights the need to develop and adapt such scores for application to populations of non-European descent. We also included wearable fitness trackers from which we observed significant age and sex differences for sleep, physical activity, and heart rate variability. This unique cohort will enable the better understanding of factors that determine immune variability within Asian populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Time on Task in Psychotherapeutic/Psychoeducational Intervention with Intermittent Explosive Disorder\nAbstract: ObjectiveAnger control has been seen as a set of learnable skills. How much time is necessary for such learning? Comparisons with time requirements for other skills make it plausible that for many people, learning anger control may require well over 100 hours of time on task. Research interventions have been shorter -- a mean of 9 sessions was reported in one meta-analysis. In this study, our goal was to examine how much psychotherapeutic intervention is being delivered in the \"real world\" to patients with Intermittent Explosive Disorder.  MethodWe studied a de-identified electronic health record data from TriNetX, collected from 87 medical institutions. We studied 32,322 individuals with Intermittent Explosive Disorder. We examined the distribution of the number of individuals across numbers of sessions received.  ResultsThe distribution for the numbers of sessions is highly skewed, resembling a curve of inverse proportion, or a Pareto function. The mode and the median were zero. Only about 25% of patients received any psychotherapy. For that subset, the median was 5 sessions, and the mean was 16. Approximately 10% received 9 visits or more; 5% 30 or more; 2% 50 or more. A large fraction of the psychotherapeutic labor was devoted to a small fraction of the patients: 80% of the sessions went to 7.5% of the patients.  ConclusionsThe ability of health care systems to reduce the societal problem of aggression, at least by psychotherapeutic intervention, appears limited by the factors leading to low, or no, time on task.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Selected miRNAs in urinary extracellular vesicles show promise for non-invasive diagnostics of diabetic kidney disease\nAbstract: Diabetic kidney disease is a growing health burden that lacks specific early non-invasive diagnostic procedures. To approach a solution for this clinical need, we sequenced microRNAs of urinary extracellular vesicles and performed biomarker discovery by small RNA sequencing in a type 1 diabetes cohort including males with and without albuminuria. The results were replicated by sequencing or qPCR in two independent cohorts and four previously published datasets including type 1 and 2 diabetes as well as both sexes. Non-diabetic and prostate cancer cohorts were used as additional controls and miRNAs changed due to preanalytical urine collection variables were excluded. Using these data, we additionally validated previously identified reference candidate miRNAs. Correlations with clinical parameters, receiver operating characteristic analysis, targeted mRNAs and pathways including integrated single cell data, and targeted circulating proteins from type 1 and 2 diabetes cohorts were analyzed. We pinpointed 6 stable microRNAs, 11 differentially expressed microRNAs, 9 target proteins and 16 DKD-associated pathways in individuals with diabetic kidney disease. Replication showed that the differentially expressed miRNAs in DKD were partly shared between diabetes subtypes and sexes with overall strongest evidence for miR-192-5p, miR-146a-5p, miR-486-5p, and miR-574-5p. Combination of these miRNAs with clinical variables showed potential to classify individuals with the fastest kidney function decline (sensitivity 0.75-1.00 and specificity 0.83-1.00) even in the normoalbuminuria group, thus holding the potential as early diagnostic markers. Altogether, the candidate microRNAs show specificity for diabetic kidney disease, identify declining kidney function, and target key kidney cell types, mRNAs, proteins, and pathogenic mechanisms.  Lay summaryDiabetic kidney disease (DKD) damages the kidneys severely. DKD progression differs between diabetes subtypes and sexes and currently the diagnosis comes too late when the kidney is already damaged. Thus, clinical care needs better and earlier diagnostic markers. Here we studied the microRNAs in urinary extracellular vesicles, small particles secreted actively by the kidney cells. We found 11 candidate microRNA markers for DKD. The discovery was made in males with type 1 diabetes, but some of the microRNAs were confirmed across type 1 and 2 diabetes, as well as female or combined sex populations. Altogether we studied over 250 samples. Analysis of miRNAs regulatory pathways and correlations with clinical measurements in individuals with DKD suggest that some miRNAs may hold the potential as early diagnostic markers. Our findings could thus impact clinical practice by providing early and specific DKD diagnostic tools allowing effective care at an early DKD stage.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Low-intensity focused ultrasound stimulation in stroke: An intensity escalation phase I safety and feasibility study\nAbstract: BACKGROUNDLow-intensity focused ultrasound stimulation (LIFUS) has recently emerged as a promising neuromodulation tool for certain neuropsychiatric diseases. However, its safety and feasibility in stroke patients remains unknown. Intensity is a critical safety parameter for LIFUS. We aimed to determine the maximum safe and tolerable intensity of LIFUS in stroke patients, and to explore its effect on upper-extremity motor learning and corticospinal excitability.  METHODSSubjects with first-ever stroke participated in this Phase I study. We adopted the classic 3+3 dose-escalation paradigm to sham/0, 1, 2, 4, 6, and 8 W/cm2 spatial-peak pulse-average intensity (ISPPA, estimated in-vivo transcranial value; LOW: sham/0, 1 and 2 W/cm2, HIGH: 4, 6 and 8 W/cm2). Stopping rules (dose limiting toxicities) were pre-defined: [&ge;]2nd-degree scalp burn, clinical seizures, [&ge;]20% topical apparent diffusion coefficient change, or participant discontinuation due to any reason. A 12-minute LIFUS was applied over the ipsilesional motor cortex while participants were concurrently practicing three blocks of motor sequence learning (MSL) task using the affected hand. We collected the occurrences of pre-defined adverse events, post-minus-pre improvements in MSL response time, and post-minus-pre differences in corticospinal excitability quantified by motor evoked potentials.  RESULTSISPPA was escalated to 8 W/cm2 with eighteen stroke participants without meeting stopping rules. Compared to the LOW, the HIGH performed significantly better on the MSL (24.7{+/-}13.3% vs. 13.2{+/-}10.9%, p=0.01). Similarly, the HIGH also showed signs of increased corticospinal excitability (32.0{+/-}34.3% vs. 12.9{+/-}48.0%) but did not reach significance, p=0.53.  CONCLUSIONSOur Phase I safety study suggests that a single session of 12-minute LIFUS up to 8 W/cm2 ISPPA is safe and feasible in stroke patients. Higher LIFUS intensities can induce greater MSL retention. The next logical step is to conduct a Phase II study to further test the efficacy of LIFUS and monitor its safety profiles in stroke patients.  REGISTRATIONURL: https://www.clinicaltrials.gov; Unique identifier: NCT05016531\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Systematic Review of the Etiology and Neurobiology of Intermittent Explosive Disorder\nAbstract: Intermittent Explosive Disorder (IED) is characterized by repeated inability to control aggressive impulses. Although the etiology and neurobiology of impulsive anger and impulse control disorders have been reviewed, no systematic review on these aspects has been published for IED specifically. We conducted a systematic search in seven electronic databases for publications about IED, screened by two authors, and retained twenty-four studies for the review. Our findings highlight a multifactorial etiology and neurobiology of IED, emphasizing the role of the amygdala and orbitofrontal cortex in emotional regulation and impulse control, and supporting interventions that target serotonergic signaling. Research also shows that childhood trauma and adverse family environment may significantly contribute to the development of IED. Yet, genetic studies focusing on IED were largely lacking, despite many examining the genetics underlying aggression as a general trait or other related disorders. Future research using consistently defined IED as a phenotype is required to better understand the etiology and underlying mechanisms and assist in informing the development of more effective interventions for IED.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Forecasting local surges in COVID-19 hospitalizations through adaptive decision tree classifiers\nAbstract: During the COVID-19 pandemic, many communities across the US experienced surges in hospitalizations, which strained the local hospital capacity and affected the overall quality of care. Even when effective vaccines became available, many communities remained at high risk of surges in COVID-19-related hospitalizations due to waning immunity, low uptake of booster vaccinations, and the continual emergence of new variations of SARS-CoV-2. Some risk metrics, such as the CDCs Community Levels, were developed to predict the impact of COVID-19 on the community-level healthcare system based on routine surveillance data. However, they had limited utility as they were not routinely updated based on accumulating data and were not directly linked to specific outcomes, such as surges in COVID-19 hospitalizations beyond local capacities. Regression models could resolve these limitations, but they have limited interpretability and do not convey the reasoning behind their predictions. In this paper, we evaluated decision tree classifiers that were developed in \"real-time\" to predict surges in local hospitalizations due to COVID-19 between July 2020 and November 2022. These classifiers would have provided visually intuitive and interpretable decision rules for local decision-makers to understand and act upon, and by being updated weekly, would have responded to changes in the epidemic. We showed that these classifiers exhibit reasonable predictive ability with the area under the receiver operating characteristic curve (auROC) > 80%. These classifiers maintained their performance temporally (i.e, over the duration of the pandemic) and spatially (i.e., across US counties). We also showed that these classifiers outperformed the CDCs Community Levels for predicting high hospital occupancy.  Significance StatementA major concern during the COVID-19 pandemic was the risk of exceeding local healthcare capacity due to COVID-19-related hospitalizations. To assess this risk and inform mitigating strategies, several risk assessment tools were developed during the pandemic. Many of these tools, however, did not predict local outcomes, were not updated as the pandemic progressed, and/or were not interpretable by decision-makers. We propose an adaptive framework of decision tree classifiers to predict whether COVID-19-related hospital occupancy would exceed a given capacity threshold. This framework would provide interpretable classification rules to predict surges in local hospitalizations,and maintained its performance over time and across US counties, and outperformed the CDCs Community Level tool.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Framework to Assess Clinical Safety and Hallucination Rates of LLMs for Medical Text Summarisation\nAbstract: The integration of large language models (LLMs) into healthcare settings holds great promise for improving clinical workflow efficiency and enhancing patient care, with the potential to automate tasks such as text summarisation during consultations. The fidelity between LLM outputs and ground truth information is therefore paramount in healthcare, as errors in medical summary generation can lead to miscommunication between patients and clinicians, leading to incorrect diagnosis and treatment decisions and compromising patient safety. LLMs are well-known to produce a variety of errors. Currently, there is no established clinical framework for assessing the safety and accuracy of LLM-generated medical text.  We have developed a new approach to: a) categorise LLM errors within the clinical documentation context, b) establish clinical safety metrics for the live usage phase, and c) suggest a framework named CREOLA for assessing the safety risk for errors. We present clinical error metrics over 18 different LLM experimental configurations for the clinical note generation task, consisting of 12,999 clinician-annotated sentences. We illustrate the utility of using our platform CREOLA for iteration over LLM architectures with two experiments. Overall, we find our best- performing experiments outperform previously reported model error rates in the note generation literature, and additionally outperform human annotators. Our suggested framework can be used to assess the accuracy and safety of LLM output in the clinical context.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development and Validation of Nomograms for predicting Coronary Artery Calcification and Severe Coronary Artery Calcification: a retrospective cross-sectional study\nAbstract: IntroductionThere is a significant lack of effective pharmaceutical interventions for treating coronary artery calcification (CAC). Severe CAC (sCAC) poses a formidable challenge to interventional surgery and exhibits robust associations with adverse cardiovascular outcomes. Therefore, it is imperative to develop tools capable of early-stage detection and risk assessment for both CAC and sCAC. This study aims to develop and validate nomograms for the accurate prediction of CAC and sCAC.  MethodsThis retrospective cross-sectional study was conducted in Taizhou, Jiangsu Province, China. CAC assessment was performed using non-gated thoracic CT scans. Demographic data and clinical information were collected from patients who were then randomly divided into a training set (70%) or a validation set (30%). Least absolute shrinkage and selection operator (LASSO) regression as well as multiple logistic regression analyses were utilized to identify predictive factors for both CAC and sCAC development. Nomograms were developed to predict the occurrence of CAC or sCAC events. The models performance was evaluated through discrimination analysis, calibration analysis, as well as assessment of their clinical utility.  ResultsThis study included 666 patients with an average age of 75 years, of whom 56% were male. 391 patients had CAC, with sCAC in 134 cases. Through LASSO and multiple logistic regression analysis, age increase, hypertension, carotid artery calcification, CHD, and CHADS2 score were identified for the CAC risk predictive nomogram with an area under the receiver operating characteristic (ROC) curve (AUC) of 0.845(95%CI 0.809-0.881) in the training set and 0.810(95%CI 0.751-0.870) in the validation set. Serum calcium level, carotid artery calcification, and CHD were identified for the sCAC risk predictive nomogram with an AUC of 0.863(95%CI 0.825-0.901) in the training set and 0.817(95%CI 0.744-0.890) in the validation set. Calibration plots indicated that two models exhibited good calibration ability. According to the decision curve analysis (DCA) results, both models have demonstrated a positive net benefit within a wide range of risks.  ConclusionsThe present study has successfully developed and validated two nomograms to accurately predict CAC and sCAC, both of which have demonstrated robust predictive capabilities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Methodological issues in visible LED therapy dermatological research and reporting\nAbstract: The advent of mass-market Light Emitting Diodes (LEDs) has seen considerable interest in potential dermatological applications of LED light photobiomodulation (PBM) for a range of conditions, with a thriving market for direct-to-consumer LED treatments, including red light, blue light, and yellow light wavelengths. Evidence of efficacy for many conditions is however decidedly mixed, with starkly different outcomes reported by different authors. Due to the wide range of irradiances and wavelengths used, interpretation, comparison, and even efficacy evaluation is often impossible or prohibitive, impeding evidence synthesis. This work establishes a framework for objectively cross-comparing patient dose in terms of fluence, and a model for contrasting received dose to typical solar dose at ground level to facilitate interpretation of results and evidence synthesis. This allowes direct cross-comparison of patient skin fluence from LED PMB treatments under different regimes, and a means for evidence synthesis. This was applied to LED PMB data from 27 clinical trials to examine fluences and patient-equivalent solar exposure from LED light-sources for dermatological conditions, including acne vulgaris, wrinkle-reduction, wound-healing, psoriasis severity, and erythemal index. The results of this analysis suggest that fluences, wavelengths, and solar exposure equivalent differed by orders of magnitude in he studies analysed, with effective doses often comparable to typical daily solar exposure. Better dose quantification and plausible biological justification for various wavelengths and fluences are imperative if LED therapy studies for dermatology are to be informative and research replicability improved.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: How young people experienced Long COVID services: a qualitative analysis.\nAbstract: ObjectiveWe aimed to evaluate how acceptable paediatric Long COVID services were to patients and clinicians. This paper focuses on how acceptable Long COVID services were to paediatric patients.  DesignThis study was explorational. Semi-structured qualitative interviews with 13 paediatric patients were used to understand the experiences of patients with Long COVID.  SettingParticipants were recruited from specialist paediatric services in the Southwest of England from June 2022 to September 2023.  PatientsParticipants were children and young people (CYP) aged 11-17 years old with a Long COVID diagnosis who accessed the specialist services in the Southwest of England.  ResultsFour themes were reported. Accessing specialist clinics helped CYP to feel validated, they appreciated consulting with clinicians who were knowledgeable about Long COVID and empathetic. CYP found comfort in knowing other CYP were experiencing Long COVID. CYP wanted to be proactive in their Long COVID management, appreciating regular appointments and the opportunity to learn about their condition. CYP desired normality, and therefore sought flexible appointment times, online appointments, and reasonable adjustments. CYP found the waiting times to access Long COVID services were too long.  ConclusionsOur results stress the importance to CYP of several features of the care received in the specialist clinics. These relate to the experiences of CYP with Long COVID but potentially extend to CYP with other conditions, particularly long-term and/or poorly understood conditions. The results support creating community-based support groups for CYP with long-term medical conditions, providing online flexible appointments, offering early reasonable adjustments for school and providing quicker access to specialist clinics.  Key messages/Summary boxO_ST_ABSWhat is already known on this topicC_ST_ABSThe existing literature which explores adult experiences of Long COVID services is in agreement with this study in multiple ways. Firstly, it appears that clinician validation is very important to the clinician patient relationship (1-5). Peer support and building a Long COVID community for patients is also valued by individuals with Long COVID (1, 3, 5, 6), as are online appointments (1,3). Finally, long waiting lists to access Long COVID clinics are a barrier to care (1, 3). This can be mitigated to some extent by providing sign-posting or self-management resources while waiting for clinic access (3). However, the literature regarding paediatric experiences of Long COVID is limited. Two papers discuss the impact of a lack of reasonable adjustments on school (7,8) and the importance of validation through peer support (7).  What this study addsTo the best of our knowledge, there are no studies on Long COVID services for paediatric patients that highlight how patients experienced management of their condition. Our study highlights the patients desire to be proactive in their management, including being given opportunities to learn about Long COVID.  How this study might affect research, practice or policyThis study highlights recommendations for clinical practice. It is recommended to consider the following when designing specialist paediatric services for CYP with Long COVID: CYP with complex medical conditions want clinicians to validate their experience by acknowledging that their symptoms are real and their concerns are valid. Community-based groups for CYP experiencing the same condition are valued by patients, as are online flexible appointments, liaison with schools to provide early reasonable adjustments and rapid access to services for CYP. Future research should explore how these recommendations positively impact patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Psychiatric, Neurological, and Somatic Comorbidities in Intermittent Explosive Disorder: a retrospective cohort study of electronic health records\nAbstract: ImportanceIntermittent Explosive Disorder (IED) is an understudied psychiatric condition that presents with repeated episodes of impulsive aggression and poorly regulated emotional control, often resulting in interpersonal and societal consequences. Better understanding of comor-bidities will allow for enhanced screening, diagnosis, and treatment of patients.  ObjectiveTo investigate prevalence and associations of IED with psychiatric, neurological, and somatic disorders using real-world data  DesignMatched cohorts of patients with or without IED diagnosis were identified using data from the TriNetX Research Network (until January 31, 2024). Cox proportional hazard models were used to estimate and compare the probabilities of acquiring other diagnoses using pa-tients available medical records.  SettingAnalysis of electronic medical records from two patient populations.  Participants30,357 individuals with IED and equal number of demographically matched individuals without IED from the TriNetX Research.  ExposureIED diagnosis identified through the associated ICD codes.  Main Outcomes and MeasuresThe main outcomes were ICD-10-CM diagnostic categories and root codes for disorders and health conditions in both cohorts. Main measures are total numbers and proportions of patients who had the diagnostic codes, as well as adjusted hazard ratios for IED diagnosis.  ResultsAlthough only 0.03% of the total patient population had an IED diagnosis, we found extensive and widespread comorbidities with psychiatric, neurological and somatic conditions. A significant 95.7% of the individuals with IED had another psychiatric diagnosis. All psychiatric sub-categories and 95% of the psychiatric diagnoses were significantly associated with IED, with HRs ranging from 2 to 77. Among neurological conditions, neurodegenerative diseases and epilepsy had the highest HRs, followed by extrapyramidal and movement disorders, cerebral palsy and other paralytic syndromes, and sleep disorders. Notable associations with IED also includes conditions such as obesity, hyperlipidemia, hypertension, and GERD.  Conclusion and RelevanceOur findings illuminate the extensive comorbid relationships between IED and psychiatric, neurological, and somatic disorders. This underscores the necessity for an integrated diagnostic and treatment approach that addresses both the psychological and physical health aspects of IED. Additionally, our work highlights the need for more accurate and inclusive diagnosis of IED in patients with mental disorders.  Key PointsFocused Question: What is the pattern of comorbidity of IED with other disorders?  Findings: Despite being underdiagnosed in the clinical cohort, IED was found significantly associated with a wide range of psychiatric disorders, many neurological, and some somatic disorders.  Meaning: The widespread comorbidity highlights the critical need for integrated care approaches that consider the multifaceted health challenges faced by individuals with IED.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of the WHELD/Brief Psychosocial Therapy intervention on psychosis in people with dementia: A Cluster Randomized Trial\nAbstract: Neuropsychiatric Symptoms (NPS), particularly psychosis, are common in dementia and can significantly impact patient outcomes, caregivers and disease trajectory. Psychosis, which includes hallucinations and delusions, occurs in up to 50% of people with dementia and has been linked with lower quality of life and faster cognitive decline. While best practice guidelines have highlighted the importance of non-pharmacological treatments for NPS, evidence-based non-pharmacological approaches are limited. This exploratory analysis of a cluster randomized control trial (RCT) from the WHELD programme compares the WHELD/Brief Psychosocial Therapy intervention with treatment as usual in a 9-month trial across 69 UK nursing homes (N=8477, 553 completed). The current report analyzed outcomes for the participants with dementia-related psychosis (N=163) participating in the trial. Whilst the WHELD/Brief Psychosocial Therapy intervention did not significantly reduce NPI psychosis score, it did significantly improve apathy (p=0.006), agitation (p=0.038) and quality of life (p=0.01) in participants with psychosis. In addition there was a non-significant numerical improvement in caregiver perceived disruptiveness. These findings suggest that whilst the WHELD/ Brief Psychosocial Therapy intervention does not directly alleviate psychosis in people with dementia, it does significantly improve related neuropsychiatric symptoms and quality of life, offering meaningful benefits to people with dementia experiencing distressing psychotic symptoms.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of Parental Prenatal Mental Health on Offspring Neurodevelopmental Disorders: A Systematic Review and Meta-Analysis\nAbstract: ObjectiveParental prenatal mood and anxiety disorders (PMAD) are linked to child neurodevelopmental disorders (NDDs), but evaluations of the magnitude and mechanisms of this association are limited. This study estimates the strength of the association and whether it is impacted by genetic and environmental factors.  MethodA systematic search of PubMed, CENTRAL, PsycINFO, OVID, and Google Scholar was performed for articles published from January 1988 to January 2024. Of 2,170 articles screened, 64 met the inclusion criteria. Meta-analyses were conducted on 20 studies, and 44 were included in the narrative synthesis. We conducted random-effects meta-analyses, along with tests for heterogeneity (I{superscript 2}) and publication bias (Eggers test). The review followed PRISMA and MOOSE guidelines.  ResultsMaternal PMADs were associated with a significantly increased risk of ADHD (OR 1.91, 95% CI 1.45-2.52) and ASD (OR 1.57, 95% CI 1.37-1.81) in children. Paternal PMADs were also associated with the risk of NDDs, with combined odds for ASD and ADHD (OR 1.24, 95% CI 1.15-1.34). Several studies suggested that the link between parental PMADs and offspring NDDs might be impacted by both genetic and environmental factors, including the impact of ongoing parental depression on child behavior.  Conclusions and RelevanceParental PMADs are significantly associated with an increased risk of NDDs in children. These associations may be influenced by both genetic predispositions and environmental factors. Understanding these pathways is important for informing interventions aimed at mitigating mental health risks in families and supporting child development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Scoping Review: Outpatient Psychotherapeutic Care for Children and Adolescents in Germany - Status Quo and Challenges in Assessment\nAbstract: In the context of multiple global crises, including the COVID-19 pandemic, climate change, and global conflicts, children and adolescents worldwide are experiencing heightened psychological stress. As the foundation for lifelong mental health is established during childhood and adolescence, early prevention and treatment of mental health problems, such as through psychotherapy, are crucial. In Germany, current outpatient psychotherapeutic care capacities appear inadequate, while systematic evaluations of the care situation are lacking. This study investigates the state of statutory health insurance-funded outpatient psychotherapeutic care for children and adolescents in Germany and evaluates various methodological approaches for its assessment. We conducted a scoping review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) guidelines. Publications from January 2018 to December 2023 were sourced from PubPsych, PubMed, APA PsycInfo, Google Scholar, and ProQuest. Included studies reported quantitative primary data on the mental health of community samples of children and adolescents in Germany or their outpatient psychotherapeutic care. We included 41 publications comprising epidemiological studies, administrative data, and psychotherapist and patient reports. A lack of systematic and standardized research approaches resulted in significant variance in data. Nonetheless, qualitative analysis revealed that approximately one four children and adolescents in Germany is affected by mental health problems, while one in six to seven children and adolescents requires psychotherapeutic treatment. Yet, only up to one in fifty receives guideline-based psychotherapy. Most requests for initial psychotherapeutic consultations are unmet, with waiting times for guideline-based psychotherapy exceeding six months for at least half of the patients. Overall, our findings suggest that outpatient psychotherapeutic care for children and adolescents in Germany is still insufficient. They advocate for a systematic, multimodal, and longitudinal assessment of statutory health insurance-funded outpatient psychotherapeutic care, along with an expansion of treatment capacities to enhance access for children and adolescents in Germany.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Developing and validating modular surveys for vector-borne diseases: a study protocol\nAbstract: Vector-borne diseases are an increasing threat to human health and well-being in the United States. Understanding public perception and practices taken to reduce vector abundance and vector-human contact can guide effective interventions that can mitigate health risks. Nevertheless, vector-borne disease surveys, which are widely used in the field to understand public perception and practices, are often inconsistent in terms of structure and implementation. This protocol is designed to provide guidance for public health professionals and researchers in the development of future KAP studies by ensuring uniformity in design and structure. This manuscript describes a rigorous three-phase protocol for the development of standardized vector-borne disease survey modules that can be used throughout the United States to generate data that are comparable across diverse regions. During phase one, a workshop with subject matter experts and a comprehensive literature review will be conducted to identify survey domains and generate items of interest. Survey items will also be mapped based on two theoretical frameworks, the Health Belief Model and the Risks, Attitudes, Norms, Abilities and Self-Regulation framework, to help gauge individual perceptions of risk severity and self-efficacy. During phase two, a group of expert judges will evaluate survey items based on content relevance, representativeness, and technical quality. During the final phase, cognitive interviews and surveys with target audience groups will be conducted to ensure the face validity of the modules. Participants will be drawn from a diverse range of educational and geographic locations, and computer-assisted personal interviewing will be implemented. The surveys developed through this protocol will be available to researchers aiming to gain deeper insights into the publics knowledge, attitudes, and practices concerning vector-borne diseases, facilitating the collection of more comparable data across various regions in the United States.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Impacts of Neighborhood Disparities on US Population Health During the COVID-19 Pandemic: A Literature Review and Policy Analysis for Future Response\nAbstract: Introduction/BackgroundThe COVID-19 pandemic has disrupted major aspects of daily life since its emergence in late 2019, impacting health and well-being worldwide. Aside from genetic predisposition, numerous external factors play key roles in determining levels of disease susceptibility and overall health status.  Aim/ObjectivesThis review and policy analysis sought to examine literature focused on the impact of neighborhood environments on population health and well-being during the COVID-19 pandemic period. Examined studies explore the impacts of various aspects of the neighborhood environment (i.e., walkability, transportation, access to healthcare/vaccination, etc.) during the COVID-19 era on population health and well-being.  MethodsDatabases were searched for studies published from March 2020 to August 2022. Selected studies examine the impacts of various aspects of the neighborhood environment (i.e., walkability, transportation, access to healthcare/vaccination, climate, crime rates, persistent poverty, the social spread of misinformation, etc.) during the COVID-19 era on population health and well-being.  ResultsFindings from our review suggest that those living in less-than-favorable environments were faced with significant challenges, making vulnerable populations more prone to the severity of COVID-19 infection.  ConclusionWe argue these results establish cause for the consideration of the effects of neighborhood environments in developing intelligent intervention strategies for both pandemic recovery and preparation for future public health emergencies, especially among vulnerable populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of early postoperative ambulation on gait recovery after hip fracture surgery: A multicenter cohort study\nAbstract: ObjectiveThis study aimed to investigate the effect of early postoperative ambulation on gait recovery at the initial postoperative week and at discharge after hip fracture surgery in older patients.  DesignMulticenter prospective cohort study.  Setting and ParticipantsThe study included 882 patients aged [&ge;]65 years from 10 acute hospitals in Japan.  MethodsPatients were divided into two groups according to the interval between surgery and first ambulation: early-ambulation (EA) group (initiation of ambulation on postoperative day 1 or 2) and late-ambulation (LA) group (initiation of ambulation on postoperative day 3 or later). The Functional Independence Measure (FIM) was assessed 1 day postoperatively, 1 week postoperatively, and at discharge. Independent walking regardless of use of walking aids was defined as walking FIM [&ge;]5. Confounding variables were age, mobility and cognitive function before injury, medical history, fracture type, and waiting days for surgery.  Multivariate logistic regression analysis was conducted to determine whether EA affected independent walking at 1 week postoperatively and at discharge.  ResultsThe number of patients in the EA and LA groups was 292 (33.1%) and 590 (66.9%), respectively. The number of patients walking independently 1 week postoperatively and at discharge was 156 (17.7%) and 292 (33.1%), respectively. Multivariate logistic regression analysis revealed that EA was associated with independent walking at 1 week postoperatively (odds ratio [OR], 3.27; 95% confidence interval [CI], 2.17-4.94; P < .0001) and at discharge after adjusting for confounders (OR, 3.33; 95% CI, 2.38-4.69; P < .0001). EA was associated with the recovery to pre-injury walking status at discharge after adjusting for confounders (OR, 3.05; 95% CI, 1.59-5.93; P =.0009).  Conclusion and ImplicationsEarly ambulation after hip fracture surgery has an impact on independent walking and recovery of pre-injury walking status at 1 week postoperatively and at discharge from acute hospitals in older patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Building and validating a predictive model for stroke risk in Chinese community-dwelling patients with chronic obstructive pulmonary disease using machine learning methods\nAbstract: BackgroundThe occurrence of stroke in patients with chronic obstructive pulmonary disease (COPD) can have potentially devastating consequences; however, there is still a lack of predictive models that accurately predict the risk of stroke in community-based COPD patients in China. The aim of this study was to construct a novel predictive model that accurately predicts the predictive model for the risk of stroke in community-based COPD patients by applying a machine learning methodology within the Chinese community.  MethodsThe clinical data of 809 Community COPD patients were analyzed by using the 2020 China Health and Retirement Longitudinal Study (CHARLS) database. The least absolute shrinkage and selection operator (LASSO) and multivariate logistic regression were used to analyze predictors. Multiple machine learning (ML) classification models are integrated to analyze and identify the optimal model, and Shapley Additive exPlanations (SHAP) interpretation was developed for personalized risk assessment.  ResultsThe following six variables:Heart_disease,Hyperlipidemia,Hypertension,ADL_score, Cesd_score and Parkinson are predictors of stroke in community-based COPD patients. Logistic classification model was the optimal model, test set area under curve (AUC) (95% confidence interval, CI):0.913 (0.835-0.992), accuracy: 0.823, sensitivity: 0.818, and specificity: 0.823.  ConclusionsThe model constructed in this study has relatively reliable predictive performance, which helps clinical doctors identify high-risk populations of community COPD patients prone to stroke at an early stage.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring the intersection between orthostatic hypotension and daytime sleepiness in Parkinson disease\nAbstract: IntroductionDaytime sleepiness, reported in about 50% of patients with Parkinsons disease (PD), is associated with high morbidity, poor quality of life and increased risk for accidents. While an association between dysautonomia and daytime sleepiness in early, de-novo PD has been reported, our understanding of the role of medications, cognitive status and disease duration on this relationship is inadequate.  MethodsData were analyzed from the prospective Cincinnati Cohort Biomarkers Program. The primary outcome of interest was daytime sleepiness, as measured by the Epworth Sleepiness Scale (ESS). The primary exposure variable was orthostatic hypotension (OH) with a sub-analysis for the neurogenic OH (nOH) subtype. Regression analyses were carried out adjusting for the following covariates: age, sex, disease duration, education, comorbidities, anti-cholinergic burden, levodopa equivalent dose (LEDD), motor subscore of the Movement disorder society-unified Parkinsons disease rating scale, Hoehn and Yahr stage (H&Y), Beck Depression Inventory, and Beck Anxiety Inventory.  ResultsData on 456 subjects with PD were analyzed. OH was strongly associated with ESS scores, particularly in those with anticholinergic medication use after adjusting for all covariates (RC, 4.30; p<0.001). This adjusted association was more pronounced in men with early disease duration, early H&Y stage, no cognitive decline, and LEDD[&le;]750 mg. Similar results were noted with nOH.  ConclusionsOH is associated with daytime sleepiness to a greater extent in male patients with early disease and magnified by such prescribing practices as anticholinergic medication use and dopaminergic dosage in early PD. This relationship is independent of cognitive decline.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Oral-motor complexity influences center of pressure patterns in adults with stroke-related communication disorders\nAbstract: People with stroke (PwS) often exhibit altered postural control, and concomitant stroke-related communication disorders (e.g., aphasia, dysarthria) may be an underrecognized risk factor for post-stroke falls. This heightened fall risk may be related to alterations in postural control that emerge during different speaking and listening conditions. This study evaluated how variations in the relative articulatory demands during speech production--termed \"oral-motor complexity\"--affect postural center of pressure (COP) patterns among PwS, both with communication disorders (PwS-CDis) and without (PwS). Three groups of adults (PwS, PwS-CDis, and a nondisabled Control group) stood on a force platform while completing four 30-second quiet stance trials, followed by twelve 30-second trials randomized across three experimental conditions of varying oral-motor complexities (\"ba\", \"puh tuh kuh\", \"rah shah lah nah\"). COP variability (SD) was significantly higher during experimental conditions compared to quiet stance, regardless of group and movement plane. Differences in nonlinear time-dependent metrics were found across oral-motor task conditions, particularly among PwS-CDis, suggesting oral-motor complexity may influence underlying postural-motor organization. Distinct temporal-dynamical patterns observed in PwS-CDis indicate a possible link between pathology, postural control, and speech motor tasks, which is relevant when evaluating postural control in individuals with stroke-related communication disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development of a Novel Dynamic Leak Model to Simulate Leak for Performance Testing of Manual Neonatal Resuscitation Devices. Does Leak Matter? A Bench Study\nAbstract: BackgroundNewborn resuscitation is commonly performed in the presence of face mask leak. Leak is highly variable, pressure dependent and often unrecognised. The effectiveness of resuscitation devices to deliver adequate inflations in the presence of leak is unknown. Bench models simulating continuous leak have disadvantages of not accurately reflecting leak occurring during clinical resuscitation. A dynamic leak model based on pressure release valves was thus developed.  AimTo assess self-inflating bag (SIB) and T-piece resuscitator (TPR) ventilation performance in the presence of dynamic (DLM) compared to continuous (CLM) leak models in a bench study.  MethodFive predefined leak levels were tested for each leak model (0-87%). Resuscitation devices were connected to a test lung (compliance 0.6 mL/cmH2O) and respiratory parameters were measured using respiratory function monitors before (patient interface) and after (actual) an induced leak at 40, 60, 80 inflations/min.  Results3,600 inflations were analysed. DLM showed a decrease in actual tidal volumes from 0%-87% leak with tidal volume differences (SIB 4.8mL, TPR 2.9mL), contrasting to minimal change for CLM (SIB -0.6mL, TPR 0.3mL). CLM demonstrated larger differences between patient interface and actual leak. The absolute difference at 60 inflations/min at 87% leak were SIB 37.5%, TPR 18.2% for CLM compared to SIB 4.6%, TPR 1.4% for DLM.  ConclusionCLM may underestimate the impact of resuscitation device performance with poor correlation between patient interface and actual delivered volume. DLM demonstrates several advantages with more accurate representation of face mask leak and will prove useful in modelling all systems delivering PPV.  O_LIWhat is already known on this topic? - Mask leak is common, variable and often unrecognised during newborn resuscitation. - Excessive or insufficient tidal volumes may cause newborn lung and brain injury. - Current leak models used to test ventilation devices have a poor fidelity in modelling clinical mask leak.  C_LIO_LIWhat this study adds? - Development of a novel dynamic leak model to enhance performance testing of resuscitation devices by representing pressure dependent leak. - Highlights the dynamic nature of leak during clinical resuscitation. - Relates RFM displayed leak reliably determining delivered lung volume with leak levels to 86%.  C_LIO_LIHow this study might affect research, practice or policy? - The use of dynamic leak model as a higher fidelity simulation tool for the testing of not only resuscitation devices but also ventilators and RFMs. - Further research will determine the ability of currently used ventilation devices to perform in the presence of dynamic leak.  C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Non-pharmacological interventions for psychotic symptoms in people with dementia: a Delphi consensus\nAbstract: BackgroundPsychotic symptoms such as delusion and hallucinations are common in people with dementia. They are associated with various deleterious outcomes including reduced quality of life and increased caregiver burden. Pharmacological interventions to combat psychotic symptoms have shown limited efficacy and can be associated with significant adverse events. Non-pharmacological interventions are recommended as the first line option for treatment, however there is a paucity of evidence for specific non-pharmacological options to primarily target psychotic symptoms in people with dementia. Further work is needed to identify, adapt and develop possible non-pharmacological options to target psychotic symptoms in dementia.  AimTo establish which non-pharmacological interventions could be used or adapted to treat psychotic symptoms and/or confer benefits in people with dementia  DesignModified Delphi consensus process. Two rounds of feedback were conducted and included a directed scoping review, based on the interventions recommended in the first round of the Delphi.  ParticipantsAn expert panel consisted of 12 members with clinical and research expertise in managing psychotic symptoms in people with dementia  ResultsThere were three top nominated treatment options: cognitive behavioural therapy (CBT), family intervention, and personalized activities/environmental/sensory interventions, without a clear priority between the 3 approaches.  The WHELD/Brief Psychosocial Therapy programme focussing on personalized activities improves concurrent neuropsychiatric symptoms in people with dementia related psychosis. Preliminary studies also suggest that combining personalized activities with family training may improve the direct impact on psychosis. There are also opportunities to adapt CBT interventions for people with psychosis related to early or mild dementia.  ConclusionsThere were clear recommendations for three non-pharmacological options that could be used or adapted to benefit people with psychosis in the context of dementia.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of chronic sedative-hypnotic use on sleep architecture and brain oscillations in older adults with chronic insomnia.\nAbstract: RationaleHigh rates of insomnia in older adults lead to widespread benzodiazepine (BZD) and benzodiazepine receptor agonist (BZRA) use, even though chronic use has been shown to disrupt sleep regulation and impact cognition. Little is known about sedative-hypnotic effects on NREM slow oscillations (SO) and spindles, including their coupling, which is crucial for memory, especially in the elderly.  ObjectivesOur objective was to investigate the effect of chronic sedative-hypnotic use on sleep macro-architecture, EEG relative power, as well as SO and spindle characteristics and coupling.  MethodsOne hundred and one individuals (66.05 {+/-} 5.84 years, 73% female) completed a one-night study and were categorized into three groups: good sleepers (GS, n=28), individuals with insomnia (INS, n=26) or individuals with insomnia who chronically use either BZD or BZRA to manage their insomnia difficulties (MED, n=47; dose equivalent in Diazepam: 6.1 {+/-} 3.8 mg/week). We performed a comprehensive comparison of sleep architecture, EEG relative spectrum, and associated brain oscillatory activities, focusing on NREM brain oscillations crucial for sleep-dependent memory consolidation (i.e., SO and spindles) and their temporal coupling.  ResultsChronic use of BZD/BZRA worsened sleep architecture and spectral activity compared to older adults with and without insomnia disorder. The use of BZD/BZRAs also altered the characteristics of sleep-related brain oscillations and their synchrony. An exploratory interaction model suggested that BZD use exacerbated sleep alterations compared to BZRA, and higher BZD/BZRA dosage worsened alteration in sleep micro-architecture and EEG spectrum.  ConclusionsOur results suggest that chronic use of sedative-hypnotics is detrimental to sleep when compared to drug-free GS and INS. Such alteration of sleep regulation - at the macro and micro-architectural levels - may contribute to the reported association between sedative-hypnotic use and cognitive impairment in older adults.  STATEMENT OF SIGNIFICANCEWidespread use of sedative-hypnotics is driven by high insomnia rates among older adults. Chronic use can disrupt sleep and cognitive function, however, its impact on sleep regulation - at the macro and micro-architecture levels - is not well understood. We assessed the effect of chronic sedative-hypnotic use in older adults using a between-group design involving good sleepers, individuals with insomnia disorder who do not take any pharmacological treatment to manage their symptoms and individuals with insomnia disorder who chronically use sedative-hypnotics as a sleep aid. We performed a comprehensive comparison of sleep architecture, EEG relative spectrum, and associated NREM brain oscillations crucial for sleep-dependent memory consolidation (i.e., SO and spindles) and their temporal coupling. We showed that chronic use of sedative-hypnotics is detrimental to sleep regulation - at the macro and micro level - compared to drug-free GS and INS, and this may contribute to the reported link between sedative-hypnotic use and cognitive impairment in older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Trans-Ancestry GWAS of Hot Flashes Reveals Potent Treatment Target and Overlap with Psychiatric Disorders\nAbstract: BackgroundMost women experience hot flashes (hot flushes) during the menopause transition. Menopausal hot flashes typically persist for years. For a sizeable minority of women, hot flashes are severe and substantially impairing. It is worthwhile to further investigate the genetic underpinnings of hot flashes.  MethodWe conducted the largest trans-ancestry genome-wide association study (GWAS) of hot flashes available to date (N=149,560). We used self-assessment of hot flashes in the Nurses Health Study, Nurses Health Study II, Womens Health Initiative, and Queensland Institute of Medical Research samples (total n=42,489). In one sample (UK Biobank, n=107,071) direct assessment of hot flashes was not available, so menopausal hormone therapy was used as a proxy variable. We estimated the heritability of hot flashes and genetic correlations with psychiatric phenotypes using linkage disequilibrium score regression (LDSR).  ResultsIn component analyses and our trans-ancestry meta-analysis, the top locus was on chromosome 4 in the neurokinin 3 receptor gene (TACR3, position 104,556,732, trans-ancestry p=7.2x10-41). A second novel locus was identified (LINC02428, p=3.5x10-8). Gene results implicated TACR3, GRID1, NUDT4, and PHF21B. Using the hot flash GWAS meta-analysis (n=42,489; i.e., no proxy variable), SNP heritability was estimated: h2liab=.08 (h2SNP=.04, se=.02). Genetic correlations were statistically significant between hot flashes and posttraumatic stress disorder (PTSD, rg=0.25, p=0.01), schizophrenia (rg=0.17, p=0.02), and depression (rg=0.21, p=0.01).  DiscussionThese genomic findings are consistent with independent, robust basic science research which led to a novel treatment for hot flashes, namely, neurokinin 3 receptor antagonists. This new class of hot flash drugs blocks the receptor (neurokinin 3 receptor) coded for by the top locus for hot flashes (TACR3). This GWAS of hot flashes provides an uncommonly clear example of how GWAS findings can point to potent treatment targets for complex brain phenotypes. We also found that the proxy variable (menopausal hormone therapy) pointed to the same target (TACR3), and that exclusively intronic and intergenic variants signaled this target.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gut-Brain Nexus: Mapping Multi-Modal Links to Neurodegeneration at Biobank Scale\nAbstract: Alzheimers disease (AD) and Parkinsons disease (PD) are influenced by genetic and environmental factors. Using data from UK Biobank, SAIL Biobank, and FinnGen, we conducted an unbiased, population-scale study to: 1) Investigate how 155 endocrine, nutritional, metabolic, and digestive system disorders are associated with AD and PD risk prior to their diagnosis, considering known genetic influences; 2) Assess plasma biomarkers specificity for AD or PD in individuals with these conditions; 3) Develop a multi-modal classification model integrating genetics, proteomics, and clinical data relevant to conditions affecting the gut-brain axis. Our findings show that certain disorders elevate AD and PD risk before AD and PD diagnosis including: insulin and non-insulin dependent diabetes mellitus, noninfective gastro-enteritis and colitis, functional intestinal disorders, and bacterial intestinal infections, among others. Polygenic risk scores revealed lower genetic predisposition to AD and PD in individuals with co-occurring disorders in the study categories, underscoring the importance of regulating the gut-brain axis to potentially prevent or delay the onset of neurodegenerative diseases. The proteomic profile of AD/PD cases was influenced by comorbid endocrine, nutritional, metabolic, and digestive systems conditions. Importantly, we developed multi-modal prediction models integrating clinical, genetic, proteomic and demographic data, the combination of which performs better than any single paradigm approach in disease classification. This work aims to illuminate the intricate interplay between various physiological factors involved in the gut-brain axis and the development of AD and PD, providing a multifactorial systemic understanding that goes beyond traditional approaches.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Patterns and functional consequences of antibody speciation in maternal-fetal transfer of coronavirus-specific humoral immunity\nAbstract: Maternal antibodies serve as a temporary form of inherited immunity, providing humoral protection to vulnerable neonates. Whereas IgG is actively transferred up a concentration gradient via the neonatal Fc Receptor (FcRn), maternal IgA and IgM are typically excluded from fetal circulation. Further, not all IgG molecules exhibit the same transfer efficiency, being influenced by subclass, Fab and Fc domain glycosylation, antigen-specificity, and the temporal dynamics of maternal antibody responses. Here, we investigate the phenotypes and functions of maternal and cord blood antibodies induced by SARS-CoV-2 infection and compare them to those induced by mRNA vaccination, focusing on breadth of antigen recognition and antiviral functions including neutralization and effector function. While cord blood coronavirus-specific antibody functional breadth and potency appeared to be more compromised than binding breadth and potency in both groups, vaccination induced substantially greater function and breadth in cord blood than did natural infection. These functional phenotypes were associated with speciation of the maternal serum repertoires, as some IgG subpopulations were enriched while others were relatively depleted. Relevant to the continued protection of vulnerable populations in the context of a diversifying pathogen, greater breadth was observed for antibody effector functions than for neutralization, and these activities were associated with greater affinity for antigen. This work provides insights into the functional breadth of maternal-fetal antibody responses in the context of novel mRNA vaccines and a recently emerged pathogen that is likely to be a public health burden for the foreseeable future.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Using Genomic Context Informed Genotype Data and Within-model Ancestry Adjustment to Classify Type 2 Diabetes\nAbstract: Despite high heritability estimates, complex genetic disorders have proven difficult to predict with genetic data. Genomic research has documented polygenic inheritance, cross-disorder genetic correlations, and enrichment of risk by functional genomic annotation, but the vast potential of that combined knowledge has not yet been leveraged to build optimal risk models. Additional methods are likely required to progress genetic risk models of complex genetic disorders towards clinical utility. We developed a framework that uses annotations providing genomic context alongside genotype data as input to convolutional neural networks to predict disorder risk. We validated models in a matched-pairs type 2 diabetes dataset. A neural network using genotype data (AUC: 0.66) and a convolutional neural network using context-informed genotype data (AUC: 0.65) both significantly outperformed polygenic risk score approaches in classifying type-2 diabetes. Adversarial ancestry tasks eliminated the predictability of ancestry without changing model performance.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Optimizing Large Language Models for Discharge Prediction: Best Practices in Leveraging Electronic Health Record Audit Logs\nAbstract: Electronic Health Record (EHR) audit log data are increasingly utilized for clinical tasks, from workflow modeling to predictive analyses of discharge events, adverse kidney outcomes, and hospital readmissions. These data encapsulate user-EHR interactions, reflecting both healthcare professionals behavior and patients health statuses. To harness this temporal information effectively, this study explores the application of Large Language Models (LLMs) in leveraging audit log data for clinical prediction tasks, specifically focusing on discharge predictions. Utilizing a years worth of EHR data from Vanderbilt University Medical Center, we fine-tuned LLMs with randomly selected 10,000 training examples. Our findings reveal that LLaMA-2 70B, with an AUROC of 0.80 [0.77-0.82], outperforms both GPT-4 128K in a zero-shot, with an AUROC of 0.68 [0.65-0.71], and DeBERTa, with an AUROC of 0.78 [0.75-0.82]. Among various serialization methods, the first-occurrence approach--wherein only the initial appearance of each event in a sequence is retained--shows superior performance. Furthermore, for the fine-tuned LLaMA-2 70B, logit outputs yield a higher AUROC of 0.80 [0.77-0.82] compared to text outputs, with an AUROC of 0.69 [0.67-0.72]. This study underscores the potential of fine-tuned LLMs, particularly when combined with strategic sequence serialization, in advancing clinical prediction tasks.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Technology-Supported Self-Triage Decision Making: A Mixed-Methods Study\nAbstract: Symptom-Assessment Application (SAAs) and Large Language Models (LLMs) are increasingly used by laypeople to navigate care options. Although humans ultimately make a final decision when using these systems, previous research has typically examined the performance of humans and SAAs/LLMs separately. Thus, it is unclear how decision-making unfolds in such hybrid human-technology teams and if SAAs/LLMs can improve laypeoples decisions. To address this gap, we conducted a convergent parallel mixed-methods study with semi-structured interviews and a randomized controlled trial. Our interview data revealed that in human-technology teams, decision-making is influenced by factors before, during, and after interaction. Users tend to rely on technology for information gathering and analysis but remain responsible for information integration and the final decision. Based on these results, we developed a model for technology-assisted self-triage decision-making. Our quantitative results indicate that when using a high-performing SAA, laypeoples decision accuracy improved from 53.2% to 64.5% (OR = 2.52, p < .001). In contrast, decision accuracy remained unchanged when using a LLM (54.8% before vs. 54.2% after usage, p = .79). These findings highlight the importance of studying SAAs/LLMs with humans in the loop, as opposed to analyzing them in isolation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Challenging the Chronic Perverse Bias in Prosthetic Valve Design: A Pathway Opens for Advanced Mechanical Valves.\nAbstract: Objective- In vitro evaluation of several prototype mechanical valves compared to present-day controls.   Method- simulated normal cardiac pressures and flows - gravity pressure head column tester flows. - recorded valve hydrodynamics and kinematics   Results- valves superior in performance to clinical controls   Conclusions- Prototype MHV candidates outperform the closing performance of present day SAVR prosthetic valves, including bioprosthetic control.   Competing InterestsNone declared  Financial DisclosureThis research was performed on a pro bono basis by indicted coauthors*, in part, to assist coauthor and Ph.D. candidate Dylan Goode.  CENTRAL MESSAGEIn-vitro dynamics of optimized prototype mechanical heart valves (MHVs) outperformed those of current clinical prosthetic SAVR valves. -Achieving the objective of an anticoagulation-free and durable MHV is directly related to mitigation of detrimental valve closing hydrodynamics and kinematics.  PERSPECTIVEImprovements in prosthetic valve performance and durability notwithstanding, the objective of an anti-coagulation free device with durability exceeding the projected life expectancy of all recipients has not been achieved. Our work identifies a design and development void that may have significantly delayed progress toward this objective.  SIGNIFICANCEOur results challenge a longstanding bias in valve design, shifting the focus towards crucial behavior during valve closure. This study paves the way for advanced mechanical valves bringing us closer to the elusive goal of anticoagulation-free performance--a long-awaited milestone in the evolution of prosthetic valves.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mosaic loss of chromosome Y characterizes late-onset rheumatoid arthritis and contrasting associations of polygenic risk score based on age at onset.\nAbstract: Objectivesmosaic chromosomal alterations (mCAs) increase with age and are associated with age-related diseases. The association between mCAs and rheumatoid arthritis (RA), particularly late-onset rheumatoid arthritis (LORA), has not been explored.  MethodsmCAs were detected in peripheral blood samples from two independent Japanese datasets (Set 1:2,107 RA cases and 86,998 controls; Set 2:2,359 RA cases and 86,998 controls). The associations between mCAs and RA were evaluated in each dataset using logistic regression models and meta-analysis. In each dataset, we evaluated the effect sizes of mosaic loss of Y (mLOY) and polygenic risk score (PRS) of RA in males and subsequently performed a meta-analysis. The interaction between mLOY and PRS was assessed. These models were applied separately to RA, LORA, and young-onset RA (YORA).  ResultsmLOY increased significantly in LORA (OR=1.43, P=0.0070). We observed a negative association between mLOY and YORA (OR=0.66, P=0.0034). On the other hand, we found consistently negative associations of autosomal mCAs or mosaic loss of X (mLOX) with RA, LORA, and YORA. The effect sizes of PRS were lower for LORA than for YORA. mLOY with a high cell fraction strengthened the association between PRS and LORA (P=0.0036), whereas the association with YORA was independent of mLOY.  ConclusionLORA was characterised by the presence of a high burden of mLOY. The observed interaction between mLOY and PRS in LORA, but not in YORA, supports different gene-environment interactions between the subsets. These data suggest that distinct pathophysiological mechanisms underlie the development of LORA and YORA.  Key messagesO_ST_ABSWhat is already known about this subject?C_ST_ABS{square} The prevalence of late-onset rheumatoid arthritis (LORA) in aging societies is increasing worldwide. {square}LORA has unique clinical characteristics, including higher prevalence in males, acute onset of the disease, and lower proportion of seropositivity compared with young-onset RA (YORA), suggesting distinct genetic and environmental components between the RA subsets. {square}Mosaic chromosomal alterations (mCAs) accumulate with age and are associated with age-related disorders. mCAs occur in both autosomes and sex chromosomes and would reflect the clonal expansion of dysregulated immune cells.   What does this study add?{square} Mosaic loss of Y (mLOY) is increased in male patients with LORA. {square}While mLOY is positively associated with LORA, mLOY is negatively associated with YORA. {square}The association of the RA-polygenic risk score (PRS) with LORA was more apparent in the presence of mLOY, while the association with YORA was independent of mLOY.   How might this impact clinical practice or future developments?{square} mLOY plays an acquired risk for RA in males by modifying the contribution of the genetic risk to RA development depending on age at onset. {square}Further investigation of the different effects of mLOY on LORA and YORA would lead to a better understanding of the pathological basis of RA influenced by aging and sex.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Utilizing AI-Generated Plain Language Summaries to Enhance Interdisciplinary Understanding of Ophthalmology Notes: A Randomized Trial\nAbstract: BackgroundSpecialized terminology employed by ophthalmologists creates a comprehension barrier for non-ophthalmology providers, compromising interdisciplinary communication and patient care. Current solutions such as manual note simplification are impractical or inadequate. Large language models (LLMs) present a potential low-burden approach to translating ophthalmology documentation into accessible language.  MethodsThis prospective, randomized trial evaluated the addition of LLM-generated plain language summaries (PLSs) to standard ophthalmology notes (SONs). Participants included non-ophthalmology providers and ophthalmologists. The study assessed: (1) non-ophthalmology providers comprehension and satisfaction with either the SON (control) or SON+PLS (intervention), (2) ophthalmologists evaluation of PLS accuracy, safety, and time burden, and (3) objective semantic and linguistic quality of PLSs.  Results85% of non-ophthalmology providers (n=362, 33% response rate) preferred the PLS to SON. Non-ophthalmology providers reported enhanced diagnostic understanding (p=0.012), increased note detail satisfaction (p<0.001), and improved explanation clarity (p<0.001) for notes containing a PLS. The addition of a PLS narrowed comprehension gaps between providers who were comfortable and uncomfortable with ophthalmology terminology at baseline (intergroup difference p<0.001 to p>0.05). PLS semantic analysis demonstrated high meaning preservation (BERTScore mean F1 score: 0.85) with greater readability (Flesch Reading Ease: 51.8 vs. 43.6, Flesch-Kincaid Grade Level: 10.7 vs. 11.9). Ophthalmologists (n=489, 84% response rate) reported high PLS accuracy (90% \"a great deal\") with minimal review time burden (94.9% [&le;] 1 minute). PLS error rate on initial ophthalmologist review and editing was 26%, and 15% on independent ophthalmologist over-read of edited PLSs. 84.9% of identified errors were deemed low risk for patient harm and 0% had a risk of severe harm/death.  ConclusionsLLM-generated plain language summaries enhance accessibility and utility of ophthalmology notes for non-ophthalmology providers while maintaining high semantic fidelity and improving readability. PLS error rates underscore the need for careful implementation and ongoing safety monitoring in clinical practice.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Barriers and Facilitators to Community Pharmacist-Provided Injectable Naltrexone for Formerly Incarcerated Individuals During Community Reentry in Wisconsin\nAbstract: Medications for opioid use disorder (MOUD), including injectable naltrexone, are a key component in the treatment of opioid use disorder (OUD). These medications are especially important for individuals transitioning out of correctional facilities and back into their communities, as individuals receiving MOUD are 85% less likely to die due to drug overdose in the first month post-release and have a 32% lower risk of rearrest. Unfortunately, few formerly incarcerated individuals have access to MOUD upon reentry, incurring a 40-fold greater likelihood of overdose following release compared to the general population. While 84% of Wisconsin jails offering MOUD offer naltrexone, less than half provide linkage to community treatment for reentering individuals. In Wisconsin, community pharmacists have the authority to provide naltrexone injections. However, they have not been explored as a resource for improving access to this medication for formerly incarcerated individuals. As a first step, the goal of this study was to understand the barriers and facilitators impacting access to community pharmacist-provided injectable naltrexone for this patient population during community reentry period. The researcher conducted semi-structured interviews with 18 individuals representing five stakeholder groups. Deductive and inductive content analysis were used to identify barrier and facilitator categories across the five levels of the Socioecological Model. Overall, participants discussed factors at every level, and many barriers and facilitators confirmed findings from existing literature focused on MOUD access for formerly incarcerated individuals. Participants also identified factors more specific to community pharmacies, including 1) lack of interagency collaboration between pharmacists, prescribers, and correctional facilities and 2) lack of awareness of community pharmacist-provided MOUD services. Future research should explore interventions to address the barriers identified in this study and improve connections between community pharmacists and formerly incarcerated individuals. This work can help ensure that these individuals are given the chance to successfully reintegrate into society.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Effectiveness of Nirsevimab in Reducing Pediatric RSV Hospitalizations\nAbstract: Background and objectiveRespiratory syncytial virus (RSV) is a major cause of hospitalization in infants. Nirsevimab has demonstrated to be a promise tool for preventing severe RSV disease. Although clinical trials have demonstrated the efficacy of Nirsevimab in preventing severe RSV disease, evidence regarding its performance in real-world clinical settings is still limited due to its recent introduction. This study aims to fill this knowledge gap by evaluating the impact of Nirsevimab in a cohort of infants and determining its effectiveness in reducing the burden of RSV disease.  Material and MethodsRetrospective study of RSV hospitalizations in children under six months of age, between October 1st and March 31st, across four seasons: pre-COVID (2018-2019), COVID (2019-2020), post-COVID pre-Nirsevimab (2022-2023), and Nirsevimab season (2023-2024).  ResultsNirsevimab has demonstrated significant efficacy in reducing RSV-related hospitalizations in infants under six months of age. During the 2023/24 season, following the introduction of Nirsevimab, there was a substantial reduction in RSV-related lower respiratory tract infection (LRTI) hospitalizations. Among infants under 3 months of age, hospitalizations decreased by 79.3% (IRR: 0.21, 95% CI: 0.12-0.34). In infants aged 3 to 6 months, there was a 66.9% reduction (IRR: 0.33, 95% CI: 0.15- 0.64). Additionally, Nirsevimab decreased the severity of RSV cases with LRTI who required support of equipment for sanitary use further reducing overall healthcare burden.  ConclusionThese results underscore Nirsevimabs vital role in preventing severe RSV infections and hospitalizations, especially among the most vulnerable infants, positioning it as a critical advancement in pediatric respiratory care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Effectiveness of Nirsevimab in Reducing Pediatric RSV Hospitalizations in Spain\nAbstract: Background and objectiveRespiratory syncytial virus (RSV) is a major cause of hospitalization in infants. Nirsevimab has demonstrated to be a promise tool for preventing severe RSV disease. Although clinical trials have demonstrated the efficacy of Nirsevimab in preventing severe RSV disease, evidence regarding its performance in real-world clinical settings is still limited due to its recent introduction. This study aims to fill this knowledge gap by evaluating the impact of Nirsevimab in a cohort of infants and determining its effectiveness in reducing the burden of RSV disease.  Material and MethodsRetrospective study of RSV hospitalizations in children under six months of age, between October 1st and March 31st, across four seasons: pre-COVID (2018-2019), COVID (2019-2020), post-COVID pre-Nirsevimab (2022-2023), and Nirsevimab season (2023-2024).  ResultsNirsevimab has demonstrated significant efficacy in reducing RSV-related hospitalizations in infants under six months of age. During the 2023/24 season, following the introduction of Nirsevimab, there was a substantial reduction in RSV-related lower respiratory tract infection (LRTI) hospitalizations. Among infants under 3 months of age, hospitalizations decreased by 79.3% (IRR: 0.21, 95% CI: 0.12-0.34). In infants aged 3 to 6 months, there was a 66.9% reduction (IRR: 0.33, 95% CI: 0.15- 0.64). Additionally, Nirsevimab decreased the severity of RSV cases with LRTI who required support of equipment for sanitary use further reducing overall healthcare burden.  ConclusionThese results underscore Nirsevimabs vital role in preventing severe RSV infections and hospitalizations, especially among the most vulnerable infants, positioning it as a critical advancement in pediatric respiratory care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neural emotion regulation during pregnancy - a fMRI study investigating a transdiagnostic mental health factor in healthy first-time pregnant women\nAbstract: Pregnancy is a psycho-neuro-endocrinological transition phase in which a plethora of hormone levels rise substantially, modulating socioemotional functions, brain structures, and networks and thus presenting a window of vulnerability for mental health. A transdiagnostic factor for psychopathology is emotion regulation, which is influenced by sex hormones, such as estradiol (E2), across the menstrual cycle on the behavioral and neural level. Whether this is also the case in the antepartum period remains unknown. For the first time, behavioral and neural emotion regulation were investigated in healthy primiparous pregnant females with extremely high E2 levels during the second trimester (N = 15) using a functional magnetic resonance imaging (fMRI) paradigm. Results were compared with naturally-cycling females with high E2 levels (after E2-administration, N = 16) and low E2 levels (early follicular phase, N = 16). Although pregnant females reported the lowest trait use of cognitive reappraisal, all females successfully regulated their emotions by applying cognitive reappraisal in the scanner. On the neural level, all females had increased activity in the left middle frontal gyrus during downregulation of negative emotions. Pregnant females showed no significant differences in functional connectivity (psychophysiological interaction, resting-state) related to emotion regulation compared to the nonpregnant group. However, group differences emerged for amygdala activation. In pregnant females, increased amygdala activity predicted reduced regulation success and was positively associated with depression scores. This first fMRI study during pregnancy indicates that depression scores are reflected in heightened amygdala activity already observable in the antepartum period. Thus, through its association with reduced regulation success, increased amygdala activity suggests a neural risk marker for peripartum mental health. Future research needs to investigate emotion regulation in pregnant and postpartum women to further understand pregnancy-related changes and associations of mood, emotional and neural functions. Eventually, this will allow enhanced identification, prevention, and treatment of peri- and postpartum mental ill-health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A multi-omics bidirectional mendelian randomization study and meta-analysis on the causal relationship between gut microbiota, inflammatory proteins, and fibromyalgia.\nAbstract: BackgroundFibromyalgia (FM) is a chronic disorder characterized by widespread pain and immune dysregulation. Emerging evidence suggests that gut microbiota and inflammatory proteins may contribute to the development of FM.  ObjectiveThe aim of this study was to investigate the causal relationships between gut microbiota, inflammatory proteins (cytokines/chemokines), and FM using bidirectional Mendelian randomization (MR) and meta-analysis approaches.  MethodsMR analyses were conducted using genetic data from European populations, employing methods such as MR-IVW, MR-Egger, and MR-weighted median. Reverse MR was also performed, with FM treated as the exposure. A meta-analysis was conducted to consolidate the findings.  ResultsRuminococcus gauvreauii was identified as a risk factor for FM, while Enterorhabdus, Parabacteroides, Butyricicoccus, and Prevotella 9 were found to be protective. Five inflammatory proteins--C-X-C motif chemokine 5 (CXCL5), S100-A12, Leukemia inhibitory factor receptor (LIFR), Monocyte chemoattractant protein 2 (MCP-2/CCL8), and Tumor necrosis factor (TNF-)--exhibited protective associations, while Natural killer cell receptor 2B4 (NKCR-2B4/CD244) and Interleukin-12 subunit beta (IL-12{beta}) were associated with an increased risk of FM.  ConclusionThis study highlights the role of gut microbiota and inflammatory proteins (cytokines/chemokines) in the pathogenesis of FM. Through Gene Ontology (GO) functional enrichment and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analyses, the findings suggest their involvement in immune regulation, inflammatory responses, and viral pathways. These findings provide new insights into potential therapeutic targets for modulating gut health and immune responses, opening new avenues for future research and clinical interventions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Conspiratorial thinking in a 50-state survey of American adults\nAbstract: BackgroundWhile the NIMH Research Domain Criteria framework stresses understanding how neuropsychiatric phenotypes vary across populations, little is known outside of small clinical cohorts about conspiratorial thoughts as an aspect of cognition.  MethodsWe conducted a 50-state non-probability internet survey conducted in 6 waves between October 6, 2022 and January 29, 2024, with respondents age 18 and older. Respondents completed the American Conspiratorial Thinking Scale (ACTS) and the 9-item Patient Health Questionnaire (PHQ-9). Survey-weighted regression models were used to examine sociodemographic and clinical associations with ACTS score, and associations with vaccination status.  ResultsAcross the 6 survey waves, there were 123,781 unique individuals. After reweighting, a total of 78.6% of respondents somewhat or strongly agreed with at least one conspiratorial idea; 19.0% agreed with all four of them. More conspiratorial thoughts were reported among those age 25 - 54, males, individuals who finished high school but did not start or complete college, those with household income between $25,000 and $50,000 per year, and those who reside in rural areas, as well as those with greater levels of depressive symptoms. Endorsing more conspiratorial thoughts was associated with a significantly lower likelihood of being vaccinated against COVID-19.  DiscussionA substantial proportion of US adults endorsed at least some conspiratorial thinking, which varied widely across population subgroups. The extent of correlation with non-vaccination suggests the importance of considering such thinking in designing public health strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: High power transient 15-29Hz beta event features as early biomarkers of Alzheimer's Disease conversion: a MEG study\nAbstract: A typical pattern observed in M/EEG recordings of Mild Cognitive Impairment (MCI) patients progressing to Alzheimers disease is a continuous slowing of brain oscillatory activity. Definitions of oscillatory slowing are imprecise, as they average across time and frequency bands, masking the finer structure in the signal and potential reliable biomarkers of the disease.  Recent studies show that high averaged band power can result from transient increases in power, termed  events or  bursts. To better understand MEG oscillatory slowing in AD progression, we analyzed features of high-power oscillatory events and their relationship to cognitive decline. MEG resting-state oscillations were registered in age-matched patients with MCI who later convert (CONV, N=41) or do not convert (NOCONV, N=44) to AD, in a period of 2.5 years. To distinguish future CONV from NOCONV, we characterised the rate, duration, frequency span and power of transient high-power events in the alpha and beta band in anterior cingulate (ACC) and precuneus (PC).  Results revealed event-like patterns in resting-state power in both the alpha and beta-bands, how-ever only beta-band features were predictive of conversion to AD, particularly in PC. Specifically, compared to NOCONV, CONV had a lower number of beta events, along with lower power events and a trend toward shorter duration events in PC (p < 0.05). Beta event durations were also significantly shorter in ACC (p < 0.01). Further, this reduced expression of beta events in CONV predicted lower values of mean relative beta power, increased probability of AD conversion, and poorer cognitive performance.  Our work paves the way for reinterpreting M/EEG slowing and examining beta event features as a new biomarker along the AD continuum, and a potential link to theories of inhibitory cognitive control in neurodegeneration. These results may bring us closer to understanding the neural mechanisms of the disease that help guide new therapies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cross-Sectional Analysis of the Association Between Abnormal Immune Responses in the Pathogenesis of Postpartum Cardiomyopathy in Ethiopian Women: A Hospital-based Study at Saint Paul Hospital\nAbstract: 1.0BackgroundPostpartum cardiomyopathy (PPCM) is a condition that is characterized by the weakening of heart muscles which is known as left ventricular dysfunction and occurs during the later stages of pregnancy or during the early stages of postpartum.  ObjectiveTo evaluate the role of abnormal immune responses and risk factors such as advanced age, high parity, and presence of gestational diabetes in the pathogenesis of PPCM in Ethiopia.  MethodA cross-sectional hospital-based study was conducted at Saint Paul Millennium Medical College (SPMCC) between January 2021 and January 2023. All female pregnant patients who were attending the Maternal Care Fetal Unit, Antenatal Unit, and High-Risk Unit at SPMMC were included in this study. However, among those patients, those mothers younger than 20 years old and older than 40 years old were excluded from the study. The total sample size collected from this facility was 250 patients.  ResultsOxidative stress and inflammation were primarily correlated with pre-eclampsia and gestational diabetes. These risk factors were particularly prevalent within patients diagnosed with PPCM, 52.8% and 40% respectively. Prolactin Cleavage and Microvascular Dysfunction was associated with higher BMI and advanced age. With a general increasing trend observed in PPCM incidence and advancing age. As well as a high prevalence rate of PPCM in patients with Obesity Class I (at 33.0%). Another notable risk factor was high parity ( 45.0% with 4+ prior pregnancies). The most common symptom presented was dyspnea at 35.0%. The mortality rate was 14% whilst recurrence and the fully recovered ratio were at 13.1% and 34.0%, respectively.  ConclusionResults aligned with those conducted in other African countries (e.g. Zambia and South Africa) however mitigating high mortality as well as low full recovery rate will need to be done by earlier diagnosis, effective treatment, and intervention mechanisms. A different study design will need to be conducted (over a longer time period) to support and make findings more holistic.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The VIPR-1 trial (Visualizing Ischemia in the Pancreatic Remnant) - Assessing the role of intraoperative indocyanine green perfusion of the transected pancreas in predicting postoperative pancreatic leaks: protocol for a prospective phase II trial.\nAbstract: Surgery of the pancreas has come a long way since its inception; however, postoperative morbidity is still high. Pancreatic leaks and fistulas are common complications in patients undergoing surgery to remove the pancreas. Fistulas delay subsequent oncological care after surgery and prolong the hospital stay. Hypoperfusion to the pancreas has been characterized as one factor leading to fistulas. Indocyanine green (ICG) injection allows the surgeon to evaluate blood perfusion to tissue in real-time. This protocol describes a trial that aims to assess the effectiveness of intraoperative ICG metrics of the cut edge of the pancreas to predict postoperative fistulas. A single group will participate in an observational, surgeon-blinded, phase II trial. ICG measurements of the cut edge of the pancreas will be recorded before reconstruction. International Study Group on Pancreatic Surgery criteria for pancreatic fistula will be used to define leaks and fistulas. The primary outcome will be the correlation between ICG measurements and the development or absence of fistula formation. Currently, limited objective intraoperative predictors exist for predicting postoperative fistulas. Having a reliable predictive tool could decrease the healthcare burden posed by fistulas. The findings of this trial will provide conclusions on the usefulness of ICG measurements in predicting postoperative pancreatic fistulas and leaks. This clinical trial is registered in ClinicalTrials.gov with the ID NCT06084013. The current protocol version is v1.0.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Altered Cytokine Profile in Clinically Suspected Seronegative Autoimmune Associated Epilepsy\nAbstract: Background and ObjectivesAutoimmune-associated epilepsy (AAE), a condition which responds favorably to immune therapies but not traditional anti-seizure interventions, is emerging as a significant contributor to cases of drug-resistant epilepsy. Current standards for the diagnosis of AAE rely on screening for known neuronal autoantibodies in patient serum or cerebrospinal fluid. However, this diagnostic method fails to capture a subset of drug-resistant epilepsy patients with suspected AAE who respond to immunotherapy yet remain seronegative (snAAE) for known autoantibodies.  MethodsTo identify potential biomarkers for snAAE, we evaluated the most comprehensive panel of assayed cytokines and autoantibodies to date, comparing patients with snAAE, anti-seizure medication (ASM) responsive epilepsy, and patients with other neuroinflammatory diseases.  ResultsWe found a unique signature of 14 cytokines significantly elevated in snAAE patients including: GM-CSF, MCP-2/CCL8, MIP-1a/CCL3, IL-1RA, IL-6, IL-8, IL-9, IL-10, IL-15, IL-20, VEGF-A, TNF-b, LIF, and TSLP. Based on prior literature, we highlight IL-6, IL-8, IL-10, IL-13, VEGF-A, and TNF-b as potentially actionable cytokine biomarkers for snAAE, which could be of diagnostic utility in clinical evaluations of snAAE patients. Autoantibody-ome screening failed to identify autoantibodies targeting neuronal channel proteins in snAAE patients. Interestingly, ASM-responsive epilepsy patients displayed elevations in the proportion of autoantibodies targeting brain plasma membrane proteins, possibly pointing to the presence of immune hyperactivity/dysfunction despite well-controlled seizure activity and suggesting ASM-responsive patients may experience disease progression independent of seizure activity (PISA).  DiscussionOverall, our findings suggest that simply expanding existing autoantibody screens may not sufficiently enhance diagnostic power for snAAE. Instead, we propose that cytokine analysis may serve as a promising diagnostic avenue for identifying immune dysregulation in AAE patients and enabling opportunities for trials of immunotherapies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-center improvement in screening for dystonia in young people with cerebral palsy\nAbstract: Background and ObjectivesDystonia is a common, debilitating, and often treatment refractory motor symptom of cerebral palsy (CP), affecting 70-80% of this population based on research assessments. However, routine clinical evaluation for dystonia in CP has failed to match these expected numbers. Addressing this diagnostic gap is a medical imperative because the presence of dystonia rules in or out certain treatments for motor symptoms in CP. Therefore, our objective was to optimize rates of clinical dystonia screening to improve rates of clinical dystonia diagnosis.  MethodsUsing the quality improvement (QI) infrastructure of the Cerebral Palsy Research Network (CPRN), we developed and implemented interventions to increase the documentation percentage of five features of dystonia in young people with CP, aged 3-21 years old. This QI initiative was implemented by seven physiatry and pediatric movement disorders physicians at four tertiary-care pediatric hospitals between 10/10/21 and 7/1/23. We collected visit data cross-sectionally across all participating sites every 2 weeks and tracked our progress using control charts.  ResultsWe assessed 847 unique visits, mostly for established patients (719/847, 85%) who were 9.2 years old on average (95% CI 8.8-9.5). By 4/10/22, the mean percentage of dystonia screening elements documented across all sites rose from 39% to 90% and the mean percentage of visits explicitly documenting the presence or absence of dystonia rose from 65% to 94%. By 10/23/22, the percentage of visits diagnosing dystonia rose from 57% to 74%. These increases were all sustained through the end of the study period in 7/1/23.  DiscussionUsing a rigorous QI-driven process across four member sites of a North American learning health network (CPRN), we demonstrated that we could increase screening for dystonia and that this was associated with increased clinical dystonia diagnosis, matching expected research-based rates. We propose that similar screening should take place across all sites caring for people with CP.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Predicting cancer patient mortality within 30 days of radiotherapy consultation to inform palliative radiotherapy fractionation decisions\nAbstract: BackgroundRadiation and medical oncologists evaluate patients risk of imminent mortality with scales like Karnofsky Performance Status (KPS) and predicate treatment decisions on these evaluations. However, we hypothesized that statistical models derived from structured electronic health record (EHR) data could predict patient deaths within 30 days of radiotherapy consultation better than models developed only with patient age and physician-reported KPS.  MethodsClinical data from patients who consulted in a radiotherapy department from June 2018 - February 2024 were abstracted from EHR databases, including patient demographics, laboratory results, medications, comorbidities, KPS, cancer stages, oncologic treatment histories, oncologist notes, radiologist reports, and pathologist narratives. A subset of structured features known or believed to be associated with mortality were curated and used to train and test logistic regression, random forest, and gradient-boosted decision classifiers.  ResultsOf 38,262 patients, 951 (2.5%) died within 30 days of radiotherapy consultation. From 34.5 gigabytes of tabular data, 2,977 clinical features were chosen or derived by a radiation oncologist, then reduced to 1,000 features using ANOVA F values. Using an event probability classification threshold of 0.2, optimized logistic regression, random forest, and gradient-boosted decision classifiers tested with high accuracy (0.97, 0.98, and 0.98, respectively) and F1 scores (0.50, 0.54, and 0.52). The areas under receiver operating and precision-recall curves for the random forest model were respectively 0.94 and 0.55, which outperformed a model trained only with patient age and KPS (0.61 and 0.06). Models prominently weighed features that were rationally associated with mortality.  ConclusionStatistical models developed from a physician-curated feature space of structured EHR data predicted patient deaths within 30 days of radiotherapy consultation better than a model developed only with a patients age and physician-assessed KPS. With clinically explicable feature weights, these models could influence treatment decisions such as the length of palliative radiotherapy courses.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prediction of the ectasia screening index from raw Casia2 volume data for keratoconus identification by using convolutional neural networks\nAbstract: PurposePrediction of Ectasia Screening Index (ESI), an estimator provided by the Casia2 for identifying keratoconus, from raw Optical Coherence Tomography (OCT) data with Convolutional Neural Networks (CNN).  MethodsThree CNN architectures (ResNet18, DenseNet121 and EfficientNetB0) were employed to predict the ESI. Mean Absolute Error (MAE) was used as the performance metric for predicting the ESI by the adapted CNN models on the test set. Scans with an ESI value higher than a certain threshold were classified as Keratoconus, while the remaining scans were classified as Not Keratoconus. The models performance was evaluated using metrics such as accuracy, sensitivity, specificity, Positive Predictive Value (PPV) and F1 score on data collected from patients examined at the eye clinic of the Homburg University Hospital. The raw data from the Casia2 device, in 3dv format, was converted into 16 images per examination of one eye. For the training, validation and testing phases, 3689, 1050 and 1078 scans (3dv files) were selected, respectively.  ResultsIn the prediction of the ESI, the MAE values for the adapted ResNet18, DenseNet121 and EfficientNetB0, rounded to two decimal places, were 7.15, 6.64 and 5.86, respectively. In the classification task, the three networks yielded an accuracy of 94.80%, 95.27% and 95.83%, respectively; a sensitivity of 92.07%, 94.64% and 94.17%, respectively; a specificity of 96.61%, 95.69% and 96.92%, respectively; a PPV of 94.72%, 93.55% and 95.28%, respectively; and a F1 score of 93.38%, 94.09% and 94.72%, respectively.  ConclusionsOur results show that the prediction of keratokonus based on the ESI values estimated from raw data outperforms previous approaches using processed data. Adapted EfficientNetB0 outperformed both the other adapted models and those in state-of-the-art studies, with the highest accuracy and F1 score.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: APOE4 and Infectious Diseases Jointly Contribute to Brain Glucose Hypometabolism, a Biomarker of Alzheimers Pathology: New findings from the ADNI\nAbstract: Background Impaired brain glucose metabolism is a preclinical feature of neurodegenerative diseases such as Alzheimers disease (AD). Infections may promote AD-related pathology. Therefore, we investigated the interplay between infections and APOE4, a strong genetic risk factor for AD. Methods We analyzed data on 1,509 participants in the Alzheimers Disease Neuroimaging Initiative (ADNI) database using multivariate linear regression models. The outcomes were rank-normalized hypometabolic convergence index (HCI), statistical regions of interest (SROI) for AD, and mild cognitive impairment (MCI). Marginal mean estimates for infections, stratified by APOE4 carrier status, were then computed. Results Prior infections were associated with greater HCI [beta=0.15, 95% CI: 0.03, 0.27, p=0.01]. The combined effects of infections and APOE4 carriers on HCI levels were significantly greater than either variable alone. Among APOE4 carriers, the estimated marginal mean was 0.62, rising to 0.77, with infections (p<0.001), indicating an interaction effect. Carriers with multiple infections showed greater hypometabolism (higher HCI), with an estimate of 0.44 (p=0.01) compared to 0.11 (p=0.08) for those with a single infection, revealing a dose-response relationship. The estimates for the association of infections with SROI AD and SROI MCI were beta=-0.01 (p=0.02) and beta=-0.01 (p=0.04), respectively. Conclusion Our findings suggest that infections and APOE4 jointly contribute to brain glucose hypometabolism and AD pathology, supporting a multi-hit mechanism in AD development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: APOE4 and Infectious Diseases Jointly Contribute to Brain Glucose Hypometabolism, a Biomarker of Alzheimers Pathology: New findings from the ADNI\nAbstract: Background Impaired brain glucose metabolism is a preclinical feature of neurodegenerative diseases such as Alzheimers disease (AD). Infections may promote AD-related pathology. Therefore, we investigated the interplay between infections and APOE4, a strong genetic risk factor for AD. Methods We analyzed data on 1,509 participants in the Alzheimers Disease Neuroimaging Initiative (ADNI) database using multivariate linear regression models. The outcomes were rank-normalized hypometabolic convergence index (HCI), statistical regions of interest (SROI) for AD, and mild cognitive impairment (MCI). Marginal mean estimates for infections, stratified by APOE4 carrier status, were then computed. Results Prior infections were associated with greater HCI [beta=0.15, 95% CI: 0.03, 0.27, p=0.01]. The combined effects of infections and APOE4 carriers on HCI levels were significantly greater than either variable alone. Among APOE4 carriers, the estimated marginal mean was 0.62, rising to 0.77, with infections (p<0.001), indicating an interaction effect. Carriers with multiple infections showed greater hypometabolism (higher HCI), with an estimate of 0.44 (p=0.01) compared to 0.11 (p=0.08) for those with a single infection, revealing a dose-response relationship. The estimates for the association of infections with SROI AD and SROI MCI were beta=-0.01 (p=0.02) and beta=-0.01 (p=0.04), respectively. Conclusion Our findings suggest that infections and APOE4 jointly contribute to brain glucose hypometabolism and AD pathology, supporting a multi-hit mechanism in AD development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma glucosylceramide levels are regulated by ATP10D and are not involved in Parkinson's disease pathogenesis.\nAbstract: GBA1 variants and decreased glucocerebrosidase (GCase) activity are implicated in Parkinsons disease (PD). We investigated the hypothesis that increased levels of glucosylceramide (GlcCer), one of GCase main substrates, are involved in PD pathogenesis. Using multiple genetic methods, we show that ATP10D, not GBA1, is the main regulator of plasma GlcCer levels, yet it is not involved in PD pathogenesis. Plasma GlcCer levels were associated with PD, but not in a causative manner, and are not predictive of disease status. These results argue against targeting GlcCer in GBA1-PD and underscore the need to explore alternative mechanisms and biomarkers for PD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma glucosylceramide levels are regulated by ATP10D and are not involved in Parkinson's disease pathogenesis.\nAbstract: GBA1 variants and decreased glucocerebrosidase (GCase) activity are implicated in Parkinsons disease (PD). We investigated the hypothesis that increased levels of glucosylceramide (GlcCer), one of GCase main substrates, are involved in PD pathogenesis. Using multiple genetic methods, we show that ATP10D, not GBA1, is the main regulator of plasma GlcCer levels, yet it is not involved in PD pathogenesis. Plasma GlcCer levels were associated with PD, but not in a causative manner, and are not predictive of disease status. These results argue against targeting GlcCer in GBA1-PD and underscore the need to explore alternative mechanisms and biomarkers for PD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Generative AI and Large Language Models in Reducing Medication Related Harm and Adverse Drug Events - A Scoping Review\nAbstract: BackgroundMedication-related harm has a significant impact on global healthcare costs and patient outcomes, accounting for deaths in 4.3 per 1000 patients. Generative artificial intelligence (GenAI) has emerged as a promising tool in mitigating risks of medication-related harm. In particular, large language models (LLMs) and well-developed generative adversarial networks (GANs) showing promise for healthcare related tasks. This review aims to explore the scope and effectiveness of generative AI in reducing medication-related harm, identifying existing development and challenges in research.  MethodsWe searched for peer reviewed articles in PubMed, Web of Science, Embase, and Scopus for literature published from January 2012 to February 2024. We included studies focusing on the development or application of generative AI in mitigating risk for medication-related harm during the entire medication use process. We excluded studies using traditional AI methods only, those unrelated to healthcare settings, or concerning non-prescribed medication uses such as supplements. Extracted variables included study characteristics, AI model specifics and performance, application settings, and any patient outcome evaluated.  FindingsA total of 2203 articles were identified, and 14 met the criteria for inclusion into final review. We found that generative AI and large language models were used in a few key applications: drug-drug interaction identification and prediction; clinical decision support and pharmacovigilance. While the performance and utility of these models varied, they generally showed promise in areas like early identification and classification of adverse drug events and support in decision-making for medication management. However, no studies tested these models prospectively, suggesting a need for further investigation into the integration and real-world application of generative AI tools to improve patient safety and healthcare outcomes effectively.  InterpretationGenerative AI shows promise in mitigating medication-related harms, but there are gaps in research rigor and ethical considerations. Future research should focus on creation of high-quality, task-specific benchmarking datasets for medication safety and real-world implementation outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A case is not a case is not a case - challenges and solutions in determining urolithiasis caseloads using the digital infrastructure of a clinical data warehouse\nAbstract: BackgroundTo provide more evidence in urolithiasis research, we have established the German Nationwide Register for RECurrent URolithiasis (RECUR) using local clinical data warehouses (CDWH). For RECUR and other registers relying on digitalized clinical data, it is crucial to ensure the datas reliability for answering scientific questions. In this work, we aim to compare the results of different CDWH-based queries on urolithiasis cases next to manual case extraction from the primary source.  MethodsSources for data extraction included the Medical Center University of Freiburg (MCUF) hospital information system (HIS), MCUF performance data (a clinical data set with merged data from patients including data from vari-ous time points throughout their treatment), and MCUF reimbursement data. We extracted data on caseloads in urolithiasis algorithmically (performance and reimbursement data) and compared those to a reference group compiled of man-ually extracted data from the local HIS and algorithmically extracted data.  ResultsAlgorithmic extraction based on performance data resulted in correct and complete case identification as compared to the reference group. The case numbers from manual extraction from HIS data and algorithmic extraction from reimbursement data differed by 14% and 12%, respectively. The reasons for devi-ations in HIS data included human errors and a lack of data availability from different wards. Deviations in reimbursement data arose primarily due to the merging of cases in the context of reimbursement mechanisms. As the CDWH at MCUF is part of the German Medical Informatics Initiative (MII), the results can be transferred to other medical centers with similar CDWH structure.  ConclusionsThe current study provides firm evidence of the importance of clearly defining a studys target variable, e.g., urolithiasis cases, and a thorough understanding of the data sources and modes used to extract the target data. Our work clearly shows that, depending on various data sources, a case is not a case is not a case.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A case is not a case is not a case - challenges and solutions in determining urolithiasis caseloads using the digital infrastructure of a clinical data warehouse\nAbstract: BackgroundTo provide more evidence in urolithiasis research, we have established the German Nationwide Register for RECurrent URolithiasis (RECUR) using local clinical data warehouses (CDWH). For RECUR and other registers relying on digitalized clinical data, it is crucial to ensure the datas reliability for answering scientific questions. In this work, we aim to compare the results of different CDWH-based queries on urolithiasis cases next to manual case extraction from the primary source.  MethodsSources for data extraction included the Medical Center University of Freiburg (MCUF) hospital information system (HIS), MCUF performance data (a clinical data set with merged data from patients including data from vari-ous time points throughout their treatment), and MCUF reimbursement data. We extracted data on caseloads in urolithiasis algorithmically (performance and reimbursement data) and compared those to a reference group compiled of man-ually extracted data from the local HIS and algorithmically extracted data.  ResultsAlgorithmic extraction based on performance data resulted in correct and complete case identification as compared to the reference group. The case numbers from manual extraction from HIS data and algorithmic extraction from reimbursement data differed by 14% and 12%, respectively. The reasons for devi-ations in HIS data included human errors and a lack of data availability from different wards. Deviations in reimbursement data arose primarily due to the merging of cases in the context of reimbursement mechanisms. As the CDWH at MCUF is part of the German Medical Informatics Initiative (MII), the results can be transferred to other medical centers with similar CDWH structure.  ConclusionsThe current study provides firm evidence of the importance of clearly defining a studys target variable, e.g., urolithiasis cases, and a thorough understanding of the data sources and modes used to extract the target data. Our work clearly shows that, depending on various data sources, a case is not a case is not a case.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Breast Cancer Genetic Testing Experience: Probing the Potential Utility of an Online Decision Aid in Risk Perception and Decision Making\nAbstract: BackgroundDespite the role of pathogenic variants (PVs) in cancer predisposition genes conferring significantly increased risk of breast cancer (BC), uptake of genetic testing (GT) remains low, especially among ethnic minorities. Our prior study identified that a patient decision aid, RealRisks, improved patient-reported outcomes relative to standard educational materials. This study examined patients GT experience and its influence on subsequent actions. We also sought to identify areas for improvement in RealRisks that would expand its focus from improved GT decision-making to understanding results.  MethodsWomen enrolled in the parent randomized controlled trial were recruited and interviewed. Demographic data was collected from surveys in the parent study. Interviews were conducted, transcribed, and coded to identify recurring themes. Descriptive statistics were generated to compare the interviewed subgroup to the original study cohort of 187 women.  ResultsOf the 22 women interviewed, 11 (50%) had positive GT results, 2 (9.1%) with a BRCA1/2 PV, and 9 (40.9%) with variants of uncertain significance (VUS). Median age was 40.5 years and 15 (71.4%) identified as non-Hispanic. Twenty (90.9%) reported a family history of BC, and 2 (9.1%) reported a family history of BRCA1/2 PV. The emerging themes included a preference for structured communication of GT results and the need for more actionable knowledge to mitigate BC risk, especially among patients with VUS or negative results. Few patients reported lifestyle changes following the return of their results, although they did understand that their behaviors can impact their BC risk.  ConclusionsPatients preferred a structured explanation of their GT results to facilitate a more personal testing experience. While most did not change lifestyle behaviors in response to their GT results, there was a consistent call for further guidance following the initial discussion of GT results. Empowering patients, especially those with negative or VUS results, with the knowledge and context to internalize the implications of their results and form accurate risk perception represents a powerful opportunity to mediate subsequent risk management strategies. Informed by this study, future work will expand RealRisks to foster an accurate perception of GT results and include decision support to navigate concrete next steps.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Accuracy of Online Symptom-Assessment Applications, Large Language Models, and Laypeople for Self-Triage Decisions: A Systematic Review\nAbstract: Symptom-Assessment Application (SAAs, e.g., NHS 111 online) that assist medical laypeople in deciding if and where to seek care (self-triage) are gaining popularity and their accuracy has been examined in numerous studies. With the public release of Large Language Models (LLMs, e.g., ChatGPT), their use in such decision-making processes is growing as well. However, there is currently no comprehensive evidence synthesis for LLMs, and no review has contextualized the accuracy of SAAs and LLMs relative to the accuracy of their users. Thus, this systematic review evaluates the self-triage accuracy of both SAAs and LLMs and compares them to the accuracy of medical laypeople. A total of 1549 studies were screened, with 19 included in the final analysis. The self-triage accuracy of SAAs was found to be moderate but highly variable (11.5 - 90.0%), while the accuracy of LLMs (57.8 - 76.0%) and laypeople (47.3 - 62.4%) was moderate with low variability. Despite some published recommendations to standardize evaluation methodologies, there remains considerable heterogeneity among studies. The use of SAAs should not be universally recommended or discouraged; rather, their utility should be assessed based on the specific use case and tool under consideration.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Machine Learning Insights into HLA Noncoding Sequence Mismatches and Their Impact on DPB1 Matching in Hematopoietic Cell Transplantation\nAbstract: PurposeHCT is vital for treating hematological malignancies, relying on HLA matching between unrelated patient-donor pairs to significantly reduce adverse outcomes. Recent studies recognize the potential impact of HLA-DPB1 mismatches on HCT outcomes. Multiple approaches focus on finding better-tolerated HLA-DPB1 mismatches. Additionally, recent studies suggest matching at noncoding HLA sequence may improve HCT outcomes. This study aims to evaluate different approaches for categorizing DPB1 mismatches in patient-donor pairs and explore the potential impact of noncoding mismatches (available in class I HLA genes) on clinical outcomes.  MethodsA retrospective study of 5,106 HCT pairs using Cox proportional hazards models, weighted by a machine learning algorithm, evaluates the impact of particular combinations of HLA-DPB1 mismatches in the context of noncoding HLA class I mismatches on outcomes of HCT. HLA-DPB1 mismatch criteria included T-cell epitope permissive/non-permissive mismatches, expression markers, and evolutionary clade mismatches.  ResultsTwo HLA-DPB1 mismatches, using multiple criteria, lead to significant hazards of acute graft versus host disease grades 2-4, in the T cell replete group. When HLA-DPB1 mismatches occurred across evolutionary clades (DP2 allele/low-expression patient vs DP5 allele/high-expression in the donor), the deplete group showed significant hazards for treatment-related mortality (TRM) (HR=1.94, p-value=8.9x10-7) and overall survival (OS) (HR=1.67, p-value=1.3x10-5) for additive effects of noncoding mismatches with two HLA-DPB1 mismatches.  ConclusionTwo HLA-DPB1 mismatches remain to predict worse outcomes. However, noncoding mismatches in HLA class I genes confer elevated hazards of TRM and OS in conjunction with mismatches across evolutionary branches of HLA-DPB1. Therefore, noncoding mismatches may inform donor selection in the presence of HLA-DPB1 mismatches and improve HCT outcomes, emphasizing the utility of comprehensive sequencing of HLA alleles in HCT settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparing the test performance of dried-blood-spot and plasma HIV recent infection testing samples in a nationally scaled sex worker programme in Zimbabwe\nAbstract: Recency testing can provide strategic insights as to whether a person newly diagnosed with HIV recently acquired their infection or not. To understand potential biases associated with HIV recency testing, we explored the extent sample type influences whether a person is assigned as being recent. Implementing a laboratory-based Recent Infection Testing Algorithm (RITA) across the Centre for Sexual Health and HIV/AIDS Research (CeSHHAR) key populations programme in Zimbabwe between October 2021 and January 2023, we compared plasma-based and dried-bloodspot (DBS) HIV recency samples. Over the study period, 24,976 individual female sex workers HIV tested, of whom 9.5% (2,363/24,979) newly tested HIV positive. Of these 2,363 women, 55.5% (1311/2,363) were offered and gave consent for a sample to be taken for DBS recency and viral load testing, among whom 11.7% (153/1,311) were classified as having a recent infection. A subset of 464 women were offered and consented to paired sample collection, among whom 10.1% (47) and 12.3% (57) of plasma and DBS samples, respectively, were classified as recent. Overall, categorical determination was good, with 97% of results concordant. Of 58 women with paired sample collection who had a test result classified as recent, 46 (79.3%) were concordant recent on both DBS and plasma, with 12 (20.7%) being dis-concordant. Of these 12 womens samples, 11 were deemed long-standing by the plasma assay but recent by the paired DBS, and one deemed long-standing by DBS but recent by the paired plasma sample. Depending on use-case and setting, there are trade-offs when considering DBS or plasma-based samples between test performance and ease of implementation. Our data can help inform statistical adjustments to harmonise cut-offs on DBS and plasma assays, thereby improving the use and interpretation of recency assays in population-level HIV surveillance activities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Lipoprotein (a) is associated with increased risk of Abdominal Aortic Aneurysm\nAbstract: IntroductionLipoprotein(a) (Lp(a)) is a circulating apolipoprotein B (ApoB) containing particle that has been observationally linked to atherosclerotic cardiovascular disease and is the target of emerging therapeutics. Recent work has highlighted the role of circulating lipoproteins in abdominal aortic aneurysm (AAA). We sought to triangulate human observational and genetic evidence to evaluate the role of Lp(a) in AAA.  MethodsWe tested the association between circulating levels of Lp(a) and clinically diagnosed abdominal aortic aneurysms while controlling for traditional AAA risk factors and levels of ApoB using logistic regression among 795 individuals with and 374,772 individuals without AAA in the UK Biobank (UKB). Multivariable Mendelian randomization (MVMR) was used to test for putatively causal associations between Lp(a) and AAA controlling for ApoB. Genetic instruments for Lp(a) and ApoB were created from genome-wide association studies (GWAS) of Lp(a) and ApoB comprising 335,796 and 418,505 UKB participants, respectively. The instruments were tested for association with AAA using data from a GWAS of 39,221 individuals with and 1,086,107 without AAA.  ResultsElevated Lp(a) levels were observationally associated with an increased risk of AAA (OR 1.04 per 10 nmol/L Lp(a); 95%CI 1.02-1.05; P<0.01). Clinically elevated Lp(a) levels (>150nmol/L) were likewise associated with an increased risk of AAA (OR 1.47; 95% CI 1.15-1.88; P < 0.01) when compared to individuals with Lp(a) levels <150nmol/L. MVMR confirmed a significant, ApoB-independent association between increased Lp(a) and increased risk of AAA (OR 1.13 per SD increase in Lp(a); 95%CI 1.02-1.24; P<0.02).  ConclusionBoth observational and genetic analyses support an association between increased Lp(a) and AAA risk that is independent of ApoB. These findings suggest that Lp(a) may be a therapeutic target for AAA and drive the inclusion of AAA as an outcome in clinical trials of Lp(a) antagonists.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Donor HLA class 1 evolutionary divergence and late allograft rejection after liver transplantation in children: an emulated target trial.\nAbstract: HLA evolutionary divergence (HED), a continuous metric quantifying the differences between each amino acid of two homologous HLA alleles, reflects the importance of the immunopeptidome presented to T lymphocytes. It has been associated with rejection after liver transplantation. This retrospective cohort study aimed to analyze the potential effect of donor or recipient HED on liver transplant rejection in a new series of patients transplanted during childhood and followed in adulthood. The study included 120 children who had been transplanted between 1991 and 2010 and were followed by routine biopsies and histological evaluations with a median of 14.1 years post-LT. Liver biopsies were performed routinely 1, 5, 10 and 20 years after transplantation and in the event of liver dysfunction. HED was calculated using the physicochemical Grantham distance for donor and recipient class I (HLA-A, -B, -C) and class II (HLA-DRB1, -DQB1) alleles. The influence of HED on rejection was analyzed using IPW and target trial emulation using the g method. Based on the IPW score, donor HED class I was correlated with the occurrence of late (>90 days) rejection (HR, 1.19, 95% CI: 1.01-1.40) independently of HLA mismatches, donor age and initial induction. This emulated target trial confirmed that donor HED class I has a causal effect on liver graft rejection and this relationship was observed long-term.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal changes in epigenetic clocks predict survival in the InCHIANTI cohort\nAbstract: AbstractsO_ST_ABSImportanceC_ST_ABSCross-sectional assessment of epigenetic clocks provides information on the pace of aging. Whether longitudinal acceleration or deceleration of epigenetic clocks over time provides additional mortality prediction is unknown.  ObjectiveTo test the independent associations of baseline levels and longitudinal changes in epigenetic clocks with mortality  DesignLongitudinal study  SettingInCHIANTI, a population-based study of community dwelling individuals in Tuscany, Italy.  Participants699 InCHIANTI study participants aged 21-95 years at baseline with longitudinal measurements of DNA methylation.  ExposureBaseline levels and longitudinal changes in seven epigenetic clocks, including two first-generation clocks developed using chronological age for reference (Hannum Clock, Horvath Clock), three second-generation clocks developed using time-to-death for references (DNAmPhenoAge, DNAmGrimAge, DNAmGrimAge Version 2), and two third-generation clocks developed using longitudinal rate of change of multiple phenotypes for reference (DunedinPOAm_38, DunedinPACE).  Main Outcomes and MeasuresMortality was the primary outcome. Cox regression was used to estimate independent associations of baseline and longitudinal changes in epigenetic clocks with mortality.  ResultsAdjusting for age, sex, study sites, and epigenetic clock at the baseline, longitudinal changes of the following epigenetic clocks were associated with mortality: Hannum clock (aHR = 1.14, 95% CI:[1.03, 1.26]), DNAmPhenoAge (aHR = 1.23, 95% CI: [1.10,1.37]), DNAmGrimAge (aHR = 1.13, 95% CI: [1.02,1.26]), DNAmGrimAge Version 2 (aHR = 1.18, 95% CI:[1.06,1.31]), and DunedinPOAm_38 (aHR = 1.15, 95%CI: [1.01,1.30]).  Conclusions and RelevanceOur findings confirm that epigenetic clocks capture a dimension of health that is predictive of mortality and add the notion that time changes of epigenetic age reflect changes in health that additionally and independently contribute to mortality prediction. Future studies should test whether interventions that slow down the rate of epigenetic aging are associated with longer healthspan and lifespan.  Key PointsQuestion: Is the rate of change in epigenetic clock associated with differential mortality?  Findings: In 699 adults with followed for up to 24 years, faster longitudinal changes in epigenetic clocks (Hannum clock, DNAmPhenoAge, DNAmGrimAge, DNAmGrimAge version 2, DunedinPOAm_38, DunedinPACE) were significantly associated with higher mortality, independent of baseline epigenetic age and other confounders.  Meaning: Independent of chronological age, epigenetic clock and change over time of epigenetic clock independently predicted the risk of death. Interventions that slow down the pace of epigenetic aging may enhance healthy longevity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human genetic evidence to inform clinical development of interleukin-6 signaling inhibition for abdominal aortic aneurysm\nAbstract: BackgroundAbdominal aortic aneurysm (AAA) represents a significant cause of mortality, yet no medical therapies have proven efficacious. The aim of the current study was to leverage human genetic evidence to inform clinical development of interleukin-6 (IL6) signaling inhibition for treatment of AAA.  MethodsWe focused on rs2228145, a missense variant in the IL6R gene region whose associations are expressed per additional copy of the C allele, corresponding to the genetically-predicted effect of IL6 signaling inhibition. We consider genetic associations with AAA risk in the AAAgen consortium (39,221 cases, 1,086,107 controls) and UK Biobank (2215 cases, 365,428 controls). To validate against known effects of IL6 signaling inhibition, we present associations with rheumatoid arthritis, polymyalgia rheumatica, and severe COVID-19. To explore mechanism specificity, we present associations with thoracic aortic aneurysm, intracranial aneurysm, and coronary artery disease. We further evaluated associations with measures of the abdominal aorta in UK Biobank, and explored genetic associations in clinically-relevant subgroups of the population.  ResultsWe observed strong genetic associations with AAA risk in the AAAgen consortium and in UK Biobank: odds ratio (OR) 0.91 (95% confidence interval [CI]: 0.90 to 0.92, p = 4x10-30) and OR 0.90 (95% CI: 0.84, 0.96, p=0.0007), respectively. The association with AAA risk in UK Biobank was linear in the number of minor alleles: OR 0.91 (95% CI: 0.83, 1.00) in heterozygotes and OR 0.80 (95% CI: 0.71, 0.92) in minor homozygotes. The association was similar for fatal AAA, but with greater uncertainty due to the lower number of events. The association with AAA was of greater magnitude than associations with coronary artery disease and even rheumatologic disorders for which IL6 inhibitors have been approved. No strong associations were observed with thoracic aortic aneurysm, intracranial aneurysm, or abdominal aorta diameter in the general population without AAA. Associations attenuated towards the null in populations with concomitant inflammatory or connective tissue disease.  ConclusionsThis drug target Mendelian randomization study supports that IL6 signaling inhibition will be efficacious for treating AAA, but not other types of aneurysmal disease. These findings serve to help inform clinical development of IL6 signaling inhibition for AAA treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Circulating Biomarkers as Predictors of Improvement in Physical Function in Hospitalized Older Adults with Geriatric Syndromes: Findings from the REHAB-HF Trial\nAbstract: IntroductionCirculating biomarkers play an important role in patients with heart failure (HF) for risk stratification and mechanistic insights. We aimed to examine if a diverse set of biomarkers in the REHAB-HF trial would predict improvement in physical function following a 12-week tailored physical therapy rehabilitation intervention compared to attention control.  MethodsThe study population consisted of participants [&ge;]60 years of age who were hospitalized with acute HF and randomized to a subsequent multidomain outpatient physical rehabilitation intervention vs. attention control with outcomes of 12-week functional change including the Short Physical Performance Battery (SPPB) and six-minute walk distance (6MWD). Blood was collected prior to randomization and at 12-weeks for cardiac, renal, and inflammatory biomarkers. Linear trends across progressively higher biomarker values versus improvement in functional outcomes based on treatment assignment were evaluated. Classification and regression trees (CART) were created to estimate optimal biomarker levels associated with differential improvement in the two functional outcomes.  ResultsA total of 242 of 349 participants (69%) had baseline biomarkers measured. In an adjusted regression model, higher baseline cardiac troponin (cTn) I and T were associated with greater gains in SPPB and 6MWD respectively with the rehabilitation intervention (P=0.04 and 0.03 for interaction) versus attention control. In the CART analysis of the physical rehabilitation and attention control participants, those with baseline C-reactive protein (CRP) [&ge;]9.9 mg/L and hs-cTnT [&ge;]36 ng/L receiving the rehabilitation intervention had a 129 m (95% CI 78-180m) greater 12-week 6MWD increase vs attention control. In contrast, for participants with CRP<9.9 mg/L there was no significant incremental 6MWD difference (30m, 95% CI -0.5m, 60.2m). For SPPB, a CRP [&ge;]9.9 mg/L and creatinine [&ge;]1.4 mg/dL optimally identified a differential improvement with the rehabilitation intervention versus attention control. The biomarkers (except for creatinine) decreased by 12 weeks post hospitalization but with no differences based on treatment assignment.  ConclusionHigher baseline levels of biomarkers of inflammation, cardiac injury, and renal dysfunction identified older adults after a HF hospitalization with the greatest differential improvement in physical function with a rehabilitation intervention. Biomarkers may help clinicians predict the benefits of this treatment.  (Funded by the National Institutes of Health and others; REHAB-HF ClinicalTrials.gov number, NCT02196038).\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Primary Care Physicians' Practices and Barriers in Evaluating and Managing Chronic Kidney Disease in New Providence, The Bahamas\nAbstract: ObjectivesTo assess the practices and barriers in evaluating and managing chronic kidney disease among primary care physicians in New Providence, The Bahamas.  MethodsA cross-sectional study utilizing an anonymous, self-administered questionnaire was given to General Practitioners, Family Medicine, and Internal Medicine physicians after using a simple random sampling approach. Descriptive and inferential statistical analysis was conducted using IBM SPSS software.  ResultsThere were 119 physicians in this study with Family Medicine specialty area representing 52.1%. Seventy-four (74) physicians reported following CKD guidelines. The most common at-risk groups identified were Diabetes Mellitus (100%), Hypertension (98.3%), and use of nephrotoxic agents (97.5%). The most common diagnostic test used to identify CKD was eGFR (97.5%) and 72.2% of physicians used eGFR alone to stage CKD. Physicians overall agreed (40.3 - 50.4%) they were comfortable in diagnosing and managing CKD and its complications except for bone disorders (43.2%) and metabolic acidosis (34.7%) where responses were neutral. Physicians were neutral in having tools/resources to help them manage bone disorders (35.3%) and metabolic acidosis (31.9%) and disagreed to having educational tools for patients to understand bone disorders (32.2%) and metabolic acidosis (32.8%). Physicians agreed-strongly agreed with 12 of 13 perceived barriers, and there were 26 unique barriers expressed (8 patient-level, 7 provider-level, 11 systems-level).  ConclusionsDeficits in the evaluation and management of CKD, and numerous barriers to CKD care were discovered. Recommendations include the development of a national CKD guideline, local CKD continuous medical education seminars, and public health campaigns on CKD education.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Covidization and decovidization of the scientific literature and scientific workforce\nAbstract: We examined the growth trajectory and impact of COVID-19-related papers in the scientific literature until August 1, 2024 and how the scientific workforce was engaged in this work. Scopus indexed 718,660 COVID-19-related publications. As proportion of all indexed scientific publications, COVID-19-related publications peaked in September 2021 (4.7%) remained at 4.3-4.6% for another year and then gradually declined, but was still 1.9% in July 2024). COVID-19-related publications included 1,978,612 unique authors: 1,127,215 authors had [&ge;]5 full papers in their career and 53,418 authors were in the top-2% of their scientific subfield based on a career-long composite citation indicator. Authors with >10%, >30% and >50% of their total career citations be to COVID-19-related publications were 376,942, 201,702, and 125,523, respectively. As of August 1, 2024, 65 of the top-100 most-cited papers published in 2020 were COVID-19-related, declining to 24/100, 19/100, 7/100, and 5/100 for the most-cited papers published in 2021, 2022, 2023, and 2024, respectively. Across 174 scientific subfields, 132 had [&ge;]10% of their active influential (top-2% by composite citation indicator) authors publish something on COVID-19 during 2020-2024. Among the 300 authors with highest composite citation indicator specifically for their COVID-19-related publications, 41 were editors or journalists/columnists and another 23 had most of their COVID-19 citations to published items other than full papers (opinion pieces/letters/notes). COVID-19 massively engaged the scientific workforce in unprecedented ways. As the pandemic ended, there has been a sharp decline in the overall volume and high impact of newly published COVID-19-related publications.  Significance statementCOVID-19 massively mobilized the scientific workforce. Between 2020 and 2024, over 700,000 papers were published on COVID-19, including 2 million different authors. Across science, almost a third of authors at the top-2% of citation impact in their subfield published on COVID-19. There was a sharp decline in the proportion of COVID-19 papers across science after 2022 and an even more sharp decline in the proportion of COVID-19 papers reaching the highest level of citations. Authors with the highest COVID-19 citation impact prominently included many who were editors, journalists/columnists and opinion writers publishing massively. While other epidemics also witnessed sharp increases and subsequent decline in interest, the magnitude of the covidization and decovidization process is unique in the scientific literature to-date.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Normal feeding movements expressed by dimensionality reduction of whole-body joint motions using principal component analysis\nAbstract: Understanding elementary feeding movements and postures is essential for improving assessment and intervention strategies in occupational therapy, particularly for individuals with eating difficulties, and for educating caregivers and students; however, current assessment tools lack precision in evaluating complex feeding movements and often rely on subjective judgments rather than objective measures. We aimed to determine elementary movements and postures corresponding to different feeding phases using principal component analysis (PCA). This cross-sectional observational study was conducted at a Local National University Hospital and included 45 healthy, right-handed adult volunteers (23 men and 22 women) aged 20-39 years (mean age, 27.3 years), with no neurological or musculoskeletal impairments. Movements during yogurt feeding using a spoon were captured with a three-dimensional inertial sensor motion capture system. Principal components (PCs) and their scores were derived from PCA of whole-body joint motion data across four feeding phases. PC scores were compared between phases using Friedmans and post-hoc tests. The primary PC, representing whole-body movement, accounted for 50.0% of the variance; the second PC, associated with hand direction changes, accounted for 13.7%. The cumulative variance of the first six PCs was 87.4%, including individual body-part movements and fixations or combinations of these. Significant differences existed between feeding phases, particularly in the reaching and transport phases, which showed greater whole-body movement than that during the spooning and mouth phases. Hand direction changes were more prominent during the spooning phase than during the mouth phase. PCA helped determine key elementary movements and their corresponding feeding phases, which can be used to assess patients with feeding difficulties and guide occupational therapy interventions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Knowledge and experiences of adolescent girls and young women in the use of sexual reproductive health and HIV services at health facilities in Maputo City, Mozambique\nAbstract: BackgroundKnowledge and use of sexual reproductive health and human immunodeficiency virus (SRH and HIV) services are crucial for the prevention of pregnancy and sexually transmitted infections (STIs) among adolescent girls and young women (AGYW). This study aims to assess the knowledge and perceptions of AGYW about the SRH and HIV services offered in health facilities in Maputo, Mozambique.  Material and methodsA cross-sectional descriptive study was conducted based on exit surveys with AGYW held at Zimpeto and 1{degrees} de Junho Health Facilities in Maputo City, between May 1, and June 9, 2023. Data were analyzed through descriptive statistics, t-test and ANOVA, using SPSS version 20.  Results590 AGYW, aged 15-24 years of age, were included in the study. In general, knowledge of SRH and HIV services was fairly high, with knowledge of each specific service offered ranging between 38% and 97%. Knowledge about SRH and HIV services differed depending on the health facility where the AGYW sought SRH and HIV services; the participants age; their occupation; their religion, and who they lived with. Counseling services were the most commonly reported services attended, with >90% of participants reporting having received counseling for each of the following: STI and HIV and pregnancy prevention, sexuality, and safer sex practices. The quality of SRH and HIV services, and attitudes of the providers were considered good by >90% of AGYW. Roughly 95% of AGYW at Zimpeto Health Facility were either \"satisfied\" or \"very satisfied\". Whereas at 1{degrees} de Junho Health Facility, only roughly 75% of AGYW were either \"satisfied\" or \"very satisfied\", and roughly 20% of AGYW were \"little satisfied that their needs had been met that day.  ConclusionsAmong AGYW there is high levels of knowledge about counseling services in contrast to diagnostics, treatment and clinical care. Specific attention should be given to ensuring appropriate physical infrastructure, such as dedicated adolescent friendly spaces and comfortable seating, and targeted interventions designed and implemented for those health facilitiess identified. Targeted interventions should be designed and implemented for those HFs identified with lower AGYW perceived quality of service delivery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Relationship Between Electrodermal Activity and Cardiac Troponin in Patients with Paroxysmal Sympathetic Hyperactivity\nAbstract: ObjectiveTo determine the relationship between electrodermal activity (EDA) and cardiac troponin in patients with paroxysmal sympathetic hyperactivity (PSH).  MethodsThis was a study with prospectively-identified patients and a retrospective analysis utilizing electrodermal data taken from the wrist-worn Empatica E4 device (Empatica Srl, Milan, Italy) and troponin values obtained from critically-ill patients with suspected PSH (N=10). The maximum EDA value and temporally-nearest cardiac troponin were correlated to test for significance using Pearson correlation coefficient.  ResultsA moderate correlation was found between EDA and troponin in 10 patients using the most temporally-proximal troponin to each patients maximal EDA (r=0.634; p = 0.049). A subanalysis was performed excluding any patients whose available troponin data did not fall within seven days of their maximal EDA, which demonstrated a strong correlation (r=0.943; p = 0.005). No relationships between troponin and pulse, blood pressure, or temperature were found.  ConclusionsThis study establishes an association between wrist-worn EDA and a measure of possible myocardial injury in critically ill patients with PSH. Patients with elevated sympathetic activity may be at increased risk for concurrent cardiac injury or dysfunction, and thus EDA data from wrist-worn monitors may provide clinically significant data regarding sympathetic function.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Do editorial board members publish in their own journal? Review of editorial board members as authors in the main foot and ankle journals\nAbstract: BackgroundScientific publications by editorial board members in their own journals raise questions about potential biases in the peer-review process. This study investigates the prevalence of self-publishing in high-impact factor foot and ankle focused journals.  MethodsA review was performed of the highest impact factor foot and ankle focused journals/: Foot and Ankle International, Foot and Ankle Surgery y Journal of Foot and Ankle Surgery. In January 2023, the editorial board members were identified, and their names, roles, academic backgrounds, and regions were obtained. For each board member, the number of total published articles listed in PubMed and those for each corresponding journal over their entire history, during the last 5 years and during the last 3 years were compiled. Descriptive statistics analyses were performed using IBM SPSS Statistics v26.0.  ResultsThe study included 196 editorial board members from the 3 selected journals. Editorial board members have published 1694 articles in their own journals (9.17% of all the articles published in those 3 journals). Editorial board members published 23.4% (SD 23.6) of their overall production in their affiliated journals. Of that production, 39.0% (SD 38.6) have been published in the last 5 years, considering this 5-year period as the baseline for their role on the editorial board in question. Some 10% of editorial board members have published more than 50% of their scientific production in their own affiliated journal in the last 5 years. European editors (51%) have published more in their own journal over the last 5-year period than North Americans (29%) (p<0.001). Being a surgeon is related to greater publication rates in ones own affiliated journal when compared to other specialist profiles (p=0.003).  ConclusionThe publication scientific articles by editorial board members as authors in journals with which they are affiliated is a present-day phenomenon in the highest impact factor journals with a focus on the foot & ankle. Knowledge of this data could be the key to understanding the prevalence of this phenomenon, and lead to making this data more accessible.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A plasma proteomic signature for atherosclerotic cardiovascular disease risk prediction in the UK Biobank cohort\nAbstract: BackgroundWhile risk stratification for atherosclerotic cardiovascular disease (ASCVD) is essential for primary prevention, current clinical risk algorithms demonstrate variability and leave room for further improvement. The plasma proteome holds promise as a future diagnostic and prognostic tool that can accurately reflect complex human traits and disease processes. We assessed the ability of plasma proteins to predict ASCVD.  MethodClinical, genetic, and high-throughput plasma proteomic data were analyzed for association with ASCVD in a cohort of 41,650 UK Biobank participants. Selected features for analysis included clinical variables such as a UK-based cardiovascular clinical risk score (QRISK3) and lipid levels, 36 polygenic risk scores (PRSs), and Olink protein expression data of 2,920 proteins. We used least absolute shrinkage and selection operator (LASSO) regression to select features and compared area under the curve (AUC) statistics between data types. Randomized LASSO regression with a stability selection algorithm identified a smaller set of more robustly associated proteins. The benefit of plasma proteins over standard clinical variables, the QRISK3 score, and PRSs was evaluated through the derivation of {Delta} AUC values. We also assessed the incremental gain in model performance using proteomic datasets with varying numbers of proteins. To identify potential causal proteins for ASCVD, we conducted a two-sample Mendelian randomization (MR) analysis.  ResultThe mean age of our cohort was 56.0 years, 60.3% were female, and 9.8% developed incident ASCVD over a median follow-up of 6.9 years. A protein-only LASSO model selected 294 proteins and returned an AUC of 0.723 (95% CI 0.708-0.737). A clinical variable and PRS-only LASSO model selected 4 clinical variables and 20 PRSs and achieved an AUC of 0.726 (95% CI 0.712-0.741). The addition of the full proteomic dataset to clinical variables and PRSs resulted in a {Delta} AUC of 0.010 (95% CI 0.003-0.018). Fifteen proteins selected by a stability selection algorithm offered improvement in ASCVD prediction over the QRISK3 risk score [{Delta} AUC: 0.013 (95% CI 0.005-0.021)]. Filtered and clustered versions of the full proteomic dataset (consisting of 600-1,500 proteins) performed comparably to the full dataset for ASCVD prediction. Using MR, we identified 11 proteins as potentially causal for ASCVD.  ConclusionA plasma proteomic signature performs well for incident ASCVD prediction but only modestly improves prediction over clinical and genetic factors. Further studies are warranted to better elucidate the clinical utility of this signature in predicting the risk of ASCVD over the standard practice of using the QRISK3 score.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma proteomic signatures for type 2 diabetes mellitus and related traits in the UK Biobank cohort\nAbstract: Aims/hypothesisThe plasma proteome holds promise as a diagnostic and prognostic tool that can accurately reflect complex human traits and disease processes. We assessed the ability of plasma proteins to predict type 2 diabetes mellitus (T2DM) and related traits.  MethodsClinical, genetic, and high-throughput proteomic data from three subcohorts of UK Biobank participants were analyzed for association with dual-energy x-ray absorptiometry (DXA) derived truncal fat (in the adiposity subcohort), estimated maximum oxygen consumption (VO2max) (in the fitness subcohort), and incident T2DM (in the T2DM subcohort). We used least absolute shrinkage and selection operator (LASSO) regression to assess the relative ability of non-proteomic and proteomic variables to associate with each trait by comparing variance explained (R2) and area under the curve (AUC) statistics between data types. Stability selection with randomized LASSO regression identified the most robustly associated proteins for each trait. The benefit of proteomic signatures (PSs) over QDiabetes, a T2DM clinical risk score, was evaluated through the derivation of delta ({Delta}) AUC values. We also assessed the incremental gain in model performance metrics using proteomic datasets with varying numbers of proteins. A series of two-sample Mendelian randomization (MR) analyses were conducted to identify potentially causal proteins for adiposity, fitness, and T2DM.  ResultsAcross all three subcohorts, the mean age was 56.7 years and 54.9% were female. In the T2DM subcohort, 5.8% developed incident T2DM over a median follow-up of 7.6 years. LASSO-derived PSs increased the R2 of truncal fat and VO2max over clinical and genetic factors by 0.074 and 0.057, respectively. We observed a similar improvement in T2DM prediction over the QDiabetes score [{Delta} AUC: 0.016 (95% CI 0.008, 0.024)] when using a robust PS derived strictly from the T2DM outcome versus a model further augmented with non-overlapping proteins associated with adiposity and fitness. A small number of proteins (29 for truncal adiposity, 18 for VO2max, and 26 for T2DM) identified by stability selection algorithms offered most of the improvement in prediction of each outcome. Filtered and clustered versions of the full proteomic dataset supplied by the UK Biobank (ranging between 600-1,500 proteins) performed comparably to the full dataset for T2DM prediction. Using MR, we identified 4 proteins as potentially causal for adiposity, 1 as potentially causal for fitness, and 4 as potentially causal for T2DM.  Conclusions/InterpretationPlasma PSs modestly improve the prediction of incident T2DM over that possible with clinical and genetic factors. Further studies are warranted to better elucidate the clinical utility of these signatures in predicting the risk of T2DM over the standard practice of using the QDiabetes score. Candidate causally associated proteins identified through MR deserve further study as potential novel therapeutic targets for T2DM.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Improving Access and Efficiency of Acute Ischemic Stroke Treatment Across Four Canadian Provinces: A Stepped-Wedge Trial\nAbstract: BackgroundAn evidence-to-practice gap exists in acute ischemic stroke treatment, and improvements in access and efficiency of treatment with iv thrombolysis and endovascular thrombectomy (EVT) is needed. The objective of this study was to improve access and efficiency of ischemic stroke treatment across four Atlantic Canadian Provinces.  MethodsA stepped-wedge cluster trial was conducted over 30 months with 3 clusters covering 34 sites. The trial was conducted across all 4 Atlantic Canadian provinces: Nova Scotia (NS), New Brunswick (NB), Prince Edward Island (PE), and Newfoundland and Labrador (NL). The design was quasi-randomized, with each cluster associated with one or more provinces: cluster 1 - NS; cluster 2 - NB and PE; and cluster 3 - NL. The patient population was all ischemic stroke patients across all 4 provinces. The intervention was a 6-month modified Quality Improvement Collaborative (mQIC), which was modified from the Breakthrough Series Collaborative to be half of the 1-year period and conducted virtually. The intervention consisted of assembling an interdisciplinary improvement team, 2 full-day workshops, webinars, and virtual site visits. Suggested changes included 6 process improvement strategies.  ResultsThe proportion of patients that received treatment did not increase significantly with the intervention [0.4% increase for patients that received thrombolysis and/or EVT (p=0.68)]. Median door-to-needle time was reduced by 9.2 minutes with the intervention (p=0.01). Cluster 3 saw the greatest improvements in both access and efficiency.  ConclusionsA mQIC intervention resulted in improvement of process measures like door-to-needle time. Quality improvement initiatives may need to be longer to see improvements in proportion of patients treated. Tailored interventions for each health system can ensure that each system sees improvement. In-person activities might be critical to ensure fidelity of the intervention.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: I am a quarterback: A mixed methods study of death investigators' communication with family members of young sudden cardiac death victims from suspected heritable causes\nAbstract: BackgroundSudden cardiac death (SCD) is a devastating event and a leading cause of mortality, globally. In the young (2-45 years), SCD is often attributable to a heritable cardiac condition. Death investigators are often responsible for investigating the cause of death and communicating their results and risk of heritable cardiac conditions with family members of SCD victims. Family often struggles to comprehend the information that is communicated to them.  PurposeTo understand the delivery, reach and impact of communication strategies informing family members of SCD victims about their relatives cause of death and their own risk for heritable cardiac conditions.  MethodsWe conducted an explanatory sequential mixed methods study. We collected quantitative data via a web-based survey and qualitative data via telephone interviews to investigate how death investigators in Ontario and Nova Scotia, Canada, communicate with family members of SCD victims. We used descriptive statistics to analyze the survey data and thematic analysis to analyze the qualitative data. We triangulated data at multiple levels.  ResultsBetween October 2022 and July 2023, we surveyed 78 death investigators and interviewed a subset (n=20). Death investigators reported that SCDs due to suspected heritable cardiac conditions were more difficult (40%, n=31) or slightly more difficult (35%, n = 27) to investigate, often requiring a higher frequency of communication with families. Death investigators reported contacting family members via phone (n=75, 96.1%) and used various strategies to achieve their communication goals. Strategies were influenced by family characteristics; involvement of other professionals; characteristics of the investigation, access to resources, and system-level barriers.  ConclusionSCD investigations in the young due to suspected heritable cardiac conditions were more challenging and required a higher frequency of communication. Death investigators used various strategies to achieve their communication goals. Further research should examine how systematic changes can improve communication with family members.  What is Known?O_LISudden cardiac death (SCD) is a devastating and unexpected event that can be caused by heritable cardiac conditions, putting the decedents family at risk of SCD. C_LIO_LICommunication with death investigators and other health care professionals influences families experiences learning about the cause of death and about their risk for heritable cardiac condition. C_LI  What this Study AddsO_LIAccording to death investigators, SCD cases due to suspected heritable cardiac conditions are more difficult to investigate, require a higher frequency of communication with family members than other types of cases, and benefit from using different communication modalities. C_LIO_LIDespite their best intentions, death investigators are contending with many factors beyond their control that influence how communication with family members is carried out. C_LIO_LIProvincial death investigation systems alone do not currently provide families of SCD victims with sufficient communication, as families often seek external resources. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A GWAS of ACE Inhibitor-Induced Angioedema in a South African Population.\nAbstract: BackgroundAngiotensin-converting enzyme inhibitor-induced angioedema (AE-ACEI) is a life-threatening adverse event and, globally, the commonest cause of emergency presentations with angioedema. Several large genome-wide association studies (GWAS) have found genomic associations with AE-ACEI. However, despite African Americans having a 5-fold increased risk of AE-ACEI, there are no published GWAS from Africa. The aim of this study was to conduct a case-control GWAS of AE-ACEI in a South African population and perform a meta-analysis with an African American and European American population.  MethodsThe GWAS included 202 South African adults with a history of AE-ACEI and 513 controls without angioedema following angiotensin-converting enzyme inhibitor (ACEI) treatment for at least 2 years. A meta-analysis was conducted with GWAS summary statistics from an African American and European American cohort (from Vanderbilt/Marshfield with 174 cases and 489 controls).  ResultsNo SNPs attained genome-wide significance. However, 26 SNPs in the post-imputation standard GWAS of the South African cohort and 37 SNPs in the meta-analysis were associated to AE-ACEI with suggestive threshold(p-value<5.0x10-06). Some of these SNPs were found to be located close to the genes PRKCQ and RIMS1, previously linked with drug-induced angioedema, and also close to the CSMD1 gene linked to ACEI cough, providing replication at the gene level, but with novel lead SNPs.  ConclusionsOur results highlight the importance of African populations to detect novel variants in replication studies. Further increased sampling across the continent and matched functional work are needed to confirm the importance of genetic variation in understanding the biology of AE-ACEI.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: is metallic perception a taste, an aroma or a flavor?\nAbstract: AimMetallic taste is known to vanish with nasal occlusion, suggesting it should be termed metallic \"aroma\" rather than metallic \"taste.\" However, it also appears after neurological injuries, such as a chorda tympani section, which suppresses taste perception mediated by the facial nerve.  MethodsIn 120 healthy volunteers, the perception of an iron sulfate solution was assessed at different lingual locations--corresponding to the facial and glossopharyngeal nerves--and with either open (n=60) or closed (n=60) noses to evaluate if it is a taste or an aroma.  ResultsNasal occlusion significantly reduced the perception of iron sulfate. It prevented perception in 31.7% of participants, though it did not completely eliminate it in the remaining 68.3%. Additionally, in open-nosed subjects, the intensity of iron sulfate perception was significantly greater when applied to the base of the tongue (glossopharyngeal nerve) than to the tip (facial nerve). These differences did not persist with nasal occlusion.  ConclusionNasal occlusion diminished but did not abolish the perception of iron sulfate. With an open nose, a differential taste perception was significant, but not with a closed nose. Therefore, metallic perception involves both retro-olfactory and gustatory components, suggesting it is a metallic flavor.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diagnostic Validity of Drinking Behaviour for Identifying Alcohol Use Disorder: Findings from a Nationally Representative Sample of Community Adults and an Inpatient Clinical Sample\nAbstract: Background and AimsAlcohol consumption is an inherent feature of alcohol use disorder (AUD), and drinking characteristics may be diagnostically informative. This study had three aims: (1) to examine the classification accuracy of several drinking quantity/frequency indicators in a large representative sample of U.S. community adults; (2) to extend the findings to a clinical sample of adults; and (3) to examine potential sex differences.  DesignThis retrospective study utilized receiver operating characteristic (ROC) curves to evaluate area under the curve (AUC). Optimal cut-offs were identified using the Youden Index. Diagnostic validity was evaluated using accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV).  MeasurementsIndex tests included measures of quantity/frequency (e.g., drinks/drinking day, largest drinks/drinking day, number of drinking days, and heavy drinking frequency). The reference standard was AUD status as determined via a clinical interview (community sample) or a symptom checklist (clinical sample).  Setting and ParticipantsTwo samples were examined: A large, nationally representative random sample of U.S. community adults who reported past-year drinking (N=25,778, AUD=20%) and a consecutive drinking clinical sample from a Canadian mental health and addictions inpatient treatment centre (N=1,341, AUD=82%).  FindingsAll drinking indicators performed much better than chance at classifying AUD (AUCs=0.60-0.92, ps<.0001). Heavy drinking frequency indicators performed optimally in both the community (AUCs=0.78-0.87; accuracy=0.72-0.80) and clinical (AUC=0.85-0.92; accuracy =0.77-0.89) samples. Collectively, the most discriminating drinking behaviors were heavy drinking episodes and exceeding NIAAA drinking low-risk guidelines. No substantive sex differences in optimal cut-offs or variable performance were observed.  ConclusionsDrinking patterns performed well at classifying AUD in both a nationally representative and large inpatient sample, robustly identifying AUD at rates much better than chance and above accepted benchmarks, with limited differences by sex. Findings broadly support the potential utility of quantitative drinking indicators as being diagnostically informative in clinical settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Education as a Proxy for Cognitive Reserve: Moderating Effects on White Matter Hyperintensity Burden in Healthy Aging and Cognitive Decline\nAbstract: BackgroundCognitive reserve, often approximated by levels of education, is thought to protect against the deleterious effects of brain pathology on cognitive function. White matter hyperintensities (WMHs) are commonly associated with aging and cognitive decline, and higher WMH burden has been linked to the progression from healthy cognitive status (HC) to mild cognitive impairment (MCI). Understanding how cognitive reserve, as indicated by education, influences the relationship between WMH burden and cognitive outcomes can provide valuable insights for interventions aimed at delaying cognitive decline.  ObjectiveThis study investigates the moderating role of education, as a proxy for cognitive reserve, on the relationship between WMH burden and the transition from HC to MCI.  MethodsData were obtained from the Alzheimers Disease Neuroimaging Initiative (ADNI) database, focusing on participants classified as cognitively healthy at baseline. A total of 153 cognitively healthy adults at the baseline were split into two groups: one group (n=85) remained cognitively healthy for at least 7 years, while the other group (n=68) progressed to MCI within 7 years. A multiple linear regression model was used to examine the interaction between group membership, baseline age, education, and sex in predicting WMH loads. The primary focus was on the interaction between group membership and education to assess the protective effect of cognitive reserve.  ResultsThe regression model explained 18.5% of the variance in WMH load. The analysis revealed statistically significant interaction between group membership and education on WMH loads (Interaction term: {beta} = -0.097, p = 0.047), indicating that higher education levels are associated with a reduced WMH burden among individuals who progressed to MCI. The main effect of education alone was not significant, nor were the interactions involving sex (p > 0.05).  ConclusionThese findings support the hypothesis that education, as a proxy for cognitive reserve, provides a protective effect against the accumulation of WMH burden in older adults. The results suggest that higher cognitive reserve may mitigate the impact of neurodegenerative processes, thereby delaying the transition from HC to MCI. This underscores the importance of educational attainment in the preservation of cognitive health during aging.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Impact of Chlorinated Drinking Water Exposure on Gut Microbiota Development in Infants: a Randomised Controlled Trial.\nAbstract: BackgroundEarly gut microbiota disruptions can increase the risk for dysbiosis and predispose to chronic diseases. While chlorinated drinking water is generally considered safe, the antimicrobial effects of chlorine-based disinfectants may negatively impact the developing infant microbiota, which is particularly vulnerable during this critical period. This study investigates the specific effects of chlorinated water on the gut microbiome in infants.  MethodsThe waTer qUality and Microbiome Study (TUMS) is a double-blinded, randomized controlled trial (RCT). Six-month old infants (n=197) received either de-chlorinated drinking water (via benchtop filtration), or regular tap water for twelve months. Stool samples were collected at six-months (baseline) and at eighteen-months of age. Metagenomic sequencing was used for faecal microbiome analysis. Samples of participant tap water was also collected pre- and post-intervention.  ResultsParticipants were balanced for sex, delivery method, and breast-feeding status at time of recruitment between the control (n=98) and treatment (n=99) groups. We collected a total of 170 baseline stool samples (83 in the control group and 87 in the treatment group), and 130 follow-up stool samples (65 in the control group and 65 in the treatment group). Interindividual variation was higher at six-months compared to eighteen months. No significant differences in overall community structure (beta diversity (p=0.35), richness (p=0.98) or Shannon Index (p=0.45)) were found between treatment groups. However, 55 genera were differentially abundant at follow-up (adjusted p-value < 0.01), primarily within the Firmicutes phylum. Analysis of metabolic pathways revealed the chlorinated water group showed significantly higher abundance of antibiotic resistance genes mostly attributable to Escherichia and Klebsiella species.  ConclusionWater chlorination induces predominantly minor changes in infant gut microbiome composition; but appears to increase the abundance of antibiotic-resistant genes. While water chlorination remains a vital public health tool for ensuring safe drinking water, our findings underscore the need for continued research into the potential for increased antibiotic resistance and suggest there may be value in exploring alternative disinfectant strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mayo Normative Studies: regression-based normative data for remote self-administration of the Stricker Learning Span, Symbols Test and Mayo Test Drive Screening Battery Composite and validation in individuals with Mild Cognitive Impairment and dementia\nAbstract: ObjectiveFew normative data for unsupervised, remotely-administered computerized cognitive measures are available. We examined variables to include in normative models for Mayo Test Drive (a multi-device remote cognitive assessment platform) measures, developed normative data, and validated the norms.  Method1240 Cognitively Unimpaired (CU) adults ages 32-100-years (96% white) from the Mayo Clinic Study of Aging and Mayo Alzheimers Disease Research Center with Clinical Dementia Rating(R) of 0 were included. We converted raw scores to normalized scaled scores and derived regression-based normative data adjusting for age, age2, sex and education (base model); alternative norms are also provided (age+age2+sex; age+age2). We assessed additional terms using an a priori cut-off of 1% variance improvement above the base model. We examined low test performance rates (<-1 standard deviation) in independent validation samples (n=167 CU, n=64 mild cognitive impairment (MCI), n=14 dementia). Rates were significantly different when 95% confidence intervals (CI) did not include the expected 14.7% base rate.  ResultsNo model terms met the a priori cut-off beyond the base model, including device type, response input source (e.g., mouse, etc.) or session interference. Norms showed expected low performance rates in CU and greater rates of low performance in MCI and dementia in independent validation samples.  ConclusionTypical normative models appear appropriate for remote self-administered MTD measures and are sensitive to cognitive impairment. Device type and response input source did not explain enough variance for inclusion in normative models but are important for individual-level interpretation. Future work will increase inclusion of individuals from under-represented groups.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: EEG frontal alpha asymmetry mediates the association between maternal and child internalizing symptoms in childhood\nAbstract: BackgroundAnxiety and depression are highly prevalent in youth and can cause significant distress and functional impairment. The presence of maternal anxiety and depression are well-established risk factors for child internalizing psychopathology, yet the responsible mechanisms linking the two remain unclear.  MethodsWe examined the potential mediating and moderating roles of EEG frontal alpha asymmetry (FAA) in the intergenerational transmission of internalizing symptoms in a longitudinal sample of N = 323 mother-child dyads. Self-report maternal internalizing symptoms were evaluated at child age 3 years and 5 years, child EEG at 5 years, and parent-report child internalizing symptoms at age 7 years. Mediation was evaluated via bootstrapped (N = 5000) confidence intervals.  ResultsWe found significant associations among maternal internalizing (anxiety, depressive) symptoms at child ages 3 and 5 years, child FAA at age 5 years, and child internalizing symptoms at age 7 years. There was a significant mediation effect, whereby greater maternal anxiety and depressive symptoms at age 3 years were significantly associated with greater relative right FAA in children at age 5 years, which, in turn, was significantly associated with greater child internalizing symptoms at age 7 years (ps<.001). There was no moderating effect of FAA on the association between maternal internalizing symptoms at age 5 years and child internalizing symptoms at age 7 years.  ConclusionsGreater right frontal asymmetry may be a neurophysiological mechanism that mediates the intergenerational transmission of internalizing symptoms.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and real-world effectiveness of popular smoking cessation aids in England: a population-based study\nAbstract: ImportanceA wide range of medications, non-combustible nicotine products, behavioural support, and alternative treatments are available in England to help people stop smoking. Understanding their effectiveness in the real world can support informed decision-making.  ObjectivesTo provide up-to-date estimates of the prevalence and real-world effectiveness of different smoking cessation aids and explore moderation of effectiveness by socioeconomic position.  DesignPopulation-based survey, 2006-2024.  SettingEngland.  Participants25,094 adults ([&ge;]16y) who reported having tried to quit smoking in the past year.  Main outcomes and measuresThe outcome variable was self-reported continuous abstinence from the start of the most recent quit attempt up to the time of survey. Independent variables were use (yes/no) of the following aids in the most recent attempt: nicotine replacement therapy (NRT) obtained on prescription or over-the-counter; varenicline; bupropion; e-cigarettes; face-to-face behavioural support; telephone support; written self-help materials; websites; smartphone apps; hypnotherapy; Allen Carrs Easyway method; heated tobacco products (HTPs); nicotine pouches. Covariates included sociodemographic characteristics and features of the quit attempt.  ResultsWe analysed data from 25,094 participants (mean [SD] age = 38.7y [15.3]; 48.5% women). In 2023/24, the most used aids were e-cigarettes (40.2%) and over-the-counter NRT (17.3%); 40.8% of quit attempts were unaided. While e-cigarette use was associated with higher odds of abstinence after adjustment for use of other aids and covariates (OR=1.95 [1.74-2.17]), use of over-the-counter NRT was not (OR=1.03 [0.93-1.15]). Other aids positively associated with abstinence were websites (used by 4.6% in 2023/24; OR=1.43 [1.03-1.98]), prescription NRT (4.5%; OR=1.33 [1.12-1.58]), varenicline (1.1%; OR=1.80 [1.50-2.18]), and HTPs (0.7%; OR=2.37 [1.24-4.51]). Face-to-face behavioural support (used by 2.2% in 2023/24) was also associated with higher odds of abstinence among those from less advantaged (OR=1.59 [1.19-2.14]) but not more advantaged social grades (OR=0.91 [0.65-1.29]). There was not clear evidence of a benefit of any other aid, although some analyses were inconclusive.  Conclusions and relevanceA range of effective smoking cessation aids are available in England, but many people try to quit using less effective forms of support or none at all. Quit success rates could be improved by encouraging people to use more effective methods.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of air pollution from a landfill site with primary care consultation\nAbstract: BackgroundWaste landfill sites are associated with gaseous emissions and this air pollution can cause unpleasant smells (\"malodour\"). This causes concerns about its impact on the health of the local population. This study assessed change in general practice consultation behaviour during a period of increased complaints associated with air pollution at a UK landfill site.  MethodsThe study period was October 2020 to December 2021. The age-sex standardised prevalence and incidence of consultations for mental health, respiratory, and other symptoms hypothesised to be impacted by the air pollution issues were determined and compared between: i) 6 practices located close to the landfill site (zone A), ii) 6 practices located a mid-distance from the site (zone B), iii) 6 practices located further away and expected to have had less impact (zone C).  ResultsWhilst there was an increased consultation for mental health problems in practices nearest to the landfill site compared to those furthest away, consultation frequencies for respiratory and other potentially associated symptoms were lower and likelihood of consultation was consistently highest in practices located in zone B.  ConclusionThis study did not show clear evidence of an increase in recorded primary healthcare contacts for conditions and symptoms hypothesised to be connected to air pollution. It highlighted the challenges of examining the impact of air pollution on the health of local populations. Since this study focussed on coded consultations in primary care and not symptoms present in the general population, an impact on the health of individuals cannot be ruled out.  How this fits inO_LIAir pollution from waste landfill sites may impact on the health of the local population. C_LIO_LIWe did not find consistent evidence of increased healthcare consultations to general practices which were nearest to such pollution. C_LIO_LIThis study highlights the challenges in examining the impact of air pollution on health. C_LIO_LISymptoms may still be increased in the general population and an impact on the health of individuals cannot be ruled out. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: INCIDENCE OF BENIGN PROSTATIC HYPERPLASIA IN TESTICULAR CANCER SURVIVORS IN THE VETERANS AFFAIRS HEALTH SYSTEM\nAbstract: Testosterone and prostatic inflammation have been postulated to influence the development of benign prostatic hyperplasia (BPH). Our study aims to evaluate the incidence of BPH in Testicular Cancer (TCa) survivors, focusing on the impact of chemotherapy and post TCa diagnosed hypogonadism. We conducted a retrospective cohort analysis of US veterans diagnosed with TCa between 1990 to 2021, using the Veterans affairs database. BPH was defined using International Classification of Diseases (ICD) codes, Current Procedural Terminology (CPT) codes, or a 6-month prescription of medications. Associations with BPH were analysed, stratifying the cohort by receipt of chemotherapy and presence of hypogonadism. Multivariable cox regression models were used to determine statistical significance (p-value <0.05). Our cohort included 2038 TCa survivors with a median age at diagnosis of 41 years. On multivariable cox regression analysis, receipt of chemotherapy wasnt significantly associated with incidence of BPH (p-value= 0.13). When stratified by diagnosis of hypogonadism prior to BPH, no significant associations were found on univariable (p=0.81) as well as multivariable (p=0.65) analyses. In the multivariable model, age at diagnosis was significantly associated with an increased incidence of BPH (Hazard ratio: 1.06, p<0.001). Our findings demonstrate that age is a significant factor associated with development of BPH in this population, while suggesting that chemotherapy for TCa and hypogonadism might not substantially alter the development of BPH.  Patient summaryIn this study, we looked at whether testicular cancer survivors are more likely to develop an enlarged prostate (Benign Prostatic Hyperplasia), especially if they received chemotherapy or had low testosterone afterward. We found that age, rather than cancer treatment or testosterone levels, was the main factor linked to developing an enlarged prostate.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Barriers and facilitators for the implementation of wiki- and blog-based Virtual Learning Environments as tools for improving collaborative learning in the Bachelor of Nursing degree.\nAbstract: There is little research on teachers perceptions of the use of Virtual Learning Environments (VLEs) in undergraduate nursing education. The aim of this study was to understand teachers perceptions of the barriers and facilitators for the implementation of wiki- and blog-based VLEs as tools to improve collaborative learning.  A qualitative action-research study in an intentional opinion-intensity sample of teachers on the Bachelor of Nursing degree course was used. The data were collected and analysed according to the SWOT approach, the constant comparison method, and the coding process.  The analysis highlighted weaknesses (e.g., limited audio-visual communication and feedback, privacy concerns), threats (e.g., training, pre-planning, and time cost), strengths (e.g., being intuitive, friendly and accessible, creating shared knowledge) and opportunities (e.g., improving technological skills, teaching innovation, evaluation and peer learning) for the incorporation of VLEs to promote collaborative learning in nursing training.  Although both our study and the existing literature on the subject show many advantages that encourage the implementation of VLEs in nursing training, the barriers described in this paper cannot be ignored in the context in which the university currently finds itself.  These barriers and facilitators to implementing VLEs in nursing training will be of interest to educational authorities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Contraceptive Outcomes of the Natural Cycles Birth Control App: A Study of Canadian Women\nAbstract: ObjectiveThis study aimed to investigate the key demographics and evaluate the real-world contraceptive failure and continuation rates of the Natural Cycles app in a cohort of women from Canada.  MethodsThis was a real-world, prospective cohort study. Demographics were assessed via in-app questionnaires. Contraceptive failure rates in typical and perfect use were calculated using the 13-cycle cumulative pregnancy probability (Kaplan-Meier survival analysis) and the one-year Pearl Index (PI). One-year continuation rates were estimated through survival analysis.  ResultsThe study included 8  798 women who contributed an average of 9.2 months of data, amounting to a total of 7 063 woman-years of exposure. The average user was 27.3 years old, had a body mass index of 24.6, and reported being in a stable relationship. With typical use, the app demonstrated a 13-cycle cumulative pregnancy probability of 4.8 [95% CI: 4.3, 5.4] and a Pearl Index of 4.3 [95% CI: 3.9, 4.8]. Under perfect use, the contraceptive failure rate was 2.3 [95% CI: 0.7, 3.9] for life table analysis and 1.7 [95% CI: 0.5, 2.8] for the 1-year PI. The contraceptive methods continuation rate after one year was 62.4%.  ConclusionsThe data presented in this study offer valuable insights into the cohort of women using the Natural Cycles app in Canada and provide country-specific effectiveness estimates. The apps contraceptive effectiveness aligns with previously published data on Natural Cycles.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PSMA+ Extracellular Vesicles are a Biomarker for SABR in Oligorecurrent Prostate Cancer Analysis from the STOMP-like and ORIOLE trial cohorts\nAbstract: PurposeTwo randomized clinical trials (STOMP and ORIOLE) demonstrated that stereotactic ablative radiotherapy (SABR) can prolong ADT-free survival or progression-free survival (PFS) in patients with metachronous oligometastatic prostate cancer (omCSPC) patients. While most omCSPC patients have a more modest delay in progression, a small subset achieves a durable response following SABR. We investigated the prognostic and predictive value of circulating PSMA-positive extracellular vesicles (PSMA+EV) and prostate specific antigen (PSA) in a biomarker correlative study using blood samples from three independent patient cohorts.  MethodsPlasma samples from 46 patients on the ORIOLE trial and 127 patietns on the STOMP trial protocol with omCSPC patients treated with SABR. Pre-SABR PSMA+EV levels (EVs/ml) were measured by nanoscale flow cytometry. Kaplan-Meier curves and logistic regression models were used to determine the association of PSMA+EV and PSA levels with clinical outcomes.  ResultsIn the pooled cohorts, median bPFS were 26.1 and 15.0 months (p=0.005) and median rPFS were 36.0 and 25.0 months (p=0.003) for PSMA+EV low and high groups, respectively. The combination of pre-SABR low levels of both PSMA+EV and PSA was associated with lower risk of radiographic progression (HR=0.34, 95% CI: 0.18-0.58, p=0.0002). In the ORIOLE cohort, which included both a SABR arm and an observation arm, low PSMA+EV was predictive of benefit from SABR (p=0.012).  ConclusionsPSMA+EV is a novel prognostic and predictive biomarker of radiographically occult tumor burden in omCSPC. PSMA+EV may inform clinical decisions regarding which patients achieve a durable benefit from consolidative SABR alone.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deciphering the functional impact of Alzheimers Disease-associated variants in resting and proinflammatory immune cells\nAbstract: Genome-wide association studies have identified loci associated with Alzheimers Disease (AD), but identifying the exact causal variants and genes at each locus is challenging due to linkage disequilibrium and their largely non-coding nature. To address this, we performed a massively parallel reporter assay of 3,576 AD-associated variants in THP-1 macrophages in both resting and proinflammatory states and identified 47 expression-modulating variants (emVars). To understand the endogenous chromatin context of emVars, we built an activity-by-contact model using epigenomic maps of macrophage inflammation and inferred condition-specific enhancer-promoter pairs. Intersection of emVars with enhancer-promoter pairs and microglia expression quantitative trait loci allowed us to connect 39 emVars to 76 putative AD risk genes enriched for AD-associated molecular signatures. Overall, systematic characterization of AD-associated variants enhances our understanding of the regulatory mechanisms underlying AD pathogenesis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Linking the plasma proteome to genetics in individuals from continental Africa provides insights into type 2 diabetes pathogenesis\nAbstract: Individuals of African ancestry remain largely underrepresented in genetic and proteomic studies. Here, we measure the levels of 2,873 proteins using the Olink proximity extension assay in plasma samples from 163 individuals with type 2 diabetes (T2D) or prediabetes and 362 normoglycemic controls from the Ugandan population for the first time. We identify 88 differentially expressed proteins between the two groups and 208 proteins associated with cardiometabolic traits. We link genome-wide data to protein expression levels and construct the first protein quantitative trait locus (pQTL) map in this population. We identify 399 independent associations with 346 (86.7%) cis-pQTLs and 53 (13.3%) trans-pQTLs. 16.7% of the cis-pQTLs and all of the trans-pQTLs have not been previously reported in African-ancestry individuals. Of these, 37 pQTLs have not been previously reported in any population. We find evidence for colocalization between a pQTL for SIRPA and T2D genetic risk. Mendelian randomization analysis identified 20 proteins causally associated with T2D. Our findings reveal proteins causally implicated in the pathogenesis of T2D, which may be leveraged for personalized medicine tailored to African-ancestry individuals.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterizing the connection between Parkinson's disease progression and healthcare utilization\nAbstract: Background and ObjectivesParkinsons disease (PD) progression can be characterized in terms of healthcare utilization by analyzing clinical events across different stages of disease.  MethodsPD progression was measured by the Hoehn & Yahr (H&Y) clinical rating scale and clinical events at each stage were evaluated. Natural language processing and a large language model were used to extract H&Y values from real-world data enabling a larger cohort than manually collected studies, and multi-state hidden Markov models were used for H&Y progression likelihood.  ResultsWithin the one year, most patients in H&Y stages 2-5 remained in the same stage. Stage transitions, when they occurred, were most frequently to the next higher stage. Higher H&Y stages were associated with discharges into long term care and higher rates of additional clinical events.  ConclusionsStratifying key clinical events by H&Y score demonstrates the increases of health care utilization and economic burden with PD severity. Modelling the progression likelihood establishes a progression timeline and emphasizes the unmet need to identify treatment options that stop or slow these transitions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparing Client and Provider Preferences for HIV Care Coordination Program Features using Discrete Choice Experiments\nAbstract: IntroductionThe New York City (NYC) HIV Care Coordination Program (CCP) is designed to promote care engagement and treatment adherence among the people with HIV (PWH) who struggle the most with these key components of managing their health. We assessed preferences for CCP components among PWH enrolled in the program (\"clients\") and among providers of CCP services. In this report we compare the preferences between clients and providers, previously analyzed separately.  MethodsWe used a discrete choice experiment to assess preferences for four CCP features (\"attributes\"): Help with Adherence to Antiretroviral Therapy (ART), Help with Primary Care Appointments, Help with Issues other than Primary Care, and Where Program Visits Happen. Each of these attributes had three to four variants (\"levels\"). In the original surveys, levels within Where Program Visits Happen varied by participant type (client versus provider). We re-coded the levels by visit location (VL) or by travel time (TT) to make them comparable, and report results from both approaches. Preferences were quantified using the relative importance of the attributes and utility of the levels.  ResultsJanuary 2020 to March 2021, 152 providers and 181 clients completed the survey. In both the VL and TT analyses, clients were most influenced by Help with Adherence to ART, preferring medication reminders via phone or text, and Where Program Visits Happen, preferring visits via phone or video chat. In the VL analysis, providers were most influenced by Help with Adherence to ART, valuing directly observed therapy most highly, and Help with Issues other than Primary Care, valuing helping clients with connections to specialty medical care. In the TT analysis, providers were most influenced by Where Program Visits Happen, preferring to meet at clients homes, and Help with Issues other than Primary Care, again preferring helping clients make connections to specialty medical care.  ConclusionsClient and provider preferences clearly diverged with regard to CCP service intensity: in the aggregate, clients tended to prefer lower-intensity services, whereas providers endorsed higher-intensity services. These results highlight the importance of engaging clients as partners in decisions about program services so that they are aligned with client values.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Efficacy and Safety of Nicorandil for Prevention of Contrast-Induced Nephropathy in Patients Undergoing Coronary Procedures: A Systematic Review and Meta-Analysis\nAbstract: BackgroundContrast-induced nephropathy (CIN) is a potentially serious complication of intravenous or intra-arterial contrast administration during angiographic procedures that results in renal dysfunction. This meta-analysis assesses the efficacy and safety of nicorandil for the prevention of CIN in patients undergoing percutaneous coronary intervention (PCI) or coronary angiography (CAG).  MethodsCochrane Central Register of Controlled Trials, MEDLINE, Embase, and ClinicalTrials.gov were used to perform a thorough literature search from their inception to July 2024. A random-effects meta-analysis was performed on RevMan and pooled estimates were presented as forest plots. The Mantel-Haenszel method was used for dichotomous outcomes and risk ratios (RRs) were calculated along with 95% confidence intervals (95% CI).  ResultsThis meta-analysis included 12 RCTs consisting of 2787 participants (nicorandil: 1418, control: 1394). The use of nicorandil was protective against CIN (RR 0.38, 95% CI 0.29-0.50). The incidence of major adverse events was comparable in both groups (RR 0.77, 95% CI 0.52-1.13, p=0.18). Similarly, the use of nicorandil did not affect the risk of developing stroke (RR 1.05), myocardial infarction (RR 0.90), heart failure (RR 0.81), cardiac death (RR 0.90), and dialysis (RR 0.70).  ConclusionThis study revealed that nicorandil effectively reduced the risk of developing CIN in patients undergoing angiographic procedures like PCI or coronary angiography. However, more RCTs should be conducted for a more definitive conclusion.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of Major Adverse Cardiovascular Events following Nicotinamide Exposure: Cohort Study\nAbstract: IMPORTANCENicotinamide metabolites have recently been implicated in increased risk of major cardiovascular events (MACE). Supportive data about clinical risk of MACE for nicotinamide users is lacking.  OBJECTIVETo determine whether nicotinamide use results in an increase of MACE.  DESIGN, SETTING, PARTICIPANTSRetrospective cohort study of two patient cohorts, Vanderbilt University Medical Center (VUMC) and Military Veteran Program (MVP). The risk of MACE in patients exposed to nicotinamide was compared to the risk of MACE in unexposed patients. In the VUMC cohort, 1228 patients were exposed to nicotinamide based on keyword entry for \"nicotinamide\" or \"niacinamide\" and hand-review of charts, while 253 were unexposed but had documented recommendation for use. In the MVP cohort, there were 1594 with exposure to nicotinamide propensity score matched to 2694 without exposure.  EXPOSURESThe primary exposure for the VUMC cohort was a confirmed exposure to nicotinamide in chart review. The primary exposure for the MVP cohort was medication entry for \"nicotinamide\" or \"niacinamide\".  MAIN OUTCOME(S) AND MEASURE(S)The primary outcome was development of MACE based on a validated phenotype.  RESULTSBetween both cohorts, 6039 patients were included, of whom 5125 were male with a mean age of 63.2 years. Neither cohort had significant differences in mean age, sex, race and ethnicity between the nicotinamide exposed and unexposed groups. In the VUMC cohort, there was no significant association between nicotinamide exposure and the primary outcome of MACE (HR 0.76, 95% CI 0.46 - 1.25, p = 0.28). MACE prior to nicotinamide exposure was strongly associated with subsequent MACE (HR 9.01, 95% CI 5.90 - 13.70, p < 0.001). In the MVP cohort, we adjusted for MACE risk factors as potential confounding variables and saw no significant association between nicotinamide exposure and MACE (HR 1.00 95% CI 0.75 - 1.32), while history of prior MACE remained strongly associated with subsequent MACE (HR 9.50, 95% CI 6.38 - 14.1).  CONCLUSIONS AND RELEVANCEIn this retrospective cohort study of 6039 adults from two different patient populations, we found no increased risk of MACE in patients with nicotinamide exposure.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rapid emergence of UV stabilizer Bis(2,2,6,6-tetramethyl-4-piperidyl) sebacate (BTMPS) in the illicit fentanyl supply across the United States in July-August 2024: Results from drug and drug paraphernalia testing\nAbstract: BackgroundChanges to the US drug supply historically unfold slowly with predictable patterns of geographic diffusion. Here we draw on drug checking results from around the United States to report a rapid shift in the illicit drug supply with important implications for public health. Bis(2,2,6,6-tetramethyl-4-piperidyl) sebacate, or \"BTMPS\" is a hindered amine light stabilizer with various industrial applications. Animal studies indicate multiple kinds of adverse health effects.  MethodsDrug samples collected by community-based drug checking programs in Los Angeles and Philadelphia, along with drug residue samples from other jurisdictions in California, Delaware, Maryland, and Washington, were submitted to the National Institute on Standards and Technology. Samples were qualitatively tested with Direct Analysis in Real Time mass spectrometry, with reflex to liquid chromatography mass spectrometry (LCMS) for confirmatory testing. Quantitation - percent by mass - was performed using LCMS. At both sites where drug samples were collected, participants were asked to respond to a survey that included questions about what the substance was sold as and any unexpected effects.  ResultsBetween June 1, 2024 and August 31, 2024, a total of 178 samples sold as fentanyl were tested. Of these, 43 (24%) contained BTMPS, with the proportion per month rising from 0% in June to more than a third in August. An additional 23 residue samples from sites doing residue testing contained BTMPS. Fentanyl samples with BTMPS also contained many other compounds, including local anesthetics and alpha-2 agonists. Average fentanyl purity was significantly lower in samples with BTMPS compared to samples without.  ConclusionsThe introduction of an industrial chemical to the illicit drug supply at this speed and scale is unprecedented and concerning. Further research is urgently needed to determine why it is present in the fentanyl supply and characterize effects on human health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deriving Imaging Biomarkers for Primary Central Nervous System Lymphoma Using Deep Learning\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSPurposeC_ST_ABSPrimary central nervous system lymphoma (PCNSL) is typically treated with chemotherapy, steroids, and/or whole brain radiotherapy (WBRT). Identifying which patients benefit from WBRT following chemotherapy, and which patients can be adequately treated with chemotherapy alone remains a persistent clinical challenge. Although WBRT is associated with improved outcomes, it also carries a risk of neuro-cognitive side effects. This study aims to refine patient phenotyping for PCNSL by leveraging deep learning (DL) extracted imaging biomarkers to enable personalized therapy.  MethodsOur study included 71 patients treated at our institution between 2009-2021. The primary outcome of interest was overall survival (OS) assessed at one-year, two-year, and median cohort survival cutoffs. The DL model leveraged an 8-layer 2D convolutional neural network which analyzed individual slices of post-contrast T1-weighted pre-treatment MRI scans. Survival predictions were made using a weighted voting system related to tumor size. Model performance was assessed with accuracy, sensitivity, specificity, and F1 scores. Time-dependent AUCs were calculated and C-statistics were computed to summarize the results. Kaplan-Meier (KM) survival analysis assessed differences between low and high-risk groups and statistically evaluated using the log-rank test. External validation of our model was performed with a cohort of 40 patients from an external institution.  ResultsThe cohorts average age was 65.6 years with an average OS of 2.80 years. The one-year, two-year, and median OS models achieved AUCs of 0.73 (95% C.I., 0.60-0.85), 0.70 (95% C.I., 0.58-0.82), and 0.73 (95% C.I., 0.58-0.82) respectively. KM survival curves showcased discrimination between low and high-risk groups in all models. External validation with our one-year model achieved AUC of 0.64 (95% C.I., 0.63-0.65) and significant risk discrimination. A sub-analysis showcased stable model performance across different tumor volumes and focality.  ConclusionsDL classifiers of PCNSL MRIs can stratify patient phenotypes beyond traditional risk paradigms. Given dissensus surrounding PCNSL treatment, DL can augment risk stratification and treatment personalization, especially with regards to WBRT decision making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deriving Imaging Biomarkers for Primary Central Nervous System Lymphoma Using Deep Learning\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSPurposeC_ST_ABSPrimary central nervous system lymphoma (PCNSL) is typically treated with chemotherapy, steroids, and/or whole brain radiotherapy (WBRT). Identifying which patients benefit from WBRT following chemotherapy, and which patients can be adequately treated with chemotherapy alone remains a persistent clinical challenge. Although WBRT is associated with improved outcomes, it also carries a risk of neuro-cognitive side effects. This study aims to refine patient phenotyping for PCNSL by leveraging deep learning (DL) extracted imaging biomarkers to enable personalized therapy.  MethodsOur study included 71 patients treated at our institution between 2009-2021. The primary outcome of interest was overall survival (OS) assessed at one-year, two-year, and median cohort survival cutoffs. The DL model leveraged an 8-layer 2D convolutional neural network which analyzed individual slices of post-contrast T1-weighted pre-treatment MRI scans. Survival predictions were made using a weighted voting system related to tumor size. Model performance was assessed with accuracy, sensitivity, specificity, and F1 scores. Time-dependent AUCs were calculated and C-statistics were computed to summarize the results. Kaplan-Meier (KM) survival analysis assessed differences between low and high-risk groups and statistically evaluated using the log-rank test. External validation of our model was performed with a cohort of 40 patients from an external institution.  ResultsThe cohorts average age was 65.6 years with an average OS of 2.80 years. The one-year, two-year, and median OS models achieved AUCs of 0.73 (95% C.I., 0.60-0.85), 0.70 (95% C.I., 0.58-0.82), and 0.73 (95% C.I., 0.58-0.82) respectively. KM survival curves showcased discrimination between low and high-risk groups in all models. External validation with our one-year model achieved AUC of 0.64 (95% C.I., 0.63-0.65) and significant risk discrimination. A sub-analysis showcased stable model performance across different tumor volumes and focality.  ConclusionsDL classifiers of PCNSL MRIs can stratify patient phenotypes beyond traditional risk paradigms. Given dissensus surrounding PCNSL treatment, DL can augment risk stratification and treatment personalization, especially with regards to WBRT decision making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Deriving Imaging Biomarkers for Primary Central Nervous System Lymphoma Using Deep Learning\nAbstract: AO_SCPLOWBSTRACTC_SCPLOWO_ST_ABSPurposeC_ST_ABSPrimary central nervous system lymphoma (PCNSL) is typically treated with chemotherapy, steroids, and/or whole brain radiotherapy (WBRT). Identifying which patients benefit from WBRT following chemotherapy, and which patients can be adequately treated with chemotherapy alone remains a persistent clinical challenge. Although WBRT is associated with improved outcomes, it also carries a risk of neuro-cognitive side effects. This study aims to refine patient phenotyping for PCNSL by leveraging deep learning (DL) extracted imaging biomarkers to enable personalized therapy.  MethodsOur study included 71 patients treated at our institution between 2009-2021. The primary outcome of interest was overall survival (OS) assessed at one-year, two-year, and median cohort survival cutoffs. The DL model leveraged an 8-layer 2D convolutional neural network which analyzed individual slices of post-contrast T1-weighted pre-treatment MRI scans. Survival predictions were made using a weighted voting system related to tumor size. Model performance was assessed with accuracy, sensitivity, specificity, and F1 scores. Time-dependent AUCs were calculated and C-statistics were computed to summarize the results. Kaplan-Meier (KM) survival analysis assessed differences between low and high-risk groups and statistically evaluated using the log-rank test. External validation of our model was performed with a cohort of 40 patients from an external institution.  ResultsThe cohorts average age was 65.6 years with an average OS of 2.80 years. The one-year, two-year, and median OS models achieved AUCs of 0.73 (95% C.I., 0.60-0.85), 0.70 (95% C.I., 0.58-0.82), and 0.73 (95% C.I., 0.58-0.82) respectively. KM survival curves showcased discrimination between low and high-risk groups in all models. External validation with our one-year model achieved AUC of 0.64 (95% C.I., 0.63-0.65) and significant risk discrimination. A sub-analysis showcased stable model performance across different tumor volumes and focality.  ConclusionsDL classifiers of PCNSL MRIs can stratify patient phenotypes beyond traditional risk paradigms. Given dissensus surrounding PCNSL treatment, DL can augment risk stratification and treatment personalization, especially with regards to WBRT decision making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Randomized dose-response trial of n-3 fatty acids in hormone receptor negative breast cancer survivors--impact on breast adipose oxylipin and DNA methylation patterns\nAbstract: BackgroundIncreasing evidence suggests the unique susceptibility of estrogen receptor and progesterone receptor negative (ERPR-) breast cancer to dietary fat amount and type. Dietary n-3 polyunsaturated fatty acids (PUFAs), such as docosahexaenoic acid (DHA) and eicosapentaenoic acid (EPA), may modulate breast adipose fatty acid profiles and downstream bioactive metabolites to counteract pro-inflammatory, pro-carcinogenic signaling in the mammary microenvironment.  ObjectiveTo determine effects of [~]1 to 5 g/d EPA+DHA over 12 months on breast adipose fatty acid and oxylipin profiles in women with ERPR(-) breast cancer, a high-risk molecular subtype.  MethodsWe conducted a 12-month randomized controlled, double-blind clinical trial of [~]5g/d vs [~]1g/d DHA+EPA supplementation in women within 5 years of completing standard therapy for ERPR(-) breast cancer Stages 0-III. Blood and breast adipose tissue specimens were collected every 3 months for biomarker analyses including fatty acids by gas chromatography, oxylipins by LC-MS/MS, and DNA methylation by reduced-representation bisulfite sequencing (RRBS).  ResultsA total of 51 participants completed the 12-month intervention. Study treatments were generally well-tolerated. While both doses increased n-3 PUFAs from baseline in breast adipose, erythrocytes, and plasma, the 5g/d supplement was more potent (n =51, p <0.001). The 5g/d dose also reduced plasma triglycerides from baseline (p =0.008). Breast adipose oxylipins at 0, 6, and 12 months showed dose-dependent increases in unesterified and esterified DHA and EPA metabolites (n =28). Distinct DNA methylation patterns in adipose tissue after 12 months were identified, with effects unique to the 5g/d dose group (n =17).  ConclusionsOver the course of 1 year, EPA+DHA dose-dependently increased concentrations of these fatty acids and their derivative oxylipin metabolites, producing differential DNA methylation profiles of gene promoters involved in metabolism-related pathways critical to ERPR(-) breast cancer development and progression. These data provide evidence of both metabolic and epigenetic effects of n-3 PUFAs in breast adipose tissue, elucidating novel mechanisms of action for high-dose EPA+DHA-mediated prevention of ERPR(-) breast cancer.  Clinicaltrials.gov identifier NCT02295059\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic value of YiDiXie\u2122-SS and YiDiXie\u2122-HS in esophageal cancer\nAbstract: BackgroundEsophageal cancer is a serious threat to human health and causes a heavy economic burden. upper gastrointestinal imaging(UGI imaging), enhanced CT, Fecal occult blood Tumor markers such as test(FOBT) and CEA, CA125 and CA19-9 are widely used in the screening or preliminary diagnosis of esophageal cancer. However, false positive results such as UGI imaging will bring unnecessary mental pain, expensive examination costs, examination injuries and other adverse consequences. However, false negative results such as UGI imaging lead to delayed treatment, and patients will have to bear the adverse consequences of poor prognosis, high treatment costs, poor quality of life, and short survival time. It is urgent to find a convenient, economical and non-invasive diagnostic method to reduce the false negative rate and false positive rate of UGI imaging. The objective of this study was to evaluate the diagnostic value of YiDiXie-SS and YiDiXie-HS in esophageal cancer.  Patients and methodsThis study included 164 subjects (malignant group, n=105; Benign group, n=59 cases). The remaining serum samples of the subjects were collected and the sensitivity and specificity of the YiDiXi -SS and YiDiXie-HS were evaluated using the YiDiXieall-cancer detection kit.  ResultsThe sensitivity of YiDiXie-SS was 99.0% (95% CI: 94.8% - 100%) and its specificity was 62.7% (95% CI: 50.0% - 73.9%).  The sensitivity of YiDiXie-HS was 92.3% (95% CI: 85.7% - 96.1%) and its specificity was 86.4% (95% CI: 75.5% - 93.0%). The sensitivity of YiDiXie-SS in UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 positive patients was 96.6% (95% CI: 82.8-99.8%) and 98.7% (95% CI: 93.1% - 99.9%), 100% (95% CI: 17.8% 100%), 100% (95% CI: 81.6% 100%), 100% (95% CI: 61.0% 100%), 100% (95%CI: 56.6%-100%); The specific degrees were 60.0% (95% CI: 23.1% 92.9%), 75.0% (95% CI: 30.1% 98.7%), 100% (95% CI: 5.1% 100%), 100% (95% CI: 43.9% - 100%), 100% (95% CI: 5.1% 100%), 50.0% (95% CI: 2.6% 97.4%). This means that the application of YiDiXie-SS, without basically increasing the missed diagnosis of malignant tumors, reduced the false positive range of UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 by 60.0% (95% CI: 23.1% - 92.9%), 75.0% (95% CI: 30.1% 98.7%), 100% (95% CI: 5.1% 100%), 100% (95% CI: 43.9% 100%), 100% (95% CI: 5.1% - 100%), 50.0% (95% CI: 2.6% 97.4%).  The sensitivity of YiDiXie-HS in UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 negative patients was 88.9% (95% CI: 56.5% - 99.4%), 92.6% (95% CI: 84.8% - 96.6%), 96.9% (95% CI: 84.3% - 99.8%), 92.6% (95% CI: 84.8% - 96.6%), 92.0% (95% CI: 84.5% - 96.1%), 91.3% (95% CI: 83.8% - 95.5%), respectively; The specific degrees were 60.0% (95% CI: 23.1% 92.9%), 87.3% (95% CI: 76.0% 93.7%), 80.0% (95% CI: 37.6% 99.0%), 89.1% (95% CI: 78.2% - 94.9%), 79.3% (95% CI: 61.6% 90.2%), 87.0% (95% CI: 75.6% 93.6%). This means that YiDiXie-HS reduced false negatives for UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 by 88.9% (95% CI: 56.5% - 99.4%), 92.6% (95% CI: 84.8% 96.6%), 96.9% (95% CI: 84.3% 99.8%), 92.6% (95% CI: 84.8% 96.6%), 92.0% (95% CI: 84.5% - 96.1%), 91.3% (95% CI: 83.8% 95.5%).  ConclusionYiDiXie-SS significantly reduced the false-positive rate of UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9 without substantially increasing the delayed treatment of malignant tumors. YiDiXie -HS significantly reduced false negative rates for UGI imaging, enhanced CT, FOBT, CEA, CA125 and CA19-9. YiDiXie-SS and YiDiXie-HS have important diagnostic value in esophageal cancer, and are expected to solve the two problems of \"too high false positive rate such as UGI imaging\" and \"too high false negative rate such as UGI imaging\" in esophageal cancer.  Clinical trial numberChiCTR2200066840.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic value of YiDiXie\u2122-SS, YiDiXie\u2122-HS, and YiDiXie\u2122-D in Ovarian cancer\nAbstract: BackgroundOvarian cancer is a serious risk to human health and causes a heavy economic burden. Ultrasound is widely used in the diagnosis of ovarian tumors. However, false-positive ultrasound results can lead to false diagnosis, and patients will have to bear unnecessary mental pain, expensive surgery and examination costs, surgical trauma, organ removal, loss of function, and even serious complications in the perioperative period, and other adverse consequences. False-negative ultrasound results lead to delayed treatment, and patients will have to bear the consequences of poor prognosis, high treatment costs, poor quality of life, and poor survival. There is an urgent need to find convenient, cost-effective and non-invasive diagnostic methods to reduce the false-negative and false-positive rates of ovarian ultrasound. The purpose of this study was to evaluate the diagnostic value of YiDiXie-SS, YiDiXie-HS and YiDiXie-D in Ovarian cancer.  Patients and methodsThe study finally included 79 study subjects (malignant group, n=12; benign group, n=67). Remaining serum samples from the subjects were collected and tested by applying YiDiXie all-cancer detection kit to evaluate the sensitivity and specificity of YiDiXie-SS, YiDiXie-HS and YiDiXie-D, respectively.  ResultsYiDiXie-SS had a sensitivity of 100% (95% CI: 75.8% - 100%) and a specificity of 61.2% (95% CI: 49.2% - 72.0%). YiDiXie -HS had a sensitivity of 91.7% (95% CI: 64.6% - 99.6%) and a specificity of 86.6% (95% CI: 76.4% - 92.8%). The sensitivity of YiDiXie  -D was 33.3% (95% CI: 13.8% - 60.0%) and its specificity was 97.0% (95% CI: 89.8% - 99.5%). The sensitivity of YiDiXie-SS in ultrasound-positive patients was 100% (95% CI: 67.6% - 100%) and its specificity was 61.9% (95% CI: 40.9% - 79.2%). This represents a 61.9% (95% CI: 40.9% - 79.2%) reduction in the rate of false-positive ovarian ultrasound with the application of YiDiXie-SS with essentially no increase in malignant tumor under-diagnosis. The sensitivity of YiDiXie-HS in ultrasound-negative patients was 75.0% (95% CI: 30.1% - 98.7%) and its specificity was 84.8% (95% CI: 71.8% - 92.4%). This means that the application of YiDiXie-HS reduces the false negative rate of ultrasound by 75.0% (95% CI: 30.1% - 98.7%). YiDiXie -D had a sensitivity of 25.0% (95% CI: 4.4% - 59.1%) in ultrasound-positive patients and its specificity was 95.2% (95% CI: 77.3% - 99.8%). This represents a 95.2% (95% CI: 77.3% - 99.8%) reduction in the rate of ultrasound false positives with YiDiXie-SS.  ConclusionYiDiXie-SS markedly reduced the false-positive rate of ovarian ultrasound with essentially no increase in delayed treatment of malignant tumors. YiDiXie-HS substantially reduced the false-negative rate of ovarian ultrasound. YiDiXie -D substantially reduced the false-positive rate of ovarian ultrasound. The YiDiXie test has an excellent diagnostic value in ovarian cancer, and promises to solve the problems of \"high false-positive rate of ultrasound\" and \"high false-negative rate of ultrasound\" in ovarian tumors.  Clinical trial numberChiCTR2200066840.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Women with fibromyalgia: Insights into behavioral and brain imaging\nAbstract: Fibromyalgia (FM) is a chronic condition marked by widespread pain, fatigue, sleep problems, cognitive decline, and other symptoms. Despite extensive research, the pathophysiology of FM remains poorly understood, complicating diagnosis and treatment, which often relies on self-report questionnaires. This study explored structural and functional brain changes in women with FM, identified potential biomarkers, and examined their relationship with FM severity. MRI data from 33 female FM patients and 33 matched healthy controls were utilized, focusing on T1-weighted MRI and resting-state fMRI scans. Functional connectivity (FC) analysis was performed using a machine learning framework to differentiate FM patients from healthy controls and predict FM symptom severity. No significant differences were found in brain structural features, such as gray matter volume, white matter volume, deformation-based morphometry, and cortical thickness. However, significant differences in FC were observed between FM patients and healthy controls, particularly in the default mode network (DMN), somatomotor network (SMN), visual network (VIS), and dorsal attention network (DAN). The FC metrics were significantly associated with FM severity. Our prediction model differentiated FM patients from healthy controls with an area under the curve of 0.65. FC measures accurately estimated FM symptom severities with a significant correlation (r = 0.45, p = 0.007). Functional connections in the DMN, VIS, and DAN were crucial in determining FM severity. These findings suggest that integrating brain FC measurements could serve as valuable biomarkers for early detection of FM and predicting FM symptom severity, improving diagnostic accuracy and facilitating the development of targeted therapeutic strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic associations between SGLT2 inhibition, DPP4 inhibition or GLP1R agonism and prostate cancer risk: a two-sample Mendelian randomisation study\nAbstract: BackgroundEpidemiological studies have linked the use of the anti-diabetic medications, sodium-glucose co-transporter-2 inhibitors (SGLT2I), dipeptidyl peptidase-4 inhibitors (DPP4I) and glucagon-like peptide-1 receptor agonists (GLP1RA), with prostate cancer risk. However, these studies cannot infer causality.  MethodsThis was a two-sample Mendelian randomization (MR) using genome-wide association study data designed to identify causal relationships between SGLT2I, DPP4I or GLP1RA and prostate cancer. Genetic associations with HbA1c and risk of prostate cancer were extracted from IEU Open-GWAS Project database with GWAS id ukb-d-30750_irnt (UK Biobank cohort) and ebi-a-GCST006085 (European Molecular Biology Laboratorys European Bioinformatics Institute cohort), respectively. The two GWAS datasets chosen were obtained from individuals of European ancestry to minimise potential bias from population stratification. The encoding genes targeted by SGLT2I, DPP4I and GLP1RA were SGC5A2, DPP4 and GLP1R, located in Chr16: 31494323-31502181, Chr2: 162848755-162930904 and Chr6: 39016557-39059079, respectively.  ResultsA total of 31, 2 and 5 single nucleotide variants (SNVs) were used for SGC5A2, DPP4 and GLP1R. Our MR analysis results supported a causal relationship between genetic variation in SLC5A2 and DPP4 and reduced risk of prostate cancer at the Bonferroni-corrected threshold, with odds ratios (OR) [95% confidence intervals] of 0.47 [0.38-0.58] and 0.35 [0.24-0.53], but not for GLP1R (OR: 1.39 [0.93-2.07]). Sensitivity analyses by the leave-one-out method did not significantly alter the OR for SGLT2I.  ConclusionsThe two-sample MR analysis found that SGLT2 and DPP4 inhibition, but not GLP1R agonism, was associated with lower risks of developing prostate cancer.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Genome-wide Association Study Identifies Novel Genetic Variants Associated with Knee Pain in the UK Biobank (N = 441,757)\nAbstract: Knee pain is a widespread musculoskeletal condition affecting millions globally, with significant socio-economic implications. This study endeavors to identify genetic variants associated with knee pain through a comprehensive genome-wide association study (GWAS) using data from 441,757 individuals in the UK Biobank. The primary GWAS identified ten significant loci, including eight novel loci, with the most significant single nucleotide polymorphism (SNP) being rs143384 near the GDF5 gene on chromosome 20 (p = 4.68 x 10-19). In the replication study, seven loci (rs143384, rs919642, rs55760279, rs56076919, rs3892354, rs687878, rs368636424) were found to be significant in the FinnGen cohort. Further, sex-specific analyses revealed distinct genetic associations, identifying three loci (rs143384 with p = 1.70x10-15, rs56076919 with p = 1.60x10-9, rs919642 with p = 1.45x10-8) in females and four loci ( rs2899611 with p = 2.77 x 10-11, rs891720 with p = 5.55 x 10-11, rs2742313 with p = 4.19 x 10-9, rs2019689 with p = 6.51 x 10-9) in males. The phenome-wide association analysis and Mendelian randomization analysis revealed significant links between several phenotypes and knee pain such as leg pain on walking. These findings enhance our understanding of the genetic factors of knee pain, offering potential pathways for therapeutic interventions and personalized medical strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Genome-wide Association Study Identifies Novel Genetic Variants Associated with Knee Pain in the UK Biobank (N = 441,757)\nAbstract: Knee pain is a widespread musculoskeletal condition affecting millions globally, with significant socio-economic implications. This study endeavors to identify genetic variants associated with knee pain through a comprehensive genome-wide association study (GWAS) using data from 441,757 individuals in the UK Biobank. The primary GWAS identified ten significant loci, including eight novel loci, with the most significant single nucleotide polymorphism (SNP) being rs143384 near the GDF5 gene on chromosome 20 (p = 4.68 x 10-19). In the replication study, seven loci (rs143384, rs919642, rs55760279, rs56076919, rs3892354, rs687878, rs368636424) were found to be significant in the FinnGen cohort. Further, sex-specific analyses revealed distinct genetic associations, identifying three loci (rs143384 with p = 1.70x10-15, rs56076919 with p = 1.60x10-9, rs919642 with p = 1.45x10-8) in females and four loci ( rs2899611 with p = 2.77 x 10-11, rs891720 with p = 5.55 x 10-11, rs2742313 with p = 4.19 x 10-9, rs2019689 with p = 6.51 x 10-9) in males. The phenome-wide association analysis and Mendelian randomization analysis revealed significant links between several phenotypes and knee pain such as leg pain on walking. These findings enhance our understanding of the genetic factors of knee pain, offering potential pathways for therapeutic interventions and personalized medical strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Federated Multiple Imputation for Variables that Are Missing Not At Random in Distributed Electronic Health Records\nAbstract: Large electronic health records (EHR) have been widely implemented and are available for research activities. The magnitude of such databases often requires storage and computing infrastructure that are distributed at different sites. Restrictions on data-sharing due to privacy concerns have been another driving force behind the development of a large class of distributed and/or federated machine learning methods. While missing data problem is also present in distributed EHRs, albeit potentially more complex, distributed multiple imputation (MI) methods have not received as much attention. An important advantage of distributed MI, as well as distributed analysis, is that it allows researchers to borrow information across data sites, mitigating potential fairness issues for minority groups that do not have enough volume at certain sites. In this paper, we propose a communication-efficient and privacy-preserving distributed MI algorithms for variables that are missing not at random.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: \"Were here to help them if they want to come\": A qualitative exploration of hospital staff perceptions and experiences with outpatient non-attendance\nAbstract: BackgroundPatient non-attendance remains a major challenge for health services. Few studies have examined how health service providers think about, potentially address, and prioritise non-attendance within the scope of their practice. This study aimed to (1) explore healthcare professionals perspectives, beliefs, and opinions about the impact of patient non-attendance within a publicly-funded outpatient physiotherapy clinic context; (2) explore perceived barriers and facilitators associated with the implementation of non-attendance mitigation strategies; and (3) identify health service staff generated solutions to address perceived barriers and enhance facilitators.  O_TBL View this table: org.highwire.dtl.DTLVardef@f3d46forg.highwire.dtl.DTLVardef@1fff730org.highwire.dtl.DTLVardef@1bd9330org.highwire.dtl.DTLVardef@10a6257org.highwire.dtl.DTLVardef@be54db_HPS_FORMAT_FIGEXP  M_TBL C_TBL MethodsA focus group discussion and semi-structured interviews were conducted between June 2023 to January 2024 with 27 physiotherapy department clinic outpatient staff involved in operationalising clinic referral processing, appointment scheduling, or providing care to patients. Data was analysed using a hybrid inductive/deductive framework analysis approach.  ResultsParticipants indicated that non-attendance had predominantly negative implications for the health service, healthcare provider, and patient. The interconnected issue of non-attendance encompassed multiple areas and were broadly categorised into five inductively identified themes: impact of non-attendance, perceptions of value, material deprivation, service delivery and built environment, and professional role and identity. Non-attendance mitigation strategies generated by participants were deductively mapped to the theoretical domains framework (TDF) to explore behavioural determinants that may influence successful implementation. This included knowledge, reinforcement, goals, optimism, memory, attention and decision-making, environmental resources and context, and emotions.  ConclusionsStaff identified multiple strategies for reducing non-attendance; implementing many of these strategies would require additional resourcing. Research determining the effectiveness of such strategies both in the short-term and long-term following implementation into practice remains a priority for future investigation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Selective effects of dopaminergic and noradrenergic degeneration on cognition in Parkinson's disease\nAbstract: The substantia nigra and locus coeruleus are among the first brain regions to degenerate in Parkinsons disease. This has important implications for early cognitive deficits as these nuclei are sources of ascending neuromodulators (i.e., dopamine and noradrenaline) that support various cognitive functions like learning, memory, and executive function. However, because most studies of the relationship between patterns of degeneration and cognition have either studied these neuromodulator systems in isolation or studied specific cognitive domains in isolation, it is unknown if degeneration in the substantia nigra and degeneration in the locus coeruleus independently and selectively contribute to different cognitive deficits in Parkinsons disease.  To address this gap, we tested people with Parkinsons disease and older adults on tasks of positive reinforcement learning, attention/working memory, executive function, and memory to measure performance in domains of cognition specifically thought to be related to dopaminergic and noradrenergic function. Participants also underwent neuromelanin-sensitive magnetic resonance imaging which provides a measure of degeneration of dopamine neurons in the substantia nigra and of noradrenergic neurons in the locus coeruleus. Brain-behaviour relationships were evaluated by separate linear regressions predicting cognitive performance in each domain from substantia nigra and locus coeruleus neuromelanin signal intensities controlling for age, sex, and education.  As expected, Parkinsons disease patients had significantly slower learning from positive feedback and lower performance on tests of attention/working memory, executive function, and memory than controls. Parkinsons patients also had lower neuromelanin signal intensity in the substantia nigra and locus coeruleus. Examining brain-behaviour relationships, we found that reduced neuromelanin signal in the substantia nigra in Parkinsons disease patients was independently associated with impaired positive reinforcement learning, controlling for changes in the locus coeruleus, but was not associated with other domains of cognition. In contrast, reduced neuromelanin signal in the locus coeruleus was independently associated with impairments in attention/working memory and executive function, controlling for changes in the substantia nigra, but not with reinforcement learning performance. These results show that substantia nigra degeneration and locus coeruleus degeneration independently and selectively contribute to cognitive deficits and therefore suggests that individual differences in the degree of neurodegeneration in these nuclei could explain the significant heterogeneity that exists in the cognitive and behavioural manifestations of Parkinsons disease. These findings also highlight the potential value of leveraging known brain-behaviour relationships to develop performance-based measures of cognition that reflect underlying patterns of neurodegeneration.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Serum, Cell-Free HPV-Human DNA Junction Detection and HPV Typing for Predicting and Monitoring Cervical Cancer Recurrence\nAbstract: Almost all cervical cancers are caused by human papillomaviruses (HPVs). In most cases, HPV DNA is integrated into the human genome. We found that tumor-specific, HPV-human DNA junctions are detectable in serum cell-free DNA of cervical cancer patients at initial treatment. Retrospective analysis revealed these junctions were more frequently detectable in women in whom the cancer later recurred. We also found that cervical cancers caused by HPV types outside of phylogenetic clade 9 had a higher recurrence frequency than those caused by 9 types in both our study and The Cancer Genome Atlas cervical cancer database, despite the higher prevalence of 9 types including HPV16 in cervical cancer. Thus, HPV-human DNA junction detection in serum cell-free DNA and HPV type determination in tumor tissue may help predict recurrence risk. Screening serum cell-free DNA for junctions may also offer an unambiguous, non-invasive means to monitor absence of recurrence following treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Allelic effects on KLHL17 expression likely mediated by JunB/D underlie a PDAC GWAS signal at chr1p36.33\nAbstract: Pancreatic Ductal Adenocarcinoma (PDAC) is the third leading cause of cancer-related deaths in the U.S. Both rare and common germline variants contribute to PDAC risk. Here, we fine-map and functionally characterize a common PDAC risk signal at 1p36.33 (tagged by rs13303010) identified through a genome wide association study (GWAS). One of the fine-mapped SNPs, rs13303160 (r2=0.93 in 1000G EUR samples, OR=1.23, P value=2.74x10-9) demonstrated allele-preferential gene regulatory activity in vitro and allele-preferential binding of JunB and JunD in vitro and in vivo. Expression Quantitative Trait Locus (eQTL) analysis identified KLHL17 as a likely target gene underlying the signal. Proteomic analysis identified KLHL17 as a member of the Cullin-E3 ubiquitin ligase complex in PDAC-derived cells. In silico differential gene expression analysis of the GTExv8 pancreas data suggested an association between lower KLHL17 (risk associated) and pro-inflammatory pathways. We hypothesize that KLHL17 may mitigate inflammation by recruiting pro-inflammatory proteins for ubiquitination and degradation thereby influencing PDAC risk.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plaintiff experiences of the medico-legal environment in Ireland\nAbstract: IntroductionThe recent surge in clinical claims in Ireland has sparked concerns about the unsustainable trajectory of medical negligence litigation. Current evaluations have primarily focused on the financial and temporal aspects of litigation, leaving a gap in understanding the experiences of plaintiffs within the adversarial system. This study aims to fill this gap by critically exploring the experiences of those affected by medical negligence and the ensuing legal process.  MethodsA qualitative descriptive approach was employed to explore the experiences of plaintiffs following patient safety incidents and their interactions with the legal process. Semi-structured, open-ended interviews were conducted with participants who had been involved in medical negligence litigation in Ireland. Participants were eligible for inclusion if they were aged 18 years or over and were involved in medical negligence litigation in Ireland (as a plaintiff), whether the case was resolved by negotiated settlement, a form of alternative dispute resolution (e.g. mediation), or trial hearing. Maximum variation sampling was used to capture a diverse range of experiences, with sample size determined by the concept of  information power. Recruitment was facilitated by the Health Service Executive (HSE) through invitations sent by The National Open Disclosure Office. Interviews were conducted in-person or online, recorded, transcribed, and analysed thematically. Ethical approval was obtained from the Social Research Ethics Committee of University College Cork.  FindingsThis research presents the views and experiences of fifteen participants; eleven participants shared their experiences relating to an adverse event which impacted a family member (one participant spoke about two family members), nine of whom were children (including both minors and adult children), and three were a spouse. Of the twelve individuals discussed, eight were deceased. Five main themes were identified from the analysis: i) Navigating the aftermath of a patient safety event: Communication, Support and Abandonment; ii) The pathway from adverse event to litigation; iii) Experiences of the Legal System; iv) Emotional and Mental Health Impact of Litigation on Plaintiffs; v) Advocating for Change: Participant Recommendations.  DiscussionThis research highlights the profound impact of actions taken after a patient safety event on patients, families, healthcare professionals, and organisations, and the importance of Open Disclosure in meeting ethical obligations and ensuring healthcare accountability. It explores the complex relationships between financial compensation, justice-seeking, and the healthcare and legal systems. The findings contribute significant insights to the discourse on medical negligence in Ireland.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Transcranial magnetic stimulation of dorsomedial prefrontal cortex for cocaine use disorder: A pilot study\nAbstract: Cocaine use disorder (CUD) is a difficult-to-treat condition with no FDA-approved medications. Recent work has turned to brain stimulation methods to help rectify hypofrontality and dopamine reward system changes often observed in individuals with CUD. Preliminary studies using transcranial magnetic stimulation (TMS) have demonstrated promising results, but there is room for optimization of the stimulation site, stimulation pattern, and identification of relevant biomarkers of TMS effects. The current pilot study aimed to test the feasibility, safety, and preliminary effects of a double-blind, sham-controlled, cross-over, acute design using intermittent theta burst stimulation to dorsomedial prefrontal cortex (dmPFC) on electroencephalogram (EEG) as intermediate outcome assessment in CUD patients. This small pilot enrolled five individuals with moderate-to-severe CUD for feasibility and proof-of-concept. Participants completed safety, psychometric, and EEG measures before and after receiving two sessions of active or sham TMS to dmPFC on two separate days. All five participants completed all the study tasks and found the TMS to be tolerable. The side effects were minimal and consistent with an acute TMS design. Visible changes were observed in the electrical activity of the brain during a monetary guessing task, while minimal changes in psychometric measures were observed. These results indicate the feasibility and safety of the current approach and suggest that dmPFC is a viable target for treating CUD. Future work should expand upon these findings in a randomized controlled clinical trial.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Free fatty acids accelerate \u03b2-cell death in type 1 diabetes\nAbstract: Type 1 diabetes (T1D) results from autoimmune destruction of the insulin producing pancreatic {beta} cells. The bodys lipid metabolism is strongly regulated during this process but there is a need to understand how this regulation contributes to the {beta}-cell death. Here, we show that fatty acids are released from plasma lipoproteins in children during islet autoimmunity, prior to T1D onset. These fatty acids (FFAs) enhanced cytokine-mediated apoptosis in cultured insulin-producing cells by downregulating the production of nicotinamide adenosine dinucleotide (NAD) via its salvage pathway, as well as deregulated central carbon metabolism and impaired levels of ATP. Downregulation of the NAD salvage pathway and central carbon metabolism enzymes were further observed during T1D development, supporting that the pathways for NAD and energy production are compromised in vivo. Our findings show that fatty acids are released during islet autoimmunity, accelerating disease development through impaired NAD metabolism.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gut microbiome shifts in adolescents after sleeve gastrectomy with increased oral-associated taxa and pro-inflammatory potential\nAbstract: BackgroundBariatric surgery is highly effective in achieving weight loss in children and adolescents with severe obesity, however the underlying mechanisms are incompletely understood, and gut microbiome changes are unknown.  Objectives1) To comprehensively examine gut microbiome and metabolome changes after laparoscopic vertical sleeve gastrectomy (VSG) in adolescents and 2) to assess whether the microbiome/metabolome changes observed with VSG influence phenotype using germ-free murine models.  Design1) A longitudinal observational study in adolescents undergoing VSG with serial stool samples undergoing shotgun metagenomic microbiome sequencing and metabolomics (polar metabolites, bile acids and short chain fatty acids) and 2) a human-to-mouse fecal transplant study.  ResultsWe show adolescents exhibit significant gut microbiome and metabolome shifts several months after VSG, with increased alpha diversity and notably with enrichment of oral-associated taxa. To assess causality of the microbiome/metabolome changes in phenotype, pre-VSG and post-VSG stool was transplanted into germ-free mice. Post-VSG stool was not associated with any beneficial outcomes such as adiposity reduction compared pre-VSG stool. However, post-VSG stool exhibited an inflammatory phenotype with increased intestinal Th17 and decreased regulatory T cells. Concomitantly, we found elevated fecal calprotectin and an enrichment of proinflammatory pathways in a subset of adolescents post-VSG.  ConclusionWe show that in some adolescents, microbiome changes post-VSG may have inflammatory potential, which may be of importance considering the increased incidence of inflammatory bowel disease post-VSG.  What is already known on this topicBariatric surgery is highly effective in achieving weight loss in children and adolescents with severe obesity, however the underlying mechanisms are incompletely understood, and gut microbiome changes are unknown.  What this study addsSignificant gut microbiome and metabolome shifts were found several months after vertical sleeve gastrectomy in adolescents, notably with enrichment of oral-associated taxa. Using human to germ-free mice fecal transplant studies, the post-surgery changes in the gut microbiome/metabolome were shown to have inflammatory potential. Furthermore, raised fecal calprotectin and inflammatory systemic pathways were seen in a subset of adolescents post-surgery.  How this study might affect research, practice or policyThese findings may be of importance given the growing recognition of an increased incidence of inflammatory bowel disease after bariatric surgery and warrants further investigation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Generative AI for Qualitative Analysis in a Maternal Health Study: Coding In-depth Interviews using Large Language Models (LLMs)\nAbstract: Study ObjectivesIn-depth interviews are one of the most widely used approaches for qualitative studies in public health. The coding of transcripts is a critical step for information extraction and preliminary analysis. However, manual coding is often labor-intensive and time-consuming. The emergence of generative artificial intelligence (GenAI), supported by Large Language Models (LLMs), presents new opportunities to understand human languages, which may significantly facilitate the coding process. This study aims to build a computational coding framework that uses GenAI to automatically detect and extract themes from in-depth interview transcripts.  MethodsWe conducted an experiment using transcripts of in-depth interviews with maternity care providers in South Carolina. We leveraged ChatGPT to perform two tasks automatically: (1) deductive coding, which involves applying a predefined set of codes to dialogues; and (2) inductive coding, which can generate codes from dialogues without any preconceptions or assumptions. We fine-tuned ChatGPT to understand the content of the interview transcripts, enabling it to detect and summarize codes. We then evaluated the performance of the proposed approach by comparing the codes generated by ChatGPT with those generated manually by human coders, involving human-in-the-loop evaluation.  ResultsThe results demonstrated the potential of GenAI in detecting and summarizing codes from in-depth interview transcripts. ChatGPT could be utilized for both deductive and inductive coding processes. The overall accuracy of GenAI is higher than 80% and the codes it generated showed high positive associations with those generated manually. More impressively, GenAI reduced the time required for coding by 81%, demonstrating its efficiency compared to traditional methods.  DiscussionGenAI models like ChatGPT show high generalizability, scalability and efficiency in handling large datasets, and are proficient in multi-level semantic structure identification. They demonstrate promising results in qualitative coding, making it a valuable tool for supporting people in public health research. However, challenges such as inaccuracy, systematic biases, and privacy concerns must be addressed when using them in practice. GenAI-based coding results should be handled with caution and reviewed by human coders to ensure accuracy and reliability.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond Algorithms: The Impact of Simplified CNN Models and Multifactorial Influences on Radiological Image Analysis\nAbstract: This paper demonstrates that simplified Convolutional Neural Network (CNN) models can outperform traditional complex architectures, such as VGG-16, in the analysis of radiological images, particularly in datasets with fewer samples. We introduce two adopted CNN architectures, LightCnnRad and DepthNet, designed to optimize computational efficiency while maintaining high performance. These models were applied to nine radiological image datasets, both public and in-house, including MRI, CT, X-ray, and Ultrasound, to evaluate their robustness and generalizability. Our results show that these models achieve competitive accuracy with lower computational costs and resource requirements. This finding underscores the potential of streamlined models in clinical settings, offering an effective and efficient alternative for radiological image analysis. The implications for medical diagnostics are significant, suggesting that simpler, more efficient algorithms can deliver better performance, challenging the prevailing reliance on transfer learning and complex models. The complete codebase and detailed architecture of the LightCnnRad and DepthNet, along with step-by-step instructions, are accessible in our GitHub repository at https://github.com/PKhosravi-CityTech/LightCNNRad-DepthNet.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Targeted deep brain stimulation of the motor thalamus improves speech and swallowing motor functions after cerebral lesions\nAbstract: Speech and swallowing are complex motor acts that depend upon the integrity of input neural signals from motor cortical areas to control muscles of the head and neck. Lesions damaging these neural pathways result in weakness of key muscles causing dysarthria and dysphagia, leading to profound social isolation and risk of aspiration and suffocation. Here we show that Deep Brain Stimulation (DBS) of the motor thalamus improved speech and swallowing functions in two participants with dysarthria and dysphagia. First, we proved that DBS increased excitation of the face motor cortex, augmenting motor evoked potentials, and range and speed of motion of orofacial articulators in n=10 volunteers with intact neural pathways. Then, we demonstrated that this potentiation led to immediate improvement in swallowing functions in a patient with moderate dysphagia and profound dysarthria as a consequence of a traumatic brain lesion. In this subject and in another with mild dysarthria, we showed that DBS immediately ameliorated impairments of respiratory, phonatory, resonatory, and articulatory control thus resulting in a clinically significant improvement in speech intelligibility. Our data provide first-in-human evidence that DBS can be used to treat dysphagia and dysarthria in people with cerebral lesions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: CROSS-SECTIONAL ANALYSIS: INTERPRETATION OF NON-STATISTICALLY SIGNIFICANT RESULTS IN RANDOMISED CONTROLLED CLINICAL TRIALS IN REHABILITATION\nAbstract: IntroductionDespite the CONSORT guidelines, which aim to improve the quality of studies, authors often formulate conclusions based on the dichotomous distinction of the p-value, declaring differences between  statistically significant and  non-significant. This approach confuses the identification of the real efficacy of the studied treatment. To solve this problem, CONSORT guidelines recommend using confidence intervals, which offer a more complete view of possible effects. However, authors conclusions often remain based on a binary approach, confusing the absence of evidence with the evidence of absence. This error can influence clinical practice and future research, leading to the identification of  negative treatments based on  statistical insignificance, which reflects a lack of evidence of absence, not the absence of evidence.  ObjectivesTo assess the prevalence of misinterpretation of non-statistically significant results, both in the abstract and in the article, in a sample of all randomised controlled trials (RCTs) with non-statistically significant primary outcomes published in 5 rehabilitation journals with the highest impact factor (IF) published between 2019 and 2023 and to assess whether the primary outcome result is reported according to CONSORT guidelines.  MethodsWe will conduct a cross-sectional analysis of all Rcts with non-statistically significant primary outcomes in 5 general rehabilitation journals with the highest IF published between 2019 and 2023. We will determine the prevalence of trials in which non-significance is interpreted as absence of evidence, evidence of absence, or advice to use the intervention in clinical practice in the abstract and article conclusions, and the prevalence of trials that adhered to CONSORT guidelines for reporting the primary outcome.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Access to Allogeneic Cell Transplantation Based on Donor Search Prognosis: An Interventional Trial\nAbstract: ImportancePatients requiring allogeneic hematopoietic cell transplantation have variable likelihoods of identifying an 8/8 HLA-matched unrelated donor. A Search Prognosis calculator can estimate the likelihood.  ObjectiveTo determine if using a search algorithm based on donor search prognosis can result in similar incidence of transplant between patients Very Likely (>90%) vs Very Unlikely (<10%) to have a matched unrelated donor.  DesignThis interventional trial utilized a Search Prognosis-based biologic assignment algorithm to guide donor selection. Trial enrollment from June 13, 2019-May 13, 2022; analysis of data as of September 7, 2023 with median follow-up post-evaluability of 14.5 months.  SettingsNational multi-center Blood and Marrow Transplantation Clinical Trials Network 1702 study of US participating transplant centers.  ParticipantsAcute myeloid and lymphoid leukemias, myelodysplastic syndrome, Hodgkins and non-Hodgkins lymphomas, severe aplastic anemia, and sickle cell disease patients referred to participating transplant centers were invited to participate. 2225 patients were enrolled and 1751 were declared evaluable for this study. Patients were declared evaluable once it was determined no suitable HLA-matched related donor was available.  InterventionPatients assigned to the Very Likely arm were to proceed with matched unrelated donor, while Very Unlikely were to utilize alternative donors. A third stratum, Less Likely ([~]25%) to find a matched unrelated donor, were observed under standard center practices, but were not part of the primary objective.  Main OutcomeCumulative incidence of transplantation by Search Prognosis arm  ResultsEvaluable patients included 1751 of which 413 (24%) were from racial/ethnic minorities. Search prognosis was 958 (55%) Very Likely, 517 (30%) Less Likely and 276 (16%) Very Unlikely. 1171 (67%) received HCT, 384 (22%) died without HCT, and 196 (11%) remained alive without HCT. Among the 1,234 patients, the adjusted cumulative incidence (95% CI) of HCT at 6-months was 59.8% (56.7-62.8) in the Very Likely group versus 52.3% (46.1-58.5) in the Very Unlikely (P=0.113).  ConclusionsA prospective Search Prognosis-based algorithm can be effectively implemented in a national multicenter clinical trial. This approach resulted in rapid alternative donor identification and comparable rates of HCT in patients Very Likely and Very Unlikely to find a matched unrelated donor.  Trial Registration: NCT#03904134\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Providing an e-cigarette starter kit for smoking cessation and reduction as adjunct to usual care to smokers with a mental health condition: Findings from the ESCAPE feasibility study\nAbstract: BackgroundSmoking rates in the UK have declined steadily over the past decades, masking considerable inequalities, as little change has been observed among people with a mental health condition. This trial sought to assess the feasibility and acceptability of supplying an electronic cigarette (e-cigarette) starter kit for smoking cessation as an adjunct to usual care for smoking cessation, to smokers with a mental health condition treated in the community, to inform a future effectiveness trial.  MethodsThis randomised controlled feasibility trial, conducted March-December 2022, compared the intervention (e-cigarette starter kit with a corresponding information leaflet and demonstration with Very Brief Advice) with a  usual care control at 1-month follow-up. Participants were [&ge;]18 years, receiving treatment for any mental health condition in primary or secondary care in three Mental Health Trusts in Yorkshire and one in London, UK. They were also willing to address their smoking through either cessation or reduction of cigarette consumption. The agreed primary outcome measure was feasibility (consent[~]15% of eligible participants; attrition rate<30%). Acceptability, validated sustained abstinence and [&ge;]50% cigarette consumption reduction at 1-month, were also evaluated and qualitative interviews conducted to further explore acceptability in this population.  ResultsFeasibility targets were partially met; of 201 eligible participants, 43 (mean age = 45.2, SD = 12.7; 39.5% female) were recruited (21.4%) and randomised (intervention:48.8%, n=21; control:51.2%, n=22). Attrition rate was 37.2% at 1-month follow-up and was higher (45.5%) in the control group. At follow-up (n=27), 93.3% (n=14) in the intervention group and 25.0% (n=3) in the control group reported e-cigarette use. The intervention was well received with minimal negative effects. In intention-to-treat analysis, validated sustained abstinence at 1-month was 2/21 (9.5%) and 0/22 (0%) and at least 50% reduction in cigarette consumption 13/21 (61.9%) and 3/22 (13.6%), for the intervention and control group, respectively. Qualitative analysis of participant interviews (N=5) showed the intervention was broadly acceptable, but they also highlighted areas of improvements for the intervention and trial delivery.  ConclusionsOffering an e-cigarette starter kit to smokers with a mental health condition treated in the community was acceptable and largely feasible, with harm reduction outcomes (i.e. switching from cigarette smoking to e-cigarette use and substantial reduction in cigarette consumption) favouring the intervention. The findings of the study will be used to help inform the design of a main trial.  Trial RegistrationRegistry: ISRCTN  Registration number: ISRCTN17691451  Date of registration: 30/09/2021\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Electroencephalographic (EEG) Changes Accompanying Normal Breathing of Concentrated Oxygen (Hyperoxic Ventilation) by Healthy Adults: A Systematic Review\nAbstract: IntroductionDivers often increase their fraction of inspired oxygen (FiO2) to decrease their risk of decompression sickness. However, breathing concentrated oxygen can cause hyperoxia, and central nervous system oxygen toxicity (CNS-OT). This study aims to review the literature describing hyperoxic ventilations effect on the electroencephalogram (EEG), thus exploring the potential for real-time detection of impending CNS-OT seizure.  MethodsWe searched Medline, Embase, Scopus, and Web of Science for articles that reported EEG measures accompanying hyperoxic ventilation (FiO2 = 1.0) in healthy participants. We included peer-reviewed journal articles, books, and government reports with no language or date restrictions. Randomised controlled trials and cross-over studies were included; case reports were excluded. We used the Newcastle-Ottawa scale to evaluate evidence quality.  ResultsOur search strategy returned 1025 unique abstracts; we analysed the full text of 40 articles; 22 articles (16 studies) were included for review. Study cohorts were typically small, and comprised of male non-divers. We discovered a variety of EEG analysis methods: studies performed spectral analysis (n = 12), the analysis of sensory-evoked potentials (n = 4), connectivity/complexity analysis (n = 3), source localization (n = 1), and expert qualitative analyses (n = 4). Studies of severe exposures (long duration at hyperbaric pressure) typically reported qualitative measures, and studies of mild exposures typically reported quantitative measures.  ConclusionsThere is a need for a large randomised controlled trial (RCT) reporting quantitative measures to better understand hyperoxic ventilations effect on EEG, thus enabling the development of real-time monitoring of CNS-OT risk.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Right Ventricular Work and Pulmonary Capillary Wedge Pressure in Heart Failure with Preserved Ejection Fraction\nAbstract: BackgroundSymptoms of heart failure with preserved ejection fraction (HFpEF) are closely related to elevated pulmonary capillary wedge pressure (PCWP) during exercise. Understanding right ventricular (RV) myocardial work, using RV pressure-strain loops to assess RV function in HFpEF, is lacking. The study aims to evaluate the effectiveness of right ventricular myocardial work parameters in diagnosing HFpEF and their correlation with pulmonary capillary wedge pressure during exercise.  MethodsThe study included patients who underwent invasive cardiopulmonary exercise tests, measuring pressures at rest and during exercise to identify HFpEF. Echocardiography assessed left and right ventricular parameters. RV myocardial work was calculated using strain-rate and pressure curves, matched with ECG data. RV global constructive work (RV GCW), RV global work index (RV GWI), RV global wasted work (RV GWW), and RV global work efficiency (RV GWE) were analyzed and compared with invasively measured PCWP at rest and peak exercise.  ResultsForty-one patients with adequate data were enrolled, with 21 diagnosed with HFpEF. No significant differences in various echocardiographic parameters were found between HFpEF and non-HFpEF groups, except higher post-exercise PCWP and mean pulmonary artery pressure in HFpEF patients. HFpEF patients had higher RV GWW and lower RV GWE. RV GWW and RV GWE had higher predictive ability for HFpEF diagnosis compared to other echocardiographic parameters. RV GCW (r = 0.504, P = 0.001) and RV GWW (r = 0.621, P < 0.001) correlated with post-exercise {Delta}PCWP and exercise PCWP, with RV GWW independently associated with both after adjustment for confounding factors.  ConclusionsRV GWW is a novel predictive parameter that provides a better explanation of RV performance regarding post-exercise {Delta}PCWP than other standard echocardiographic parameters in HFpEF.  WHAT IS NEW?O_LIRight ventricular global wasted work (RV GWW) is identified as a novel predictive parameter in heart failure with preserved ejection fraction (HFpEF), providing a more accurate explanation of right ventricular (RV) performance regarding post-exercise changes in pulmonary capillary wedge pressure ({Delta}PCWP) compared to standard echocardiographic parameters. C_LIO_LIstudy highlights the significant correlation of RV GWW with post-exercise {Delta}PCWP and exercise PCWP, demonstrating its independent association after adjusting for confounding factors. C_LIO_LImyocardial work, assessed using RV pressure-strain loops from invasive cardiopulmonary exercise tests and echocardiography, offers valuable insights into the role of RV in exercise intolerance and dyspnea among HFpEF patients. C_LI  WHAT ARE THE CLINICAL IMPLICATIONS?O_LIRV GWW serves as a superior predictive marker for diagnosing HFpEF, independently correlating with post-exercise {Delta}PCWP. This enhances the understanding of RV contribution to exercise intolerance and dyspnea in HFpEF, potentially aiding in more accurate diagnosis and tailored management strategies. C_LIO_LIRV GWW analysis in clinical practice may improve the diagnostic precision and management of HFpEF, optimizing treatment strategies for patients with unexplained dyspnea and suspected HFpEF. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: EpiSemoLLM: A Fine-tuned Large Language Model for Epileptogenic Zone Localization Based on Seizure Semiology with a Performance Comparable to Epileptologists\nAbstract: SignificanceSeizure semiology, the study of signs and clinical manifestations during seizure episodes, provides crucial information for inferring the location of epileptogenic zone (EZ). Given the descriptive nature of seizure semiology and recent advancements in large language models (LLMs), there is a potential to improve the localization accuracy of EZ by leveraging LLMs for interpreting the seizure semiology and mapping its descriptions to the corresponding EZs. This study introduces the Epilepsy Semiology Large Language Model, or EpiSemoLLM, the first fine-tuned LLM designed specifically for this purpose, built upon the Mistral-7B foundational model.  MethodA total of 865 cases, each containing seizure semiology descriptions paired with validated EZs via intracranial EEG recording and postoperative surgery outcome, were collected from 189 publications. These collected data cohort of seizure semiology descriptions and EZs, as the high-quality domain specific data, is used to fine-tune the foundational LLM to improve its ability to predict the most likely EZs. To evaluate the performance of the fine-tuned EpiSemoLLM, 100 well-defined cases were tested by comparing the responses from EpiSemoLLM with those from a panel of 5 epileptologists. The responses were graded using the rectified reliability score (rRS) and regional accuracy rate (RAR). Additionally, the performance of EpiSemoLLM was compared with its foundational model, Mistral-7B, and various versions of ChatGPT, Llama as other representative LLMs.  ResultIn the comparison with a panel of epileptologists, EpiSemoLLM achieved the following score for regional accuracy rates (RAR) with zero-shot prompts: 60.71% for the frontal lobe, 83.33% for the temporal lobe, 63.16% for the occipital lobe, 45.83% for the parietal lobe, 33.33% for the insular cortex, and 28.57% for the cingulate cortex; and mean rectified reliability score (rRS) 0.291. In comparison, the epileptologists averaged RAR scores were 64.83% for the frontal lobe, 52.22% for the temporal lobe, 60.00% for the occipital lobe, 42.50% for the parietal lobe, 46.00% for the insular cortex, and 8.57% for the cingulate cortex; and rectified reliability score (rRS) with mean of 0.148. Notably, the fine-tuned EpiSemoLLM outperformed its foundational LLM, Mistral-7B-instruct, and various versions of ChatGPT and Llama, particularly in localizing EZs in the insular and cingulate cortex. EpiSemoLLM offers valuable information for presurgical evaluations by identifying the most likely EZ location based on seizure semiology.  ConclusionEpiSemoLLM demonstrates comparable performance to epileptologists in inferring EZs from patients seizure semiology, highlighting its value in epilepsy presurgical assessment. EpiSemoLLM outperformed epileptologists in interpreting seizure semiology with EZs originating from the temporal and parietal lobes, as well as the insular cortex. Conversely, epileptologists outperformed EpiSemoLLM regarding EZ localizations in the frontal and occipital lobes and the cingulate cortex. The models superior performance compared to the foundational model underscores the effectiveness of fine-tuning LLMs with high-quality, domain-specific samples.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: In-utero exposure to PM2.5 and adverse birth outcomes in India: Geostatistical modelling using remote sensing and demographic health survey data 2019-21\nAbstract: Rapid urbanization in India is contributing to heightened poor air quality. Yet research on the impact of poor air on adverse birth outcomes (ABOs) especially in the public health aspect is less in India. This study investigates the influence of air quality on birth weight (LBW) and preterm birth (PTB). Utilizing data from the National Family Health Survey and satellite images, the study employs various statistical analyses and spatial models to elucidate the connection between in-utero exposure to air pollution and birth outcomes, both at the individual and district levels. It was observed that approximately 13% of children were born prematurely, and 17% were born with low birth weight. Increased ambient PM2.5 concentrations during pregnancy were associated with higher odds of LBW (AOR: 1.4; 95% CI: 1.29-1.45). Mothers exposed to PM2.5 during pregnancy had a heightened likelihood of delivering prematurely (AOR: 1.7; 95% CI: 1.57-1.77) in comparison to unexposed mothers. Climatic factors such as rainfall and temperature had a greater association with ABOs. Children residing in the Northern districts of India appeared to be more susceptible to the adverse effects of ambient air pollution. Furthermore, indoor air pollution was found to be associated with LBW. Employing a distributed spline approach, the study identified a discernible upward trend in the risk of adverse birth outcomes as the level of exposure increased, particularly following an exposure level of 40 PM2.5 ug/m3. Among the spatial models employed, the MGWR spatial model exhibited the highest level of goodness of fit. In addition to addressing immediate determinants such as nutrition and maternal healthcare, it is imperative to collaboratively address distal factors encompassing both indoor and outdoor pollution to attain lasting enhancements in child health.  HighlightsO_LIAn estimated 13% of the children were preterm and 17% were low birth weight in India in 2019-21. C_LIO_LIHigh PM2.5 concentration during pregnancy was associated with LBW and PTB. C_LIO_LIChildren residing in the Northern districts of India were found to be more vulnerable to poor air quality. C_LIO_LIA rising trend in the risk of adverse birth outcomes was observed after exposure level of 40 PM2.5 ug/m3. C_LIO_LIThe MGWR spatial model demonstrated the highest level of goodness of fit. C_LI  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=96 SRC=\"FIGDIR/small/24313773v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (37K): org.highwire.dtl.DTLVardef@1f8496eorg.highwire.dtl.DTLVardef@19cf48aorg.highwire.dtl.DTLVardef@17acd5forg.highwire.dtl.DTLVardef@14149f8_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Viral transcript and tumor immune microenvironment-based transcriptomic profiling of HPV-associated head and neck squamous cell carcinoma identifies subtypes associated with prognosis\nAbstract: Human papillomavirus (HPV)-associated head and neck squamous cell carcinoma (HPV-positive HNSCC) has distinct biological characteristics from HPV-negative HNSCC. Using an AI-based analytical platform on meta cohorts, we profiled expression patterns of viral transcripts and HPV viral genome integration, and classified the tumor microenvironment (TME). Unsupervised clustering analysis revealed 5 distinct and novel TME subtypes across patients (immune-enriched, highly immune and B-cell enriched, fibrotic, immune-desert, and immune-enriched luminal). These TME subtypes were highly correlated with patient prognosis. In order to understand specific factors associated with prognosis, we used unsupervised clustering of a HPV-positive HNSCC cohort from The Cancer Genome Atlas (TCGA) (n = 53) based on HPV transcript expression, and identified 4 HPV-related subtypes (E2/E5, E6/E7, E1/E4 and L1/L2). Utilizing both viral transcript and TME subtypes, we found that the E2/E5 HPV subtype was associated with an immune-enriched TME and had a higher overall survival compared to other subtypes. The E2/E5 subtype was also enriched for samples without HPV-genome integration, suggesting that episomal HPV status and E2/E5 expression pattern may be associated with an inflamed microenvironment and improved prognosis. In contrast, E6/E7 subtype samples were associated with the fibrotic and immune-desert TME subtypes, with lower values of T-cell and B-cell gene expression signatures and lower overall survival. Both E1/E4 and L1/L2 subtypes were associated with the immune-enriched luminal subtype. Our results suggest that HPV- transcript expression patterns may drive modulation of the TME and thereby impact prognosis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reliable Online Auditory Cognitive Testing: An observational study\nAbstract: Technological advances have allowed researchers to conduct research remotely. Online auditory testing has received interest since the Covid-19 pandemic. A number of web-based developments have improved the range of auditory tasks during remote participation. Most of these studies have been conducted in young, motivated individuals who are comfortable with technology. Such studies have also used stimuli testing auditory perceptual abilities. Research on auditory cognitive abilities in real-world older adults is lacking.  In this study, we assess the reproducibility of a range of auditory cognitive abilities in older adults, with a range of hearing abilities, who took part in in-person and online experiments. Participants performed a questionnaire-based assessment and were asked to complete two verbal speech-in-noise perception tasks, for digits and sentences, and two auditory memory tasks, for different sound features. In the first part of the study, 58 Participants performed these tests in-person and online in order to test the reproducibility of the tasks. In the second part, 147 participants conducted all the tasks online in order to test if previously published findings from in-person research were reproducible.  We found that older adults under the age of 70 and those with a better hearing were more likely to take part in online testing. The questionnaire-based test had significantly better reproducibility than the behavioural auditory tests but there were no differences in reproducibility between in-person and online auditory cognitive metrics. Relationships between relationships with age and hearing thresholds in an in-person or online setting were not significantly different.  Furthermore, important relationships between auditory metrics, evidenced in literature previously, were reproducible online.  This study suggests that auditory cognitive testing may be reliably conducted online.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of Monitoring and Evaluation Systems on the Performance of Neonatal Intensive Care Unit at Yumbe Regional referral hospital; A Pre-post quasi-experimental study design\nAbstract: PurposeThis study explored the effect of implementing monitoring and Evaluation (M&E) systems on the performance of the Neonatal Intensive care Unit at Yumbe regional referral hospital.  MethodsA pretest-posttest quasi-experimental design was employed involving 236 neonates, with 103 in the pretest group (Before the implementation monitoring and evaluation systems) and 130 in the posttest group (after the implementation of monitoring and evaluation). The intervention lasted 105 days. Key performance indicators (KPIs) such as; neonatal mortality rates, length of stay, neonatal intensive cares effectiveness, morbidity rate, survival rates, and infection control were measured. Patient satisfaction as a secondary outcome was also explored through questionnaire surveys. Data collected was entered directly in Micro software, and exported to the STATA version 18 for analysis  ResultsNeonatal mortality rates significantly decreased from 19.4% in the pretest group to 7.7% in the posttest group (P<0.01). The survival rates improved from 80.6% in the pretest group to 92.3% in the posttest group. The average length of stay was reduced from 10 days (SD=4) to 8 days (SD=3) (P<0.05). Neonatal intensive care effectiveness scores improved from a mean of 2.8 to 3.5 (P<0.01). Compliance with Neonatal intensive care unit protocols increased from 70% to 80% (P<0.01). The reliability of monitoring and evaluation components was high, with Cronbachs alpha values ranging from 0.754 to 0.915  ConclusionImplementation of monitoring and evaluation systems significantly enhanced NICUs performance, reduced mortality rate, improved survival rates and improved patient satisfaction. These findings underline the importance of M&E frameworks in optimizing neonatal care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Postoperative 20% Albumin and Cardiac Surgery Associated Kidney Injury, Statistical Analysis Plan and Updated Protocol\nAbstract: BackgroundThe incidence of cardiac surgery associated acute kidney injury (CS-AKI) remains high. Patients who develop AKI after cardiac surgery are at higher risk of persistent renal dysfunction and increased long-term mortality. The risk of CS-AKI is significantly increased in patients with chronic kidney disease and in patients having prolonged bypass for complex surgery. Previous trials of albumin did not show any benefit in prevention of CS-AKI. These trials, however, did not focus on high-risk patients and used albumin as a resuscitation strategy. The aim of ALBICS-AKI is to demonstrate the effect of concentrated albumin infusion on CS-AKI in high-risk patients undergoing cardiac surgery compared with standard care.  MethodsALBICS-AKI is an investigator initiated, multicentre, randomised, open label trial. Seven centres in Australia and Italy will participate in the trial. We will randomise 620 adult patients who will undergo on-pump cardiac surgery with one of the following: an estimated glomerular filtration rate <60 ml/min/1.73m2, combined valve/s, coronary artery, or surgery involving thoracic aorta. Within 6 hours after surgery, a 20% albumin infusion will commence at 20ml/h for 15 hours. All patients will receive standard care as per institutional protocols. The primary outcome is the proportion of patients with AKI according to creatinine based KDIGO definition at hospital discharge or day 28, whichever comes first. Secondary outcomes include Major Adverse Kidney Events at day 28, AKI stage II and III, need for renal replacement therapy, and hospital mortality.  Ethics and disseminationThe trial was approved by Monash Health Lead Research Committee for Australian sites and by the Italian Medicine Agency for Italian sites. The estimated study completion date is Sep 2024. The results will be presented at major conferences and submitted for publication in peer-reviewed journals.  Trial registration numberAustralian New Zealand Clinical Trials Registry ACTRN12619001355167\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association Between Life's Essential 8 and Atherogenic Index of Plasma in Adults: Insights from NHANES 2007-2018\nAbstract: ObjectivesThis study aimed to investigate the relationship between Lifes Essential 8 (LE8) and the Atherogenic Index of Plasma (AIP).  MethodsWe conducted an analysis of data from 8,215 U.S. adults aged 20 years and older, utilizing the National Health and Nutrition Examination Survey data from 2007 to 2018. Based on LE8 scores, Cardiovascular Health (CVH) was stratified into three levels--low, moderate, and high--while AIP was categorized into four risk levels: extremely low (AIP<-0.3), low (-0.3[&le;]AIP<0.1), medium (0.1[&le;]AIP<0.24), and high (AIP[&ge;]0.24). Weighted ordinal logistic regression analysis was utilized to examine the association between CVH scores and AIP risk levels, adjusting for potential confounding variables.  ResultsA significant inverse correlation exists between CVH scores and AIP risk levels (OR=0.51, 95%CI: 0.49-0.54, P<0.001). Higher CVH scores were associated with lower AIP risk levels, while lower CVH scores corresponded to elevated AIP risk levels. Notably, improvements in specific CVH components--such as Body Mass Index and Blood Lipids--exhibited a strong relationship with reductions in AIP risk levels.  ConclusionsEnhancing CVH is vital for effectively reducing AIP risk levels, thus underscoring the critical importance of health management strategies in the prevention of cardiovascular diseases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A longitudinal study of depressive symptom trajectories and risk factors in congestive heart failure\nAbstract: BackgroundDepression is prevalent among patients with congestive heart failure (CHF) and is associated with increased mortality and healthcare utilization. However, most research has focused on high-income countries, leaving a gap in knowledge regarding the relationship between depression and CHF in low-to-middle-income countries (LMICs). This study aimed to delineate depressive symptom trajectories and identify potential risk factors for poor outcomes among CHF patients.  MethodsLongitudinal data from 783 patients with CHF from public hospitals in Karachi, Pakistan was analyzed. Depressive symptom severity was assessed using the Beck Depression Inventory (BDI). Baseline and 6-month follow-up BDI scores were clustered through Gaussian Mixture Modeling to identify distinct depressive symptom subgroups and extract trajectory labels. Further, a random forest algorithm was utilized to determine baseline demographic, clinical, and behavioral predictors for each trajectory.  ResultsFour depressive symptom trajectories were identified:  good prognosis,  remitting course,  clinical worsening, and  persistent course. Risk factors associated with persistent depressive symptoms included lower quality of life and the New York Heart Association (NYHA) class 3 classification of CHF. Protective factors linked to a good prognosis included less disability and a non-NYHA class 3 classification of CHF.  ConclusionsBy identifying key characteristics of patients at heightened risk of depression, clinicians can be aware of risk factors and better identify patients who may need greater monitoring and appropriate follow-up care.  Clinical Perspective What is new?O_LITo the best of our knowledge, this is the first study to use machine learning techniques to investigate depressive symptom trajectories in CHF patients from an LMIC. C_LIO_LIFour distinct depressive symptom trajectories were identified, ranging from good prognosis to persistent depressive symptoms. C_LIO_LIThis study highlights protective and risk factors associated with these trajectories based on patients demographics and clinical presentations at baseline. C_LI  What are the clinical implications?O_LIPersonalized interventions based on identified protective factors for high-risk CHF patients could enhance both mental health and cardiovascular outcomes. C_LIO_LIEarly detection and management of depression, particularly in patients with poor quality of life or advanced heart failure, may help reduce healthcare utilization and mortality. C_LIO_LIThis study emphasizes the importance of routine depression screening in CHF patients, especially in LMICs, to enhance overall patient care and outcomes. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Tucaresol: An Oral Candidate Drug With Two Distinct Antiviral Mechanisms.\nAbstract: Globally, approximately 39 million people are living with Human Immunodeficiency Virus, HIV, arising from approximately 86 million infections since this epidemic began in 1981. However, the number of HIV infections is unevenly distributed with two thirds of global infections confined to Sub-Saharan Africa. Due to viral drug resistance, the most effective treatment requires a triple drug combination thereby adding to the complexity and cost of therapy. As such, many people living with HIV or at risk of infection do not have access to prevention or treatment of this potentially fatal disease. There is no cure for HIV [1]. Tucaresol is an orally active clinical stage drug which functions as a host targeted antiviral agent by protection or reconstitution of CD4+ T helper immune cells. We report herein that Tucaresol also displays in-vitro activity against HIV in infected human peripheral blood mononuclear cells. Although this in-vitro antiviral activity is not potent, the excellent safety profile and bioavailability of Tucaresol, along with its low Molecular Weight, support attainment of relevant drug concentrations in man to achieve significant in-vivo activity. This is demonstrated by previously reported stabilization of viremia in a prior proof of concept phase 1b/2a HIV clinical trial [2]. It is possible that the significant in-vivo activity of Tucaresol arises from synergy between co-stimulation of CD4+ T helper cells and the direct activity against virally infected cells. A pan in-vitro viral screen of Tucaresol further revealed a weak, direct antiviral activity against human herpes virus 6B, human papillomavirus 11, measles virus and hepatitis B virus.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparative Risk of the Onset of Atrial Fibrillation after Icosapent Ethyl versus Omega-3-Acid-Ethyl-Esters Adjuvant to Statins\nAbstract: BackgroundIcosapent ethyl (ICP), an ethyl ester of eicosapentaenoic acid (EPA), and omega-3 acid ethyl esters (DHA/EPA), comprised of ethyl esters of EPA and doxosahexaenoic acid (DHA), are approved as adjunctive therapy to statins for reducing adverse cardiovascular events (CV) in patients with CV risks. However, there are concerns regarding a potential association between ICP and atrial fibrillation (AF). This study evaluated the incidence of AF onset between ICP and DHA/EPA when used as adjuvant therapy with statins.  Methods and ResultsThis retrospective study utilized administrative healthcare claims to analyze adult AF-naive patients from one year preceding their first prescription for ICP or DHA/EPA. These patients were followed for two years, spanning from2013-2021. AF incidence was assessed during active treatment with either ICP or DHA/EPA as adjunct statin therapy. A propensity score (PS) matched cohort controlled for baseline characteristics and the effect of calendar year on the use of ICP or DHA/EPA. The cumulative incidence of AF was estimated using a product-limit estimator and compared between groups using a Cox proportional hazards regression model. The PS-matched cohort included 17,638 participants with a mean age 56 years, predominantly male (65.7% ICP vs. 64.5% DHA/EPA). Over two years, the cumulative incidence of AF from ICP and DHA/EPA was 5.32% and 3.99% respectively, resulting in a HR of 1.242 (95% CI: 1.061 to 1.455).  ConclusionsIn adult AF-naive patients, ICP, when compared to DHA/EPA in conjunction with statin therapy, was associated with a significantly higher significant risk of developing AF.  RESEARCH PERSPECTIVEO_ST_ABSWhat is New?C_ST_ABSO_LIDoes icopasent ethyl (ICP), an ethyl ester of eicosapentaenoic acid (EPA) and omega-3 acid ethyl esters comprised of ethyl esters of EPA and doxosahexaenoic acid (DHA) in atrial fibrillation (AF)-naive patients taking statins increase the incidence of AF? C_LIO_LIOver two years, the cumulative incidence of AF from ICP and DHA/EPA was 5.32% and 3.99% respectively, resulting in a HR of 1.242 (95% CI: 1.061 to 1.455). C_LIO_LIIn adult AF-naive patients, ICP, when compared to DHA/EPA in conjunction with statin therapy was associated with a higher significant risk of developing AF. C_LI  What Question Should be Addressed Next?O_LIWhat should be considered as clinical and demographic factors in identifying patients at risk of atrial fibrillation prior to being prescribed ICP or DHA/EPA agents. C_LIO_LIInvestigation into the underlying mechanism of the increase in atrial fibrillation with marine omega-3 ethyl esters should continue. C_LIO_LIUnderstanding AF outcomes from ICP or DHA/EPA use including AF burden, need for AF medical or electrophysiological interventions, and health-care total costs. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Perceived barriers to research and scholarship among physicians\nAbstract: IntroductionInadequate scholarship is a common concern in graduate medical education. Many barriers to scholarship have been identified, but there are limited data on which are most important. A rank-order of barriers from learners perspectives would better enable programs to address perceived barriers.  MethodsGiven that learners are experts in their own perceptions, we applied the Delphi method of generating consensus expert opinion to construct ranked lists of physician-perceived barriers to scholarly activity at various sites. The survey was conducted within three separate health systems. Respondents were asked to identify their perceived barriers via free text and the listed barriers were consolidated by the research team. In the second round, respondents were presented with the consolidated lists and asked to rank them. In the third and final round, each respondent was shown a comparison of their own rankings to that of their peers and given an opportunity to make changes. Ranking differences between programs were compared using Rank Biased Overlap (RBO).  ResultsThe Delphi method is a straightforward method to obtain a ranked list of perceived learner barriers to scholarly activity; its primary limitation is learner engagement and, of note in our study, high dropout rates. RBO is an effective method of ranking differences between programs and specialties. Top barriers across programs included time, overwhelm with the research process, and lack of interest or energy.  DiscussionSeveral of the identified barriers may be addressed with enthusiastic mentors, streamlined administrative processes, and education. This could be done within a hospital system or on a national level through specialty organizations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Whole-exome sequencing study of opioid dependence offers novel insights into the contributions of exome variants\nAbstract: Opioid dependence (OD) is epidemic in the United States and it is associated with a variety of adverse health effects. Its estimated heritability is [~]50%, and recent genome-wide association studies have identified more than a dozen common risk variants. However, there are no published studies of rare OD risk variants. In this study, we analyzed whole-exome sequencing data from the Yale-Penn cohort, comprising 2,100 participants of European ancestry (EUR; 1,321 OD cases) and 1,790 of African ancestry (AFR; 864 cases). A novel low-frequency variant (rs746301110) in the RUVBL2 gene was identified in EUR (p=6.59x10-10). Suggestive associations (p<1x10-5) were observed in TMCO3 in EUR, in NEIL2 and CFAP44 in AFR, and in FAM210B in the cross-ancestry meta-analysis. Gene-based collapsing tests identified SLC22A10, TMCO3, FAM90A1, DHX58, CHRND, GLDN, PLAT, H1-4, COL3A1, GPHB5 and QPCTL as top genes (p<1x10-4) with most associations attributable to rare variants and driven by the burden of predicted loss-of-function and missense variants. This study begins to fill the gap in our understanding of the genetic architecture of OD, providing insights into the contribution of rare coding variants and potential targets for future functional studies and drug development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A systematic review of psychological factors influencing attitudes and intentions toward, and uptake of, Covid-19 vaccines in adolescents\nAbstract: Vaccination was a key measure to tackle the Covid-19 pandemic, however adolescents were less likely than adults to accept the vaccine. Low vaccine uptake reduces the effectiveness of vaccination campaigns and threatens global public health. Understanding why adolescents are hesitant to accept new vaccines is therefore crucial to support the development of novel vaccine uptake interventions. Prior reviews have included far fewer citations, excluded qualitative data, studies after 2022 and have not mapped adolescent Covid-19 vaccine behaviour onto psychological models. This systematic review investigated psychological factors influencing attitudes and intentions toward and uptake of Covid-19 vaccines in adolescents aged 10 to 19 years globally. It mapped results onto the COM-B framework to inform future interventions. Our search identified 25,354 citations, and included 77 in this review. The quality of studies was mixed, predominantly cross-sectional in design. According to our review, key influences on adolescent Covid-19 vaccine behaviour were: i) Reflective motivation (safety concerns, perceived susceptibility to/severity of Covid-19, perceived vaccine effectiveness, ii) Social opportunity (social norms, autonomy and prosocial attitudes), iii) Psychological capability (attitude and knowledge about vaccines). Our review provides new insights into psychological factors influencing adolescent Covid-19 vaccine behaviour, and maps factors to the COM-B model of behaviour change. To improve vaccine uptake, future vaccine interventions should support adolescents to think critically about the pros and cons of vaccines and consider external influences on their decisions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prenatal Exposure of Pesticide Mixtures and the Placental Transcriptome: Insights from Trimester-specific, Sex-Specific and Metabolite-Scaled Analyses in the SAWASDEE Cohort\nAbstract: We investigated the effect of exposure to pesticide mixtures during pregnancy on the placental transcriptome, to link these exposures and placental functions. The Study of Asian Women and their Offsprings Development and Environmental Exposures (SAWASDEE) enrolled pregnant farmworkers from Thailand (n=248), who were primarily exposed to organophosphate (OP) and pyrethroid pesticides. We measured maternal urinary levels of six non-specific OP metabolites expressed as three summary measures (dimethylalkylphosphates (DMAP), diethylalkylphosphates (DEAP), and dialkylphosphates (DAP) and three pyrethroid metabolites (3-phenoxybenzoic acid (3-PBA), cis- and trans-3-(2,2-dichlorovinyl)-2,2-dimethylcyclopropane carboxylic acid (Cis-DCCA, Trans-DCCA) during early, middle, and late pregnancy, and adjusted for urine dilution using creatinine. RNA-sequencing was used to profile the placental transcriptome from which 21 co-expression network modules were identified by Weighted Gene Co-expression Network Analysis. Quantile g-computation analysis identified an average pregnancy positive mixture exposure effect on the E2f Target Module ({beta} = 0.013, p = 0.012) and a negative mixture exposure effect ({beta} = -0.016, p = 0.008) on the Myogenesis Module. The pesticide metabolites driving the associations differed for each module, highlighting differential susceptibilities within the placental transcriptome to various pesticides. When stratifying by infant sex, the average pregnancy mixture exhibited a significant negative effect ({beta}= -0.018, P=0.016) on the Myogenesis Module only in females; other modules, such as epithelial-mesenchymal transition, though not demonstrating an overall mixture effect, did demonstrate differential impacts of the mixture by sex. Pesticide mixtures in both the second trimester ({beta} = -0.013, p = 0.015) and the third trimester ({beta} = -0.012, p = 0.028) exhibited consistently significant negative associations with the Myogenesis module. These findings underscore the importance of considering the prenatal environment more holistically, understanding the placentas susceptibility to contaminants, and incorporating sex-specific analyses to understand differential impacts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Health professionals beliefs and attitudes towards preconception care: A systematic review\nAbstract: BackgroundHealth professionals have previously identified various barriers and factors that would help facilitate preconception care services in healthcare settings. Clinically relevant preconception information and clinical practice guidelines have since been developed to aid health professionals in preconception care delivery. This systematic review aimed to 1) synthesise recent literature (past five years) describing health professionals beliefs and attitudes towards preconception care services or programmes and 2) determine if the experience of health professionals providing preconception care has changed compared to literature reviews conducted more than five years ago.  MethodsFive databases were searched between 27/01/2016 and 27/01/2022. Primary quantitative and qualitative research studies were included if they examined health professionals beliefs and attitudes towards delivering preconception care services or programmes. Study quality was assessed using the CASP Checklist (qualitative studies) and AXIS tool (quantitative studies). Data synthesis used thematic categorisation adapted from the framework approach.  ResultsTwenty-one studies were included (n=8 qualitative, n=11 quantitative, n=2 mixed-methods studies). Methodological quality was generally good for qualitative studies but varied for quantitative studies. The results covered three categories: 1) addressing preconception care health literacy (i.e. lack of knowledge, awareness, training and resources), 2) clinical practicalities of preconception car e (i.e. need for coordination of care and clarity on role responsibility), and 3) the role of the patient (i.e. need for public health education to support patient-led conversations).  ConclusionsLittle has changed regarding the barriers and facilitators to providing preconception care reported by health professionals. To improve the provision of preconception care, there is a need to co-develop professional and public preconception health education, clinical resources, and a coordinated preconception healthcare service model.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ich-Mupong, a swollen stomach: An ethnographic study of the daily lived experiences of schoolchildren in schistosomiasis high transmission areas along Lake Albert, Hoima District\nAbstract: BackgroundOur primary focus was Schistosoma mansoni infection and schoolchildren. Within communities the social environment may promote individual risk of infection for the school-aged children. There will also be demographic groups who are not targeted or reached by preventive chemotherapy campaigns. The behaviours of these other groups will interact with those of school-aged children, resulting in further infection risk through exposure-related behaviours. Furthermore, perception of the disease may significantly influence the schoolchildrens lived experience of the infection and associated disease. It is therefore crucial to document the daily experiences of schoolchildren living in schistosomiasis high transmission areas along Lake Albert, Hoima District.  MethodsAn ethnographic study explored schoolchildrens perspectives and daily life organisations that shape their risk of schistosomiaisis and their perceptions of the disease. The study was conducted between November 2022 and August 2023. It involved in-depth interviews with schoolchildren and their parents, key informant interviews, focus group discussions with schoolchildren, and participant observations. Data was analysed using a reflexive thematic analysis. Code reports were generated inductively using ATLAS.ti (Version 7).  ResultsThe study revealed a significant level of knowledge and awareness about schistosomiasis among schoolchildren. They had understanding of the risk factors, continued exposure, and experiences of illness, though they had little autonomy to address these through their own behaviour as they were influenced by the behaviour of others and macro-factors such as WASH provision and economic need. Study participants experienced individual-level effects of schistosomiasis such as educational impacts and isolation as a significant form of stigma.  ConclusionsThere is a need for continued community sensitisation and awareness campaigns to address social stigma, educational impact, and contamination and exposure-related behaviours. National and regional policies and programmes on WASH, livelihood and poverty eradication programmes need to be revisited in schistosomiasis high transmission areas to help provide alternatives and improve schoolchildrens lived experiences.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring subthreshold functional network alterations in women with phenylketonuria by higher criticism\nAbstract: ObjectivePhenylketonuria (PKU) is an inherited disorder of amino acid metabolism. Despite early dietary treatment, cognitive functioning of patients has been reported as being inferior to healthy controls. Objective of this study was to assess functional connectivity (FC) alterations in PKU in cognition-related brain networks by resting-state functional magnetic resonance imaging. We followed a hierarchical analysis approach partially based on higher criticism (HC) statistics as previously applied in a larger sister-project in fetal alcohol syndrome.  ResultsAfter exclusions for excessive head movement, 11 female young adults with early-treated PKU (age: 27.2 {+/-} 3.7 years) and 11 age-matched female healthy controls (age: 25.9 {+/-} 3.8 years) were included in the analysis. We observed effects within attention networks and the default mode network, but not in fronto-parietal networks, at the HC-based intermediate analysis level. No between-network FC differences were found. In the most detailed analysis level, we could not identify single affected functional connections. Despite statistical power limitations in this small sample, findings are in line with previously reported FC alterations in PKU and the cognitive profile in young adults with PKU, particularly with the still uncertain notion that cognitive control deficits might become less pronounced when PKU patients reach adulthood.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of Item-Level Responses to Cognitive Function Index with Tau Pathology and Hippocampal volume in The A4 Study\nAbstract: BackgroundAlzheimers Disease (AD) has a lengthy asymptomatic preclinical phase during which individuals may show pathological signs like {beta}-amyloid (A{beta}) pathology and tau tangles without noticeable objective cognitive impairments. Subjective cognitive impairment reports may offer valuable and early insights into individuals cognitive functioning and serve as indicators of early stages of cognitive decline.  ObjectiveTo investigate the associations of the item-level response to Cognitive Function Index (CFI) by participant and study partner with tau pathology and adjusted hippocampal volume (HVa).  MethodParticipants were 339 cognitively unimpaired, A{beta} positive, individuals enrolled in the Anti-Amyloid Asymptomatic Alzheimers (A4) Study who underwent tau-PET imaging. Participants and their study partners assessed subjective changes in cognition and function over the past year using the 15-item CFI questionnaire. For each CFI item, the relationship among tau, HVa, and CFI reports was investigated.  ResultParticipants were on average 72.38 (SD = 4.87) years old, 58.1% were female, and 23.6% were tau positive. Higher tauMTL was significantly associated with participant report of decline on three CFI items including depending on written notes, seeing a doctor for memory concern, and feeling lost while navigating. Higher tauMTL was associated with study partner report of decline on two different items: needing help from others to remember appointments/occasions and asking same questions. Additionally, HVa was linked to challenges with driving for participants and noticeable memory decline for study partners.  ConclusionWe showed that early changes reported on specific items of the CFI are associated with higher tauMTL and lower HVa in A{beta}+ participants. Different CFI items were associated with tau and hippocampal volume for participants and study partners, highlighting the importance of both perspective.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: First-in-human evaluation of memory-like NK cells with an IL-15 super-agonist and CTLA-4 blockade in advanced head and neck cancer\nAbstract: Cytokine induced memory-like natural killer (CIML NK) cells combined with an IL-15 super-agonist (N-803) are a novel modality to treat relapsed/refractory head and neck cancer. We report data from a phase I trial of haploidentical CIML NK cells combined with N-803 with or without ipilimumab (IPI) in relapsed/refractory head and neck cancer patients after a median of 6 prior lines of therapy. The primary endpoint was safety, which was established, with dose-limiting toxicity in 1/10 patients. A promising though transient disease control rate of 70% correlated with donor NK cell expansion, the latter occurring irrespective of IPI. High-resolution immunophenotypic and transcriptional profiling characterized the NK cells and their interacting partners in vivo. IPI was associated with contraction of Treg:Tcon, rapid recovery of recipient CD8+ T cells, and accelerated rejection of donor NK cells. These results inform evaluation of CIML NK therapy for advanced malignancies, with considerations for combination with IPI.  SignificanceCIML NK cells combined with N-803 and ipilimumab to treat head and neck cancer is safe, and associated with a more proliferative NK cell phenotype. However, the combination leads to reduced HLA mismatched NK cell persistence, resulting in an important limitation informing future NK cell combination therapies in clinical trials.  Trial RegistrationNCT04290546  FundingGateway for Cancer Research, Ted and Eileen Pasquarello Research Fund, Goldfarb and Rudkin Family Fellowship, Dr. Antins Research Fund, Massey Family Fund. MS is funded by the Sidney Farber Scholar Program, Dana Farber, and RR is a recipient of the Career Development Award from the Leukemia and Lymphoma Society and is a member of the Parker Institute for Cancer Immunotherapy at Dana-Farber Cancer Institute.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Developing a virtual Endoscopic Surgery Planning system to optimize surgical outcomes\nAbstract: ObjectivePlanning and predicting functional outcomes of endoscopic sinus surgeries (e.g., nasal airflow) based solely on visualizing Computerized Tomography (CT) or endoscopy poses a challenge to produce optimal clinical outcomes.  Study designTechnology development, retrospective case report.  MethodsA virtual surgery planning (VSP) tool is developed that can load any patients CT data and allow surgeons to remove obstructive tissue using both visual and haptic feedback endoscopically. Pre-calculated airflow resistance, wall shear stress, pressure drop are displayed on the anatomy to identify potential sites of obstruction. After each virtual surgery, changes in nasal airflow can be computed, and the process is reiterated until an optimal result is reached.  ResultsAs proof-of-concept, a series of isolated or combined procedures were performed on CT of one patient, who had olfactory losses that may involve obstructions blocking the air/odor flow to the olfactory fossa (OF). For this patient, an isolated medial partial middle turbinectomy (PMT) demonstrated the best outcome, better than traditionally performed lateral PMT, while septal body reduction worsened air/odor flow to OF.  ConclusionThis proof of concept case report demonstrates the potential usefulness of VSP in preoperative planning based on objective benchmarks and could be a valuable tool for optimizing future surgical outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Self Reported Financial Difficulties Among Patients with Multiple Myeloma and Chronis Lymphocytic Leukemia Treated at U.S. Community Oncology Clinics (Alliance A231602CD)\nAbstract: ObjectivesTo estimate the proportion and correlates of self-reported financial difficulty among patients with multiple myeloma (MM) or chronic lymphocytic leukemia (CLL).  Setting23 U.S. community and minority oncology practice sites affiliated with the National Cancer Institute Community Oncology Research Program (NCORP).  Participants521 patients ([&ge;]18 years) with MM or CLL were consented and 416 responded to a survey (completion rate=79.8%). Respondents had a MM diagnosis (74.0%), an associate degree or higher (53.4%), were White (89.2%), insured (100%) and treated with clinician-administered drugs (68.0%).  InterventionsObservational, prospective, protocol-based survey administered in 2019-2020.  Primary and secondary outcome measuresFinancial difficulty was assessed using a single-item standard measure, the EORTC QLQC30: \"Has your physical condition or medical treatment caused you financial difficulties in the past year?\" and using an  any-or-none composite measure of 22 items assessing financial difficulty, worries and the use of cost-coping strategies. Multivariable logistic regression models assessed the association between financial difficulty, diagnosis, and socioeconomic and treatment characteristics.  Results16.8% reported experiencing financial difficulty using the single-item measure and 60.3% using the composite measure. Most frequently endorsed items in the composite measure were financial worry about having to pay large medical bills related to cancer and difficulty paying medical bills. Financial difficulty using the single-item measure was associated with having MM versus CLL (adjusted odds ratio [aOR], 0.34; 95% CI, 0.13-0.84; P=.02), having insurance other than Medicare (aOR, 2.53; 95% CI, 1.37-4.66; P=.003), being non-White (aOR, 2.21; 95% CI, 1.04-4.72; P=.04), and having a high school education or below (aOR, 0.36; 95% CI, 0.21-0.64; P=.001). Financial difficulty using the composite measure was associated with having a high school education or below (aOR, 0.62; 95% CI, 0.41-0.94; P=.03).  ConclusionsU.S. patients with blood cancer report financial difficulty, especially those with low socio-economic status. Evidence-based and targeted interventions are needed.  Study Strengths and LimitationsO_ST_ABSStrengthsC_ST_ABSO_LINCORP, a program of the National Cancer Institute (NCI), is a national network for cancer clinical trials and care delivery studies that is comprised of 7 research bases and 46 community sites across the U.S., 14 of which are designated as Minority/Underserved community sites. The study had strong engagement and participation across diverse NCORP Sites across the country and their affiliates. Strong site engagement resulted in high patient recruitment and retention rates for this study (79.8%), despite coincident timing with the initial stages of the COVID-19 pandemic. C_LIO_LIThe survey tool was composed of previously validated items that were modified for this population and new questions that were evaluated for comprehension, which facilitates comparison of our findings to others previously published. Patients targeted for recruitment were treated in the community and recruitment aimed to represent the socioeconomic characteristics of the prevalent patient population. The study relied on both self-report and medical chart abstraction to establish key dependent and independent variables. C_LIO_LIThe primary outcome variable was a previously developed, and empirically tested measure, supporting study internal and external validity. We also used a secondary composite measure of financial difficulty to present a more holistic picture of how cancer diagnosis and treatment impact patients daily lives and inform decisions to delay or forego care and use cost-coping strategies. By capturing specific worries, decisions and strategies, the composite measure indicates areas where there is a need for greater patient engagement and resource provision at the site of care. C_LI  LimitationsO_LIAmong 105 participants who were not included in the final sample, the majority (n=66) were excluded from analysis because they could not be contacted within the 8-week period due to unexpectedly high recruitment volumes across sites. C_LIO_LIWhile NCORP sites from across the country participated in the study, 60% of patients recruited to the study were from the Midwest. Although this is the most representative study of financial difficulty in U.S. blood cancer patients to date, our findings may not be fully generalizable to the national CLL and MM communities due to these limitations. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pediatric Long COVID Subphenotypes: An EHR-based study from the RECOVER program\nAbstract: Pediatric Long COVID has been associated with a wide variety of symptoms, conditions, and organ systems, but distinct clinical presentations, or subphenotypes, are still being elucidated. In this exploratory analysis, we identified a cohort of pediatric (age <21) patients with evidence of Long COVID and no pre-existing complex chronic conditions using electronic health record data from 38 institutions and used an unsupervised machine learning-based approach to identify subphenotypes. Our method, an extension of the Phe2Vec algorithm, uses tens of thousands of clinical concepts from multiple domains to represent patients clinical histories to then identify groups of patients with similar presentations. The results indicate that cardiorespiratory presentations are most common (present in 54% of patients) followed by subphenotypes marked (in decreasing order of frequency) by musculoskeletal pain, neuropsychiatric conditions, gastrointestinal symptoms, headache, and fatigue.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Glucagon-Like Peptide 1 Receptor Agonists and Cardiovascular Disease Risk: Findings from Real-World Data using AI-Powered Outcomes\nAbstract: BackgroundThe SELECT trial showed cardiovascular benefits of glucagon-like peptide-1 receptor agonists (GLP-1 RAs) in obese patients with cardiovascular disease; however, real-world data (RWD) on this benefit remain limited. This study used an artificial intelligence (AI)-generated algorithm and multimodal RWD to evaluate the impact of GLP-1 RAs on cardiovascular disease risk in a population of obese patients with and without preexisting cardiovascular disease.  MethodsUsing data from the Dandelion Health RWD library, an Emulated SELECT Cohort was created to include obese patients similar to those in the SELECT trial, but with and without preexisting cardiovascular disease. An AI algorithm developed by Pheiron that used 12-lead electrocardiograms (ECGs) as a predictive biomarker for the risk of major adverse cardiovascular events (MACE) was validated and used to derive MACE risk scores for the Emulated SELECT Cohort. These outcomes were compared over time between patients who used GLP-1 RAs and non-users using inverse-probability weighted linear regression models, adjusting for key covariates.  ResultsOut-of-sample validation showed high predictive accuracy of the AI algorithm, with ROC AUCs of 0.81 for myocardial infarction (MI) and 0.75 for stroke. Increased risk scores from the algorithm were correlated with higher MACE incidence in RWD. In the Emulated SELECT Cohort of 20,795 patients, GLP-1 RA use was associated with significant attenuation of MACE risk, with reductions observed in percentile risk score for MI (4%; p<0.001) and stroke (3.6%; p<0.001) per year of use. Differences in GLP-1 RA and non-GLP-1 users were evident as early as 1.7 years, with a 15-20% difference in absolute MACE risk scores between GLP-1 RA users and non-users observed by the end of the study.  ConclusionAn AI algorithm using 12-lead ECGs accurately predicted MACE risk and could be used to model risk attenuation associated with GLP-1 RA use. Using this outcome, we find that GLP-1 RA use was associated with significant reductions in MI and stroke risk, in a broader population and within a shorter timeframe than the SELECT trial. These findings suggest potentially significant cardioprotective benefits of GLP-1 RAs in real-world settings and demonstrate a proof-of-concept for utilizing clinical AI to understand these benefits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Glucagon-Like Peptide 1 Receptor Agonists and Cardiovascular Disease Risk: Findings from Real-World Data using AI-Powered Outcomes\nAbstract: BackgroundThe SELECT trial showed cardiovascular benefits of glucagon-like peptide-1 receptor agonists (GLP-1 RAs) in obese patients with cardiovascular disease; however, real-world data (RWD) on this benefit remain limited. This study used an artificial intelligence (AI)-generated algorithm and multimodal RWD to evaluate the impact of GLP-1 RAs on cardiovascular disease risk in a population of obese patients with and without preexisting cardiovascular disease.  MethodsUsing data from the Dandelion Health RWD library, an Emulated SELECT Cohort was created to include obese patients similar to those in the SELECT trial, but with and without preexisting cardiovascular disease. An AI algorithm developed by Pheiron that used 12-lead electrocardiograms (ECGs) as a predictive biomarker for the risk of major adverse cardiovascular events (MACE) was validated and used to derive MACE risk scores for the Emulated SELECT Cohort. These outcomes were compared over time between patients who used GLP-1 RAs and non-users using inverse-probability weighted linear regression models, adjusting for key covariates.  ResultsOut-of-sample validation showed high predictive accuracy of the AI algorithm, with ROC AUCs of 0.81 for myocardial infarction (MI) and 0.75 for stroke. Increased risk scores from the algorithm were correlated with higher MACE incidence in RWD. In the Emulated SELECT Cohort of 20,795 patients, GLP-1 RA use was associated with significant attenuation of MACE risk, with reductions observed in percentile risk score for MI (4%; p<0.001) and stroke (3.6%; p<0.001) per year of use. Differences in GLP-1 RA and non-GLP-1 users were evident as early as 1.7 years, with a 15-20% difference in absolute MACE risk scores between GLP-1 RA users and non-users observed by the end of the study.  ConclusionAn AI algorithm using 12-lead ECGs accurately predicted MACE risk and could be used to model risk attenuation associated with GLP-1 RA use. Using this outcome, we find that GLP-1 RA use was associated with significant reductions in MI and stroke risk, in a broader population and within a shorter timeframe than the SELECT trial. These findings suggest potentially significant cardioprotective benefits of GLP-1 RAs in real-world settings and demonstrate a proof-of-concept for utilizing clinical AI to understand these benefits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subtyping First-Episode Psychosis based on Longitudinal Symptom Trajectories Using Machine Learning\nAbstract: Clinical course after first episode psychosis (FEP) is heterogeneous. Subgrouping longitudinal symptom trajectories after FEP would be useful for developing personalized treatment approaches, and being able to predict these trajectories at baseline would facilitate individual-level treatment planning. We utilized k-means clustering to identify distinct clusters of 411 FEP patients based on longitudinal positive and negative symptom patterns. Ridge logistic regression was then used to identify predictors of cluster membership using baseline data. Three clusters were identified, demonstrating unique demographic, clinical and treatment response profiles. Cluster 1 exhibits lower positive and negative symptoms (LS), lower antipsychotic dose, and relatively higher affective psychosis; Cluster 2 shows lower positive symptoms, persistent negative symptoms (LPPN), and intermediate antipsychotic doses; Cluster 3 presents persistently high levels of both positive and negative symptoms (PPNS), as well as higher antipsychotic doses. We effectively predicted patients cluster membership (AUC of 0.74). The most important predictive features included contrasting trends of apathy, affective flattening, and anhedonia for the LS and LPPN clusters. Global hallucination severity, positive thought disorder and manic hostility predicted PPNS. These results help parse the heterogeneity of FEP trajectories and may facilitate the development of personalized treatment approaches tailored to cluster characteristics.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of a Cardiac and Psychosocial Rehabilitation Program on Anxiety, Depression, Self-Efficacy, Quality of Life, and Exercise Capacity in Young Adults With Fontan Circulation: A Randomized Controlled Trial\nAbstract: BACKGROUNDYoung adults with Fontan circulation (FC) face psychosocial, physical, and environmental challenges and are vulnerable to emotional distress. They need holistic intervention programs to face these problems and enhance their quality of life. This study developed and evaluated a cardiac and psychosocial rehabilitation (CPR) program for young adults with FC.  METHODS AND RESULTSThirty-eight young adults with FC aged 18-23 years were prospectively recruited from an outpatient clinic and randomized into a CPR group (n = 12) that underwent eight weekly group-based sessions combining a psychosocial program based on cognitive behavioral therapy with home-based cardiac rehabilitation (CR), a CR group (n = 12) that received only home-based CR, and a usual care control group (n = 12). The study assessed CPR program effectiveness based on the Hospital Anxiety and Depression Scale, self-efficacy, quality of life, and exercise capacity testing at three time points: pre-intervention, post-intervention, and four weeks post-intervention. Participants average ages were 19.75 (2.28), 19.65 (1.79), and 20.38 (1.85) years in the CPR, CR, and control groups, respectively; 50% (CPR group) to 53.8% (CR and control groups) of the participants were male. After eight weeks, depression and anxiety decreased, whereas self-efficacy and quality of life increased in the CPR group compared with the CR and control groups. The groups showed no differences in exercise capacity.  CONCLUSIONCPR can be part of an intervention for alleviating psychological distress and improving self-efficacy in young adults with FC. Efforts should be made to increase the efficacy of home-based CR.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Socio-medical Factors Associated with Neurodevelopmental Disorders on the Kenyan Coast\nAbstract: BackgroundNeurodevelopmental disorders (NDDs) are a group of conditions with their onset during the early developmental period and include conditions such as autism, intellectual disability and attention deficit hyperactivity disorder (ADHD). Occurrence of NDDs is thought to be determined by both genetic and environmental factors, but data on the role of environmental risk factors for NDD in Africa is limited. This study investigates environmental influences on NDDs in children from Kenya. This case-control study compared children with NDDs and typically developing children from two studies on the Kenyan coast that did not overlap.  Methods and FindingsWe included 172 of the study participants from the Kilifi Autism Study and 151 from the NeuroDev Study who had a diagnosis of at least one NDD and 112 and 73 with no NDD diagnosis from each study, respectively. Potential risk factors were identified using unadjusted univariable analysis and adjusted multivariable logistic regression analysis. Univariable analysis in the Kilifi Autism Study sample revealed hypoxic-ischaemic encephalopathy conferred the largest odds ratio (OR) 10.52 (95%CI 4.04 - 27.41) for NDDs, followed by medical complications during pregnancy (gestational hypertension & diabetes, eclampsia, and maternal bleeding) OR: 3.17 (95%CI 1.61 - 6.23). In the NeuroDev study sample, labour and birth complications (OR: 7.30 (2.17 - 24.61)), neonatal jaundice (OR: 5.49 (95%CI 1.61 - 18.72)) and infection during pregnancy (OR: 5.31 (1.56 - 18.11)) conferred the largest risk associated with NDDs. In the adjusted analysis, seizures before age 3 years in the Kilifi Autism study and labour and birth complications in the NeuroDev study conferred the largest increased risk. Higher parity, the child being older and delivery at home were associated with a reduced risk for NDDs.  ConclusionRecognition of important risk factors such as labour and birth complications could guide preventative interventions, developmental screening of at-risk children and monitoring progress. Further studies examining the aetiology of NDDs in population-based samples, including investigating the interaction between genetic and environmental factors, are needed.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Relationship between blood-cerebrospinal fluid barrier integrity, cardiometabolic and inflammatory factors in schizophrenia-spectrum disorders\nAbstract: AbstractThe blood-cerebrospinal fluid barrier (BCB) builds an integral interface between the central nervous system and the periphery and appears to be impaired in a substantial proportion of individuals with schizophrenia-spectrum disorders (SSD). Even though a disruption of the BCB is associated with higher symptom severity, factors linked to BCB disruption in SSDs have been minimally investigated.  To address this gap, 57 inpatients with SSD underwent cerebrospinal fluid (CSF) and blood analyses as well as comprehensive clinical assessments. In a subgroup of 28 participants structural magnetic resonance imaging (MRI) was performed. We developed a BCB dysfunction score, employing principal component analysis of CSF/serum albumin, CSF/serum IgG ratios and total protein levels in CSF, with higher values indicating stronger abnormalities. We calculated multiple regression models to explore the associations between BCB integrity and cardiometabolic, inflammatory, brain morphometric, and clinical measures respectively.  BCB dysfunction score was negatively associated with high-density lipoprotein cholesterol and positively associated with total cholesterol, low-density lipoprotein cholesterol, and triglycerides. Furthermore, we observed a trend towards a positive association between BCB dysfunction score and treatment resistance that did not survive multiple testing correction. We did not find significant associations between the BCB composite score and any other assessed cardiometabolic, inflammatory or cerebroventricular measures.  These findings suggest that BCB integrity is associated with dyslipidemia in SSD, highlighting the interplay between cardiometabolic risk factors and brain health in SSD. Addressing cardiometabolic health in individuals with SSD might thus have implications beyond physical health, potentially influencing the integrity of the BCB and, consequently, clinical trajectories.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of epidermal melanin on peripheral pulse oximetry measurements\nAbstract: ImportancePulse oximetry is used widely to assess oxygen saturation in nearly all healthcare institutions.  ObjectiveThis study aimed to investigate the relationship between epidermal melanin concentrations, determined by colorimetry, and discrepancies between arterial blood saturation (SaO2), determined by arterial blood gas (ABG), and peripheral oxygen saturation (SpO2) determined by pulse oximetry.  Design, Setting, ParticipantsThis observational, correlational study was conducted over a one-week period in 2024 at the University of the Incarnate Word School of Osteopathic Medicine. Twenty-eight healthy adult volunteers (14 male; 14 female) with varying skin pigmentation were recruited via convenience sampling. Participants with conditions affecting oxygen saturation were excluded.  ExposureParticipants underwent non-invasive pulse oximetry to measure peripheral oxygen saturation (SpO2) and invasive arterial blood gas (ABG) analysis to measure arterial oxygen saturation (SaO2). Melanin concentrations were measured using DSM III ColorMeter on the dorsal and palmar aspects of the hand. SpO2 was measured using the Masimo MightyStat(R) Rx Fingertip Pulse Oximeter, and ABG samples were analyzed using the i-STAT(R) 1 blood analyzer.  Main Outcome(s) and Measure(s)The primary outcome was the difference between SpO2 and SaO2 across varying melanin concentrations, hypothesized before data collection.  ResultsAnalysis revealed a significant difference between SaO2 and SpO2 with a moderately positive correlation with average epidermal melanin concentrations (r = 0.432; 95% CI, 0.07 to 0.693; P = 0.022) and a moderately inverse correlation with average luminance (r = -0.492; 95% CI,- 0.731 to -0.145; P = 0.008). A strong inverse relationship was found between melanin and luminance (r = -0.85; 95% CI -0.928 to -0.698; P <0.001). PO2 emerged as the leading predictor in two regression models, explaining 50.5% of the variance when combined with melanin.  Conclusion and RelevanceTaken together, these data suggest that pulse oximetry overestimates oxygen saturation in individuals with comparatively high epidermal melanin concentrations. Future investigations that include a broader age range and participants with various comorbidities may provide a more comprehensive understanding of the impact of epidermal melanin on the accuracy of pulse oximetry readings.  Key PointsO_ST_ABSQuestionC_ST_ABSHow does epidermal melanin concentration affect the accuracy of pulse oximetry measurements compared to arterial blood gas results?  FindingsThis study found that higher epidermal melanin concentrations were associated with greater discrepancies between pulse oximetry and arterial oxygen saturation readings, suggesting that pulse oximeters may overestimate oxygen levels in individuals with darker skin tones.  MeaningHigher epidermal melanin concentrations may result in less accurate pulse oximetry measurements, potentially leading to misinterpretations of oxygen saturation in patients with darker skin tones, raising concerns about the accuracy of these devices across diverse populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gaps in protection to Anopheles exposure in high malaria endemic regencies of Papua Province, Indonesia\nAbstract: BackgroundMalaria in eastern Indonesia remains high despite significant reductions and local elimination in other parts of the country. Malaria control activities that have been implemented include early diagnosis and prompt treatment, provision of Long-lasting insecticide-treated nets (LLINs), and indoor residual spraying (IRS). To expedite malaria elimination in this region, a rapid entomological assessment combined with human behaviour observations (HBOs) were conducted in eight high malaria endemic regencies in Papua Province, Indonesia. The present study focuses on identifying gaps in protection against mosquito biting indoors and outdoors that may contribute to the sustained transmission and persistently high endemicity.  MethodsThis study was conducted alongside a rapid entomologic assessment, including human landing catches (HLCs) of adult mosquitoes. Human behavior was documented by direct observations during HLCs. HBO data focused on temporal (over the night) and spatial (domestic or peri-domestic) presence, alongside bed net usage and sleeping patterns. Household questionnaires, also conducted during entomological collections, documented data on house structure materials, practices against mosquito bites, livestock presence, as well as intervention usage.  ResultsAnalysis of human behaviors in each regency identified several indoor and outdoor gaps in protection against mosquito biting. Human exposure to mosquito bites was driven by ITN usage, IRS coverage, indoor presence without protection prior to sleeping, absence of mosquito house screens, and outdoor presence without protection.  ConclusionsData demonstrates multiple gaps in protection against mosquito exposure in all eight regencies of Papua evaluated. Indoor interventions require optimization, while current vector control activities do not presently address outdoor exposure. Measured spatial and temporal exposure may be utilized to understand protective vector interventions that may function in these spaces while also pointing to continued exposure. Additional interventions, such as community-based larval source management, may reduce exposure overall, while novel interventions like spatial repellents may fill some gaps in protection - alongside optimized case detection and treatment. Results suggest that the present strategy may be insufficient to eliminate malaria in the region, and a rethought evidence-based and adaptive strategy is required.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development and validation of a 5-year risk model using mammogram risk scores generated from screening digital breast tomosynthesis\nAbstract: Screening digital breast tomosynthesis (DBT) aims to identify breast cancer early when treatment is most effective leading to reduced mortality. In addition to early detection, the information contained within DBT images may also inform subsequent risk stratification and guide risk-reducing management. We obtained a 5-year area under the curve (AUC) = 0.78 (95% confidence interval (CI) = 0.75 - 0.80) in the internal validation. The model validated in external data (n=6,553 women; AUC = 0.77 (95% CI, 0.74 - 0.80). There was no change in the AUC when age and BI-RADS density are added to the synthetic DBT image. The model significantly outperforms the Tyrer-Cuzick model (p<0.01). Our model extends risk prediction applications to synthetic DBT, provides 5-year risk estimates, and is readily calibrated to national risk strata for clinical translation and application in the setting of US risk management guidelines. The model could be implemented within any digital mammography program.  One Sentence SummaryWe develop and externally validate a 5-year risk prediction model for breast cancer using synthetic digital breast tomosynthesis and demonstrate clinical utility by calibrating to the national risk strata.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causes of Pediatric Deaths in Lusaka, Zambia: A Quantitative Geographic Information Systems Approach\nAbstract: BackgroundWhile childhood mortality has been declining in Zambia, it remains high at 58 per 1000 live births. Importantly, many leading causes of mortality in Zambia are preventable. This study was conducted to identify clusters of childhood mortality, causes of death of recently deceased children, barriers to care, and risk factors for mortality in Lusaka, Zambia.  MethodsThis study was conducted as a prospective cohort study. Family members or lawfully authorized representatives (LARs) were interviewed when they came to pick up death certificates for recently deceased children from Lusaka Childrens Hospital. Each interview included a verbal autopsy, determination of the childs location of residence, and collection of demographic information. Demographic data was also collected from a healthy control group. Quantitative Geographic Information Systems was used to visualize mortality and evaluate for clustering.  ResultsLeading primary causes of death included malnutrition (21%), complications of chronic illnesses (16%), and central nervous system infections (13%), while the leading barriers to care were cost (58%) and difficulties with travel (53%). Compared to controls, recently deceased children came from families with significantly lower incomes (1905 Kwacha vs. 2412 Kwacha, p = 0.03) and were significantly more likely to have a history of malnutrition (16.7% vs. 1.4%, p = 0.005). Mortality was clustered in two high-population density, low-income neighborhoods in Lusaka.  ConclusionsSystems to reduce financial barriers to care and improve access to transportation could reduce childhood mortality in Lusaka. The aforementioned neighborhoods are ideal locations for public health interventions or improved healthcare services.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Qualitative Study of User Experiences in Harm Reduction Programs\nAbstract: The ongoing Canadian opioid crisis has resulted in alarming rates of overdoses and related harms. Harm reduction programs have emerged as a crucial public health strategy to mitigate these risks. The N[e]wo-Y[o]tina Friendship Centre (NYFC) offers harm reduction programs that provide a safe injection site and clean supplies to reduce substance use-associated harm. Researchers have not extensively studied the effectiveness and user experience of this program. Studies have demonstrated the effectiveness of harm reduction programs in mitigating adverse effects of drug use, such as disease transmission and overdose. This in- depth study looked at what program users went through in the NYFC harm reduction program. This was done by looking at the program environment, unexpected outcomes, reasons for seeking services, and obstacles to access. The study used a phenomenological approach, utilising semi-structured interviews with 13 participants and analysing interview data using thematic analysis2 through NVivo. The motivations for seeking services were safety, access to clean supplies, and a non-judgmental environment. Findings revealed that users valued a safe and welcoming atmosphere fostered by friendly, supportive, and non- judgmental staff. The programs positive outcomes included reduced harm, access to resources, and emotional support. Nevertheless, limited operating hours, stigma, small space, and a lack of awareness were identified as barriers to access. The study recommends improving accessibility, enhancing support systems, and addressing unanticipated outcomes like drug use enablement to optimise the programs effectiveness. This study provides valuable insights into user experience within the NYFC program. The findings inform program improvements, enhance service delivery, and contribute to a broader understanding of harm reduction strategies for addressing the opioid crisis. It emphasises the importance of user-centred approaches in developing and implementing effective harm reduction programs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Auto-segmentation of hemi-diaphragms in free-breathing dynamic MRI of pediatric subjects with thoracic insufficiency syndrome\nAbstract: PurposeIn respiratory disorders such as thoracic insufficiency syndrome (TIS), the quantitative study of the regional motion of the left hemi-diaphragm (LHD) and right hemi-diaphragm (RHD) can give detailed insights into the distribution and severity of the abnormalities in individual patients. Dynamic magnetic resonance imaging (dMRI) is a preferred imaging modality for capturing dynamic images of respiration since dMRI does not involve ionizing radiation and can be obtained under free-breathing conditions. Using 4D images constructed from dMRI of sagittal locations, diaphragm segmentation is an evident step for the said quantitative analysis of LHD and RHD in these 4D images.  MethodsIn this paper, we segment the LHD and RHD in three steps: recognition of diaphragm, delineation of diaphragm, and separation of diaphragm along the mid-sagittal plane into LHD and RHD. The challenges involved in dMRI images are low resolution, motion blur, suboptimal contrast resolution, inconsistent meaning of gray-level intensities for the same object across multiple scans, and low signal-to-noise ratio. We have utilized deep learning (DL) concepts such as Path Aggregation Network and Dual Attention Network for the recognition step, Dense-Net and Residual-Net in an enhanced encoder-decoder architecture for the delineation step, and a combination of GoogleNet and Recurrent Neural Network for the identification of the mid-sagittal plane in the separation step. Due to the challenging images of TIS patients attributed to their highly distorted and variable anatomy of the thorax, in such images we localize the diaphragm using the auto-segmentations of the lungs and the thoraco-abdominal skin.  ResultsWe achieved an average{+/-}SD mean-Hausdorff distance of [~]3{+/-}3 mm for the delineation step and a positional error of [~]3{+/-}3 mm in recognizing the mid-sagittal plane in 100 3D test images of TIS patients with a different set of [~]430 3D images of TIS patients utilized for building the models for delineation, and separation. We showed that auto-segmentations of the diaphragm are indistinguishable from segmentations by experts, in images of near-normal subjects. In addition, the algorithmic identification of the mid-sagittal plane is indistinguishable from its identification by experts in images of near-normal subjects.  ConclusionsMotivated by applications in surgical planning for disorders such as TIS, we have shown an auto-segmentation set-up for the diaphragm in dMRI images of TIS pediatric subjects. The results are promising, showing that our system can handle the aforesaid challenges. We intend to use the auto-segmentations of the diaphragm to create the initial ground truth (GT) for newly acquired data and then refining them, to expedite the process of creating GT for diaphragm motion analysis, and to test the efficacy of our proposed method to optimize pre-treatment planning and post-operative assessment of patients with TIS and other disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dynamic MR of muscle contraction during electrical muscle stimulation as a potential diagnostic tool for neuromuscular disease\nAbstract: Thanks to the rapid evolution of therapeutic strategies for muscular and neuromuscular diseases, the identification of quantitative biomarkers for disease identification and monitoring has become crucial. Magnetic resonance imaging (MRI) has been playing an important role by noninvasively assessing structural and functional muscular changes. This exploratory study investigated the potential of dynamic MRI during neuromuscular electrical stimulation (NMES) to detect differences between healthy controls (HCs) and patients with metabolic and myotonic myopathies. The study included 14 HCs and 10 patients with confirmed muscular diseases. All individuals were scanned with 3T MRI with a protocol that included a multi-echo gradient echo sequence for fat fraction quantification, multi-echo spin-echo for water T2 relaxation time calculation, and 3D phase contrast sequences during NMES. The strain tensor, buildup and release rates were calculated from velocity datasets. Results showed that strain and strain buildup rate were reduced in the soleus muscle of patients compared to HCs, suggesting these parameters could serve as biomarkers of muscle dysfunction. Notably, there were no significant differences in fat fraction or water T2 measurements between patients and HCs, indicating that the observed changes reflect alterations in muscle contractile properties that are not reflected by structural changes. The findings provide preliminary evidence that dynamic muscle MRI during NMES can detect abnormalities in muscle contraction in patients with myotonia and metabolic myopathies, warranting further research with larger, more homogeneous patient cohorts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Comparison between Evidence-Generated Transtibial Sockets and Conventional CADCAM Designs, from the Patient's Perspective\nAbstract: ObjectivePersonalised prosthetic socket design depends upon skilled prosthetists who aim to balance functional human-prosthesis coupling with safe, comfortable load transmission to skin and soft tissues. This studys objective was to assess the comfort of sockets generated from past computer aided socket design records.  DesignA crossover non-inferiority trial with embedded qualitative interview study.  SettingThree United Kingdom National Health Service clinics.  ParticipantsSeventeen people with nineteen transtibial amputations.  InterventionEvidence-Generated sockets and conventional clinician-led computer aided (Control) designs  Main MeasuresSocket Comfort Score and semi-structured interview.  ResultsEvidence-Generated sockets had no statistically-significant difference in comfort compared to clinician-led Control sockets (p=0.38, effect size=0.08), but a lower socket comfort score variability across the group. Analysis of interviews revealed themes around fitting session experiences, similarities and differences between the Evidence-Generated and Control sockets, and residual limb factors impacting perceptions of socket comfort. These provided insights into the participants experience of the study and the value of expert prosthetist input in socket design.  ConclusionsEvidence-Generated sockets demonstrated noninferiority to conventional clinical computer aided design practice in terms of socket comfort. Both quantitative and qualitative results indicated how clinician input remains essential and is valued by prosthesis users. Work is underway to incorporate the evidence-generated sockets into computer aided design software such that they can act as a digital starting point for modification by expert clinicians at fitting, potentially reducing time spent on basic design, enabling prosthetists to focus on more highly-skilled customisation and co-design with their patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: What influences non-menstruator attitudes and behaviours towards menstruation among Rohingya refugees in Bangladesh? A quantitative analysis\nAbstract: Non-menstruators play an important yet overlooked role in shaping menstrual health. They may be the family budget holders who purchase menstrual materials, receive health information outside the household, or preserve social stigmas. In response, World Vision, supported by UNICEF, implemented a programme to influence non-menstruators among the Rohingya population living in Kutupalong refugee camp, Bangladesh. The intention was to ensure non-menstruators recognise their important role in supporting family members to improve their menstrual health. We evaluated this intervention using a baseline and endline survey of 150 participants based on the Risk-Attitudes-Norms-Ability-Self-regulation (RANAS) approach to behaviour change. Based on the responses, we categorised participants into  doers and  non-doers of positive behaviours. We then performed multiple linear regression analyses and ANOVA comparison of means tests to understand how psychosocial and contextual factors influence the populations attitudes and behaviours towards menstruation before and after intervention. The regression analyses showed eight psychosocial and contextual factors that had a significant relationship with the desired behaviours. These were the block they lived in, marital status, already having learnt about menstruation from World Vision, how they were introduced to menstruation, who they discuss menstruation with, family members reaction, perceptions of their role, and their commitment. Additionally, the ANOVA comparison of means between doers and non-doers showed doers were more likely to be confident to carry out the behaviour, perceive their role as important, and discuss menstruation with family. They were also more likely to be married, older, and have first learnt about menstruation from their family. This is the first study to identify which psychosocial and contextual factors significantly influence positive non-menstruator attitudes and conducive behaviours towards menstruation and menstruators. Humanitarian organisations can use these factors to improve the design and targeting of behaviour change programmes to improve menstrual health.  HighlightsO_LIMenstrual health is often limited in refugee settings C_LIO_LINon-menstruators can enable and constrain menstrual health C_LIO_LIMenstrual health intervention among Rohingya refugees shows positive change in non-menstruator behaviour C_LIO_LIBehavioural determinants for non-menstruators related to marriage, commitment, and family reaction C_LIO_LI Doers more likely to be confident, perceive role as important, and discuss menstruation with family C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of oral contraceptive consumption timing on substrate metabolism, cognition, and exercise performance in females: a randomised controlled trial\nAbstract: The pharmacokinetic profile of oral contraceptives (OCs) results in an acute, transient increase in circulating synthetic reproductive hormones. The aim of this study was to examine the effects of acute OC ingestion on cognitive function, substrate metabolism and exercise performance. Sixteen combined OC (30{micro}g ethinyl oestradiol and 150mg Levonorgestrel) users ingested either their OC or placebo (PLA) in a randomised, double-blind, crossover manner. After 60 minutes, participants completed tests of verbal memory and verbal fluency, followed by sub-maximal treadmill exercise for 6 minutes at 60% lactate threshold (LT) and 90% LT where respiratory exchange ratio (RER), carbohydrate oxidation, fat oxidation, heart rate (HR), rating of perceived exertion (RPE), felt arousal and feeling scale were recorded. Participants then completed an incremental ramp test to exhaustion to assess time to exhaustion (TTE) and peak oxygen uptake (VO2peak), before ingesting the pill corresponding to the condition, they were not in. RER, arousal and feeling scale were all significantly lower in the OC condition compared to PLA (all P < 0.05) with no difference in HR, carbohydrate oxidation, fat oxidation, RPE, TTE or VO2peak (all P > 0.05). Verbal fluency score was significantly higher in the OC condition compared to PLA (P < 0.05), with no differences between conditions for any aspect of verbal memory (all P < 0.05). Combined OC ingestion acutely affects substrate metabolism, affective responses to exercise and verbal fluency. The timing of OC ingestion should be considered in relation to aspects of physiological function.  Key findingsO_LIIngestion of a combined oral contraceptive (OC) results in a transient increase in circulating synthetic reproductive hormones. C_LIO_LIThe altered reproductive hormone profile affects substrate metabolism and affective responses to exercise. C_LIO_LICognitive performance in a verbal fluency task is also improved post OC ingestion. C_LIO_LIThe within-day timing of OC ingestion can be manipulated to affect aspects of physiology, which may have implications for athletes, exercises and the general population, in addition to interpretation of prior research using OCs. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pre-chronic kidney disease: Serial creatinine tracks glomerular filtration rate decline above 60 mL/min\nAbstract: OBJECTIVESTo allow primary clinicians to detect decline in glomerular filtration rate above 60 milliliters per minute, signaling early kidney impairment before stage-three chronic kidney disease.  RESULTSFour patient cases show how serum creatinine referenced to an individuals historical maximum can suggest increased risk, triggering investigation to separate benign processes that alter serum creatinine from true decline in glomerular filtration rate of pre-chronic kidney disease.  DISCUSSION/CONCLUSIONSAt glomerular filtration rates above 60 milliliters per minute, serial creatinine is more reliable than estimating equations and appears practical for clinical monitoring and early intervention.  METHODSWe re-examined a standard reference that found low tubular secretion of creatinine at glomerular filtration rates above 80 milliliters per minute and suggested \"observation of subtle changes in serum creatinine levels\". We used statistics to explain why that method extends to the 80 to 60 milliliters per minute range: expanding the y-axis (to reflect accuracy of modern creatinine assays), fitting a hyperbolic curve, and showing reasonable continuity down to 60 milliliters per minute. We summarized why equations estimating glomerular filtration rate are unsuitable above 60 milliliters per minute.  ABBREVIATIONSASC = adult serum creatinine, CKD = chronic kidney disease, CrCl = creatinine clearance, eGFR = estimated GFR, GFR = glomerular filtration rate, IDMS = isotope-dilution mass spectrometry, KDIGO = Kidney Disease Improving Global Outcomes, m2 = square meters, mGFR = measured GFR, mg/dL = milligrams per deciliter, mL/min = milliliter per minute, mol/L = micromoles per liter, NSAID = nonsteroidal anti-inflammatory drugs, P30 = percentage of estimates within {+/-}30%, sCr = serum creatinine, sCr-max = maximum sCr to date, sCysC = serum cystatin C, TScr = tubular secretion of creatinine.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-gesture drag-and-drop decoding in a 2D iBCI control task\nAbstract: ObjectiveIntracortical brain-computer interfaces (iBCIs) have demonstrated the ability to enable point and click as well as reach and grasp control for people with tetraplegia. However, few studies have investigated iBCIs during long-duration discrete movements that would enable common computer interactions such as \"click-and-hold\" or \"drag-and-drop\".  ApproachHere, we examined the performance of multi-class and binary (attempt/no-attempt) classification of neural activity in the left precentral gyrus of two BrainGate2 clinical trial participants performing hand gestures for 1, 2, and 4 seconds in duration. We then designed a novel \"latch decoder\" that utilizes parallel multi-class and binary decoding processes and evaluated its performance on data from isolated sustained gesture attempts and a multi-gesture drag-and-drop task.  Main ResultsNeural activity during sustained gestures revealed a marked decrease in the discriminability of hand gestures sustained beyond 1 second. Compared to standard direct decoding methods, the Latch decoder demonstrated substantial improvement in decoding accuracy for gestures performed independently or in conjunction with simultaneous 2D cursor control  SignificanceThis work highlights the unique neurophysiologic response patterns of sustained gesture attempts in human motor cortex and demonstrates a promising decoding approach that could enable individuals with tetraplegia to intuitively control a wider range of consumer electronics using an iBCI.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: I am worth saving- A Qualitative Study of People with Alzheimers Disease Considering Lecanemab Treatment\nAbstract: ImportancePeople with Alzheimers disease (AD) now have access to disease-modifying treatment with anti-amyloid monoclonal antibodies (mAbs). Their perception of risks and benefits and approach to treatment decisions remain unknown.  ObjectiveTo understand how people with early AD consider benefits and costs of anti-amyloid mAbs and make decisions about treatment.  DesignQualitative semi-structured interviews  SettingMemory care clinics at two academic medical centers  ParticipantsPeople with biomarker or imaging-confirmed early AD referred for evaluation for treatment with anti-amyloid mAbs  Main Outcomes and MeasuresThemes identified through content analysis  ResultsAmong 22 participants, mean age was 70 years, 8 (36%) were women, 22 (100%) were White, 8 (36%) had less than a college degree, 11 (50%) had annual income less than $100,000, and 6 (27%) lived in a rural area. The analysis revealed 3 major themes and associated subthemes: 1) People with AD sought and obtained information from different sources--advocacy organizations, the Internet, and clinicians; 2) hopes, expected benefits, and the existential threat of dementia drove willingness and readiness to start lecanemab--hopes included more time feeling like themselves and doing enjoyable activities; expected benefits included stalling progression, reversing cognitive decline or cure; 3) individual traits and preferences, family factors, and degree of trust in expertise influenced how people balanced risks and benefits-- some would accept treatment at any cost; others carefully weighed risks and burdens carefully, but were motivated to pursue treatment by supportive families, insurance coverage, and trust in expertise; for a few, costs decidedly outweighed their personal benefits. People with AD desired more individualized information on risks and benefits and wanted to hear more from patients who took the medication.  Conclusions and RelevanceResults from this qualitative analysis inform clinician, health system and policy efforts to promote individualized treatment decisions for anti-amyloid mAb treatment through multimodal education and outreach, evidence-based communication skills, and adaptation of similar care models.  Key PointsO_ST_ABSQuestionC_ST_ABSHow do people with Alzheimers disease (AD) decide on treatment with newly available anti-amyloid monoclonal antibodies?  FindingsIn this qualitative analysis, people with AD considering treatment relied on multiple information sources; were motivated by hope to delay cognitive decline and preserve independence; and worried side effects would impair quality of life. Personality traits, family support, and trust in expertise determined how they balanced these tradeoffs. People with AD wanted more personalized information and to hear from others who had taken the medications.  MeaningAs access to treatment expands, these findings inform how clinicians can help people with AD make individualized treatment decisions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biological markers of brain network connectivity and pain sensitivity distinguish low coping from high coping Veterans with persistent post-traumatic headache\nAbstract: Headache is the most common type of pain following mild traumatic brain injury. Roughly half of those with persistent post-traumatic headache (PPTH) also report neck pain which is associated with greater severity and functional impact of headache. This observational cohort study aimed to identify biological phenotypes to help inform mechanism-based approaches in the management of PPTH with and without concomitant neck pain. Thirty-three military Veterans (mean (SD) = 37{+/-}16 years, 29 males) with PPTH completed a clinical assessment, quantitative sensory testing, and magnetic resonance imaging of the brain and cervical spine. Multidimensional phenotyping was performed using a Random Forest analysis and Partitioning Around Medoids (PAM) clustering of input features from three biologic domains: 1) resting state functional connectivity (rsFC) of the periaqueductal gray (PAG), 2) quality and size of cervical muscles, and 3) mechanical pain sensitivity and central modulation of pain. Two subgroups were distinguished by biological features that included forehead pressure pain threshold and rsFC between the PAG and selected nodes within the default mode, salience, and sensorimotor networks. Compared to the High Pain Coping group, the Low Pain Coping group exhibited higher pain-related anxiety (p=0.009), higher pain catastrophizing (p=0.004), lower pain self-efficacy (p=0.010), and greater headache-related disability (p=0.012). Findings suggest that greater functional connectivity of pain modulation networks involving the PAG combined with impairments in craniofacial pain sensitivity, but not cervical muscle health, distinguish a clinically important subgroup of individuals with PPTH who are less able to cope with pain and more severely impacted by headache.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Partial dependence of ultrasonically estimated fetal weight on individual biometric variables\nAbstract: ObjectivesTo assess the contribution of sonographically measured parameters, namely head circumference, biparietal diameter, abdominal circumference, and femur length, to fetal weight estimation formulas.  MethodsThe Sobol method is employed for the global sensitivity analysis of the biometric parameters.  ResultsThe Sobol sensitivity indices for the parameters of 32 known formulas are presented and discussed.  ConclusionsDepending on the formula, the indices of some parameters show substantial fluctuations, while others are insignificant for fetal weight estimation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Partial dependence of ultrasonically estimated fetal weight on individual biometric variables\nAbstract: ObjectivesTo assess the contribution of sonographically measured parameters, namely head circumference, biparietal diameter, abdominal circumference, and femur length, to fetal weight estimation formulas.  MethodsThe Sobol method is employed for the global sensitivity analysis of the biometric parameters.  ResultsThe Sobol sensitivity indices for the parameters of 32 known formulas are presented and discussed.  ConclusionsDepending on the formula, the indices of some parameters show substantial fluctuations, while others are insignificant for fetal weight estimation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating Observer Reliability and Diagnostic Accuracy of CT-LEFAT Criteria for Post-Treatment Head and Neck Lymphedema: A Prospective Blinded Comparative Analysis of Oncologist Human Inter-Rater Performance\nAbstract: BackgroundRadiation-associated lymphedema and fibrosis (LEF) is a significant toxicity following radiation therapy (RT) for head and neck cancer (HNC) patients. Recently, the CT Lymphedema and Fibrosis Assessment Tool (CT-LEFAT) was developed to standardize LEF diagnosis through fat stranding visualized on CT. This study aims to evaluate the inter-observer reliability and diagnostic accuracy of the CT-LEFAT criteria.  Materials and MethodsThis study retrospectively evaluated 26 HNC patients treated with RT that received a minimum of two contrast-enhanced CT scans. Qualitative review was conducted by five physician raters to assess the fat stranding observed on CT according to the CT-LEFAT criteria. Fleiss kappa analysis was used to assess the inter- and intra-rater reliability, and Receiver Operating Characteristic (ROC) Area Under the Curve (AUC) analysis was used to evaluate diagnostic accuracy.  ResultsThe inter-rater reliability across the six CT-LEFAT regions generally indicated a slight to fair agreement across all raters (0.04 [&le;] kappa [&le;] 0.36). Intra-observer agreement was generally fair to moderate (overall kappa=0.44). The ROC AUC analysis varied based on aggregation method used (0.60 [&le;] average AUC [&le;] 0.70).  ConclusionThis specific use-case evaluating CT-LEFAT criteria displays limited performance. This suggests that additional materials, such as further training, refinement of imaging methods, or other processes may be required before achieving clinically-ready diagnostic performance of LEF diagnosis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Whole Genome Sequencing and single-cell transcriptomics identify KMT2D as a potential new driver for pituitary adenomas\nAbstract: The pituitary gland is a main component of the endocrine system and a master controller of hormone production and secretion. Unlike neoplastic formation in other organs, Pituitary Neuroendocrine Tumors (PitNETs) are frequent in the population (16%) and, for unknown reasons, almost exclusively benign. So far, few genes have been identified as drivers for PitNETs, such as GNAS in somatotroph tumors and USP8 in corticotroph tumors. Using whole genome sequencing, we uncover a potential novel driver, the histone methyltransferase KMT2D, in a patient in his 50s suffering from a mixed somato-lactotroph tumor. Coverage ratio between germline and tumor revealed extensive chromosomal alterations. Single-cell RNA sequencing of the tumor shows up-regulation of known tumorigenic pathways compared to a healthy reference, as well as a different immune infiltration profile compared to other PitNETs, more closely resembling the profile of carcinomas than adenomas. Genome-wide DNA methylation analysis identified 792 differentially methylated regions, including notable hypomethylation in the promoter of SPON2, an immune-related gene. Our results show that tumors considered as quiet and non-aggressive can share drivers, features, and epigenetic alterations with metastatic forms of cancer, raising questions about the biological mechanisms controlling their homeostasis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subcallosal Cingulate structural connectivity as a biomarker for chronic low back pain\nAbstract: BackgroundChronic low back pain (CLBP) poses a significant challenge, contributing significantly to the ongoing opioid crisis while also being a leading cause of disability. Although spinal cord stimulation (SCS) stands as the primary FDA-endorsed method for neuromodulatory therapy in CLBP, there remains a subset of patients unresponsive to SCS and others who experience insufficient pain relief over time. In view of the evidence suggesting the critical role of subcallosal cingulate cortex (SCC) connectivity in pain processing, in the current study we investigated the role of the baseline SCC structural as a potential neuroimaging predictive biomarker to identify patients that are likely to benefit from SCS.  MethodsDiffusion magnetic resonance imaging scans were acquired in 8 patients with CLBP (mean (SD) age = 70 (10) years; 6 female/2 male, 6 UCLA site, 2 UTSW) before their initial SCS trial. Probabilistic tractography from subject-specific anatomically defined SCC seed regions to the ventral striatum (VS), anterior cingulate cortex (ACC), uncinate fasciculus (UCF) and bilateral medial prefrontal cortex (mPFC) was used to calculate FSL structural probabilistic connectivity in the target network. To explore cross-sectional variations in SCC connectivity related to SCS trial response, we employed a general linear model (GLM) using the SCC probability of connectivity as dependent variable, and the response to the SCS trial as independent variable. We used Pearson correlation to evaluate further the relationships between the critical SCC probability of connectivity and the change in VAS score after the SCS trial. Finally, the role of depression in the treatment outcome was evaluated.  ResultsResponders to SCS had significantly lower ipsilateral SCC connectivity to mPFC (F1,8 =8.19, p = 0.03) and VS (F1,8 =17.48, p=0.01) on the left hemisphere compared to non-responders. Pearson correlation analysis showed that decreased ipsilateral SCC baseline connectivity to left mPFC (p=0.03) and VS (p=0.01) was correlated with higher improvement in VAS scores. The baseline depression severity did not significantly influence the change in VAS score following the SCS trial. On the other hand, baseline SCC-VS connectivity on the left hemisphere was a significant predictor of change in VAS score (p=0.02).  ConclusionsOur study highlights the important role of SCC connectivity that can serve as a potential biomarker for CLBP stratification and prediction to SCS treatment. These results can reshape our perspective on CLBP management and can serve as early indicator of response to the treatment providing a personalized approach based on the individuals underlying SCC connectivity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: De novo variant analysis of childhood-onset obsessive-compulsive disorder in the French-Canadian population\nAbstract: Childhood-onset obsessive-compulsive disorder (OCD) is a neuropsychiatric disorder with a strong genetic component. De novo variants (DNVs) have been shown to have a role in childhood-onset OCD, but to date, no DNV analysis has been performed in patients from a genetically isolated population. Here, we aimed to investigate the impact of rare de novo single nucleotide variants (dnSNVs) on childhood-onset OCD risk in the French-Canadian population. In a cohort of 36 French-Canadian trios comprised of 36 probands with childhood-onset OCD and 72 unaffected parents, we identified 34 dnSNVs harboured in 34 different genes. We found that four of these genes were previously associated with OCD, replicating their contribution to its risk. We also observed complete overlap between our 34 candidate genes and genes associated with 11 related neuropsychiatric disorders, supporting a shared underlying genetic susceptibility across psychopathologies. Among genes harbouring DNVs across three childhood-onset OCD cohorts, we observed an overrepresentation of genes involved in clathrin-dependent endocytosis (GO:0072583; p-adj = 0.0498) and phosphatidylinositol binding (GO:0035091; p-adj = 0.0431), offering potential biological mechanisms underlying childhood-onset OCD. No association was found between the number of dnSNVs in childhood-onset OCD probands and OCD symptom severity. Altogether, this study offers a framework for performing DNV analyses of complex disorders in genetically isolated populations. We have provided the first list of candidate childhood-onset OCD genes in the French-Canadian population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: De novo variant analysis of childhood-onset obsessive-compulsive disorder in the French-Canadian population\nAbstract: Childhood-onset obsessive-compulsive disorder (OCD) is a neuropsychiatric disorder with a strong genetic component. De novo variants (DNVs) have been shown to have a role in childhood-onset OCD, but to date, no DNV analysis has been performed in patients from a genetically isolated population. Here, we aimed to investigate the impact of rare de novo single nucleotide variants (dnSNVs) on childhood-onset OCD risk in the French-Canadian population. In a cohort of 36 French-Canadian trios comprised of 36 probands with childhood-onset OCD and 72 unaffected parents, we identified 34 dnSNVs harboured in 34 different genes. We found that four of these genes were previously associated with OCD, replicating their contribution to its risk. We also observed complete overlap between our 34 candidate genes and genes associated with 11 related neuropsychiatric disorders, supporting a shared underlying genetic susceptibility across psychopathologies. Among genes harbouring DNVs across three childhood-onset OCD cohorts, we observed an overrepresentation of genes involved in clathrin-dependent endocytosis (GO:0072583; p-adj = 0.0498) and phosphatidylinositol binding (GO:0035091; p-adj = 0.0431), offering potential biological mechanisms underlying childhood-onset OCD. No association was found between the number of dnSNVs in childhood-onset OCD probands and OCD symptom severity. Altogether, this study offers a framework for performing DNV analyses of complex disorders in genetically isolated populations. We have provided the first list of candidate childhood-onset OCD genes in the French-Canadian population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: De novo variant analysis of childhood-onset obsessive-compulsive disorder in the French-Canadian population\nAbstract: Childhood-onset obsessive-compulsive disorder (OCD) is a neuropsychiatric disorder with a strong genetic component. De novo variants (DNVs) have been shown to have a role in childhood-onset OCD, but to date, no DNV analysis has been performed in patients from a genetically isolated population. Here, we aimed to investigate the impact of rare de novo single nucleotide variants (dnSNVs) on childhood-onset OCD risk in the French-Canadian population. In a cohort of 36 French-Canadian trios comprised of 36 probands with childhood-onset OCD and 72 unaffected parents, we identified 34 dnSNVs harboured in 34 different genes. We found that four of these genes were previously associated with OCD, replicating their contribution to its risk. We also observed complete overlap between our 34 candidate genes and genes associated with 11 related neuropsychiatric disorders, supporting a shared underlying genetic susceptibility across psychopathologies. Among genes harbouring DNVs across three childhood-onset OCD cohorts, we observed an overrepresentation of genes involved in clathrin-dependent endocytosis (GO:0072583; p-adj = 0.0498) and phosphatidylinositol binding (GO:0035091; p-adj = 0.0431), offering potential biological mechanisms underlying childhood-onset OCD. No association was found between the number of dnSNVs in childhood-onset OCD probands and OCD symptom severity. Altogether, this study offers a framework for performing DNV analyses of complex disorders in genetically isolated populations. We have provided the first list of candidate childhood-onset OCD genes in the French-Canadian population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causal associations between plasma proteins and prostate cancer: a Proteome-Wide Mendelian Randomization\nAbstract: BackgroundDue to the limitations in specificity of current diagnostic methods for prostate cancer (PCa), more reliable biomarkers are needed to explore for improving early detection. Plasma proteins represent a promising source of biomarkers, therefore understanding the causal relationships between specific plasma proteins and PCa could be conductive to identify novel biomarkers and therapeutic targets for PCa prevention and treatment.  MethodsWe performed a meta-analysis of two independent genome-wide association studies (GWASs) including 94,397 individuals with PCa and 192,372 controls. A mendelian randomization (MR) supplemented by colocalization analysis was conducted, using cis-acting variants on 4,907 plasma proteins from deCODE Genetics (N=35,559) and 2,940 plasma proteins from UK Biobank Pharma Proteomics Project (UKB-PPP) (N=54,219). Then, the biological pathway analysis and druggability evaluation of the risk proteins were further performed.  ResultsFive possible susceptibility loci (JAZF1, PDILM5, WDPCP, EEFSEC, and TNS3) for PCa were identified through the meta-analysis of GWASs. Among 3,722 plasma proteins, 193 proteins were associated with PCa risk, of which 20 high-risk proteins, including KLK3, were validated in both the deCODE and UKB-PPP cohorts. Functional annotation of these genes encoding proteins confirmed enrichment of immune response, inflammatory response, cell-cell interaction and so on. Genetic colocalization and druggable genome analyses also identified several potential drug targets for PCa, such as HSPB1, RRM2B and PSCA.  ConclusionsWe identified novel variants as well as several protein biomarkers linked to PCa risk and indicated pathways associated with PCa, which offered new insights into PCa etiology and contributed to development of novel biomarkers for early detection and potential therapeutic interventions.  FundingThis work was supported by grants from Beijing Municipal Natural Science Foundation (grant No. JQ24059, No. L234038) and National Natural Science Foundation of China (grant No. 82274015).  Graphical abstractA comprehensive study design summarized as follows.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=147 SRC=\"FIGDIR/small/24312688v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (31K): org.highwire.dtl.DTLVardef@17fc0c9org.highwire.dtl.DTLVardef@49f7f9org.highwire.dtl.DTLVardef@371847org.highwire.dtl.DTLVardef@11af712_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Identifying individuals at risk for surgical supravalvar aortic stenosis by polygenic risk score with graded phenotyping\nAbstract: In a previous pathway-based, extreme phenotype study, we identified 1064 variants associated with supravalvar aortic stenosis (SVAS) severity in people with Williams syndrome (WS) and either no SVAS or surgical SVAS. Here, we use those variants to develop and test polygenic risk scores (PRS). We used the clumping and thresholding (CT) approach on the full 1064 variants and a 427-variant subset that was part of 13 biologically relevant pathways identified in the previous study. We also used a lasso approach on the full set. We were able to achieve an area under the curve (AUC) of >0.99 for the two CT PRS methods, using only 622 and 320 variants respectively when 2/3 of the initial 217 participants data were used for training and 1/3 for testing. The lasso performed less well. We then evaluated the performance of those PRS variant sets on an additional group of 138 patients with WS with intermediate severity SVAS and found a misclassification rate of <10% between the surgical and intermediate groups, suggesting potential for clinical utility of the score.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exome wide association study for blood lipids in 1,158,017 individuals from diverse populations\nAbstract: Rare coding alleles play crucial roles in the molecular diagnosis of genetic diseases. However, the systemic identification of these alleles has been challenging due to their scarcity in the general population. Here, we discovered and characterized rare coding alleles contributing to genetic dyslipidemia, a principal risk for coronary artery disease, among over a million individuals combining three large contemporary genetic datasets (the Million Veteran Program, n = 634,535, UK Biobank, n = 431,178, and the All of Us Research Program, n = 92,304) totaling 1,158,017 multi-ancestral individuals. Unlike previous rare variant studies in lipids, this study included 238,243 individuals (20.6%) from non-European-like populations.  Testing 2,997,401 rare coding variants from diverse backgrounds, we identified 800 exome-wide significant associations across 209 genes including 176 predicted loss of function and 624 missense variants. Among these exome-wide associations, 130 associations were driven by non-European-like populations. Associated alleles are highly enriched in functional variant classes, showed significant additive and recessive associations, exhibited similar effects across populations, and resolved pathogenicity for variants enriched in African or South-Asian populations. Furthermore, we identified 5 lipid-related genes associated with coronary artery disease (RORC, CFAP65, GTF2E2, PLCB3, and ZNF117). Among them, RORC is a potentially novel therapeutic target through the down regulation of LDLC by its silencing.  This study provides resources and insights for understanding causal mechanisms, quantifying the expressivity of rare coding alleles, and identifying novel drug targets across diverse populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Daily consumption of ketone ester, bis octanoyl (R)-1,3-butanediol does not impact functional and quality of life outcomes in healthy older adults, a randomized, parallel arm, double-blind, placebo-controlled study\nAbstract: BackgroundKetone bodies are metabolites produced during fasting or on a ketogenic diet that have pleiotropic effects on the inflammatory and metabolic aging pathways underpinning frailty in in vivo models. Ketone esters (KEs) are compounds that induce hyperketonemia without dietary changes and that may impact physical and cognitive function in young adults. The functional effects of KEs have not been studied in older adults.  ObjectivesOur long-term goal is to examine if KEs modulate aging biology mechanisms and clinical outcomes relevant to frailty in older adults. Here, we report the exploratory functional and quality-of-life outcome measures collected during a 12-week safety and tolerability study of KE (NCT05585762).  DesignRandomized, placebo-controlled, double-blinded, parallel-group, pilot trial of 12-weeks of daily KE ingestion.  SettingThe Clinical Research Unit at the Buck Institute for Research on Aging, California. Participants: Community-dwelling older adults ([&ge;] 65 years), independent in activities of daily living, with no unstable acute medical conditions (n = 30).  InterventionSubjects were randomly allocated (1:1) to consume 25 g daily of either KE (bis-octanoyl (R)-1,3-butanediol) or a taste, appearance, and calorie-matched placebo (PLA) containing canola oil.  MeasurementsLongitudinal change in physical function, cognitive function and quality of life were assessed as exploratory outcomes in n = 23 completers (n = 11 PLA, n = 12 KE). A composite functional outcome to describe the vigor-frailty continuum was calculated. Heart rate and activity was measured throughout the study using digital wearables.  ResultsThere were no statistically significant longitudinal differences between groups in exploratory functional, activity-based or quality of life outcomes.  ConclusionDaily ingestion of 25 g of KE did not affect exploratory functional or quality-of-life end points in this pilot cohort of healthy older adults. Future work will address these endpoints as primary and secondary outcomes in a larger trial of pre-frail older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development, External Validation, and Biomolecular Corroboration of Interoperable Models for Identifying Critically Ill Children at Risk of Neurologic Morbidity\nAbstract: ImportanceDeclining mortality in the field of pediatric critical care medicine has shifted practicing clinicians attention to preserving patients neurodevelopmental potential as a main objective. Earlier identification of critically ill children at risk for incurring neurologic morbidity would facilitate heightened surveillance that could lead to timelier clinical detection, earlier interventions, and preserved neurodevelopmental trajectory.  ObjectiveDevelop machine-learning models for identifying acquired neurologic morbidity while hospitalized with critical illness and assess correlation with contemporary serum-based, brain injury-derived biomarkers.  DesignRetrospective cohort study.  SettingTwo large, quaternary childrens hospitals.  ExposuresCritical illness.  Main Outcomes and MeasuresThe outcome was neurologic morbidity, defined according to a computable, composite definition at the development site or an order for neurocritical care consultation at the validation site. Models were developed using varying time windows for temporal feature engineering and varying censored time horizons prior to identified neurologic morbidity. Optimal models were selected based on F1 scores, cohort sizes, calibration, and data availability for eventual deployment. A generalizable created at the development site was assessed at an external validation site and optimized with spline recalibration. Correlation was assessed between development site model predictions and measurements of brain biomarkers from a convenience cohort.  ResultsAfter exclusions there were 14,222-25,171 encounters from 2010-2022 in the development site cohorts and 6,280-6,373 from 2018-2021 in the validation site cohort. At the development site, an extreme gradient boosted model (XGBoost) with a 12-hour time horizon and 48-hour feature engineering window had an F1-score of 0.54, area under the receiver operating characteristics curve (AUROC) of 0.82, and a number needed to alert (NNA) of 2. A generalizable XGBoost model with a 24-hour time horizon and 48-hour feature engineering window demonstrated an F1-score of 0.37, AUROC of 0.81, AUPRC of 0.51, and NNA of 4 at the validation site. After recalibration at the validation site, the Brier score was 0.04. Serum levels of the brain injury biomarker glial fibrillary acidic protein measurements significantly correlated with model output (rs=0.34; P=0.007).  Conclusions and RelevanceWe demonstrate a well-performing ensemble of models for predicting neurologic morbidity in children with biomolecular corroboration. Prospective assessment and refinement of biomarker-coupled risk models in pediatric critical illness is warranted.  Key PointsQuestion Can interoperable models for predicting neurological deterioration in critically ill children be developed, correlated with serum-based brain-derived biomarkers, and validated at an external site?  Findings A development site model demonstrated an area under the receiver operating characteristics curve (AUROC) of 0.82 and a number needed to alert (NNA) of 2. Predictions correlated with levels of glial fibrillary acidic protein in a subset of children. A generalizable model demonstrated an AUROC of 0.81 and NNA of 4 at the validation site.  Meaning Well performing prediction models coupled with brain biomarkers may help to identify critically ill children at risk for acquired neurological morbidity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: \"WE CAN ALL CONTRIBUTE IN OUR OWN WAY\" : KNOWLEDGE MOBILIZATION TOOLS TO PROMOTE BEST PRACTICES IN UNIVERSAL ACCESSIBILITY\nAbstract: BackgroundCities aim to enhance urban accessibility following the adoption of the United Nations Convention on the Rights of Persons with Disabilities. However, implementation faces challenges due to complex municipal legislation, lack of awareness, and organizational obstacles. Engaging stakeholders and empowering municipal employees through knowledge mobilization is crucial, as shown in a Quebec Citys partnership research process.  AimTo report the implementation strategy as implemented, explore the perception of the employees about the format and feasibility of the implementation strategy and explore the induced changes of knowledge mobilization tools on the implementation determinants of universal accessibility measures for municipal employees.  MethodsThe study used a multi-method design, involving interviews and a questionnaire with the project steering committee, made up of city employees and the research team. Three 30-minute participatory workshops were conducted for culture, communications, and public consultation administrative units.  ResultsParticipants appreciated the workshop format and video content, suggesting minor improvements for broader implementation. The tools effectively increased engagement in implementing universal accessibility measures, proving valuable for raising awareness.  Discussion and ConclusionThe study demonstrates the advantages of a collaborative approach in developing knowledge mobilization tools, enhancing municipal personnels capacity for universal accessibility measures, and highlighting the need for adaptable strategies.  Contributions to the litterature O_LIKnowledge mobilization tools created in partnership with knowledge users encourage buy-in and a positive view of the tools. C_LIO_LIAn interactive implementation strategy actively involving knowledge users promotes awareness and behavior change C_LIO_LIMunicipal organizations context being complex, the implementation strategy must be adapted to each group of people and their reality to facilitate the implementation and adoption of the tools. C_LIO_LIThe combined use of a theoretical framework and a participatory approach provides a guideline for the development of tools and implementation, while adapting to the specific context. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Supporting decision-making for individuals living with dementia and their care partners with knowledge translation: an umbrella review\nAbstract: Living with dementia requires decision-making about numerous topics including daily activities, such as advance care planning (ACP). Both individuals living with dementia and care partners require informed support for decision-making. We conducted an umbrella review to assess knowledge translation (KT) interventions supporting decision-making for individuals living with dementia and their informal care partners. Four databases were searched using 50 different search-terms, identifying 22 reviews presenting 32 KT interventions. The most common KT decision topic was ACP (N=21) which includes advanced care directives, feeding options, and placement in long-term care. The majority of KT interventions targeted care partners only (N=16), or both care partners and individuals living with dementia (N=13), with fewer interventions (N=3) targeting individuals living with dementia. Overall, our umbrella review offers insights into the beneficial impacts of KT interventions, such as increased knowledge and confidence, and decreased decisional conflicts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adherence, Adverse Events and Viral Control among Children and Adolescents with HIV in Zambia Switched to an Integrase Inhibitor Regimen\nAbstract: BackgroundBased on recent World Health Organization recommendations, there has been a large-scale transition in Sub-Saharan Africa to integrase inhibitor (II)-based antiretroviral therapy (ART) regimens.  SettingThis study was conducted at an urban referral center in Lusaka, Zambia.  MethodsThis study included 297 children and adolescents with HIV (CAWH) on ART for one year prior to enrollment and followed for 1-4 years after enrollment. ART adherence, ART regimen, and viral load were assessed periodically. Structured interviews were conducted with a subset of 95 children to assess adherence barriers and side effects.  ResultsChildren on protease inhibitor (PI)-based regimens were more likely to report adherence problems than children taking II- or Efavirenz-based regimens (10% vs. 28%, p=0.03) and noted more days with missed doses (median 1 vs. 0, p=0.02). In interviews, the most common reasons given for poor adherence included bad medication taste, not being home when medications were due, and perceived side effects. The PI group was more likely to report that taste was a problem affecting adherence (22% vs. 4%, p=0.05) and headache as an ART side effect (17% vs. 4%, p=0.05). Switching from a PI- to an II-based regimen was associated with improved adherence (72% vs. 92%, p=0.01) and an undetectable viral load (67% vs. 78%).  ConclusionsSwitching CAWH from PI-based to II-based regimens has many advantages including superior side effect profiles, adherence, and viral suppression. PI taste aversion may be a significant contributor to pediatric adherence issues. Palatability should be considered in pediatric HIV drug development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Executive Function and Adherence in Children and Adolescents Living with HIV: Evidence from the HIV-associated Neurocognitive Disorders in Zambia (HANDZ) Study\nAbstract: IntroductionExecutive function (EF) may be impaired in people with human immunodeficiency virus (HIV) infection, and poor EF may affect medication adherence. However, there is little data on EF in children with HIV in sub-Saharan Africa.  Methods208 children/adolescents with perinatally acquired HIV and 208 HIV-exposed uninfected controls were recruited in Zambia for this prospective cohort study. EF was measured using performance-based, self-report, and parental report measures. Adherence over one year of follow-up was assessed through questionnaires and viral load measurement.  ResultsChildren with HIV performed significantly worse on all three measures of EF. Lower parental rating of EF was associated with poorer antiretroviral therapy adherence (OR: 1.5, 95% CI = 1.02 - 2.2, p = 0.04).  ConclusionChildren with HIV have EF impairments which may lead to consequences like poor medication adherence and treatment failure. Interventions to improve EF or compensate for impaired EF may be necessary in this population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: National trends in drug overdose mortality in Asian American, Native Hawaiian, and Pacific Islander populations, 2018-2022\nAbstract: BackgroundDrug overdose deaths have surged over the past two decades, disproportionately impacting racial/ethnic minority populations. Yet, little is known about drug overdose patterns among Asian American and Native Hawaiian/Pacific Islander (AANHPI) populations.  MethodsWe obtained data on drug overdose deaths and population totals from the CDC WONDER Multiple Cause of Death database and American Community Survey between 2018 and 2022. We calculated crude mortality rates per 100,000, stratified by sex, US Census Division, and drug types--prescription opioids, heroin, fentanyl, cocaine, methamphetamine, and benzodiazepines. Additionally, we conducted disaggregated analyses for six Asian American subgroups (Asian Indian, Chinese, Filipino, Japanese, Korean, Vietnamese) and three NHPI subgroups (Hawaiian, Guamanian, Samoan).  ResultsIn 2022, there were 1226 drug overdose deaths among Asian Americans and 154 among NHPI individuals. The crude mortality rate for NHPI individuals (17.52 per 100,000; 95% CI: 14.76- 20.29) tripled that of Asian Americans (5.85 per 100,000; 95% CI: 5.52-6.18). Fentanyl was the leading cause of overdose deaths among Asian Americans (3.17 per 100,000; 95% CI: 2.93- 3.41), whereas methamphetamine was predominant among NHPI individuals (11.38 per 100,000; 95% CI: 9.15-13.61). Among Asian American subgroups, Japanese Americans had the highest mortality rate (9.90 per 100,000; 95% CI: 9.61-10.2), and among NHPI subgroups, Guamanians had the highest rates (43.16 per 100,000; 95% CI: 39.05-48.24).  ConclusionsThese findings underscore the urgent need for culturally competent harm reduction services, mental health and addiction treatment, and social services, addressing structural barriers that perpetuate drug overdose disparities in AANHPI communities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Milieu Interieur follow-up study - an integrative approach for studying immunological variation in an aging population\nAbstract: Human immune responses are highly variable from one individual to another, with these differences determined by both genetic and environmental factors. We previously established the Milieu Interieur cohort to define the boundaries of healthy immune responses and identify and quantify its different determinants. From this cohort of 1,000 well-defined healthy donors, we have identified multiple genetic and environmental factors that are associated with variable immune phenotypes. Crucially, these associations were observed in a healthy context, as defined by strict inclusion and exclusion criteria. To assess how such immune responses may vary over time, we initiated a 10-year follow-up clinical study of the cohort. From the original 1,000 donors, we identified and recruited 415 donors from whom we assessed recent medical history and lifestyle factors, in addition to collecting samples for measurement of diverse immune phenotypes. A comparison of 107 laboratory and serological measures over the 10-year period showed significant correlations, highlighting the quality of the data collected. By accounting for potential batch effects, our analyses revealed the profound effects of aging on health-related biomarkers and antibody levels against common pathogens. We determined that a significant proportion of the donors no longer meet the initial definition of good health, due to either physiological changes associated with aging, or disease incidence including cancer, autoimmune and cardiovascular diseases. We found that disease development over the past 10 years is associated with a biological aging score, assessed at the time of the initial recruitment. In summary, the Milieu Interieur follow-up study will provide new opportunities for studying biological mechanisms of immunosenescence and identifying factors associated with accelerated immune aging and poor health outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Where Adults with Heart Failure Die: Insights from the CDC-WONDER Database\nAbstract: ABSTRACTO_ST_ABSBACKGROUNDC_ST_ABSHeart failure (HF) is associated with high mortality rates and substantial healthcare costs. Although there is increasing emphasis on introducing palliative care for patients with HF, it is not well characterized where adults with HF spend their final days before death.  STUDY AIMThis study analyzed the locations and circumstances of death among adults with HF in the United States using data from the CDC-WONDER database.  METHODOLOGYThe study examined mortality data of individuals aged [&ge;] 20 years, with HF listed as the underlying cause of death between 1999 and 2023. The place of death was categorized as the emergency room (ER), hospice/nursing home, inpatient medical facility, or home. Multivariable logistic regression was used to determine the relationship between death location and demographic factors.  RESULTSFrom 1999 to 2023, HF-related deaths decreased from 1999 (3.60% and 143.6 AAMR) to 2010 (3.47% and 123.1 AAMR). From 2010 onwards, a gradual rise is seen, with the rate of HF deaths reaching 5.18% and 168.1 AAMR in 2023. Notably, deaths at home increased from 18.41% (50,648 of 275,132) in 1999 to 33.47% (132,470 of 395,826) in 2023 and deaths in hospice/nursing homes increased from 30.95% (85,144 of 275,132) in 1999 to 34.71% (116,634 of 336,014) in 2017 and then sudden fall was observed until 2023 to 29.54% (116,931 of 395,826). Older adults (65+) were more likely to die in inpatient facilities. Gender, ethnicity, and urbanization influenced the place of death, with males, White patients, and those residing in large metropolitan areas more likely to die in medical facilities.  CONCLUSIONSThis study highlights the changing patterns in the locations of death among HF patients, emphasizing the need for improved home and hospice care services. Addressing disparities in healthcare access and enhancing palliative care are essential for improving end-of-life experiences. Further research is needed to investigate the factors that contribute to these trends.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Two-step Bayesian Mendelian Randomization Study on Cholecystitis and Dermatitis\nAbstract: BackgroundCholecystitis is an inflammatory disease involving the gallbladder, often associated with digestive disorders and systemic immune response. This systemic immune response could potentially influence the immune status of the skin, particularly in conditions like dermatitis. Despite extensive research on dermatitis, the causal relationship between cholecystitis and dermatitis subtypes (DSs) remains unclear.  ObjectiveThe aim of this study was to investigate the causal relationship between cholecystitis and DSs.  MethodsTwo-sample Mendelian randomization (MR) was used to analyze the causal relationship between cholecystitis and DSs. We then utilized the Bayesian Weighted Mendelian Randomization (BWMR) method to validate our findings and applied bidirectional MR analysis to confirm the causal direction. After establishing the associations between traits, we delved into the underlying mechanisms of this interesting finding. Subsequently, we used 91 inflammatory proteins as mediators and performed summary data-based mendelian randomization (SMR) analysis to further investigate the pathogenesis of DSs.  ResultsMR results evidently showed that cholecystitis can significantly reduce the risk of allergic contact dermatitis (ACD) (IVW, OR=0.8834, p=0.0368) and exfoliative dermatitis (ED) (IVW, OR=0.5738, p=0.0126). BWMR also provided secondary validation of the casual associations. In the subsequent reverse direction MR analyses, reverse causality was not present, so cholecystitis had a unidirectional effect and existed as a protective factor for ACD and ED. Interestingly, cholecystitis appears to lower the risk of ACD and ED by downregulating IL-6, IL-7, and IFN-{gamma}. Additionally, the genes HCG27 and HLA-DRB5 may play a significant role in the pathogenesis of ACD.  ConclusionThis study used a two-step MR analysis of genetic summary data to investigate to what extent inflammatory proteins impact the protective role of cholecystitis on dermatitis. We also identified several proteins and genes that could serve as potential drug targets.  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=122 SRC=\"FIGDIR/small/24313850v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (28K): org.highwire.dtl.DTLVardef@140ec1org.highwire.dtl.DTLVardef@d4a81forg.highwire.dtl.DTLVardef@169af8dorg.highwire.dtl.DTLVardef@1846c59_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of Therapies Treating Sensory Processing Disorders in Children with Autism Spectrum Disorder\nAbstract: The prevalence of children being diagnosed with Autism Spectrum Disorder has risen dramatically over recent years. Many of those children suffer from sensory processing disorders (SPD). There is no standardized treatment for this disorder and the therapies available have produced confusing and conflicting results. A search was performed for relevant studies and systematic review articles that researched treatment in this area. Data was extracted and analyzed and then organized with summary conclusions of each paper. Qualitative notes were gathered on the studies and the results of the studies were compared and contrasted. Sensory integration therapy has been shown to produce significant results and most of the conflicting data can be explained scientifically. Research is still required for the duration frequency and rate of therapy. Reviews of other therapies to treat SPD have not shown enough evidence of significant positive outcomes to be recommended.  Purpose StatementThe purpose of this paper is to gather and analyze research regarding therapies for Sensory Processing Disorder in Children with Autism Spectrum Disorder. This review aims to determine the evidence of such therapies and to inform and educate practitioners regarding outcomes in their use to treat this disorder.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Who are the Speech-Language Pathologists of the future? Results of a national demographic survey of Canadian SLP students\nAbstract: Speech-language pathologists (SLPs) are experts in communication and swallowing who work with individuals across the lifespan. Prior demographic surveys in English-speaking countries (e.g., Canada and the United States) suggest that SLPs gender, racial, linguistic, and cultural and socioeconomic backgrounds may not be aligned with those of their clientele. The aim of this study is to describe the demographic characteristics of current SLP students, to gauge whether the demographic composition of future clinicians is changing and is aligned with the population they are trained to serve. We designed an anonymous online survey, in the Canadian context, that enabled us to compare current SLP student demographics with statistics available about the target population at large. This survey was disseminated to all SLP students enrolled in an accredited institution in 2024. Participants answered questions about their age, sex and gender, linguistic, racial and cultural identities, and socioeconomic status. More than half (N=525, 53%) of currently enrolled SLP students completed the survey. Results indicate that SLP students are overwhelmingly cisgender females. SLP students spoke 48 unique languages, and while most were bi or multilingual, few felt competent enough in languages other than English and French to engage in clinical service delivery. There were 151 unique racial and ethnic identities reported, with the largest proportion of students identifying as \"North American.\" Culturally most SLPs identified as \"Canadian.\" Very few students identified as Black or Indigenous racially or culturally. Most respondents reported a higher-than-average total household income. Findings suggest that the demographic composition of current SLP students is more diverse than those currently practicing, however there is still over-, and underrepresentation of certain populations. Implications for practice and suggestions for future research are discussed.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human papillomavirus vaccination at the national level in Tunisia: a cost-effectiveness analysis using a comparative modeling study.\nAbstract: Cervical cancer is one of the most prevalent cancer diseases in women caused by persistent infection with one of 13 sexually transmitted high-risk human papillomavirus (HPV) types. Vaccination can significantly reduce the prevalence of this burden in low-middle income countries. However, HPV vaccination is not included in the Tunisian immunization program. Since the economic evaluation of HPV vaccines is crucial to inform public-health decisions, the World Health Organization (WHO) recommends that a cost-effectiveness analysis of HPV vaccination is conducted before nationwide introduction. This study aimed to conduct a cost-effectiveness analysis of incorporating different HPV vaccines into the national immunisation schedule in Tunisia. The potential health and economic impacts of human papillomavirus (HPV) vaccination were evaluated through comparative modelling analysis using two published static models (UNIVAC and Papillomavirus Rapid Interface for Modelling and Economics (PRIME)). Academic literature and anecdotal evidence were included on the demographic variables, cervical cancer incidence and mortality, treatment costs, vaccine delivery costs and other model parameters.  The cost of vaccination, treatment costs saved, net costs, cases and deaths averted, life years saved, disability-adjusted life years (DALYs) prevented, and incremental cost-effectiveness ratios were predicted and reported as primary outcomes. The incremental cost-effectiveness ratios (ICERs) were estimated per disability-adjusted life years (DALYs) averted using the cost-effectiveness threshold (CET) defined by the World Health Organisation (WHO). All HPV vaccines were very cost effective (with every disability-adjusted life-year averted costing less than the cost-effectiveness threshold). The analyses were done from a health system and societal perspective. Despite model differences, the PRIME and UNIVAC models yielded similar vaccine-impact estimates.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human papillomavirus vaccination at the national level in Tunisia: a cost-effectiveness analysis using a comparative modeling study.\nAbstract: Cervical cancer is one of the most prevalent cancer diseases in women caused by persistent infection with one of 13 sexually transmitted high-risk human papillomavirus (HPV) types. Vaccination can significantly reduce the prevalence of this burden in low-middle income countries. However, HPV vaccination is not included in the Tunisian immunization program. Since the economic evaluation of HPV vaccines is crucial to inform public-health decisions, the World Health Organization (WHO) recommends that a cost-effectiveness analysis of HPV vaccination is conducted before nationwide introduction. This study aimed to conduct a cost-effectiveness analysis of incorporating different HPV vaccines into the national immunisation schedule in Tunisia. The potential health and economic impacts of human papillomavirus (HPV) vaccination were evaluated through comparative modelling analysis using two published static models (UNIVAC and Papillomavirus Rapid Interface for Modelling and Economics (PRIME)). Academic literature and anecdotal evidence were included on the demographic variables, cervical cancer incidence and mortality, treatment costs, vaccine delivery costs and other model parameters.  The cost of vaccination, treatment costs saved, net costs, cases and deaths averted, life years saved, disability-adjusted life years (DALYs) prevented, and incremental cost-effectiveness ratios were predicted and reported as primary outcomes. The incremental cost-effectiveness ratios (ICERs) were estimated per disability-adjusted life years (DALYs) averted using the cost-effectiveness threshold (CET) defined by the World Health Organisation (WHO). All HPV vaccines were very cost effective (with every disability-adjusted life-year averted costing less than the cost-effectiveness threshold). The analyses were done from a health system and societal perspective. Despite model differences, the PRIME and UNIVAC models yielded similar vaccine-impact estimates.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating and Reducing Subgroup Disparity in AI Models: An Analysis of Pediatric COVID-19 Test Outcomes\nAbstract: Artificial Intelligence (AI) fairness in healthcare settings has attracted significant attention due to the concerns to propagate existing health disparities. Despite ongoing research, the frequency and extent of subgroup fairness have not been sufficiently studied. In this study, we extracted a nationally representative pediatric dataset (ages 0-17, n=9,935) from the US National Health Interview Survey (NHIS) concerning COVID-19 test outcomes. For subgroup disparity assessment, we trained 50 models using five machine learning algorithms. We assessed the models area under the curve (AUC) on 12 small (<15% of the total n) subgroups defined using social economic factors versus the on the overall population. Our results show that subgroup disparities were prevalent (50.7%) in the models. Subgroup AUCs were generally lower, with a mean difference of 0.01, ranging from -0.29 to +0.41. Notably, the disparities were not always statistically significant, with four out of 12 subgroups having statistically significant disparities across models. Additionally, we explored the efficacy of synthetic data in mitigating identified disparities. The introduction of synthetic data enhanced subgroup disparity in 57.7% of the models. The mean AUC disparities for models with synthetic data decreased on average by 0.03 via resampling and 0.04 via generative adverbial network methods.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Automatically Identifying Event Reports of Workplace Violence and Communication Failures using Large Language Models\nAbstract: Safety event reporting forms a cornerstone of identifying and mitigating risks to patient and staff safety. However, variabilities in reporting and limited resources to analyze and classify event reports delay healthcare organizations ability to rapidly identify safety event trends and to improve workplace safety. We demonstrated how large language models can classify safety event report narratives as workplace violence and communication failures as a first step toward enabling automated labeling of safety event reports and ultimately improving workplace safety.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging large language models for systematic reviewing: A case study using HIV medication adherence research\nAbstract: BackgroundThe rapidly accumulating scientific literature in HIV presents a significant challenge in accurately and efficiently assessing the relevant literature. This study explores the potential capabilities of using large language models (LLMs), such as ChatGPT, for selecting relevant studies for a systematic review.  MethodScientific papers were initially obtained from bibliographic database searches using a Boolean search strategy with pre-defined keywords. From 15,839 unique records, three reviewers manually identified 39 relevant papers based on pre-specified inclusion and exclusion criteria. In the ChatGPT experiment, over 10% of records were randomly chosen as the experimental dataset, including the 39 manually identified manuscripts. These unique records (n=1,680) underwent screening via ChatGPT-4 using the same prespecified criteria. Four strategies were employed including standard prompting, i.e., input-output (IO), chain of thought with zero-shot learning (0-CoT), CoT with few-shot learning (FS-CoT), and Majority Voting (which integrates all three promoting strategies). Performance of the models were assessed using recall, F-score, and precision measures.  ResultsRecall scores (% of true abstracts successfully identified and retrieved by the model from all input data/records) for different ChatGPT configurations were 0.82 (IO), 0.97 (0-CoT), and both the FS-CoT and the Majority Voting prompts achieved a recall score of 1.0. F-scores were 0.34 (IO), 0.29 (0-CoT), 0.39 (FS-CoT), and 0.46 (majority voting). Precision measures were 0.22(IO), 0.17(0-CoT), 0.24(FS-CoT), and 0.30 (Majority Voting). Computational time varied with 2.32, 4.55, 6.44, and 13.30 hours for IO, 0-CoT, FS-CoT, and majority voting,respectively. Processing costs for the 1,680 unique records were approximately $63, $73, $186, and $325, respectively.  ConclusionLLMs, like ChatGPT, are viable for systematic reviews, efficiently identifying studies meeting pre-specified criteria. Greater efficacy was observed when a more sophisticated prompt design was employed, integrating IO, 0-CoT and FS-CoT prompt techniques (i.e., majority voting). LLMs can expedite the study selection process in systematic reviews compared to manual methods, with minimal cost implications.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Achievement of diabetes treatment goals in Mexico from 2016-2022: A retrospective analysis of nationally representative surveys\nAbstract: BACKGROUNDCardiovascular (CVD) risk factor reduction is a cornerstone of diabetes management. Here, we aimed to estimate the prevalence and determinants of individual and combined CVD risk factor control goals amongst individuals living with diagnosed diabetes in Mexico.  METHODSWe analyzed Mexican National Health and Nutrition Surveys from 2016-2022 including individuals aged [&ge;]20 years with diagnosed diabetes. We estimated the prevalence of glycemic, blood pressure, cholesterol, and smoking control, as well as combined control achievement according to current guidelines, as well as the prevalence of antihypertensive, statin and diabetes medication use. We also explored determinants of control achievement amongst individuals with diabetes using weighted logistic regression.  RESULTSWe analyzed data from 2,331 adults with diagnosed diabetes. Glycemic control increased over time reaching 41% (95%CI 30%-52%) by 2022. Blood pressure control remained similar over time reaching 45% (95%CI 35%-55%) in 2022, LDL-C control remained low regardless of the definition (<70 vs. <100 mg/dL), whilst smoking control was high and increased over time to 92% (95%CI 88%-96%) in 2022. Combined risk factor control achievement was low, primarily due to suboptimal LDL-C control, despite a high proportion of medication use. Control achievement was more likely in Northern Mexico, in younger individuals, those with college education or living in states with lower social lag.  CONCLUSIONSOur results suggest a need to improve comprehensive glycemic and CVD risk factor management for individuals living with diabetes in Mexico to improve diabetes care and reduce risk of adverse outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Statin use is associated with reduction in risk of de novo primary sclerosing cholangitis among patients with inflammatory bowel disease: A National Database Study\nAbstract: Background and AimsPrimary sclerosing cholangitis (PSC) is a liver disease without medical therapy that significantly increases the risk of malignancies, acute cholangitis and cirrhosis. Approximately 2-7% of patients with inflammatory bowel disease (IBD) develop PSC. No drug has been shown to prevent de novo PSC in patients with IBD. Statin use, however, has been associated with increased liver transplant-free survival. Yet, the impact of statins on development of new PSC among those with IBD is unknown.  MethodsWe conducted a retrospective cohort study of patients diagnosed with IBD with and without statin exposure using a large, representative national database. Patients were followed from the date of diagnosis of IBD. Patient demographics, co-morbidities, medications, and type of IBD were extracted. Unmatched and propensity score-matched Cox regression analyses were performed.  ResultsOur analysis included 33,813 patients with IBD of whom 8,813 were exposed to statins. PSC developed in 181 patients over a median follow-up of 3.7 years. Only nine patients (0.1%) who were exposed to statins developed PSC compared to 173 (0.69%) in the non-exposed population. In propensity score-matched analysis, statin therapy was associated with an 86% lower risk of developing PSC (HR 0.14; 95% CI 0.06-0.33, p<0.001). The findings were consistent when accounting for unmeasured confounders (E-value) in sensitivity analyses, including stratification by age group, duration of statin use, and type of statin.  ConclusionIn a propensity score-matched analysis, statin use was associated with an 86% risk reduction in new PSC diagnosis among patients with known IBD, suggesting a potential benefit as a prophylactic agent. These findings warrant prospective validation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the Spectrum: Subtype-Specific Molecular Insights into Autism Spectrum Disorder Via Integrated Transcriptomic Analysis\nAbstract: Some toddlers with autism spectrum disorder (ASD) have mild social symptoms and developmental improvement in skills, but for others, symptoms and abilities are moderately or even severely affected. Those with profound autism have the most severe social, language, and cognitive symptoms and are at the greatest risk of having a poor developmental outcome. The little that is known about the underlying biology of this important profound autism subtype, points clearly to embryonic dysregulation of proliferation, differentiation and neurogenesis. Because it is essential to gain foundational knowledge of the molecular biology associated with profound, moderate, and mild autism clinical subtypes, we used well-validated, data-driven patient subtyping methods to integrate clinical and molecular data at 1 to 3 years of age in a cohort of 363 ASD and controls representative of the general pediatric population in San Diego County. Clinical data were diagnostic, language, cognitive and adaptive ability scores. Molecular measures were 50 MSigDB Hallmark gene pathway activity scores derived from RNAseq gene expression. Subtyping identified four ASD, typical and mixed diagnostic clusters. 93% of subjects in one cluster were profound autism and 93% in a different cluster were control toddlers; a third cluster was 76% moderate ability ASD; and the last cluster was a mix of mild ASD and control toddlers. Among the four clusters, the profound autism subtype had the most severe social symptoms, language, cognitive, adaptive, social attention eye tracking, social fMRI activation, and age-related decline in abilities, while mild autism toddlers mixed within typical and delayed clusters had mild social symptoms, and neurotypical language, cognitive and adaptive scores that improved with age compared with profound and moderate autism toddlers in other clusters. In profound autism, 7 subtype-specific dysregulated gene pathways were found; they control embryonic proliferation, differentiation, neurogenesis, and DNA repair. To find subtype-common dysregulated pathways, we compared all ASD vs TD and found 17 ASD subtype-common dysregulated pathways. These common pathways showed a severity gradient with the greatest dysregulation in profound and least in mild. Collectively, results raise the new hypothesis that the continuum of ASD heterogeneity is moderated by subtype-common pathways and the distinctive nature of profound autism is driven by the differentially added profound subtype-specific embryonic pathways.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the Spectrum: Subtype-Specific Molecular Insights into Autism Spectrum Disorder Via Integrated Transcriptomic Analysis\nAbstract: Some toddlers with autism spectrum disorder (ASD) have mild social symptoms and developmental improvement in skills, but for others, symptoms and abilities are moderately or even severely affected. Those with profound autism have the most severe social, language, and cognitive symptoms and are at the greatest risk of having a poor developmental outcome. The little that is known about the underlying biology of this important profound autism subtype, points clearly to embryonic dysregulation of proliferation, differentiation and neurogenesis. Because it is essential to gain foundational knowledge of the molecular biology associated with profound, moderate, and mild autism clinical subtypes, we used well-validated, data-driven patient subtyping methods to integrate clinical and molecular data at 1 to 3 years of age in a cohort of 363 ASD and controls representative of the general pediatric population in San Diego County. Clinical data were diagnostic, language, cognitive and adaptive ability scores. Molecular measures were 50 MSigDB Hallmark gene pathway activity scores derived from RNAseq gene expression. Subtyping identified four ASD, typical and mixed diagnostic clusters. 93% of subjects in one cluster were profound autism and 93% in a different cluster were control toddlers; a third cluster was 76% moderate ability ASD; and the last cluster was a mix of mild ASD and control toddlers. Among the four clusters, the profound autism subtype had the most severe social symptoms, language, cognitive, adaptive, social attention eye tracking, social fMRI activation, and age-related decline in abilities, while mild autism toddlers mixed within typical and delayed clusters had mild social symptoms, and neurotypical language, cognitive and adaptive scores that improved with age compared with profound and moderate autism toddlers in other clusters. In profound autism, 7 subtype-specific dysregulated gene pathways were found; they control embryonic proliferation, differentiation, neurogenesis, and DNA repair. To find subtype-common dysregulated pathways, we compared all ASD vs TD and found 17 ASD subtype-common dysregulated pathways. These common pathways showed a severity gradient with the greatest dysregulation in profound and least in mild. Collectively, results raise the new hypothesis that the continuum of ASD heterogeneity is moderated by subtype-common pathways and the distinctive nature of profound autism is driven by the differentially added profound subtype-specific embryonic pathways.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beyond the Spectrum: Subtype-Specific Molecular Insights into Autism Spectrum Disorder Via Multimodal Data Integration\nAbstract: Some toddlers with autism spectrum disorder (ASD) have mild social symptoms and developmental improvement in skills, but for others, symptoms and abilities are moderately or even severely affected. Those with profound autism have the most severe social, language, and cognitive symptoms and are at the greatest risk of having a poor developmental outcome. The little that is known about the underlying biology of this important profound autism subtype, points clearly to embryonic dysregulation of proliferation, differentiation and neurogenesis. Because it is essential to gain foundational knowledge of the molecular biology associated with profound, moderate, and mild autism clinical subtypes, we used well-validated, data-driven patient subtyping methods to integrate clinical and molecular data at 1 to 3 years of age in a cohort of 363 ASD and controls representative of the general pediatric population in San Diego County. Clinical data were diagnostic, language, cognitive and adaptive ability scores. Molecular measures were 50 MSigDB Hallmark gene pathway activity scores derived from RNAseq gene expression. Subtyping identified four ASD, typical and mixed diagnostic clusters. 93% of subjects in one cluster were profound autism and 93% in a different cluster were control toddlers; a third cluster was 76% moderate ability ASD; and the last cluster was a mix of mild ASD and control toddlers. Among the four clusters, the profound autism subtype had the most severe social symptoms, language, cognitive, adaptive, social attention eye tracking, social fMRI activation, and age-related decline in abilities, while mild autism toddlers mixed within typical and delayed clusters had mild social symptoms, and neurotypical language, cognitive and adaptive scores that improved with age compared with profound and moderate autism toddlers in other clusters. In profound autism, 7 subtype-specific dysregulated gene pathways were found; they control embryonic proliferation, differentiation, neurogenesis, and DNA repair. To find subtype-common dysregulated pathways, we compared all ASD vs TD and found 17 ASD subtype-common dysregulated pathways. These common pathways showed a severity gradient with the greatest dysregulation in profound and least in mild. Collectively, results raise the new hypothesis that the continuum of ASD heterogeneity is moderated by subtype-common pathways and the distinctive nature of profound autism is driven by the differentially added profound subtype-specific embryonic pathways.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Investigation of factors associated with delayed initiation of breastfeeding in Papua New Guinea: a cross-sectional study\nAbstract: BackgroundBreastfeeding within the first hour of birth is critical for newborn survival. However, in Papua New Guinea (PNG), about 40% of newborns are not breastfed within the first hour of birth. This study aimed to determine the prevalence and factors associated with delayed breastfeeding initiation in PNG.  MethodsThis study utilised secondary data from the 2016-2018 PNG Demographic and Health Survey (DHS), a nationally representative cross-sectional study. A total weighted sample of 4748 women aged 15-49 were included. Complex samples analysis was performed to determine the direction of association between the independent variables and delayed initiation of breastfeeding.  ResultsAbout a quarter (24.6%) of women delayed initiation of breastfeeding. Women with an unplanned pregnancy (AOR 1.32; 95% CI: 1.03 to 1.68), those who had a caesarean section (AOR 3.16; 95% CI: 1.39 to 7.17), those who did not initiate newborn skin-to-skin contact immediately after birth (AOR 1.83; 95% CI: 1.41 to 2.38), and those who watched television (AOR 1.39; 95% CI: 1.11 to 1.75), or were from the Momase region (AOR 1.31; 95% CI: 0.88 to 1.93) had higher odds of delayed breastfeeding initiation. Conversely, those who read a newspaper or magazine (AOR 0.76; 95% CI: 0.61 to 0.95), were from the Southern (AOR 0.81; 95% CI: 0.56 to 1.15) and Highlands (AOR 0.86; 95% CI: 0.58 to 1.29) regions, and gave birth at home or in the village (AOR 0.69; 95% CI: 0.49 to 0.96) had lower odds of delayed initiation of breastfeeding.  ConclusionOne in four women in this study delayed initiation of breastfeeding until after one hour after birth. Interventions to promote optimal breastfeeding require a multi-sectoral approach, as well as bolstering health workers capacity to encourage and support early initiation of breastfeeding during the antenatal and early postnatal periods.  What is known about the subjectO_LIEarly breastfeeding initiation within the first hour of birth is an important intervention to reduce childhood morbidities and mortalities. C_LIO_LIIn PNG, 40% of newborns are not breastfed immediately or within the first hour of birth. C_LI  What this study addsO_LIOne in four women in PNG delayed early initiation of breastfeeding. C_LIO_LIUnplanned pregnancy, caesarean section, no newborn skin-to-skin contact immediately after birth, and exposure to media predicted delayed initiation of breastfeeding. C_LIO_LIBirth at home or in the village reduces the likelihood of delayed initiation of breastfeeding. C_LI  How this study affects research, practice or policyO_LIThis study seeks to promote targeted breastfeeding support for mothers, particularly in rural areas. C_LIO_LIBreastfeeding advocacy and promotion programmes, strengthening health workers capacity to address factors influencing delayed initiation of breastfeeding, and promoting optimal breastfeeding practices are required. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association of complex traits with common genetic variation across genomic regions containing pathogenic copy number variations\nAbstract: BackgroundCopy Number Variations (CNVs) are structural variation in the genome, which may impact complex human traits and diseases. The investigation of rare CNVs is impeded by low sample size. To understand the mechanisms through which CNVs influence human health, common variation in the genomic region of the CNV from large samples could be used as a proxy.  MethodsUtilising genome-wide association study (GWAS) summary statistics of 20 traits, we assessed the cumulative effect of common genetic variants in eight genomic regions containing pathogenic CNVs, using MAGMA gene-based analysis. We used GSA-MiXeR to estimate the fold enrichment of these CNV regions for the specific phenotypes.  ResultsThe distal and proximal regions of the 16p11.2 CNV exhibited the highest number of significant associations and were enriched for the highest number of traits: 12 of 27 significant MAGMA associations (44%) were enriched. These CNV regions also had the highest number of phenotype-associated genes related to ion transport, signalling, transcriptional regulation, development, and protein metabolism. We compared the significance of all the genomic regions and the genes in these regions and found two opposing patterns: 1) cumulative value of separate genes, resulting in the higher significance of the whole region than of the particular genes; 2) higher significance of the specific genes that drive the association of the whole region.  ConclusionsCharting the features of genomic regions encompassing CNVs might aid in clarifying CNVs role in human disease, especially pinpointing candidate genes within these regions that are associated with complex traits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Health Data Reporting Challenges in the Age of DHIS2: a Mixed-Methods Review in the Teso Sub-Region of Uganda\nAbstract: In Uganda, the complete and timely reporting of priority disease data by health centers is critical for detecting outbreaks. However, health centers face significant reporting challenges, which compromise data fidelity and public health. To assess the efficacy of existing systems, we aimed to (1) compare reporting performance among districts in the Teso region of Eastern Uganda, (2) ascertain the association between volume of outpatient department (OPD) visits and reporting rates at facilities, and (3) characterize reporting challenges. We queried Ugandas Electronic Health Management Information System database, DHIS2, regarding the completeness (reporting rate) and timeliness (reporting rate on time) of priority disease data submission within Teso from January-April 2024. We selected the 3 lowest-performing districts in both metrics and assessed reporting at all health centers within these districts. We used linear regression to determine the relationship between the aggregate number of outpatient visits per health facility and their mean reporting rates. At 7 health facilities across the 3 districts, we interviewed staff to enumerate reporting challenges. Of all 11 districts in Teso, 7 (64%) scored >80% for completeness and 2 (18%) scored >80% for submission timeliness across health facilities. The median (IQR) scores for completeness and timeliness were 83% (75-93%) and 69% (55-75%), respectively. The 3 lowest performing districts in both metrics were Soroti City, Soroti district, and Ngora district. In Soroti City, increasing number of OPD visits was associated with higher reporting rate percentages (b [slope]=0.005, p=0.01). The main reasons given for low reporting rates included limited staff trained on data entry protocols, competing responsibilities among reporting personnel, and lack of reliable internet access. The implementation of DHIS2 has improved public health and disease surveillance in Uganda, but institutional-level data reporting challenges continue to impair disease tracking. Targeted interventions to relieve such barriers is possible.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Health Data Reporting Challenges in the Age of DHIS2: a Mixed-Methods Review in the Teso Sub-Region of Uganda\nAbstract: In Uganda, the complete and timely reporting of priority disease data by health centers is critical for detecting outbreaks. However, health centers face significant reporting challenges, which compromise data fidelity and public health. To assess the efficacy of existing systems, we aimed to (1) compare reporting performance among districts in the Teso region of Eastern Uganda, (2) ascertain the association between volume of outpatient department (OPD) visits and reporting rates at facilities, and (3) characterize reporting challenges. We queried Ugandas Electronic Health Management Information System database, DHIS2, regarding the completeness (reporting rate) and timeliness (reporting rate on time) of priority disease data submission within Teso from January-April 2024. We selected the 3 lowest-performing districts in both metrics and assessed reporting at all health centers within these districts. We used linear regression to determine the relationship between the aggregate number of outpatient visits per health facility and their mean reporting rates. At 7 health facilities across the 3 districts, we interviewed staff to enumerate reporting challenges. Of all 11 districts in Teso, 7 (64%) scored >80% for completeness and 2 (18%) scored >80% for submission timeliness across health facilities. The median (IQR) scores for completeness and timeliness were 83% (75-93%) and 69% (55-75%), respectively. The 3 lowest performing districts in both metrics were Soroti City, Soroti district, and Ngora district. In Soroti City, increasing number of OPD visits was associated with higher reporting rate percentages (b [slope]=0.005, p=0.01). The main reasons given for low reporting rates included limited staff trained on data entry protocols, competing responsibilities among reporting personnel, and lack of reliable internet access. The implementation of DHIS2 has improved public health and disease surveillance in Uganda, but institutional-level data reporting challenges continue to impair disease tracking. Targeted interventions to relieve such barriers is possible.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Why sovereignty in PPR vaccination matters for pastoral women: Exploring experiences and perspectives in a qualitative study in the Somali region, Ethiopia\nAbstract: Peste des petits ruminants (PPR) is a viral disease that significantly affects small ruminants, posing a serious threat to the livelihoods and food security of rural communities. Pastoral women are particularly impacted, as they are the primary caretakers of sheep and goats. While managing livestock can empower women, prevailing gender norms may limit this potential. This study aimed to explore womens experiences in taking on responsibility for animal health and to analyse the challenges and opportunities presented by PPR intervention projects.  Eight focus group discussions were conducted with women from three districts in the Somali region of Ethiopia, supplemented by twelve key informant questionnaires and one key informant interview. Qualitative data were analysed using reflexive thematic analysis, while quantitative data were analysed using descriptive statistics.  The research findings present one overarching theme:  The importance of womens sovereignty in PPR vaccination, along with two main themes. The first theme,  Navigating hierarchies and the feminisation of responsibility, comprises the subthemes  Women in responsibility,  Cultural norms and masculinities, and  Men losing track. This theme highlights womens predominant roles in livestock management, household chores, and income generation, while it also explores traditional gender roles and the impacts of mens khat consumption. The second main theme,  Knowledge privilege, dilemmas, and gaps, encompasses the subthemes  Knowledge for empowerment,  Dilemmas despite knowledge, and  Challenges due to training gaps. This theme explores womens empowerment through PPR training, underscores the critical importance of unhindered access to PPR vaccines and effective cold chain maintenance, addresses challenges such as vaccine hesitancy and antimicrobial usage, and stresses the need for community-based training initiatives.  The study emphasises a shift from the traditional gendered division of labor toward an increased burden of responsibility on women, a trend that appears to have been reinforced by anti-poverty programs and further intensified by mens khat consumption. Training in animal health, particularly in PPR vaccination, has been identified as an area where women are eager to engage. To support this, the study recommends adopting  train-the-trainer and community-based approaches, while ensuring access to resources. These strategies must be gender-responsive to empower women in PPR management and reduce their workloads in the long term.  One health impact statementThis research highlights the importance of involving pastoral women in managing Peste des petits ruminants (PPR), a viral disease that significantly affects sheep and goats. It also emphasises the risk of overburdening women in poverty reduction efforts and stresses the need for gender-responsive initiatives to reduce their workload in the long term.  By empowering women in animal health management through such initiatives, both animal health and the livelihoods and food security of rural communities are improved. This underscores the value of a One Health approach, which integrates human, veterinary, and social sciences to comprehensively address health challenges.  The research was made possible through long-standing trust relationships between NGO staff and communities, which facilitated strong community engagement. The qualitative and reflexive approach to data analysis enabled the voices of affected individuals to be heard, allowing for the co-production of knowledge and enhancing the researchs societal relevance.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hypoperfusion Profiles in outcome after Endovascular Therapy for Isolated Internal Carotid Artery Occluded Patients\nAbstract: BackgroundPatients with acute symptomatic isolated internal carotid artery occlusions (iICAO), also known as ICA-I occlusion, frequently presented with minor neurological deficits. However, they remained at risk for subsequent neurological deterioration even after intravenous thrombolysis. The efficacy of endovascular treatment (EVT) in iICAO patients remains uncertain. Recently, some retrospective studies revealed EVT for acute iICAO was safe and might confer potential benefits. Our aim was to identify the hypoperfusion profiles associated with neurological deterioration and functional outcome following EVT in iICAO patients.  MethodsWe performed a multi-center, real-world cohort study involving acute symptomatic iICAO patients who underwent EVT from August 2018 to February 2024 across 3 stroke centers. Hypoperfusion profiles were assessed using Tmax volumes (>4s, >6s, >8s, and >10s) and Tmax mismatch ratios (>10s/>8s, >10s/>6s, >10s>4s, >8s/>6s, >8s/>4s, and >6s/>4s). Neurological deterioration was defined as an increase of [&gt;=]4 points in the NIHSS score prior to EVT. Good outcome was defined as modified Rankin Score 0 - 1 at 90 days.  ResultsA total of 63 patients were included in the final analysis. Multivariable models showed that a lower Tmax ratio of >6s/>4s was an independent predictor for increased risk of neurological deterioration (OR, 0.003; 95% CI: 0.000-0.133; P = 0.003) and was associated with a better outcome following EVT (OR, 0.066; 95% CI: 0.005-0.874; P = 0.039) after adjustment. The optimal threshold for the Tmax >6s/>4s ratio was identified as 0.5.  ConclusionsA perfusion defect severity ratio of Tmax >6s/>4s less than 0.5 might indicate the likelihood of neurological deterioration, yet it would be associated with achieving a good outcome following EVT for iICAO patients. The hypoperfusion profile characterized by a Tmax >6s/>4s might be useful to the neurointerventionists for facilitating appropriate patient triage and guiding prognosis for EVT in iICAO patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Acceptability of Rehabilitation Exoskeleton from the Perspective of Users with Spinal Cord Injury and Healthcare Professionals: a Mixed Methods Systematic Review\nAbstract: ObjectiveThe objective was to document the acceptability of rehabilitation exoskeletons from the perspective of users with spinal cord injury (SCI) and healthcare professionals (HP).  MethodsThis mixed-methods systematic review considered quantitative, qualitative and mixed methods studies that included adults with SCI using an exoskeleton for gait rehabilitation, as well as HP working within rehabilitation settings with individuals with SCI who used an exoskeleton. A convergent integrated approach per the Joanna Briggs Institute (JBI) was used.  ResultsA total of 22 studies were included. Overall, individuals with SCI and HP expressed a favorable level of acceptability. Participants reported a positive affective attitude, an overall satisfaction, and several psychological benefits. Few burdens, ethical issues and opportunity costs have also been reported in the studies. Maintaining realistic expectations towards exoskeleton use and ensuring the appropriate selection of users is important for intervention coherence. In general, there was a positive perception regarding effectiveness and self-efficacy. Nevertheless, only a limited number of studies focused primarily on measuring acceptability, revealing an important gap in the literature.  ConclusionsThe acceptability of exoskeletons among people with SCI and HP tends to be positive, which is promising for the sustainable implementation of this technology. However, there is still a lack of knowledge about the acceptability of HP, with only two studies conducted among this population. It is crucial to persevere in documenting the acceptability of exoskeletons, notably by standardizing comprehensive approaches for measuring acceptability, and to continue refining this technology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Social impact of the JACO wheelchair-mounted robotic arm on users and their caregivers\nAbstract: The efficacious implementation of robotic assistive technologies must be built on a thorough understanding of stakeholders experiences and perceptions. This study provides an in-depth insight into the experiences and perceptions of users of the JACO wheelchair-mounted robotic arm and those of their caregivers. A sample of JACO users (n = 21; Female : 6; Male : 15) and caregivers (n = 11; Female: 2; Male: 9) participated in individual interviews used to gain qualitative insight into the impact of JACO on their day-to-day lives. Interview transcripts were analyzed using a hybrid deductive-inductive coding process. Thematic analysis was conducted in accordance with the Consortium on Assistive Technology Outcomes Research (CATOR) taxonomy. This article exclusively reports data on the social impact of the JACO wheelchair-mounted robotic arm. In addition, participants completed three questionnaires to gather more objective data for quantitative assessment, these included the Caregiver Assistive Technology Outcome Measure (CATOM), a sociodemographic questionnaire, and a home-based questionnaire to assess the social impact of using JACO. Findings pointed to highly varied experiences among participants, including instances of positive, negative, and absence of effects from the use of JACO. Participants feedback fell within two broad categories, Human Assistance, and Cost and Use of Resources. This study provides nuanced and varied insight into the spectrum of the social impact of using JACO as perceived by users and their caregivers, highlighting the importance of considering each user as an individual with unique experiences and needs. Continued research is needed to assess the generalizability of these findings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Severe Sarcoidosis Demonstrates Heterogenous Immune Dysregulation Across Different Peripheral Immune Cell Types: A Single-Center Single Cell Multi-omic Analysis\nAbstract: Sarcoidosis provides unique management challenges due to variable presentation and disease course. In this single-center analysis, we assess transcriptomic and epigenomic differentiators between severe and mild cases of sarcoidosis using peripheral blood. We showcase differences across multiple cell types that highlight decreased immunoregulation and increased inflammation in severe sarcoidosis. We provide an overall framework for the interactions between immune cells in severe sarcoidosis as a basis for future therapeutic research.  Visual Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=133 SRC=\"FIGDIR/small/24313886v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (31K): org.highwire.dtl.DTLVardef@5a31cforg.highwire.dtl.DTLVardef@17c3746org.highwire.dtl.DTLVardef@10e4d0org.highwire.dtl.DTLVardef@11e1dfa_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Obstetric anal sphincter injuries detection by digital rectal examination and impedance spectroscopy: post-hoc analysis of the results from a prospective, comparative, multicentre clinical study\nAbstract: ObjectiveTo evaluate the clinical performance of digital rectal examination (DRE) and machine learning-assisted impedance spectroscopy (ONIRY) for detecting obstetric anal sphincter injuries (OASI) compared to three-dimensional endoanal ultrasound (EAUS).  DesignA post-hoc analysis of data from a prospective, comparative, multicentre, international study (NCT04903977).  SettingPoland, Czech Republic, Slovakia, and Spain.  Population152 vaginally delivered women to 8 weeks post-partum.  MethodsParticipants were divided into two groups based on EAUS results: Group I (no OASI, including 1st and 2nd degree perineal tears per OASIS classification) and Group II (OASI, including 3rd and 4th-degree tears per OASIS classification). DRE and impedance measurements using the ONIRY system were performed. The machine learning (ML) model for ONIRY was trained and validated. The diagnostic outcomes of ONIRY and DRE were compared to EAUS.  Main Outcome MeasuresAccuracy, sensitivity, and specificity.  ResultsDREs performance versus EAUS was 67.8% for accuracy, 44.3% for sensitivity, and 83.5% for specificity. After completion of ML model training, impedance spectroscopys accuracy, sensitivity, and specificity were 87.0%, 90.6%, and 84.6%, respectively, compared with EAUS.  ConclusionDRE is insufficient for OASI detection. The ML-assisted impedance spectroscopy demonstrated higher accuracy and could facilitate rapid OASI detection post-delivery.  FundingThe study was financed by the European Unions Fast Track program through the Polish National Centre for Research and Development (POIR.01.01.01-00-0726/18)\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Filovirus outbreak responses and occupational health effects of chlorine spraying in healthcare workers: a systematic review and meta-analysis of alternative disinfectants and application methods\nAbstract: ObjectiveIn the context of filovirus outbreaks, chlorine spraying has been the standard for infection prevention and control. Due to potential occupational health risks, public health institutions now recommend wiping, which is labor-intensive and may increase the risk of heat stress for healthcare workers wearing personal protective equipment. This systematic review and meta-analysis quantified the health effects of occupational exposure to chlorine-based products compared to other disinfectants, and the effects of spraying compared to general disinfection tasks (GDTs) like wiping and mopping, in healthcare settings.  Data sources, design and eligibility criteriaMEDLINE, Scopus, and ScienceDirect were searched for studies addressing the association between exposure to disinfectants applied by different application methods and occupational diseases in healthcare settings. Risk of bias was assessed by two independent reviewers using a validated tool.  Data extraction and synthesisTwo reviewers independently screened and performed data extraction and synthesis. A third reviewer resolved disagreements. Meta-analyses were conducted using fixed- and random-effects models based on the Higgins I{superscript 2} statistic.  Results30 studies investigating chlorine-based products (7,123 participants), glutaraldehyde (6,256 participants), peracetic acid, acetic acid and hydrogen peroxide (4,728 participants), quaternary ammonium compounds (QACs) (9,270 participants), use of spray (4,568 participants) and GDTs (3,480 participants) were included. Most had a cross-sectional design and high risk of bias. Meta-analysis indicates a significant association between respiratory conditions and exposure to chlorine-based products (OR 1.71, 95%CI 1.41- 2.08), glutaraldehyde (OR 1.44, 95%CI 1.14-1.81), QACs (OR 1.30, 95%CI 1.06-1.60), use of spray (OR 25, 95%CI 1.61-3.14) and GDTs (OR 2.20, 95%CI 1.66-2.90). The relative odds ratio (ROR) of respiratory conditions for chlorine-based products compared to QACs was 0.76 (95%CI 0.62-0.94). The ROR for the use of spray compared to GDTs was 0.98 (95%CI 0.74-1.29). Strengths include evaluating respiratory health risks of disinfectants, applying a validated tool, using both fixed- and random-effects models, and comparing pooled effect sizes. Limitations include high risk of bias for the majority of included articles, varying confounder adjustments, underreported non-respiratory outcomes, and unspecified disinfectants and PPE use for spray and GDTs articles.  ConclusionChlorine-based disinfectants significantly increase respiratory risk compared to QACs. Sprays and general disinfection tasks present similar risks. Our findings advocate for using less hazardous products like QACs, rather than banning sprays in filovirus outbreak responses to enhance disinfection safety.  Prospero registration numberCRD42023479363  Article summaryStrengths and limitations of this study  O_LIThe systematic review and meta-analysis provide a comprehensive comparison of the health effects of occupational exposure to various disinfectants and application methods in healthcare settings. C_LIO_LIThe study includes a broad range of disinfectants and application methods, offering a detailed assessment that extends beyond filovirus treatment centers. C_LIO_LIThe inclusion of both fixed- and random-effects models in the meta-analysis ensures a robust evaluation of the data, accounting for potential variability among studies. C_LIO_LIWhile this study focused on respiratory conditions, other outcomes such as skin and ocular conditions were underreported, limiting the comprehensiveness of the assessment. C_LIO_LIVariations in exposure assessment methods and the lack of information on specific disinfectant products, PPE use, and ventilation further complicate comparisons and limit the ability to attribute health effects to specific factors. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic value of YiDiXie\u2122-SS and YiDiXie\u2122-HS in endometrial carcinoma\nAbstract: BackgroundEndometrial cancer represents a significant challenge to human health and is associated with a considerable economic burden. Ultrasound is a commonly employed modality in the screening and preliminary diagnosis of endometrial cancer. However, false-positive ultrasound results can lead to misdiagnosis, patients have to bear unnecessary distress, expensive examination costs, examination injuries and other adverse consequences; while false-negative ultrasound results will result in delayed treatment, and patients will thus have to bear the adverse consequences of a poor prognosis, high treatment costs, poor quality of life and short survival. It is imperative to identify convenient, cost-effective and non-invasive diagnostic techniques to minimize the prevalence of false positives and false negatives in uterine ultrasound. The objective of this study was to assess the diagnostic efficacy of YiDiXie-SS and YiDiXie-HS in the context of endometrial cancer.  Patients and methodsThe final number of study subjects included in this study was 74, comprising 58 cases of malignant disease and 16 cases of benign disease. The remaining serum samples from the subjects were collected and tested using the YiDiXie all-cancer detection kit, with the objective of evaluating the sensitivity and specificity of the YiDiXie-SS and YiDiXie-HS, respectively.  ResultsThe sensitivity of YiDiXie-SS was 98.3% (95% CI: 90.9% - 99.9%) and its specificity was 62.5% (95% CI: 38.6% - 81.5%). YiDiXie-HS had a sensitivity of 82.8% (95% CI: 71.1% - 90.4%) and its specificity was 81.3% (95% CI: 57.0% - 93.4%). The sensitivity of YiDiXie-SS in patients with a positive uterine ultrasound was 95.0% (95% CI: 76.4% - 99.7%), while the specificity was 75.0% (95% CI: 30.1% - 98.7%). This indicates that the utilisation of YiDiXie-SS has the potential to reduce the incidence of false-positive uterine ultrasound results by 75.0% (95% CI: 30.1% - 98.7%), while simultaneously minimising the likelihood of malignancy leakage. The YiDiXie-HS in patients with a negative uterine ultrasound was 81.6% (95% CI: 66.6% - 90.8%), while the specificity was 83.3% (95% CI: 55.2% - 97.0%). This suggests a reduction of 81.6% (95% CI: 66.6% - 90.8%) in the rate of false-negative uterine ultrasound with the application of YiDiXie-HS.  ConclusionYiDiXie  -SS is an effective method for reducing the rate of uterine ultrasound false positives while maintaining a low incidence of delayed treatment of malignancies. YiDiXie-HS has been demonstrated to significantly reduce the rate of false-negative uterine ultrasound results. YiDiXie-SS and YiDiXie-HS have significant diagnostic value in endometrial cancer, and are expected to solve the two problems of  high false positive rate of uterine ultrasound and  high false negative rate of uterine ultrasound in endometrial tumors.  Clinical trial numberChiCTR2200066840.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Variance quantitative trait loci reveal gene-gene interactions which alter blood traits\nAbstract: Gene-gene (GxG) interactions play an important role in human genetics, potentially explaining part of the \"missing heritability\" of polygenic traits and the variable expressivity of monogenic traits. Many GxG interactions have been identified in model organisms through experimental breeding studies, but they have been difficult to identify in human populations. To address this challenge, we applied two complementary variance QTL (vQTL)-based approaches to identify GxG interactions that contribute to human blood traits and blood-related disease risk. First, we used the previously validated genome-wide scale test for each trait in [~]450,000 people in the UK Biobank and identified 4 vQTLs. Genome-wide GxG interaction testing of these vQTLs enabled discovery of novel interactions between (1) CCL24 and CCL26 for eosinophil count and plasma CCL24 and CCL26 protein levels and (2) HLA-DQA1 and HLA-DQB1 for lymphocyte count and risk of celiac disease, both of which replicated in [~]140,000 NIH All of Us and [~]70,000 Vanderbilt BioVU participants. Second, we used a biologically informed approach to search for vQTL in disease-relevant genes. This approach identified (1) a known interaction for hemoglobin between two pathogenic variants in HFE which cause hereditary hemochromatosis and alters risk of cirrhosis and (2) a novel interaction between the JAK2 46/1 haplotype and a variant on chromosome 14 which modifies platelet count, JAK2 V617F clonal hematopoiesis, and risk of polycythemia vera. This work identifies novel disease-relevant GxG interactions and demonstrates the utility of vQTL-based approaches in identifying GxG interactions relevant to human health at scale.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mendelian randomization suggests a causal link between glycemic traits and thoracic aortic structures and diseases\nAbstract: ImportanceType 2 diabetes mellitus (T2DM) and elevated glucose levels have been inversely associated with aortic aneurysms. However, the causality of this relationship remains uncertain. Additionally, there is a lack of studies investigating the association between glycemic traits and imaging-based thoracic aortic phenotypes.  ObjectiveWe investigated whether T2DM and glycemic measures (fasting glucose (FG), fasting insulin (FI), glycated hemoglobin (HbA1c), and 2-hour post-load glucose (2hPG)) are causally associated with various imaging and clinical thoracic aortic phenotypes.  Design, setting, and participantsWe performed Mendelian randomization (MR) analysis using summary statistics from genome-wide association studies of glycemic traits (GT) and aortic phenotypes. We employed a two-sample univariate MR (UVMR) followed by a multivariable MR and MR analysis using a cluster-based approach.  Main Outcomes and MeasuresThe outcome includes imaging-based ascending and descending aortic diameters (AAoD and DAoD), aortic distensibility (AoDist) and strain (AoStr), and thoracic aortic aneurysm and dissection (TAAD). The GT include FI, FG, HbA1c, 2hPG and T2DM.  ResultsWe observed an inverse association between 2hPG, FG, HbA1c, and T2DM and AAoD, DAoD. For instance, the genetically predicted increases levels of 2hPG, FG, HbA1c, and T2DM were associated with decreased AAoD (2hPG {beta}= -0.2, p=3x10-08; FG {beta}= -0.21, p=5x10-05; HbA1c {beta}= -0.36, p=2x10-07; T2DM {beta}=-0.04, p=2x10-04) and reduce risk TAAD (2hPG decreased TAAD (2hPG OR= 0.70, p=4x10-04; FG OR= 0.58, p=3x10-05; HbA1c OR= 0.62, p=5x10-03; T2DM OR= 0.90, p=6x10-6). Further investigation showed that the inverse association between T2DM and aortic phenotypes is driven by genetic predictors of T2DM beta cell proinsulin clusters. UVMR and Proteomic MR showed a strong association with aortic phenotypes for genes, such as AGER, GLRX, TCF7L2, and GCK, which are known to play an important role in glucose regulation.  Conclusion and relevanceOur findings suggest a potentially causal impact of GT on the aortic vasculature. Furthermore, specific glucose regulation genes such as GCK, AGER, and TCF7L2 appear to contribute to this process, opening avenues for potentially leveraging the druggability of these genes for treatment or preventions of TAAD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Meta-SAIGE: Scalable and Accurate Meta-Analysis for Rare Variants\nAbstract: A meta-analysis is a practical approach to increasing the power of rare variant tests by combining summary statistics from multiple cohorts. However, existing methods for rare variant meta-analysis often fail to correctly control type I error rates when analyzing low-prevalence binary traits and are computationally intensive when analyzing many phenotypes. This paper introduces Meta-SAIGE, a novel approach for rare variant meta-analyses that addresses these challenges. Meta-SAIGE reduces type I error inflation through precise estimation of the distribution of test statistics and allows the reuse of the linkage disequilibrium (LD) matrix across phenotypes, significantly improving computational efficiency for phenome-wide analyses. Simulation studies using UK Biobank whole-exome sequencing (WES) genotypes demonstrate that Meta-SAIGE effectively controls type I error rates and yields power similar to that of pooled individual-level data through SAIGE-GENE+. A meta-analysis of UK Biobank and All of Us WES data for 83 low prevalence disease phenotypes identified 237 associations. Notably, 80 of these associations were not significant in either dataset alone, underscoring the power of our meta-analysis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Automating ACMG Variant Classifications Using BIAS-2015: An Algorithm Overview and Benchmark Against the FDA-Approved eRepo Dataset\nAbstract: In 2015, the American College of Medical Genetics and Genomics (ACMG) in collaboration with the Association of Molecular Pathologists (AMP) published guidelines for the interpretation and classification of germline genomic variants. The ACMG terminology guidelines outlined criteria for assigning one of five categories: benign, likely benign, uncertain significance, likely pathogenic and pathogenic. While the paper laid out 28 different classifiers and the justification for them, it did not provide specific algorithms for implementing these classifiers in an automated manner. Here we present the Bitscopic Interpreting ACMG Standards 2015 (BIAS-2015) software as a complete, open-source algorithm which categorizes variants according to the ACMG classification system. BIAS-2015 evaluates 18 of the 28 ACMG criteria to classify variants in an automated and consistent way while recording the rationale for each classifier to enable in-depth review. We used the genomic data from the ClinGen Evidence Repository (eRepo v1.0.29), one of two FDA-recognized human genetic variant databases, to evaluate the performance of the BIAS-2015 algorithm. All code for BIAS-2015 has been made available on GitHub.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Causal relationship between school-entry age and adolescent health: quasi-experimental evidence from 1.6 million participants in Vietnam\nAbstract: BackgroundSchool-entry age has been suggested to affect human capital development. Little is known, however, about the impacts of school-entry age on adolescent health in low- and middle-income countries where most children and adolescents worldwide reside.  MethodsData on childrens outcomes were extracted from the longitudinal Young Lives Study in Vietnam, conducted between 2001 and 2016 (N=1,532), and the Vietnam Population and Housing Censuses of 1989, 1999, and 2009 (N=1,595,365). In Vietnam, children need to turn six years old by December 31st to enter Grade 1 in September that school year. As a result of the school-entry age policy, children born on or before December 31st start school one year earlier compared to children who are born just after December 31st. Using exposure to the policy as an exogenous instrument for school-entry age, we used two-stage least squares regressions to determine the causal effect of school-entry age on education and health outcomes by age 23 years. We considered pre-primary education, school attendance, time spent in school, childbearing, marriage or cohabitation, as well as anthropometric measurements.  ResultsChildren born after the school-entry age cut-off were more likely to have participated in pre-primary education and were more likely to be in school when compared to children born before the cut-off. A one-year increase in age at the beginning of Grade 1 because of the policy was associated with an increase in the probability of pre-primary education of 13 percentage points (95% CI: 7.8-18.5), daily time spent in school of 0.9 hours (95% CI: 0.5-1.4) and a reduced probability of having an own child of 25.3 percentage points (95% CI: 4.4-46.2). We observed a qualitatively smaller and statistically non-significant relationship between school-entry age and measured body mass index. These results were generally consistent when using alternative specifications of our model, sample, survey rounds, and data sources.  DiscussionChildren who are older when entering primary school stayed in school longer and postponed family formation compared to children who entered school earlier because of the school-entry age policy in Vietnam. Relative age for grade should be considered when designing sexual and reproductive health interventions and programs targeted to adolescents.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PANDORA: An AI model for the automatic extraction of clinical unstructured data and clinical risk score implementation\nAbstract: IntroductionMedical records and physician notes often contain valuable information not organized in tabular form and usually require extensive manual processes to extract and structure. Large Language Models (LLMs) have shown remarkable abilities to understand, reason, and retrieve information from unstructured data sources (such as plain text), presenting the opportunity to transform clinical data into accessible information for clinical or research purposes.  ObjectiveWe present PANDORA, an AI system comprising two LLMs that can extract data and use it with risk calculators and prediction models for clinical recommendations as the final output.  MethodsThis study evaluates the models ability to extract clinical features from actual clinical discharge notes from the MIMIC database and synthetically generated outpatient clinical charts. We use the PUMA calculator for Chronic Obstructive Pulmonary Disease (COPD) case finding, which interacts with the model and the retrieved information to produce a score and classify patients who would benefit from further spirometry testing based on the 7 items from the PUMA scale.  ResultsThe extraction capabilities of our model are excellent, with an accuracy of 100% when using the MIMIC database and 99% for synthetic cases. The ability to interact with the PUMA scale and assign the appropriate score was optimal, with an accuracy of 94% for both databases. The final output is the recommendation regarding the risk of a patient suffering from COPD, classified as positive according to the threshold validated for the PUMA scale of equal to or higher than 5 points. Sensitivity was 86% for MIMIC and 100% for synthetic cases.  ConclusionLLMs have been successfully used to extract information in some cases, and there are descriptions of how they can recommend an outcome based on the researchers instructions. However, to the best of our knowledge, this is the first model which successfully extracts information based on clinical scores or questionnaires made and validated by expert humans from plain, non-tabular data and provides a recommendation mixing all these capabilities, using not only knowledge that already exists but making it available to be explored in light of the highest quality evidence in several medical fields.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Minimal PBPK Model Describes the Differential Disposition of Silica Nanoparticles In Vivo\nAbstract: Nanoparticles (NPs) have emerged as promising candidates for drug delivery due to their tunable physical and chemical properties. Among these, silica nanoparticles (SiNPs) are particularly valued for their biocompatibility and adaptability in applications like drug delivery and medical imaging. However, predicting SiNP biodistribution and clearance remains a significant challenge. To address this, we developed a minimal physiologically-based pharmacokinetic (mPBPK) model to simulate the systemic disposition of SiNPs, calibrated using in vivo PK data from mice. The model assesses how variations in surface charge, size, porosity, and geometry influence SiNP biodistribution across key organs, including the kidneys, lungs, liver, and spleen. A global sensitivity analysis identified the most influential parameters, with the unbound fraction and elimination rate constants for the kidneys and MPS emerging as critical determinants of SiNP clearance. Non-compartmental analysis (NCA) further revealed that aminated SiNPs exhibit high accumulation in the liver, spleen, and kidneys, while mesoporous SiNPs primarily accumulate in the lungs. Rod-shaped SiNPs showed faster clearance compared to spherical NPs. The mPBPK model was extrapolated to predict SiNP behavior in humans, yielding strong predictive accuracy with Pearson correlation coefficients of 0.98 for mice and 0.92 for humans. This model provides a robust framework for predicting the pharmacokinetics of diverse SiNPs, offering valuable insights for optimizing NP-based drug delivery systems and guiding the translation of these therapies from preclinical models to human applications.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: SLC39A8.p.(Ala391Thr) is associated with poorer cognitive ability: a cross-sectional study of schizophrenia and the general UK population\nAbstract: The missense SNP NC_000004.12:g.102267552C>T (SLC39A8.p.(Ala391Thr), rs13107325) in SLC39A8, which encodes a zinc transporter, has been linked to schizophrenia and is the likely causal variant for one of the genome-wide association loci associated with the disorder.  We tested whether the schizophrenia-risk allele at p.(Ala391Thr) was associated with schizophrenia-related phenotypes, including positive, negative, and disorganised symptoms, cognitive ability, educational attainment, and age of psychosis onset, within three schizophrenia cohorts (combined N=1,232) and, with equivalent phenotypes, in a sample of population controls (UK Biobank, N=355,069). We used regression analyses controlling for age, sex, and population stratification.  Within the schizophrenia cohorts, after correction for multiple testing, p.(Ala391Thr) was not significantly associated with any schizophrenia-related phenotypes. In the unaffected participants from the UK Biobank, the schizophrenia-risk allele at p.(Ala391Thr) was associated with significantly poorer cognitive ability and fluid intelligence, a lower probability of obtaining GCSEs or a degree-level qualification, and fewer years in education. There was no association between p.(Ala391Thr) and self-reported psychotic experiences in this cohort.  The schizophrenia-risk allele was associated with poorer cognitive ability, but not psychotic experiences, in a volunteer sample drawn from of the general population. To determine whether p.(Ala391Thr) is associated with cognitive phenotypes in people with schizophrenia, and to understand the role of p.(Ala391Thr) in the aetiology of cognitive impairment in schizophrenia, larger independent samples are required.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: From the Ground Up: Stakeholder Perspectives on Housing Interventions to Reduce Environmentally Mediated Infections\nAbstract: BackgroundHousing conditions are intrinsically linked to human health, with inadequate housing potentially increasing exposure to environmentally mediated pathogens. Housing interventions that aim to improve housing and reduce environmentally mediated infections, such as finished floors and housing upgrades for vector-borne diseases, remain relatively under-explored as health interventions. This study explored facilitators of and barriers to funding, implementing, and scaling up housing improvements as health interventions to reduce environmentally mediated infectious diseases.  MethodsSixteen key informants (KIs) with direct experience in implementing or working within housing interventions and environmentally mediated infectious diseases in low- and middle-income countries were interviewed using a semi-structured interview format. KIs had diverse backgrounds, including academics researching housing interventions, housing policy advisors, and practitioners implementing housing interventions. A thematic analysis approach was used to identify key themes in interview transcripts, highlighting patterns, commonalities, and variations in participants responses.  ResultsKIs emphasized the multi-dimensional impacts of housing interventions that are intrinsically linked to Sustainable Development Goals (SDGs), including physical and mental health, as well as environmental, social, and economic dimensions. Moreover, a pronounced shortage of funding and financial systems to address housing interventions was highlighted, alongside the urgent need for more rigorous evidence and cost-benefit analyses. Furthermore, the imperative to raise awareness of the significance of housing and the critical importance of strong collaboration across sectors and stakeholders were stressed. Emphasizing the necessity for project-based and context-specific housing policies, the interviews revealed that contextualizing interventions to their specific setting and fostering community involvement are essential for successful implementation and scale-up.  ConclusionsHousing interventions play a pivotal role in mitigating environmentally mediated diseases. These interventions can complement existing strategies like water, sanitation, and hygiene (WASH) interventions, ensuring comprehensive approaches to healthy housing and sustainable development goals amidst climate change.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and determinants of central obesity among adults 18 to 69 years in Kenya: a cross-sectional study\nAbstract: BackgroundCentral obesity affects about 4 out of every 10 people globally, and it is a notable public health concern linked with premature morbidity and mortality. In Kenya, regional studies have approximated the prevalence to range from 37% to 50%. However, these studies have been done in specific regions or population groups, such as among urban residents or women. Therefore, we aimed to assess the general and sex-specific prevalence and determinants of central obesity among adults in Kenya.  MethodsAn analysis of the prevalence and determinants of central obesity was assessed using data from the 2015 Kenya STEPwise survey on non-communicable diseases and injuries. We included a final sample of 4 003 participants. Participants characteristics and prevalence of central obesity were described and summarized using frequencies and percentages. The bivariate and multivariate logistic regression were used to assess the determinants of central obesity.  ResultsThe overall weighted prevalence of central obesity was 46.7% [95% confidence interval (CI): 43.2, 50.3], with women exhibiting a significantly higher prevalence compared to men (58.3% vs. 35.6%, p=0.001). Sex, age, household wealth index, and smoking were among the factors significantly associated with central obesity. Men had 66% lower odds of central obesity compared to women, while the risk increased with age, ranging from 1.6 to 4 times higher odds among those aged 30--39 and 50--69 years, respectively, compared to 18--29-year-olds. Other predictors of central obesity were wealthier households and non-smoking.  ConclusionAbout half of the adult Kenyan population is centrally obese, with a higher prevalence among women than men. Kenyas policymakers should consider targeting high-risk groups in this population to reduce the burden of central obesity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A New Algorithm for Incidental Pancreatic Cyst Detection\nAbstract: ObjectivesTo develop an accurate, state-of-the-art algorithm for the incidental detection of pancreatic cystic lesions (PCLs) on computerized tomography (CT) and magnetic resonance imaging (MRI) scans.  MethodsA SwinT-Unet-based architecture was developed for the incidental detection of PCLs. The algorithm was trained and validated on a robust dataset of retrospective CT and MRI studies collected from HT Medica centers located in eight different cities using scanners fabricated by four different manufacturers.  ResultsOur algorithm was able to detect 91.6% of the confirmed PCLs in the initial dataset with 91.6% sensitivity and 92.3% specificity, while 91.7% of the healthy controls were also correctly identified. Furthermore, our tool was remarkably capable of classifying these PCLs as mucinous or non-mucinous, determining their location within the pancreas with an accuracy of 88.5%, and identifying the presence of calcifications or scars within the PCLs with an accuracy of 96%.  ConclusionsBy integrating radiological data and state-of-the-art artificial intelligence techniques, we have developed an efficient tool for the incidental identification and initial characterization of PCLs, which present a substantial prevalence within the global population. Our algorithm facilitates early diagnosis of pancreatic abnormalities, which could have a profound impact on patient management and prognosis, particularly in the case of PCLs with malignant potential.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A mapping review of good practices of participatory research for an impactful collaboration in disabilities studies\nAbstract: IntroductionParticipatory research is particularly relevant to understanding the challenges faced by people with disabilities (PWDs), as it actively involves them as partners, enabling methodologies to be better adapted to lived realities and producing more relevant and applicable results. By reducing systemic barriers and promoting inclusion, this approach improves understanding and consideration of the specific needs of PWDs in research. Yet, studies have identified hurdles associated with this approach, prompting questions about how organizations portray PWDs, the dynamics among research stakeholders, the distribution of decision-making power, and the actual impact of research on its partners.  AimThis study aims to identify the factors that influence the process and results of participatory research in the field of disability studies  MethodsWe conducted a mapping review following the PRISMA-ScR guidelines, and analysis the results according to the input-throughput-outcomes Bergen model  ResultsThis study identifies partners skills and training, power sharing and benefits of active involvement as facilitators of participatory research. On the other hand, contextual challenges, and lack of guidance are reported as obstacles.  ConclusionThis study provides insight into how the various facilitators and obstacles to participatory research and its different processes interact to produce positive, valid and rigorous results.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Vitamin D supplementation to prevent acute respiratory infections: systematic review and meta-analysis of stratified aggregate data\nAbstract: BackgroundA 2021 meta-analysis of 37 randomised controlled trials (RCTs) of vitamin D supplementation for prevention of acute respiratory infections (ARI) revealed a statistically significant protective effect of the intervention (odds ratio [OR] 0.92, 95% confidence interval [CI] 0.86 to 0.99). Since then, 6 eligible RCTs have completed, including one large trial (n=15,804).  MethodsUpdated systematic review and meta-analysis of data from RCTs of vitamin D for ARI prevention using a random effects model. Sub-group analyses were done to determine whether effects of vitamin D on risk of ARI varied according to baseline 25-hydroxyvitamin D (25[OH]D) concentration, dosing regimen or age. We searched MEDLINE, EMBASE, the Cochrane Central Register of Controlled Trials, Web of Science and the ClinicalTrials.gov were searched between May 2020 (previous search) and April 2024. No language restrictions were imposed. Double-blind RCTs supplementing vitamin D for any duration, with placebo or low-dose vitamin D control, were eligible if approved by Research Ethics Committee and if ARI incidence was collected prospectively and pre-specified as an efficacy outcome. Aggregate data, stratified by baseline 25(OH)D concentration and age, were obtained from study authors. The study was registered with PROSPERO (no. CRD42024527191).  FindingsWe identified 6 new RCTs (19,337 participants). Data were obtained for 16,086 (83.2%) participants in 3 new RCTs and combined with data from 48,488 participants in 43 previously identified RCTs. For the primary comparison of any vitamin D vs. placebo, the intervention did not significantly affect overall ARI risk (OR 0.94, 95% CI 0.88 to 1.00, P=0.057; 40 studies; I2 26.4%). Pre-specified subgroup analysis did not reveal evidence of effect modification by age, baseline vitamin D status, or dosing regimen. Vitamin D did not influence the proportion of participants experiencing at least one serious adverse event (OR 0.96, 95% CI 0.90 to 1.04; 38 studies; I2 0.0%). A funnel plot showed left-sided asymmetry (P=0.002, Eggers test).  InterpretationThis updated meta-analysis yielded a similar point estimate for the overall effect of vitamin D supplementation on ARI risk to that obtained previously, but the 95% CI for this effect estimate now spans 1.00, indicating no statistically significant protection.  FundingNone  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSWe searched MEDLINE, EMBASE, the Cochrane Central Register of Controlled Trials (CENTRAL), Web of Science and the ClinicalTrials.gov registry from 1st May 2020 (date of our previous search) to 30th April 2024 for randomised Controlled Trials and meta-analyses of randomised Controlled Trials evaluating effectiveness of vitamin D supplementation for the prevention of acute respiratory infections. Our previous meta-analysis of 43 randomised Controlled Trials (RCTs) of vitamin D supplementation for prevention of acute respiratory infections (ARI) conducted in 2021 revealed a statistically significant protective effect of the intervention (OR 0.92, 95% CI 0.86 to 0.99). A further 6 eligible RCTs, contributing data from 19,337 participants have now completed, including one large trial (n=15,804).  Added value of this studyOur meta-analysis of aggregate data from 64,086 participants in 46 randomised controlled trials, stratified by baseline 25(OH)D concentration and age, provides an updated estimate of the protective effects of vitamin D against acute respiratory infection overall (OR 0.94, 95% CI 0.88 to 1.00), and in sub-groups defined by baseline vitamin D status, age, and dosing frequency, amount and duration.  Implications of all the available evidenceUpdated meta-analysis including the latest available RCT data shows no statistically significant protective effect of vitamin D supplementation against ARI, either overall or in sub-group analyses.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bovhyaluronidase azoximer for long-term pulmonary sequelae of COVID-19: a randomized, double-blind, placebo-controlled trial\nAbstract: BackgroundHyaluronan is an emerging target for COVID-19 and lung fibrosis. In an open-label study the hyaluronidase bovhyaluronidase azoximer (BA) was associated with improved pulmonary function and exercise tolerance in patients with pulmonary sequelae of COVID-19. In this randomized, double-blind, placebo-controlled trial we evaluated the effect of BA on patients up to 12 months after COVID-19, characterized by reduced pulmonary function, dyspnea, and decreased oxygen saturation.  MethodsPatients (n=392) were randomized 1:1 to receive BA (3000U) or placebo every 5 days for 71 days. Percent of predicted forced vital capacity (ppFVC), respiratory symptoms, and exercise tolerance indicators were assessed at baseline and on days 71 and 180. The primary endpoint was a change from baseline in ppFVC by Day 71.  ResultsOn Day 71, BA was associated with a significant reduction in the proportion of patients with exertional desaturation (OR=0.35, p=0.0051) and dyspnea (OR=0.62, p=0.043). There were no significant intergroup differences in the ppFVC growth rate. Analysis of sub-populations revealed that by Day 180, BA was associated with increased ppFVC in patients with cardiovascular comorbidities (diff=3.31%, p=0.042) and those with earlier SARS-CoV-2 infection (diff=4.17%, p=0.021). BA was generally safe and well-tolerated.  ConclusionIn patients with long-term pulmonary sequelae of COVID-19, BA was associated with increased exercise tolerance. There was evidence of shorter pulmonary function recovery time following BA in patients with cardiovascular comorbidities and those with earlier COVID-19 disease.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clinical validation of a DNA methylation biomarker to predict overall survival of relapsed ovarian cancer patients.\nAbstract: BackgroundAbout 70% of ovarian cancer (OC) patients relapse after initial chemotherapy, making it crucial to predict survival before second-line treatment. Our previous work discovered a blood-based DNA methylation prognostic signature (PLAT-M8) that uses 8 CpG sites related to chemoresistance. We aim to validate this biomarker and its correlation with clinicopathological features and treatment profiles in additional cohorts.  MethodsExtracted DNA from whole blood was provided from the BriTROC 1 (n=47) and OV04 cohorts (n=57) upon the first relapse. Additional samples from Hammersmith Hospital (n=100) were collected during first-line chemotherapy (cycles 3-4 and 6). Bisulphite pyrosequencing was used to quantify DNA methylation at the previously identified 8 CpG sites. The methylation data obtained were combined with previous data from ScoTROC 1D and 1V (n=141) and OCTIPS (n=46). Cox regression was used to assess overall survival (OS) after relapse concerning clinicopathological characteristics. The DNA methylation Class (Class 1 vs 2) was determined by consensus clustering.  FindingsBlood DNA methylation at relapse predicts better clinical outcomes. Methylation Class shows no association with outcome during first-line chemotherapy treatment. Methylation Class 1 is associated with shorter survival, as indicated by a meta-analysis of five cohorts (OS: HR 2.54, 1.67-3.85). Class 2 patients on carboplatin monotherapy have the best prognosis, while Class 1 patients on the same treatment have the poorest prognosis (OS: aHR 9.69, 2.38-39.47). Class 1 is linked to older patients (>75 years) with advanced-stage, platinum-resistant cases, correlating with residual disease, and shorter progression-free survival. In contrast, Class 2 of PLAT-M8 is linked to platinum-sensitive patients, and higher complete response rates by RECIST criteria, but shows no correlation with CA-125. These findings emphasise the potential of PLAT-M8 in guiding second-line chemotherapy decisions.  InterpretationPLAT-M8 methylation biomarker is associated with survival in OC patients with relapse and hypothetically may predict platinum treatment response at second-line chemotherapy.  FundingThis work was supported by funding from Ovarian Cancer Action (\"Risk and Prevention\" programme grant), Cancer Research UK programme grant (A13086) with support from the Cancer Research UK Imperial Centre, the National Institute for Health Research Imperial Biomedical Research Centre and the Ovarian Cancer Action Research Centre.  Research in contextO_ST_ABSEvidence before this studyC_ST_ABSThere is a strong association between platinum-based chemotherapy and DNA methylation changes in blood DNA during ovarian cancer relapse. Previous findings identified eight specific CpG methylation changes (known as PLAT-M8) in blood at relapse following platinum-based chemotherapy that were associated with overall survival in patients enrolled in the ScoTROC 1 trial and the OCTIPS cohort. Using an ovarian cancer cell line model, the study also showed that functional DNA mismatch repair increased the frequency of platinum-induced methylation, providing insights into the observed epigenetic changes.  Added values of this studyOur current study validates in five large relapsed ovarian cancer cohorts that: (1) PLAT-M8 is associated with various clinicopathological characteristics, such as age, stage, platinum sensitivity, RECIST response, and progression time; (2) PLAT-M8, particularly from blood samples taken at the time of the first relapse before second-line chemotherapy, can serve not only as prognostic indicators for overall survival but also time to death after relapse in ovarian cancer patients; (3) PLAT-M8 does not have prognostic value when blood samples are taken during first-line chemotherapy before relapse, after initial diagnosis; and (4) PLAT-M8 may stratify overall survival and time to death after relapse based on the second-line treatment received by patients. These findings pave the way for our ongoing research, showcasing the potential of this non-invasive approach in predicting second-line treatment response, guiding decisions, and enhancing outcomes for relapsed ovarian cancer patients.  Implications of all the available evidenceThe lack of biomarkers guiding treatment decisions during second-line therapy highlights the need for more reliable biomarkers. As a prognostic biomarker, PLAT-M8 is considered simple yet impactful, as it only requires one blood sample taken before second-line treatment at the time of relapse. The advantages of this research include developing personalised treatment approaches, minimizing side effects and wasted time from ineffective medications, reducing the likelihood of subsequent relapse episodes, and improving clinical outcomes for patients. Ultimately, the use of biomarkers has the potential to reduce hospital stays and healthcare costs by optimizing treatment effectiveness and efficiency, while also enhancing the quality of life for patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations between RetNet gene polymorphisms and efficacy of orthokeratology for myopia control : sample from a clinical retrospective study\nAbstract: BackgroundTo study how clinical and genetic factors control the effectiveness of orthokeratology lenses in myopia.  MethodsIn this study, we conducted a retrospective clinical study of 545 children aged 8-12 years with myopia who were wearing orthokeratology lenses for one year and performed whole-genome sequencing (WGS) for 60 participants in two groups, one with rapid axial length progression of larger than 0.33 mm and the other with slow axial length progression of less than 0.09 mm. Genes in the RetNet database were used to screen candidate genes that may contribute to the effectiveness of orthokeratology lenses in controlling myopia.  ResultsWe found that children with a greater baseline eye axial length, greater spherical equivalent (SE) and greater age had better myopia control with orthokeratology. We observed a significant excess of nonsynonymous variants among those with slow myopia progression, which were prominently enriched in retinal disease related genes. We subsequently identified RIMS2 (OR=0.01, p=0.0075) and LCA5 (OR=6.96, p=0.0080) harboring an excess number of nonsynonymous variants in patients with slow progression of high myopia. Two intronic common variants rs36006402 in SLC7A14 and rs2285814 in CLUAP1 were strongly associated with axial length growth. Together, our finding identified novel genes associated with the effectiveness of orthokeratology lenses therapy in myopic children and provide insight into the genetic mechanism of orthokeratology treatment.  ConclusionThe effectiveness of orthokeratology lenses treatment involved interindividual variability in controlling axial length growth in myopic eyes. The efficacy increased when patients carried more nonsynonymous variants in retinal disease-related gene sets. Our data will serve as a well-founded reference for genetic counseling and better management of patients who choose orthokeratology lenses to control myopia.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Distinctions Between Reticular Pseudodrusen and Drusen: Insights from a Genome-Wide Association Study\nAbstract: PurposeTo explore genetic determinants specific to reticular pseudodrusen (RPD), and to compare these with genetic associations for drusen.  SettingParticipants with RPD, drusen, or controls from the UK Biobank (UKBB), a large, multisite, community-based cohort study.  MethodsA previously validated deep learning framework was deployed on 169,370 optical coherence tomography (OCT) volumes from the UKBB to identify cases with RPD and/or drusen and controls without these phenotypes. Cases were included if they were 60 years or older, with at least 5 lesions. Five retina specialists manually validated the cohorts using OCT and color fundus photographs. Quantifications of RPD and drusen derived by the framework were used as variables. Two primary genome-wide association study (GWAS) analyses were performed to explore potential genetic associations with number of RPD and drusen within  pure cases, where only RPD or drusen were present in either eye. A candidate approach was furthermore adopted to assess 46 previously known AMD loci. Secondary GWAS were undertaken for number of RPD and drusen in mixed cases, as well as binary case-control analyses for pure RPD and pure drusen. Genome-wide significance was defined as p<5e-8.  ResultsA total of 1,787 participants were identified and analysed, including 1,037 controls, 361 pure drusen, 66 pure RPD and 323 mixed cases. The primary pure RPD GWAS yielded four genome-wide significant loci: rs11200630/ARMS2-HTRA1 (p=1.9e-09), rs79641866/PARD3B on chromosome 2 (p=1.3e-08), rs143184903/ITPR1 on chromosome 3 (p=8.1e-09), and rs76377757/SLN on chromosome 11 (p=4.3e-08). The latter three are all uncommon variants (minor allele frequency <5%). A significant association at CFH was also observed adopting a candidate approach (p=1.8e-04).  Two loci reached genome-wide significance for the primary pure drusen GWAS: rs10801555/CFH on chromosome 1 (p=6.0e-33) and rs61871744/ARMS2-HTRA1 on chromosome 10 (p=4.2e-20). For the mixed RPD and drusen secondary analyses, lead variants at both the CFH and ARMS2-HTRA1 loci reached genome-wide significance, with C2-CFB-SKIV2L additionally associated for mixed drusen alone. Findings from the binary case-control GWAS for drusen mirrored those of the primary drusen analysis, however no variants reached genome-wide significance in the case-control RPD GWAS.  ConclusionsOur findings indicate a clear association between the ARMS2-HTRA1 locus with higher RPD load. Although the association at the CFH locus did not reach genome-wide significance, we observed a suggestive link. We furthermore identified three novel associations that are unique to RPD, albeit for uncommon genetic variants. These findings were only observable when quantifying RPD load as a continuous trait, which increased the studys statistical power. Further studies with larger sample sizes are now required to explore the relative contributions of AMRS2-HTRA1 and CFH to RPD development, and to explore the validity of these newly presented RPD-specific genetic associations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genomic Determinants of Biological Age Estimated By Deep Learning Applied to Retinal Images\nAbstract: With the development of deep learning (DL) techniques, there has been a successful application of this approach to determine biological age from latent information contained in retinal images. Retinal age gap (RAG) defined as the difference between chronological age and predicted retinal age has been established previously to predict the age-related disease. In this study, we performed discovery genome-wide association analysis (GWAS) on the RAG using the 31271 UK Biobank participants and replicated our findings in 8034 GoDARTs participants. The genetic correlation between RAGs predicted from the two cohorts was 0.67 (P=0.021). After meta-analysis, we found 13 RAG loci which might be related to retinal vessel density and other aging processes. The SNP-wide heritability (h2) of RAG was 0.15. Meanwhile, by performing Mendelian Randomization analysis, we found that glycated hemoglobin, inflammation hemocytes and anemia might be associated with accelerated retinal aging. Our study explored the biological implications and molecular level mechanism of RAG, which might enable causal inference of the aging process as well as provide potential pharmaceutical intervention targets for further treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development of Machine Learning Algorithms Using EEG Data to Detect the Presence of Chronic Pain\nAbstract: Chronic pain impacts more than one in five adults in the United States (US) and the costs associated with the condition amount to hundreds of billions of dollars annually. Despite the tremendous impact of chronic pain in the US and worldwide, the standard of care for diagnosis depends on subjective self-reporting of pain state, with no effective objective assessment procedure available. This study investigated the application of signal processing and machine learning to electroencephalography (EEG) data for the development of classification algorithms capable of differentiating subjects in pain from pain free subjects. In this study, nineteen (19) channels of EEG data were obtained from subjects in an eyes closed resting state, and ultimately data from 186 participants were used for algorithm development, including 35 healthy controls and 151 chronic pain patients. Signal processing was applied to identify noise free segments of EEG data and 6375 quantitative EEG (qEEG) measures were calculated for each subject. Various machine learning methodologies were applied to the data, with Elastic Net chosen as the optimal methodology. The final classifier developed using Elastic Net contained 34 qEEG features with non-zero weights. The classifier was able to differentiate pain versus no pain subjects with an accuracy of 79.6%, sensitivity of 82.2%, and specificity of 66.7%. The features used in the classifier were evaluated and found to align well with contemporary literature regarding changes in neurological characteristics associated with chronic pain.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rare Variant Association Analysis Uncovers Involvement of VNN2 in Stroke Outcome\nAbstract: BACKGROUNDA strokes functional outcome presents vast variability among patients, which is influenced by age, sex, characteristics of the lesion, and genetic factors. However, there is very little knowledge about stroke recovery genetics. Recently, some GWAS (Genome-Wide Association Studies) have highlighted the involvement of common or low-frequency variants near or within PATJ, PPP1R21, PTCH1, NTN4 and TEK genes, whereas the role of rare variants is still unclear. This study aims to identify the genetic contributions to differences in stroke outcome analyzing the effect of rare variants.  METHODSWe performed a pilot study analyzing 90 exomes of extreme good or bad recovery (modified Rankin Scale (mRS) at 3 months 0-1 vs 4-5) to select target genes involved in stroke recovery. To expand this study, 702 additional samples were sequenced by Targeted Next-Generation Sequencing capturing loci selected from the pilot study, GWAS studies and literature input. Here, we performed continuous (mRS 0-6) and dichotomous (mRS 0-1 vs 3-6) analyses, yielding one candidate gene. Protein structure and stability analysis were performed on selected variants.  RESULTSOur work identified rare coding variants in VNN2 associated with patients with a better stroke recovery ({Delta}DIC > 10, equivalent to p-value < 0.001). Six rare variants were predicted to significantly affect protein stability ({Delta}{Delta}G > 1.6 kcal/mol), meanwhile, another variant, located in the active site, could affect the electrostatic surface.  CONCLUSIONSVNN2 could play a role in post-stroke inflammation altering the cell adhesion and migration of neutrophils during recovery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: HiFi long-read genomes for difficult-to-detect clinically relevant variants\nAbstract: Clinical short-read exome and genome sequencing approaches have positively impacted diagnostic testing for rare diseases. Yet, technical limitations associated with short reads challenge their use for detection of disease-associated variation in complex regions of the genome. Long-read sequencing (LRS) technologies may overcome these challenges, potentially qualifying as a first-tier test for all rare diseases. To test this hypothesis, we performed LRS (30x HiFi genomes) for 100 samples with 145 known clinically relevant germline variants that are challenging to detect using short-read sequencing and necessitate a broad range of complementary test modalities in diagnostic laboratories.  We show that relevant variant callers readily re-identify the majority of variants (120/145, 83%), including [~]90% of structural variants, SNVs/InDels in homologous sequences and expansions of short tandem repeats. Another 10% (n=14) was visually apparent in the data but not automatically detected. Our analyses also identified systematic challenges for the remaining 7% (n=11) of variants such as the detection of AG-rich repeat expansions. Titration analysis showed that 89% of all automatically called variants could also be identified using 15-fold coverage.  Thus, long-read genomes identified 93% of pathogenic variants that are most challenging to detect using short-read technologies. Even with reduced coverage, the vast majority of variants remained detectable, possibly enhancing cost-effective diagnostic implementation. Most importantly, we show the potential to use a single technology to accurately identify all types of clinically relevant variants.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ethical Alignment of LLMs in Healthcare: Does GPT-o1 Adopt a Deontological or Utilitarian Approach?\nAbstract: In moral philosophy, two foundational approaches shape ethical decisions: deontology and utilitarianism, often exemplified by the \"Trolley\" dilemma. We conducted an experiment evaluating multiple LLMs, including OpenAIs GPT-o1, across five medical versions of this dilemma. While some models adhered to established ethical standards, others inconsistently favored utilitarian outcomes, raising concerns about their alignment with human medical ethics. Careful evaluation of LLMs ethics in healthcare is warranted, to ensure their safe integration into clinical practice.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Digital Engagement of Neurocutaneous Syndrome Communities on Facebook: A Descriptive Study\nAbstract: IntroductionSocial media has become a platform for healthcare providers and parents to communicate about common and rare pediatric disorders. Neurocutaneous syndromes including Tuberous Sclerosis Complex, Neurofibromatosis, and Sturge-Weber syndrome require lifelong monitoring and complex treatments. Clinician directed information is supplemented by online support groups, non-profit fundraising organizations, and educational programs through various Facebook features.  ObjectiveThe objective of this study is to explore the socialization patterns of individuals affected by neurocutaneous syndromes as they interact and engage within various Facebook forums.  MethodsPublic accounts on Facebook were analyzed throughout August 2022. The search terms used were \"Sturge-Weber Syndrome\", \"Sturge Weber\", \"SWS\", \"Tuberous Sclerosis\", \"Tuberous Sclerosis Complex (TSC)\", and \"Neurofibromatosis\", \"Neurofibromatosis 1 (NF1)\", and \"Neurofibromatosis 2 (NF2)\". Facebook accounts were analyzed on the basis of page ownership and video content.  ResultsSearching Sturge-Weber syndrome (SWS) yielded 99 Facebook pages and 37 Facebook videos. Tuberous sclerosis resulted in 100 Facebook pages and 139 Facebook videos. Neurofibromatosis yielded 102 Facebook pages and 129 Facebook Videos. Patient released stories comprised 51% of the Facebook videos (157/305), educational videos comprised 37% (112/305), and 12% (36/305) related to the syndromes awareness day. Facebook Pages were managed by nonprofit organizations 37% (111/301), community support groups 36% (108/301), and patients creating a \"private blog\" 23% (70/301), and physicians 4% (12/301). Figure 1 shows a breakdown of the Facebook page ownership and video content of neurocutaneous syndromes.  ConclusionThis study describes the online discussion of neurocutaneous syndromes through social media. The benefits of anonymized discussion for patients and families are many. Physicians manage only 4% of the Facebook pages and this may represent an opportunity to further disseminate medical advice in the future.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Synthetic Population Generation with Public Health Characteristics for Spatial Agent-Based Models\nAbstract: AbstractAgent-based models (ABMs) simulate the behaviors, interactions, and disease transmission between individual \"agents\" within their environment, enabling the investigation of the underlying processes driving disease dynamics and how these processes may be influenced by policy interventions. Despite the critical role that characteristics such as health attitudes and vaccination status play in disease outcomes, the initialization of agent populations with these variables is often oversimplified, overlooking statistical relationships between attitudes and other characteristics or lacking spatial heterogeneity. Leveraging population synthesis methods to create populations with realistic health attitudes and protective behaviors for spatial ABMs has yet to be fully explored. Therefore, this study introduces a novel application for generating synthetic populations with protective behaviors and associated attitudes using public health surveys instead of traditional individual-level survey datasets from the census. We test our approach using two different public health surveys (one national and the other representative of the study area, Virginia, U.S.) to create two synthetic populations representing individuals aged 18 and over in Virginia, U.S., and their COVID-19 vaccine attitudes and uptake as of December 2021. Results show that integrating public health surveys into synthetic population generation processes preserves the statistical relationships between vaccine uptake and attitudes in different demographic groups while capturing spatial heterogeneity at fine scales. This approach can support disease simulations that aim to explore how real populations might respond to interventions and how these responses may lead to demographic or geographic health disparities. Our study also demonstrates the potential for initializing agents with variables relevant to public health domains that extend beyond infectious diseases, ultimately advancing data-driven ABMs for geographically targeted decision-making.  Author SummaryIn this study, we introduce a new method for generating synthetic populations of individuals or \"agents\" with characteristics that include health protective behaviors and attitudes, which are crucial for modeling disease spread. Traditional methods for parameterizing agents often overlook the complex relationships between demographic factors and health behaviors like vaccination. Additionally, detailed spatial data capturing these behaviors are limited, meaning agent behaviors are more uniform across geographic space. By fitting public health surveys with spatially aggregated census data, we created more realistic agent populations for disease spread simulations. We focused on Virginia, U.S. and generated a population with COVID-19 vaccine uptake and attitudes as of December 2021. Our results show that this approach captures the statistical relationships between demographic variables and vaccine uptake, along with the spatial variation in these behaviors. We also show that using national survey data is comparable to using local survey data representative of Virginia collected in 2021. The approach is flexible so that it can be applied to various public health studies beyond just infectious diseases. Our work highlights the potential of public health surveys for enhancing synthetic population generation, offering a valuable approach for initializing models with more realistic populations to explore public health challenges.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interactive effects of bacterial vaginal colonization and HIV on pregnancy outcomes: a systematic review and meta-analysis.\nAbstract: BackgroundThe independent impact of HIV and bacterial vaginal colonization on pregnancy outcomes has been documented and is compounded by the burden of rapidly escalating antimicrobial resistance. However, the interactive effect of HIV and lower genital tract bacterial colonization, on pregnancy outcomes has not been thoroughly studied and is examined in our study.  MethodsWe performed a systematic review and meta-analysis to quantitatively assess the interaction between HIV and vaginal bacterial colonization and associations with birth weight and preterm birth. We searched Ovid MEDLINE, Ovid EMBASE, CINAHL, Scopus, Web of Science, Cochrane Library, African Journals Online, and PubMed databases to identify studies published up to December 31, 2023. We included observational reporting on vaginal colonization with bacterial pathogens stratified by HIV status that reported pregnancy outcomes. We followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines and used a modified Newcastle-Ottawa Scale to assess study quality. Meta-analysis was conducted using random-effects modeling in STATA Version 18. Pooled log-odds ratios were calculated. The study protocol was registered in PROSPERO(CRD42023485123).  ResultsWe selected 13 studies, involving 6,073 pregnant women, from 5,807 studies identified. The overall pooled prevalence of bacterial colonization was 26%(95%CI:17.3-37.4). There was no significant effect of HIV status and vaginal colonization on birth weight(OR=1.2, 95%CI:-2.57-2.20, p=0.88) and borderline increased odds of preterm birth (OR=2.64, 95%CI:-0.01-1.94, p=0.05). There was no significant association between HIV status and bacterial colonization(OR=1.08, 95%CI =-0.91-1.07), nor in antimicrobial resistance between pregnant women with HIV and those without.  ConclusionBacterial colonization is prevalent among pregnant women, but there is no clear evidence to suggest that HIV and bacterial colonization interact to affect birth weight or preterm birth. Research with large sample sizes, strict selection criteria, reliable and valid measurement, adequate control for confounding variables, and birthweight and gestational age at delivery assessment as continuous outcomes are still needed to provide robust evidence.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cryo-PRO facilitates whole blood cryopreservation for single-cell RNA sequencing of immune cells from clinical samples\nAbstract: Single-cell RNA sequencing (scRNA-seq) of peripheral blood mononuclear cells (PBMCs) has enhanced our understanding of host immune mechanisms in small cohorts, particularly in diseases with complex and heterogeneous immune responses such as sepsis. However, PBMC isolation from blood requires technical expertise, training, and approximately two hours of onsite processing using Ficoll density gradient separation ( Ficoll) for scRNA-seq compatibility, precluding large-scale sample collection at most clinical sites. To minimize onsite processing, we developed Cryo-PRO (Cryopreservation with PBMC Recovery Offsite), a method of PBMC isolation from cryopreserved whole blood that allows immediate onsite sample cryopreservation and subsequent PBMC isolation in a central laboratory prior to sequencing. We compared scRNA-seq results from samples processed using Cryo-PRO versus standard onsite Ficoll separation in 23 patients with sepsis. Critical scRNA-seq outputs including cell substate fractions and marker genes were similar for each method across multiple cell types and substates, including an important monocyte substate enriched in patients with sepsis (Pearson correlation 0.78, p<0.001; 70% of top marker genes shared). Cryo-PRO reduced onsite sample processing time from >2 hours to <15 minutes and was reproducible across two enrollment sites, thus demonstrating potential for expanding scRNA-seq in multicenter studies of sepsis and other diseases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Patient-specific in silico prediction of outcomes of partial continuous-flow LVAD treatment in peripartum cardiomyopathy\nAbstract: Patients with severe peripartum cardiomyopathy (PPCM) often receive mechanical circulatory support with good outcomes. However, the mechanisms underlying the functional improvements are poorly understood. This study investigated the effects of partial, continuous-flow left ventricular assist device (LVAD) support on cardiac function and mechanics in patients with PPCM of different severity. Patient-specific biventricular finite element models of six PPCM patients (four recovered, two non-recovered) were developed from magnetic resonance images and combined with a circulatory system model, including variable LVAD support. Ventricular function and myocardial mechanics were predicted, and changes due to LVAD support were quantified. The LVAD support decreased myofiber stress and increased ejection fraction (EF) of the LV. EF increased steadily (two patients), fluctuated (two patients), or peaked before a steady decrease (two patients) with increasing LVAD speed. Improvement due to LVAD support was greater for PPCM patients with higher disease severity than those with lower disease severity. The LVAD and native LV jointly generated stroke volume (SV) in four patients, and the LV contribution diminished with increasing LVAD speed. In the two patients with the lowest EF, the LVAD was the sole source of SV. The improvement of cardiac function and mechanics due to LVAD support in PPCM exceeds that reported for chronic heart failure due to ischemia. However, the predicted variability of the LVAD benefits with PPCM severity and mechanical support level suggests the need and potential for further studies to guide clinicians in selecting personalised treatment parameters required for optimised LVAD therapy for each PPCM patient.  Key points summaryO_LIPartial continuous-flow left ventricular assist device (LVAD) therapy has presented positive outcomes for critically ill patients with peripartum cardiomyopathy (PPCM), but the underlying LVAD mechanisms are poorly understood. C_LIO_LIThis study showed greater functional improvement for patients who did not recover than those who recovered from PPCM. C_LIO_LIIn patients with severe functional impairment, the LVAD provides the entire ventricular output at all speeds, whereas the LVAD and left ventricle generate the output jointly in patients with mild impairment, and the contribution of the left ventricle decreases with increasing LVAD speed. C_LIO_LIThe variability of the LVAD benefits with disease severity and device speeds emphasises the need for patient-specific treatment to achieve optimal therapy outcomes. C_LIO_LIThe developed patient-specific computational models offer a tool for further research and the potential for developing a clinical decision guide for personalised treatment of PPCM. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of the diagnostic value of YiDiXie\u2122-SS, YiDiXie\u2122-HS and YiDiXie\u2122-D in gallbladder cancer\nAbstract: BackgroundGallbladder cancer is a grave threat to human health and poses a severe economic burden. Enhanced CT is extensively used in the diagnosis of gallbladder tumors. However, false-positive results of enhanced CT can lead to misdiagnosis. As a result, patients have to bear unnecessary mental pain, expensive surgery and examination costs, surgical trauma, organ removal, loss of function, and even serious perioperative complications. False-negative enhanced CT results can lead to delayed treatment. Patients will thus have to bear the adverse consequences of negative prognosis, high treatment costs, poor quality of life, and short survival. There is an urgency to find convenient, cost-effective and noninvasive diagnostic methods to decrease the false-negative and false-positive rates of gallbladder-enhanced CT. The goal of this study was to assess the diagnostic value of YiDiXie-SS, YiDiXie-HS and YiDiXie-D in gallbladder cancer.  Patients and methodsFifty study subjects (malignant group, n=12; benign group, n=38 cases) were finally recruited in the study. Remaining serum samples from the subjects were collected and tested by applying YiDiXie  all-cancer detection kit (YiDiXie all-cancer detection kit) to assess the sensitivity and specificity of YiDiXie-SS, YiDiXie-HS and YiDiXie-D, respectively.  ResultsYiDiXie-SS had a sensitivity of 100% (95% CI: 75.8% - 100%) and a specificity of 65.8% (95% CI: 49.9% - 78.8%). YiDiXie-HS had a sensitivity of 91.7% (95% CI: 64.6% - 99.6%) and a specificity of 84.2% (95% CI: 69.6% - 92.6%). YiDiXie-D had a sensitivity of 41.7% (95% CI: 19.3% - 68.0%) and a specificity of 97.4% (95% CI: 86.5% - 99.9%). YiDiXie-SS had a sensitivity of 100% (95% CI: 64.6% - 100%) and its specificity was 60.0% (95% CI: 31.3% - 83.2%) in patients with positive enhanced CT. This implies that the application of YiDiXie-SS decreases the false-positive rate of enhanced CT of the gallbladder by 60.0% (95% CI: 31.3% - 83.2%) with essentially no increase in the leakage of gallbladder cancer. YiDiXie-HS has a sensitivity of 80.0% (95% CI: 37.6% - 99.0%) in patients with a negative enhanced CT, and its specificity was 85.7% (95% CI: 68.5% - 94.3%). This implies that the application of YiDiXie-HS reduces the false-negative rate of enhanced CT by 80.0% (95% CI: 37.6% - 99.0%). YiDiXie  -D has a sensitivity of 28.6% (95% CI: 5.1% - 64.1%) in patients with a positive enhanced CT and a specificity of 100% (95% CI: 72.2% - 100%). This implies that YiDiXie-SS decreases the false positive rate of enhanced CT by 100% (95% CI: 72.2% - 100%).  ConclusionYiDiXie  -SS markedly decreased the rate of false-positive gallbladder-enhanced CT with basically no increase in deferred treatment of gallbladder cancer. YiDiXie  -HS significantly decreases the false-negative rate of gallbladder-enhanced CT. YiDiXie-D significantly decreases the false-positive rate of gallbladder-enhanced CT. The YiDiXie test has an excellent diagnostic value in gallbladder cancer, and expected to address the problems of \"high false-positive rate of enhanced CT\" and \"high false-negative rate of enhanced CT\" in gallbladder tumors.  Clinical trial numberChiCTR2200066840.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: ExonViz: A website and Python package to visualize transcripts and genetic variants\nAbstract: SummaryExonViz is an application and website that creates biologically accurate transcript figures, including features such as coding regions, genetic variants and exon reading frames. Transcript definitions are automatically retrieved from Ensembl and RefSeq. We illustrate the full functionality of ExonViz by generating a figure for all ClinVar variants reported in CYLD.  Alvailability and ImplementationExonViz is available online via Dutch Center for RNA Therapeutics and can be installed locally via PyPI.  ContactRedmar R. van den Berg  Supplementary informationExtensive documentation on ExonViz is available on Read the Docs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Combining evidence from human genetic and functional screens to identify pathways altering obesity and fat distribution\nAbstract: Overall adiposity and body fat distribution are heritable traits associated with altered risk of cardiometabolic disease and mortality. Performing rare variant (minor allele frequency<1%) association testing using exome-sequencing data from 402,375 participants in the UK Biobank (UKB) for nine overall and tissue-specific fat distribution traits, we identified 19 genes where putatively damaging rare variation associated with at least one trait (Bonferroni-adjusted P<1.58x10-7) and 52 additional genes at FDR[&le;]1% (P[&le;]4.37x10-5). These 71 genes exhibited higher (P=3.58x10-18) common variant prioritisation scores than genes not significantly enriched for rare putatively damaging variation, with evidence of monotonic allelic series (dose-response relationships) among ultra-rare variants (minor allele count[&le;]10) in 22 genes. Five of the 71 genes have cognate protein UKB Olink data available; all five associated (P<3.80x10-6) with three or more analysed traits. Combining rare and common variation evidence, allelic series and proteomics, we selected 17 genes for CRISPR knockout in human white adipose tissue cell lines. In three previously uncharacterised target genes, knockout increased (two-sided t-test P<0.05) lipid accumulation, a cellular phenotype relevant for fat mass traits, compared to Cas9-empty negative controls: COL5A3 (fold change [FC]=1.72, P=0.0028), EXOC7 (FC=1.35, P=0.0096), and TRIP10 (FC=1.39, P=0.0157); furthermore, knockout of SLTM resulted in reduced lipid accumulation (FC=0.51, P=1.91x10-4). Integrating across population-based genetic and in vitro functional evidence, we highlight therapeutic avenues for altering obesity and body fat distribution by modulating lipid accumulation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: In vivo assessment of cardiac radiofrequency ablation in a large-animal model using photoacoustic-ultrasound imaging\nAbstract: One of the fundamental unmet clinical needs within cardiac electrophysiology is intraoperative assessment of catheter ablation, which can lead to recurrent arrhythmias and subsequent complications if ineffective. This work demonstrates photoacoustic imaging (PAI) of radiofrequency ablation (RFA) lesions in an in vivo swine model (n=3). Spectral unmixing of PAI data provides local myocardial characterization (e.g., oxygen saturation & tissue ablation) by overlaying unmixed PAI images with B-mode ultrasound imaging (PAI/US), with the latter providing anatomical context. Based on stained gross pathology, areas of central tissue necrosis coincided with increases in unmixed ablated regions of the myocardium. An average contrast-to-noise ratio of 2.8{+/-}0.2 confirmed lesion detectability, while the lesion dimensions quantified from PAI and pathology did not present significant differences. In vivo PAI of RFA lesions to determine ablation characteristics could lead to a paradigm shift in catheter ablation assessment and improve clinical outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Retrieval-Augmented Generation for Extracting CHA2DS2VASc Features from Unstructured Clinical Notes in Patients with Atrial Fibrillation\nAbstract: BackgroundAssessment of stroke risk in patients with atrial fibrillation (AF) is crucial for guiding anticoagulation therapy. CHA2DS2-VASc is a widely used score for defining this risk, but current assessments rely on manual calculation by clinicians or approximations from structured EHR data elements. Unstructured clinical notes contain rich information that could enhance risk assessment. We developed and validated a Retrieval-Augmented Generation (RAG) approach to extract CHA2DS2-VASc risk factors from unstructured notes in patients with AF.  MethodsWe employed a RAG architecture paired with the large language model, Llama3.1, to extract features relevant to CHA2DS2-VASc scores from unstructured notes. The model was deployed on a random set of 1,000 clinical notes (934 AF patients) from Yale New Haven Health System (YNHHS). To establish a gold standard, 2 clinicians manually reviewed and labeled CHA2DS2-VASc risk factors in a random subset of 200 notes. The CHA2DS2-VASc scores were calculated for each patient using structured data alone and by incorporating risk factors identified with RAG. We assessed performance across risk factors using macro-averaged area under the receiver operating characteristic (AUROC). For external validation, we utilized 100 manually labeled clinical notes from the MIMIC-IV database.  ResultsThe RAG model demonstrated robust performance in extracting risk factors from clinical notes. In the 1000 clinical notes, RAG identified several risk factors more frequently than structured elements, including hypertension (82.4% vs 26.2%), stroke/TIA (62.9% vs 45.5%), vascular disease (83.4% vs 56.6%), and diabetes (84.1% vs 47.2%). In the 200 expert-annotated notes, the RAG approach achieved high performance for various risk factors, with AUROCs ranging from 0.96 to 0.98 for hypertension, diabetes, and age [&ge;]75 years. Incorporating risk factors identified by RAG increased CHA2DS2-VASc scores compared with using structured data alone.  ConclusionAn LLM-optimized RAG can accurately extract CHA2DS2-VASc risk factors from unstructured clinical notes in AF patients. This approach can enable computable risk assessment and guide appropriate anticoagulation therapy.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Machine Learning and Bioinformatics Unravel Gene Signatures of Coronary Artery Disease Comorbidity with Periodontitis\nAbstract: BackgroundEmerging evidence suggests a complex interplay between periodontal disease (PD) and coronary artery disease (CAD) risk. The novel insights into the shared pathogenesis of PD and CAD will potentially inform future therapeutic strategies. This study aimed to identify signature genes implicated in the progression of PD to CAD.  MethodsGene expression data from NCBI GEO datasets, GSE10334 and GSE66360, associated with both PD and CAD datasets were analyzed to pinpoint differentially expressed genes (DEGs), followed by weighted gene co-expression network analysis (WGCNA) to identify key modules. Functional enrichment analysis of common DEGs was conducted. Four machine learning algorithms were employed to construct predictive models, and the optimal model was selected for subsequent feature genes selection. Using GSE6751 and GSE71226 as validation cohort, receiver operating characteristic (ROC) curves and nomograms were generated for diagnostic performance assessment and risk prediction. Furthermore, immune cell infiltration patterns were assessed using the CIBERSORT (Cell-type Identification By Estimating Relative Subsets Of RNA Transcripts) algorithm. Finally, RNA-sequencing (RNA-seq) of 5 clinical samples vs. 5 controls was performed to validate the identified genes and explore their potential as biomarkers for early diagnosis and prevention of comorbid periodontitis and CAD.  ResultsAnalysis of the GSE10334 and GSE66360 datasets revealed 48 common Differentially Expressed Genes (DEGs) associated with CAD and PD. Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment analyses of these DEGs highlighted significant overrepresentation of pathways related to inflammatory responses and immune cell trafficking, including response to lipopolysaccharides, molecules of bacterial origin, neutrophil migration, bone marrow leukocyte migration, and CXCR chemokine receptor binding. Additionally, pathways involved in lipid metabolism and atherosclerosis, such as the NF-{kappa}B signaling pathway, IL-17 signaling pathway, and TNF signaling pathway, were also enriched. Five genes (FOS, MME, PECAM1, RGS1, and VNN2) emerged as potential signature genes, demonstrating strong predictive ability with an area under the curve (AUC) greater than 0.7 on the machine learning algorithms. CIBERSORT analysis suggested a potential role of these signature genes in modulating immune cell infiltration. To further validate these findings, RNA-seq on clinical samples confirmed significant upregulation of FOS, VNN2, PECAM1, and MME genes in patients with both CAD and PD.  ConclusionThis study identified five signature genes that were significantly associated with immune cell dysregulation, where four of them were verified on clinical samples. These genes hold promise for the development of a nomogram-based approach for early diagnosis of both periodontitis and coronary artery disease, potentially informing future research directions for improved diagnosis and treatment strategies in these prevalent conditions. Notably, the prominent upregulation of FOS suggests its potential as a key target for future investigations. These insights hold significant implications for improving prevention and diagnostic strategies for individuals affected by both PD and CAD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cardiomyocyte-derived circulating extracellular vesicles allow a non-invasive liquid biopsy of myocardium in health and disease\nAbstract: The ability to track disease without tissue biopsy in patients is a major goal in biology and medicine. Here, we identify and characterize cardiomyocyte-derived extracellular vesicles in circulation (EVs; \"cardiovesicles\") through comprehensive studies of induced pluripotent stem cell-derived cardiomyocytes, genetic mouse models, and state-of-the-art mass spectrometry and low-input transcriptomics. These studies identified two markers (POPDC2, CHRNE) enriched on cardiovesicles for biotinylated antibody-based immunocapture. Captured cardiovesicles were enriched in canonical cardiomyocyte transcripts/pathways with distinct profiles based on human disease type (heart failure, myocardial infarction). In paired myocardial tissue-plasma from patients, highly expressed genes in cardiovesicles were largely cardiac-enriched (vs. \"bulk\" EVs, which were more organ non-specific) with high expression in myocardial tissue by single nuclear RNA-seq, largely in cardiomyocytes. These results demonstrate the first \"liquid\" biopsy discovery platform to interrogate cardiomyocyte states non-invasively in model systems and in human disease, allowing non-invasive characterization of cardiomyocyte biology for discovery and therapeutic applications.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Returning Individual-Level Urgent or Emergent Research Results to Participants: The Project Baseline Health Study Experience\nAbstract: BackgroundReturning results to research participants is increasingly recognized as an ethical mandate, yet little is known about best practices to optimally communicate urgent or emergent results.  MethodsThe Project Baseline Health Study (PBHS) was a prospective observational cohort study of 2,502 participants enrolled from 2017-2019 and followed through 2023. The cohort represented a broad spectrum of health and disease, enriched to include participants with an elevated risk for breast or ovarian cancer, lung cancer, and/or atherosclerotic cardiovascular disease (60% of participants). Urgent or emergent results were returned during or after the baseline visit from vital signs; clinical laboratory testing; and ocular, cardiovascular, and pulmonary imaging.  ResultsAmong 2,002 participants in this analysis, 39.7% had at least one urgent or emergent finding returned, representing a total of 1,159 results returned over 3 years. The most commonly returned results were eye findings (n=246), pulmonary nodules (n=159), abnormal stress echocardiograms (n=123), abnormal rest electrocardiograms (bradycardia) (n=74), and lung parenchyma findings (n=55). Participants with urgent or emergent incidental findings were older (mean [SD] 58.0 [16.2] years vs. 48.0 [16.6] years) with a greater burden of cardiovascular, metabolic, or cancer comorbidities than those without urgent or emergent incidental findings.  ConclusionsThis report from the PBHS study is one of the first to describe a process to systematically return urgent or emergent results to research participants. This process led to the successful return of clinically important results to participants but also required significant time and effort from study clinicians and staff.  ClinicalTrials.gov Identifier: NCT03154346\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effectiveness of Antimicrobial Photodynamic Therapy Versus Doxycycline in the Treatment of Periodontitis on Glycaemic Control and Periodontal Parameters in Adults with Type 2 Diabetes Mellitus\nAbstract: BackgroundThis meta-analysis aimed to compare the efficacy of antimicrobial photodynamic therapy (aPDT) with systemic doxycycline, as adjunctive treatments to scaling and root planing (SRP) for treating periodontitis in patients with type 2 diabetes mellitus (T2DM).  MethodsA search across electronic databases including PubMed, Scopus, CENTRAL, OVID EMBASE and OVID MEDLINE was carried out to identify relevant randomised controlled trials (RCTs), comparing aPDT or doxycycline combined with SRP, versus SRP alone. Data were pooled using random-effects models and indirect comparisons were retrieved using the Chi2 test for subgroup differences, to assess the impact of these treatments on glycated haemoglobin (HbA1c), probing depth (PD), and clinical attachment level (CAL).  ResultsEight RCTs were included. aPDT with SRP showed a significant reduction in probing depth compared to doxycycline (MD = -0.55 mm, 95% CI: -1.03 to -0.07; p = 0.02). A significant difference between the two subgroups was found (p = 0.04), suggesting aPDT was more effective. No significant differences were found for HbA1c or CAL between the two interventions.  ConclusionsThe findings suggest that aPDT may offer greater benefits for the treatment of periodontitis in T2DM patients. This suggests that aPDT could potentially be a non-antibiotic alternative to doxycycline. However, as neither treatment influenced HbA1c, clinicians should not rely on periodontal therapy for glycaemic control.  Layperson summaryPeople with type 2 diabetes have a higher risk of getting gum disease because their bodies cant manage blood sugar levels well. When people with type 2 diabetes get gum disease, the swelling in their gums makes it even harder to control their blood sugar levels, making their diabetes worse. Type 2 diabetics sometimes dont respond well to regular gum treatments so dentists will also give them antibiotics to treat the gum disease. But when antibiotics are used too often, they can stop working. This is called antibiotic resistance and its a big problem in healthcare. Therefore, this study wanted to test if adding a special light therapy to regular gum treatments could replace using antibiotics. The results from this study found that the light therapy was better at healing parts of the gums compared to antibiotics. However, neither treatment made a big difference in blood sugar levels. This is important because it means that the light therapy could replace antibiotics for treating gum disease, reducing the problem of antibiotic resistance. However, more research is needed to see if these treatments could have any beneficial effect on blood sugar levels.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Analysis of facial expressions recorded from patients during psychiatric interviews\nAbstract: Mental health research increasingly focuses on the relationship between psychiatric symptoms and observable manifestations of the face and body1. In recent studies2,3, psychiatric patients have shown distinct patterns in movement, posture and facial expressions, suggesting these elements could enhance clinical diagnostics.  The analysis of the facial expressions is grounded on the Facial Action Coding System (FACS)4. FACS provides a systematic method for categorizing facial expressions based on specific muscle movements, enabling detailed analysis of emotional and communicative behaviors. This method combined with recent advancements in Artificial Intelligence (AI) has shown promising results for the detection of the patient mental state.  We analyze video data from patients with various psychiatric symptoms, using open-source Python toolboxes for facial expression and body movement analysis. These toolboxes facilitate face detection, facial landmark detection, emotion detection and motion recognition. Specifically, we aim to explore the connection between these physical expressions and established diagnostic tools, like symptom severity scores, and finally enhance psychiatric diagnostics by integrating AI-driven analysis of video data.  By providing a more objective and detailed understanding of psychiatric symptoms, this study could lead to earlier detection and more personalized treatment approaches, ultimately improving patient outcomes. The findings will contribute to the development of innovative diagnostic tools that are both efficient and accurate, addressing a critical need in mental health care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assortative mating across nine psychiatric disorders is consistent and persistent over cultures and generations\nAbstract: Emerging evidence has shown that assortative mating (AM) is a key factor that shapes the landscape of complex human traits. It can increase the overall prevalence of disorders, influence occurrences of comorbidities, and bias estimation of genetic architectures. However, there is lack of large-scale studies to examine the cultural differences and the generational trends of AM for psychiatric disorders. Here, using national registry datasets, we conduct the largest scale of AM analyses on nine psychiatric disorders, with up to 1.4 million mated cases and 6 million matched controls. We performed meta-analyses on AM estimates from Taiwan, Denmark, and Sweden, to examine the potential impact of cultural differences. Generational changes for people born after 1930s were investigated as well. We found that AM of psychiatric disorders are consistent across nations and persistent over generations, with a small proportion of disorders showing generational changes of AM. Our results provide additional insight into the mechanisms of AM across psychiatric disorders and have evident implications on the estimation of the genetic architectures of psychiatric disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Increased atherogenicity in mood disorders: a systematic review, meta-analysis and meta-regression\nAbstract: BackgroundMajor depressive disorder (MDD) and bipolar disorder (BD) often coexist with metabolic syndrome. Both are linked to increased atherogenicity and a higher risk of cardiovascular diseases.  ObjectivesThis meta-analysis seeks to evaluate the relationship between atherogenic indices and mood disorders (MDD/BD), while identifying the most effective atherogenic biomarkers for mood disorders.  MethodsThis study adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. We searched electronic databases, including PubMed, Google Scholar, and Web of Science, for articles published up to August 1, 2024.  ResultsIn this meta-analysis, 85 eligible studies (14 on BD and 71 on MDD) were included, covering 70,856 participants: 18,738 patients and 52,118 healthy controls. Patients with mood disorders showed significant increases (p < 0.001) in the Castelli Risk Index 2 (CRI2), Atherogenic Index of Plasma (AIP), and (triglyceride or TG + low-density lipoprotein + very low-density lipoprotein)/(high-density lipoprotein cholesterol or HDL + Apolipoprotein A or ApoA) ratio, but not CRI1 and ApoB/ApoA ratio. Significant lower HDL and lecithin: cholesterol acyltransferase activity, and higher TG levels were observed in mood disordered patients compared with controls. There were no significant differences between MDD and BD patients. Most included studies lacked the most essential information on the inclusion and exclusion of important confounders.  ConclusionsAIP is the most effective atherogenicity index for mood disorders. Regular lipid profiling and metabolic syndrome screening are crucial in mood disorders. Early intervention with lipid-lowering therapies is recommended to prevent the worsening of atherogenicity and disease progression.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clinical stratification of Major Depressive Disorder in the UK Biobank: A gene-environment-brain Topological Data Analysis\nAbstract: Major depressive disorder (MDD) is a leading cause of disability worldwide, affecting over 300 million people and posing a significant burden on healthcare systems. MDD is highly heterogeneous, with variations in symptoms, treatment response, and comorbidities that could be determined by diverse etiologic mechanisms, including genetic and neural substrates, and societal factors.  Characterizing MDD subtypes with distinct clinical manifestations could improve patient care through targeted personalized interventions. Recently, Topological Data Analysis (TDA) has emerged as a promising tool for identifying homogeneous subgroups of diverse medical conditions and key disease markers, reducing complex data into comprehensible representations and capturing essential dataset features.  Our study applied TDA to data from the UK Biobank MDD subcohort composed of 3052 samples, leveraging genetic, environmental, and neuroimaging data to stratify MDD into clinically meaningful subtypes. TDA graphs were built from unimodal and multimodal feature sets and quantitatively compared based on their capability to predict depression severity, physical comorbidities, and treatment response outcomes.  Our findings showed a key role of the environment in determining the severity of depressive symptoms. Comorbid medical conditions of MDD were best predicted by brain imaging characteristics, while brain functional patterns resulted the best predictors of treatment response profiles.  Our results suggest that considering genetic, environmental, and brain characteristics is essential to characterize the heterogeneity of MDD, providing avenues for the definition of robust markers of health outcomes in MDD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comprehensive Analysis of Therapeutic Strategies Using Mesenchymal Stem Cell-Derived Exosomes in Preclinical Models of Osteoarthritis\nAbstract: BackgroundOsteoarthritis (OA) is a common degenerative disease affecting people and animals, resulting in persistent pain and joint deformities. Its growing prevalence presents considerable difficulties to public health and veterinary care systems worldwide. Despite substantial research, the molecular pathways underlying OA pathogenesis remain poorly understood, limiting the development of effective treatment strategies. Exosomes, or small endosomal membrane microvesicles, have emerged as intriguing vehicles for intercellular communication and medicinal administration in a variety of illnesses, including OA. However, their efficacy and action methods in preclinical OA models require additional exploration.  MethodsWe analyzed several databases from 2016 to 2023 for original studies on exosome treatment in preclinical OA models. The inclusion criteria included studies that used exosomes generated from mesenchymal stem cells (MSCs) in both human and animal models of OA. Thematic synthesis and data extraction were used to examine research features, dosage administration techniques, and efficacy results. The quality of included studies was assessed using recognized criteria, and statistical analysis was performed to determine the efficacy of exosome treatment in decreasing Osteoarthritis Research Society International (OARSI) scores.  ResultsOur study comprised thirteen peer-reviewed articles that included both human and animal models of OA. Most trials used bone marrow MSC-derived exosomes administered intra-articularly. The analysis of OARSI scores revealed a considerable reduction in joint deterioration following exosome therapy. Source analysis demonstrated that exosome treatment originating from human and animal MSCs was consistently effective. However, an assessment of study quality revealed potential biases and limitations, emphasizing the need for more research to validate these findings and refine therapy options for OA management.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=141 SRC=\"FIGDIR/small/24313971v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (42K): org.highwire.dtl.DTLVardef@1012662org.highwire.dtl.DTLVardef@7f0a31org.highwire.dtl.DTLVardef@763c26org.highwire.dtl.DTLVardef@66e92e_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOGraphical AbstractC_FLOATNO C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of non-drug Intervention on Cognitive Function and Blood Sugar Control of Type 2 diabetes Patients with Mild Cognitive Impairment: A meta-analysis Protocol\nAbstract: This study aims to assess non-drug therapies safety and effectiveness on cognitive function and blood glucose control of type 2 diabetes with mild cognitive impairment (T2DM-MCI) patients in randomized controlled trials by meta-analysis, providing constructive evidence for non-drug treatment decision-making. The system review plan will strictly follow the Systematic Review and Meta-Analysis Protocols entry for reporting. PubMed, EMBASE, Cochrane Library, CINAHL, Web of Science, CNKI, WANGFANG Database, and SinoMed will be systematically searched with Chinese and English language restrictions, and all randomized controlled trials comparing non-drug treatment with usual care or no intervention or placebo to study cognitive impairment in T2DM-MCI patients will be included. We will also manually search for cited literature. Our primary outcomes are cognitive function and blood sugar control. The risk of bias will be assessed for all studies using the Cochrane risk-of-bias tool (RoB 2) for Systematic Review of Intervention-version 5.1.0. Where possible, meta-analysis using random-effects models will be performed, otherwise, a qualitative summary will be provided. We will adhere to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA-P) guidelines. This meta-analysis compares the efficacy of non-drug interventions for mild cognitive impairment in type 2 diabetes mellitus. It will provide reliable evidence for patients, clinicians, and researchers.  The methodological protocol was in registered in the PROSPERO (CRD 42024496248).\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: An Analysis of Transgender Crowdfunding in the Context of State-Led Anti-Transgender Legislation\nAbstract: This study investigates the impact of anti-transgender legislation on the use of crowdfunding platforms by transgender and gender diverse (TGD) individuals in the United States. Using data from 349 GoFundMe campaigns created between March and June 2022, we analyzed the reasons for seeking funding and their potential correlation with state-level anti-transgender policies. Our findings reveal that 61% of campaigns originated from states with proposed or enacted anti-transgender legislation, with 19.5% coming from states posing significant barriers to healthcare services for TGD individuals. The most common reasons for crowdfunding included housing (44.7%), living expenses (35.5%), and gender-affirming surgeries (28.1%). Notably, campaigns from anti-transgender states showed a significant correlation with explicitly mentioning hostile state environments ({Phi} = 0.2843, p < 0.0001) and seeking relocation ({Phi} = 0.2040, p = 0.0001). These results highlight the profound impact of discriminatory legislation on TGD individuals, forcing many to seek alternative financial support for basic needs and essential medical care. This research underscores the urgent need for more inclusive healthcare policies and support systems for the TGD community.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Family income is associated with regional brain glucose metabolism in middle-aged adults\nAbstract: Socioeconomic status is a multifaceted construct that plays a prominent role in shaping our environment by defining our access to healthcare, nutrition, and enrichment, as well as represents social standing. Therefore, to address the effects of family income, and education level on brain glucose metabolism, we analyzed a large cohort of healthy middle-aged adults who underwent brain 18F-FDG PET, and survey of family income and education level. We retrospectively analyzed data of healthy males who underwent health check-up program. Health check-up program included 1) Brain 18F-FDG PET, 2) anthropometric measurements, 3) survey of family income and education level, and 4) measures of stress, anxiety, and depression. The effects of family income and education level on regional SUVR were investigated using Bayesian hierarchical modelling. A total of 233 healthy males were included in this study. Family income was positively correlated with education level. There was no significant indirect effect of family income or education level via stress, anxiety, or depression on regional brain glucose metabolism. Family income is positively associated with brain glucose metabolism in caudate, putamen, anterior cingulate, hippocampus, and amygdala, while education level does not show any significant association with brain glucose metabolism in middle-aged adults. In conclusion, family income is positively associated with brain glucose metabolism in caudate, putamen, anterior cingulate, hippocampus, and amygdala, while education level does not show any significant association with brain glucose metabolism. This finding might reflect the link between family income, and reward sensitivity, stress in middle-aged adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Acute psilocybin and ketanserin effects on cerebral blood flow: 5-HT2AR neuromodulation in healthy humans\nAbstract: Psilocin, the active metabolite of psilocybin, is a psychedelic and agonist at the serotonin 2A receptor (5-HT2AR) that has shown positive therapeutic effects for brain disorders such as depression. To elucidate the brain effects of psilocybin, we directly compared the acute effects of 5-HT2AR agonist (psilocybin) and antagonist (ketanserin) on cerebral blood flow (CBF) using pseudo-continuous arterial spin labelling magnetic resonance imaging (MRI) in a single-blind, cross-over study in 28 healthy participants. We evaluated associations between plasma psilocin level (PPL) or subjective drug intensity (SDI) and CBF. We also evaluated drug effects on internal carotid artery (ICA) diameter using time-of-flight MRI angiography. PPL and SDI were significantly negatively associated with regional and global CBF ([~]11.5% at peak drug effect, p<0.0001). CBF did not significantly change following ketanserin (2.3%, p=0.35). Psilocybin induced a significantly greater decrease in CBF compared to ketanserin in the parietal cortex (pFWER<0.0001). ICA diameter was significantly decreased following psilocybin (10.5%, p<0.0001) but not ketanserin (-0.02%, p=0.99). Our data support an asymmetric 5-HT2AR modulatory effect on CBF and provide the first in vivo human evidence that psilocybin constricts the ICA, which has important implications for understanding the neurophysiological mechanisms underlying its acute effects.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: MRISeqClassifier: A Deep Learning Toolkit for Precise MRI Sequence Classification\nAbstract: Magnetic Resonance Imaging (MRI) is a crucial diagnostic tool in medicine, widely used to detect and assess various health conditions. Different MRI sequences, such as T1-weighted, T2-weighted, and FLAIR, serve distinct roles by highlighting different tissue characteristics and contrasts. However, distinguishing them based solely on the description file is currently impossible due to confusing or incorrect annotations. Additionally, there is a notable lack of effective tools to differentiate these sequences. In response, we developed a deep learning-based toolkit tailored for small, unrefined MRI datasets. This toolkit enables precise sequence classification and delivers performance comparable to systems trained on large, meticulously curated datasets. Utilizing lightweight model architectures and incorporating a voting ensemble method, the toolkit enhances accuracy and stability. It achieves a 99% accuracy rate using only 10% of the data typically required in other research. The code is available at https://github.com/JinqianPan/MRISeqClassifier.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Autologous P63+ lung progenitor cell transplantation in idiopathic pulmonary fibrosis: a phase 1 clinical trial\nAbstract: In idiopathic pulmonary fibrosis (IPF) patients, alveolar epithelium architectures are persistently lost and lung gas transfer function would decline over time, which cannot be rescued by conventional anti-fibrotic therapy. P63+ airway basal progenitor cells are previously reported to have great potential to repair damaged lung epithelium. Here, we successfully cloned and expanded the autologous P63+ progenitor cells from IPF patients to manufacture the cell therapeutic product REGEND001, which were further characterized by cell morphology and single-cell transcriptomic analysis. Subsequently, an open-label, dose-escalation exploratory clinical trial was conducted (CTR20210349). The primary outcome was the incidence and severity of the cell therapy-related adverse events (AEs); secondary outcome included other safety and efficacy evaluation in each dose groups. We treated 12 patients with ascending doses of cells: 0.6x, 1x, 2x and 3.3x 106 cells/kg bodyweight. The data revealed that P63+ basal progenitor cell was safe and well tolerated at all doses, with no dose-limiting toxicity or cell therapy-related severe adverse events observed. Patients in the three higher dose groups showed statistically significant improvement of lung gas transfer function as well as exercise ability after REGEND001 therapy. Resolution of honeycomb lesion was also observed in patients of higher dose groups. Altogether these initial results indicated that REGEND001 has a high safety profile and meanwhile shows preliminary efficacy in IPF patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Outcomes of Kidney Transplantation in Cystic Fibrosis\nAbstract: BackgroundCystic fibrosis (CF) is a chronic multisystem disease with features including recurrent pulmonary infection, bronchiectasis, malnutrition, and alterations in drug metabolism which may discourage referral and listing for kidney transplantation. Although no specific renal phenotype is identified in CF, chronic kidney disease (CKD) occurs in young people and adults with CF with greater frequency than in the general population. The characteristics and outcomes of kidney transplantation in the CF population have not been previously described.  MethodsWe used de-identified data supplied by the US Renal Data System (USRDS) to compare persons with end stage kidney disease (ESKD) with first kidney transplant, who did and did not have a diagnosis of CF. We compared demographic and clinical characteristics, mortality, patient survival, and death-censored graft survival using linear and logistic regression, multivariable logistic regression models, and Kaplan-Meier and log-rank tests with stratification/binning by propensity scores.  ResultsOf those with dual diagnoses of CF and ESKD, half received a first kidney transplant. CF was independently associated with higher odds of receiving a living donor transplant. Those with a kidney transplant were younger than both those who did not have CF and those with CF without transplant and had higher odds of being female. Those with dual diagnoses of CF and ESKD had disproportionately lower odds of being identified as Black or African American relative to their representation in the population of all with CF and ESKD. Diabetes was more frequently a diagnosis and primary cause of ESKD in people with CF, but was approximately half as frequently the primary cause of ESKD as in those without CF. Complications of transplantation, particularly lung, were the second most frequent etiology of ESKD in people with CF. Overall survival with ESKD was 21.1 years for those with CF and 31.8 for those without CF. The survival benefit associated with transplant was 17.2 years for those with CF and 24.8 years for those without CF. Death censored median graft survival was significantly longer for those with CF, 20.4 vs 13.7 years.  ConclusionsCF is a chronic multisystem disease with features which may discourage referral and listing for kidney transplant. We used de-identified data from the USRDS datasets to describe the characteristics and outcomes of all unique individuals with the diagnosis of CF and first kidney transplant prevalent during the five-year period 2014 and 2018. Those with CF had similar odds to those without CF or receiving a first kidney transplant, and higher odds of receiving a living donor graft. Diabetes mellitus was significantly less frequently the primary cause of ESKD in those with CF and kidney transplant. Complications of solid organ transplant, particularly lung, were the second most frequent cause of ESKD in people with CF and kidney transplant. Median patient survival following the first kidney transplant was significantly shorter than for those who did not have CF, but was substantial, as was the survival advantage when compared to dialysis. Median graft survival was significantly longer for those with CF. It is our hope that this data will improve awareness of kidney disease in persons living with CF and their care teams, and encourage early referral to nephrology and transplant centers, and positive consideration of wait listing for kidney transplantation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterization of Cell Free DNA in Seminal Fluid: Implications for New Liquid Biopsies.\nAbstract: Liquid biopsies are becoming increasingly used for the detection and monitoring of disease states. While cell free DNA (cfDNA) in blood and urine have been well studied, much less is known about the composition of cfDNA in seminal fluid. We sought to characterize cfDNA in seminal fluid through tissue of origin studies using methylation analysis in men aged 21-60 yrs. We confirmed the observations of others that seminal fluid contains an abundance of cfDNA that is both nucleosomal and >1 kb. However, here we demonstrate for the first time that the high molecular weight (HMW) DNA harbors a lower sperm signal and higher somatic cell signal compared to the nucleosomal fraction. Prostate, granulocytes and kidney showed a mean predicted increased contribution of 6.2%, 4.9% and 2.9%, respectively in the HMW fraction. While sperm was the predominant signal in most men without vasectomies, the proportion of predicted prostate contribution reached as high as 26.5% in the HMW fraction. In other subjects without vasectomies, granulocyte cfDNA made up most of the signal. We also observed subject-specific cfDNA size distribution patterns that were reproducible over time, irrespective of abstinence times. These results suggest that seminal fluid is a rich source of cfDNA from various somatic cell types, and enriching for the HMW fraction would yield even higher sensitivity for somatic cfDNA detection. Considering these novel findings, it appears that seminal fluid may be able to serve as liquid biopsy for the detection and monitoring of prostate cancer, benign prostate hyperplasia, prostatitis and infertility.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: To end misuse of 'race' now: Secondary re-analysis of 'race' in veterans with acute and chronic kidney disease\nAbstract: OBJECTIVES(1) To examine  race in acute and chronic kidney disease under similar conditions, and (2) to encourage further study of implied cofactors and an international approach to end misuse of  race.  METHODSWe re-analyzed data from United States veterans, (1) comparing outcomes after removing  race correction from legacy estimated glomerular filtration rates and (2) graphing data to explore more subtle relationships. We hypothesized factors confounding the link between kidney disease and apolipoprotein L1 gene variants, including cofactors implied and controlled by veteran status.  RESULTSStudies of veterans minimized  racial disparity in chronic kidney disease, suggesting an effect of starting conditions, including Armed Services entry requirements and equitable access to healthcare. Apolipoprotein L1 \"high-risk\" and N264K+ gene variants may be proxies for  race, with gradients of effect due to colorism.  CONCLUSIONSUnder equitable conditions, comparable kidney disease outcomes should be the expected norm for all, regardless of  race, ethnicity, or nationality. Discouraging misuse of  race in medical research and healthcare is an actionable Population Health initiative with potentially high impact but low effort and cost.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Secular trends of incidence and prevalence of parkinsonism and subtypes: A cohort study in the United Kingdom\nAbstract: BackgroundWhile summarized under the umbrella term \"Parkinsonism\", several subtypes with different etiologies exist, including Parkinsons Disease, Vascular Parkinsonism and Drug-induced Parkinsonism. However, evidence on their incidence and prevalence remains limited.  ObjectivesTo evaluate secular trends of incidence and prevalence of parkinsonism, Parkinsons Disease, Vascular Parkinsonism, and Drug-induced Parkinsonism from 2007 to 2021 in the United Kingdom.  MethodsWe used primary care data, Clinical Practice Research Datalink GOLD, from the United Kingdom. Individuals were included if they were registered from January 2007 to December 2021 with at least one year of prior observation. Incidence and prevalence were calculated on a yearly basis with 95% confidence intervals and then stratified by age and sex.  ResultsFrom 2007 to 2019, the incidence of parkinsonism and Parkinsons Disease decreased, with Parkinsons Disease incidence dropping from 35.86 (95% confidence interval: 34.22 - 37.56) to 31.40 (29.40 - 33.50) per 100,000 person-years. The prevalence of parkinsonism and Parkinsons Disease increased from 0.22% (0.22% - 0.23%) and 0.21% (0.21% - 0.22%) in 2007 to peak in 2016 with 0.25% (0.25% - 0.26%) and 0.23% (0.23% - 0.24%) respectively. The number of Vascular Parkinsonism diagnoses have increased from 2010, whereas incidence and prevalence of Drug-induced Parkinsonism remained stable. Incidence and prevalence increased with age and were generally higher in males, except for Drug-induced Parkinsonism, which was slightly higher in females.  ConclusionsGiven its association with aging, parkinsonism and these subtypes continue to present an increasing challenge to our aging society.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Secular trends of incidence and prevalence of parkinsonism and subtypes: A cohort study in the United Kingdom\nAbstract: BackgroundWhile summarized under the umbrella term \"Parkinsonism\", several subtypes with different etiologies exist, including Parkinsons Disease, Vascular Parkinsonism and Drug-induced Parkinsonism. However, evidence on their incidence and prevalence remains limited.  ObjectivesTo evaluate secular trends of incidence and prevalence of parkinsonism, Parkinsons Disease, Vascular Parkinsonism, and Drug-induced Parkinsonism from 2007 to 2021 in the United Kingdom.  MethodsWe used primary care data, Clinical Practice Research Datalink GOLD, from the United Kingdom. Individuals were included if they were registered from January 2007 to December 2021 with at least one year of prior observation. Incidence and prevalence were calculated on a yearly basis with 95% confidence intervals and then stratified by age and sex.  ResultsFrom 2007 to 2019, the incidence of parkinsonism and Parkinsons Disease decreased, with Parkinsons Disease incidence dropping from 35.86 (95% confidence interval: 34.22 - 37.56) to 31.40 (29.40 - 33.50) per 100,000 person-years. The prevalence of parkinsonism and Parkinsons Disease increased from 0.22% (0.22% - 0.23%) and 0.21% (0.21% - 0.22%) in 2007 to peak in 2016 with 0.25% (0.25% - 0.26%) and 0.23% (0.23% - 0.24%) respectively. The number of Vascular Parkinsonism diagnoses have increased from 2010, whereas incidence and prevalence of Drug-induced Parkinsonism remained stable. Incidence and prevalence increased with age and were generally higher in males, except for Drug-induced Parkinsonism, which was slightly higher in females.  ConclusionsGiven its association with aging, parkinsonism and these subtypes continue to present an increasing challenge to our aging society.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Secondary brain injury after parenchymal cerebral hemorrhage in humans: the role of oxidative stress and Endothelin-1\nAbstract: Background and aimsPerihematomal hypoperfusion may lead to ischemic damage during intraparenchymal cerebral hemorrhage (ICH), resulting in worse prognosis. We aimed to (1) investigate the relationship between serum biomarkers related to oxidative stress and vasoactive substances and the occurrence of hypoperfusion and ischemic perihematomal lesions in ICH, (2) to evaluate their correlation with the volumetric evolution of the hematoma and perihematomal edema.  MethodsWe enrolled 28 patients affected by ICH. Blood samples were collected at timepoint T0 (admission to Emergency-Room), T1 (12-24hs from symptoms onset), T2 (48- 72hs from onset), to measure Endothelin-1 (ET-1), nitrites/nitrates (NO), NADPH oxidase-2 (NOX-2), metalloproteinase-12 (MMP12) and asymmetric dimethylarginine (ADMA). Patients underwent brain MRI with perfusion study at T1 and MRI without perfusion at T2.  Results12 patients had ischemic perihematomal lesions at T1. A higher NOX-2 concentration at T0 was observed in patients with ischemic perihematomal lesions compared to those without, (34.9 pg/ml vs 22.4 pg/ml, p=0.051) and with a more severe perihematomal edema at T2 (37.99 pg/ml vs. 19.17 pg/ml, p=0.011). The ischemic perihematomal lesions development was also associated with an increased hematoma volume (p<0.005), perilesional edema (p=0.046), greater midline shift (p=0.036). ET-1 values at T1 inversely correlated with hemorrhage volume at T2 ({rho}=-0.717, p=0.030).  ConclusionsNOX-2 seems to have a role in the development of ischemic perihematomal lesions. The association between higher ET-1 values and a lower hemorrhage volume could be related to the ET-1 vasoconstriction action on the ruptured vessel wall.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Real-time detection of spoken speech from unlabeled ECoG signals: A pilot study with an ALS participant\nAbstract: Objective. Brain-Computer Interfaces (BCIs) hold significant promise for restoring communication in individuals with partial or complete loss of the ability to speak due to paralysis from amyotrophic lateral sclerosis (ALS), brainstem stroke, and other neurological disorders. Many of the approaches to speech decoding reported in the BCI literature have required time-aligned target representations to allow successful training - a major challenge when translating such approaches to people who have already lost their voice. Approach. In this pilot study, we made a first step toward scenarios in which no ground truth is available. We utilized a graph-based clustering approach to identify temporal segments of speech production from electrocorticographic (ECoG) signals alone. We then used the estimated speech segments to train a voice activity detection (VAD) model using only ECoG signals. We evaluated our approach using held-out open-loop recordings of a single dysarthric clinical trial participant living with ALS, and we compared the resulting performance to previous solutions trained with ground truth acoustic voice recordings. Main results. Our approach achieves a median error rate of around 0.5 seconds with respect to the actual spoken speech. Embedded into a real-time BCI, our approach is capable of providing VAD results with a latency of only 10 ms. Significance. To the best of our knowledge, our results show for the first time that speech activity can be predicted purely from unlabeled ECoG signals, a crucial step toward individuals who cannot provide this information anymore due to their neurological condition, such as patients with locked-in syndrome. Clinical Trial Information. ClinicalTrials.gov, registration number NCT03567213.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The central response of electroacupuncture for anxiety in people with obesity based on resting-state functional magnetic resonance imaging: a protocol for a randomized, blinded, sham-controlled trial\nAbstract: IntroductionObesity is a problem that is increasing worldwide and anxiety is a major psychological disorder associated with obesity. Electroacupuncture (EA) has been proved to be a feasible treatment for obesity and anxiety respectively in clinical practice. However, to date, there are no data on EAs effectiveness on anxiety for people with obesity. Therefore, this study aims to evaluate the efficacy and safety of EA for anxiety in people with obesity, and to observe the brain functional status of patients and the intervention effects of EA on brain function by functional magnetic resonance imaging (fMRI).  Methods and analysisThis study is a randomized, blinded, sham-controlled and clinical trial. 72 obesity patients from two hospitals with anxiety will be randomly divided into EA group and control group in 1:1 ratio by using a random number table. Patients in EA group will receive EA treatment at specific acupoints with penetrating needling for 8 weeks. The control group will receive Parks acupuncture with non- penetrating needling. Weight, waist, BMI (Body Mass Index), SAS (Self-rating Anxiety Scale), STAI (State-Trait Anxiety Inventory) and PSQI (Pittsburgh Sleep Quality Index) will be performed before, after 8-week treatments and at one-month follow-up in patients. Objective metabolic parameters such as triglyceride, total cholesterol, fasting blood glucose, ghrelin, leptin, cortisol and adrenocorticotropic hormone will also be detected before and after 8-week intervention. 20 patients will be randomly selected from EA group and control group, respectively, before treatment, and 20 paired healthy participants will be recruited at the same time. The 20 patients will be scanned by fMRI before and after treatment while the other 20 healthy participants will be scanned only at baseline. Regional homogeneity, amplitude of low-frequency fluctuation and resting-state-functional-connectivity will be carried out to compare the dysfunctional brain regions between patients and healthy participants, as well as the differences between two groups of patients after treatment.  Ethics and disseminationThe study protocol has been approved by the Hospital Ethics Committee of Second Affiliated Hospital of Anhui University of Chinese Medicine (2023-zj-42). Informed consent will be obtained prior to starting study- ralated procedures. The results will be disseminated in peer-reviewed journals and at scientific conferences.  Trail Registration numberChinese Clinical Trail Registry. ChiCTR2400083594, registered 29 April 2024.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Construction of the index system for screening and assessment of dysphagia in Chinese elderly people based on Delphi method\nAbstract: BackgroundDysphagia is an important factor affecting aspiration pneumonia in the elderly, which will greatly increase the risk of poor prognosis and even death. Early detection, diagnosis and effective prevention are the key to improve the prognosis of patients. However, there is currently no systematic tool for screening and evaluating swallowing disorders in the elderly.  ObjectiveThis study aimed to establish an index system for the screening and evaluation of dysphagia in the elderly, and to provide evidence for the screening and evaluation of dysphagia in the community and clinic.  MethodsThe draft of the index system was determined based on the combination of literature review and clinical practice. The Delphi method was applied to conduct expert correspondence consultation, and the index system for screening and evaluation of dysphagia in the elderly was established. The weight of each index was determined by analytic hierarchy process.  ResultsA total of 19 experts in related fields were consulted for 3 rounds. The questionnaire recovery rates were 94.7%, 100% and 100%, respectively. 17 (89.5%), 14 (73.7%) and 5 (26.3%) experts put forward modification opinions, respectively. The expert authority coefficient was 0.920, and the Kendall harmony coefficient was 0.219, 0.261 and 0.306, respectively, with statistical significance (P < 0.001). Finally, the index system for the screening and evaluation of dysphagia in the elderly includes 3 first-level indicators, 10 second-level indicators and 26 third-level indicators.  ConclusionThe experts in this study are highly motivated and authoritative, and the established index system for the screening and evaluation of dysphagia in the elderly is scientific, reasonable and targeted, which can provide reference for the screening and evaluation of dysphagia in the community and clinical elderly patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Allium Vegetables Intake and Digestive System Cancer Risk: A Study Based on Mendelian Randomization, Network Pharmacology and Molecular Docking\nAbstract: BackgroundAllium vegetables (garlic and onion) are one of the flavorings in peoples daily diets. Observational studies suggest that intake of allium vegetables may be correlated with a lower incidence of digestive system cancers. However, the existence of a causal relationship is still controversial due to confounding factors and reverse causation. Therefore, we explored the causal relationship between intake of allium vegetables and digestive system cancers using Mendelian randomization approach.  MethodsFirst, we performed Mendelian randomization analyses using inverse variance weighting (IVW), weighted median, and MR-Egger approaches, and demonstrated the reliability of the results in the sensitivity step. Second, Multivariable Mendelian randomization was applied to adjust for smoking and alcohol consumption. Third, we explored the molecular mechanisms behind the positive results through network pharmacology and molecular docking methods.  ResultsThe study suggests that increased intake of garlic reduced gastric cancer risk. However, onion intake was not statistically associated with digestive system cancer.  ConclusionGarlic may have a protective effect against gastric cancer.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Study Protocol. The CASPAR study protocol. Can cervical stiffness predict successful vaginal delivery after induction of labour? A feasibility, cohort study.\nAbstract: BackgroundInduction of labour (IOL) is a common obstetric intervention in the UK, affecting up to 33% of deliveries. IOL aims to achieve a vaginal delivery prior to spontaneous onset of labour to prevent harm from ongoing pregnancy complications and is known to prevent stillbirths and reduce neonatal intensive care unit admissions. However, IOL doesnt come without risk and overall, 20% of mothers having an induction will still require a caesarean section birth and in primiparous mothers this rate is even higher.  There is no reliable predictive bedside tool available in clinical practice to predict which patients undergoing the IOL process will result in a vaginal birth; the fundamental aim of the IOL process. The Bishops Score (BS) remains in routine clinical practice as the examination tool to assess the cervix prior to IOL, despite it being proven to be ineffective as a predictive tool and largely subjective. This study will assess the use of the Pregnolia System, a new objective antenatal test of cervical stiffness. This study will explore its potential for pre-induction cervical assessment and indication of delivery outcome following IOL.  MethodsCASPAR is a feasibility study of term, primiparous women with singleton pregnancies undergoing IOL. Cervical stiffness will be assessed using the Pregnolia System; a novel, non-invasive, licensed, CE-marked, aspiration-based device proven to provide objective, quantitative cervical stiffness measurements represented as the Cervical Stiffness Index (CSI, in mbar). A measurement is obtained by applying the sterile single-use Pregnolia Probe directly to the anterior lip of the cervix, visualised via placement of a speculum.  Following informed consent, CASPAR study participants will undergo the Pregnolia System cervical stiffness assessment prior to their IOL process commencing. Participant questionnaires will evaluate the acceptability of this assessment tool in this population. This study will directly compare this novel antenatal test to the current BS for both patient experience of the different cervical assessment tools and for IOL outcome prediction.  DiscussionThis feasibility study will explore the use of this novel device in clinical practice for pre-induction cervical assessment and delivery outcome prediction. Our findings will provide novel data that could be instrumental in transforming clinical practice surrounding IOL. Determining recruitment rates and acceptability of this new assessment tool in this population will inform design of a further powered study using the Pregnolia System as the point-of-care, bedside cervical assessment tool within an IOL prediction model.  Study registrationThis study is sponsored by The University of Liverpool and registered at ClinicalTrials.gov, identifier NCT05981469, date of registration 7th July 2023.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: RaBIt:An Effective Visualization-Driven Tool for Power and Sample Size Estimation in Two-Stage General Randomized Basket Trial Designs\nAbstract: Basket trial designs with interim analysis have gained significant attention due to their adaptability, flexibility, and scalability. In response to the need for user-friendly tools that enhance the real-world applicability of these designs, we developed a web-based interface aimed at facilitating two-stage basket trial designs. Built using R Shiny, the tool was rigorously validated for output consistency by comparing it to an established R pipeline. Additionally, user testing was conducted to ensure the interface is intuitive and easy to use. The result is a freely accessible tool that provides effective and convenient visualizations for general basket trial designs with interim analysis, available at https://desmondzeyachen.shinyapps.io/AdaptiveTwoStageBasketTrialFeb14/. Future improvements may further expand the tools capabilities to accommodate the increasing complexity of trial designs needed by the research community.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: RaBIt: An Effective Visualization-Driven Tool for Power and Sample Size Estimation in Two-Stage General Randomized Basket Trial Designs\nAbstract: Basket trial designs with interim analysis have gained significant attention due to their adaptability, flexibility, and scalability. In response to the need for user-friendly tools that enhance the real-world applicability of these designs, we developed a web-based interface aimed at facilitating two-stage basket trial designs. Built using R Shiny, the tool was rigorously validated for output consistency by comparing it to an established R pipeline. Additionally, user testing was conducted to ensure the interface is intuitive and easy to use. The result is a freely accessible tool that provides effective and convenient visualizations for general basket trial designs with interim analysis, available at https://desmondzeyachen.shinyapps.io/AdaptiveTwoStageBasketTrialFeb14/. Future improvements may further expand the tools capabilities to accommodate the increasing complexity of trial designs needed by the research community.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Deep Learning Based Smartphone Application for Early Detection of Nasopharyngeal Carcinoma Using Endoscopic Images\nAbstract: Nasal endoscopy is crucial for the early detection of nasopharyngeal carcinoma (NPC), but its accuracy relies significantly on the physicians expertise, posing challenges for primary healthcare providers. Here, we retrospectively analysed 39,340 nasal endoscopic white-light images from three high-incidence NPC centres, utilising eight advanced deep learning models to develop an Internet-enabled smartphone application, \"Nose-Keeper\", that can be used for early detection of NPC and five prevalent nasal conditions and assessment of healthy individuals. Our App demonstrated a remarkable overall accuracy of 92.27% (95% Confidence Interval (CI): 90.66%-93.61%). Notably, its sensitivity and specificity in NPC detection achieved 96.39% and 99.91%, respectively, outperforming nine experienced otolaryngologists. Explainable artificial intelligence was employed to highlight key lesion areas, improving Nose-Keepers decision-making accuracy and safety. Nose-Keeper can assist primary healthcare providers in diagnosing NPC and related diseases efficiently, offering a valuable resource for people in high-incidence NPC regions to manage nasal cavity health effectively.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Molecular Characterization of Pediatric Acute Lymphoblastic Leukemia via Integrative Transcriptomics: A Multicenter Study in Argentina\nAbstract: Pediatric acute lymphoblastic leukemia (ALL) is a highly heterogeneous disease at the molecular level, with over 20 subtypes of B-cell ALL (B-ALL) identified to date. These subtypes are critical for guiding risk-adapted therapy and precision medicine, as they are defined by specific chromosomal rearrangements, gene expression profiles, aneuploidies and point mutations. However, the ability to accurately classify these subtypes is limited by the technical and economic challenges faced by many centers, particularly in low- and middle-income countries. In this study, we employed transcriptome sequencing to perform molecular classification of B-ALL at diagnosis in pediatric patients enrolled in the multicentric ALLIC-GATLA-2010 clinical protocol in Argentina. Using a combination of bioinformatic tools, we successfully identified single nucleotide variants, fusion transcripts and gene expression profiles, achieving molecular classification in over 90% of patients. Our analysis also revealed high-risk molecular features and novel genetic alterations. These findings hold potential clinical value for improving risk stratification and identifying therapeutic targets, particularly for patients who remain unclassified by conventional diagnostic methods.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Linkage Disequilibrium-Informed Deep Learning Framework to Identify Genetic Loci for Alzheimer's Disease Using Whole Genome Sequencing Data\nAbstract: The exponential growth of genomic datasets necessitates advanced analytical tools to effectively identify genetic loci from large-scale high throughput sequencing data. This study presents Deep-Block, a multi-stage deep learning framework that incorporates biological knowledge into its AI architecture to identify genetic regions as significantly associated with Alzheimers disease (AD). The framework employs a three-stage approach: (1) genome segmentation based on linkage disequilibrium (LD) patterns, (2) selection of relevant LD blocks using sparse attention mechanisms, and (3) application of TabNet and Random Forest algorithms to quantify single nucleotide polymorphism (SNP) feature importance, thereby identifying genetic factors contributing to AD risk. The Deep-Block was applied to a large-scale whole genome sequencing (WGS) dataset from the Alzheimers Disease Sequencing Project (ADSP), comprising 7,416 non-Hispanic white participants (3,150 cognitively normal older adults (CN), 4,266 AD). First, 30,218 LD blocks were identified and then ranked based on their relevance with Alzheimers disease. Subsequently, the Deep-Block identified novel SNPs within the top 1,500 LD blocks and confirmed previously known variants, including APOE rs429358 and rs769449. The results were cross-validated against established AD-associated loci from the European Alzheimers and Dementia Biobank (EADB) and the GWAS catalog. The Deep-Block framework effectively processes large-scale high throughput sequencing data while preserving interactions between SNPs in performing the dimensionality reduction, which can potentially introduce bias or lead to information loss. The Deep-Block approach identified both known and novel genetic variation, enhancing our understanding of the genetic architecture of and demonstrating the frameworks potential for application in large-scale sequencing studies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Online46: online cognitive assessments in elderly cohorts - the British 1946 birth cohort case study\nAbstract: INTRODUCTIONOnline assessments are scalable and cost-effective for detecting cognitive changes, especially in elderly cohorts with limited mobility and higher vulnerability to neurological conditions. However, determining the uptake, adherence, and usability of these assessments in older adults, who may have less experience with mobile devices is crucial.  METHODS1,776 members (aged 77) of the MRC National Survey of Health and Development (NSHD) were invited to complete 13 online cognitive tasks. Adherence was measured through task compliance, while uptake (consent, attempt, completion) was linked to health and sociodemographic factors. Usability was evaluated through qualitative feedback.  RESULTSThis studys consent (56.9%), attempt (80.5%), and completion (88.8%) rates are comparable to supervised NSHD sub-studies. Significant predictors of uptake included education, sex, handedness, cognitive scores, weight, smoking, alcohol consumption, and disease burden.  DISCUSSIONWith key recommendations followed, online cognitive assessments are feasible, with good adherence, and usability in older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: RiskPath: Explainable deep learning for multistep biomedical prediction in longitudinal data\nAbstract: Predicting individual and population risk for disease outcomes and identifying persons at elevated risk is a key prerequisite for targeting interventions to improve health. However, current risk stratification tools for the common, chronic diseases that develop over the lifecourse and represent the majority of disease morbidity, mortality and healthcare costs are aging and achieve only moderate predictive performance. In some common, highly morbid conditions such as mental illness no risk stratification tools are yet available. There is an urgent need to improve predictive performance for chronic diseases and understand how cumulative, multifactorial risks aggregate over time so that intervention programs can be targeted earlier and more effectively in the disease course. Chronic diseases are the end outcomes of multifactorial risks that increment over years and represent cumulative, temporally-sensitive risk pathways. However, tools in current clinical use were constructed in older data and utilize inputs from a single data collection step. Here, we present RiskPath, a multistep deep learning method for temporally-sensitive biomedical risk prediction tailored for the constraints and demands of biomedical practice that achieves very strong performance and full translational explainability. RiskPath delineates and quantifies cumulative multifactorial risk pathways and allows the user to explore performance-complexity tradeoffs and constrain models as required by clinical use cases. Our results highlight the potential for developing a new generation of risk stratification tools and risk pathway mapping in time-dependent diseases and health outcomes by leveraging powerful timeseries deep learning methods in the wealth of biomedical data now appearing in large, longitudinal open science datasets.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bibliometric Analysis of Perioperative Organ Injury: Insights into the State of Basic Science Research\nAbstract: Perioperative organ injury represents a significant clinical challenge, leading to severe and often long-term complications for patients undergoing surgery. Despite its critical importance, the basic science underlying these injuries remains underexplored. This study employs bibliometric analysis to assess the research landscape of perioperative organ injury, focusing on key conditions such as myocardial infarction, ischemia-reperfusion injury, heart failure, acute respiratory distress syndrome (ARDS), perioperative lung injury, liver ischemia-reperfusion injury, ischemic acute kidney injury, and perioperative stroke. By analyzing publication trends, citation patterns, and research themes, this study aims to provide insights into the current state of basic science research in this field, highlighting gaps and opportunities for future investigations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Transformers in Skin Lesion Classification and Diagnosis: A Systematic Review\nAbstract: ObjectivesThis systematic review aims to provide a comprehensive overview of the current state of research on the application of transformers in skin lesion classification.  Materials and MethodsOver the period 2017-2023, this systematic review investigated the application of transformer-based models in skin lesion classification, focusing on 57 articles retrieved from prominent databases which are PubMed, Scopus, and Medline. The inclusion criteria encompass studies centering on transformer-based models for skin lesion classification, utilization of diverse datasets (dermoscopic images, clinical images, or histopathological images), publication in peer-reviewed journals or conferences, and availability in English. Conversely, exclusion criteria filter out studies not directly related to skin lesion classification, research applying algorithms other than transformer-based models, non-academic articles lacking empirical data, papers without full-text access, and those not in English.  ResultsOur findings underscore the adaptability of transformers to diverse skin lesion datasets, the utilization of pre-trained models, and the integration of various mechanisms to enhance feature extraction.  ConclusionOur Systematic review showed the implementation and the application of the Transformer models for skin lesion classification. Our study showed the research areas and future research ideas for the use of transformers on skin lesion classification.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Transformers in Skin Lesion Classification and Diagnosis: A Systematic Review\nAbstract: ObjectivesThis systematic review aims to provide a comprehensive overview of the current state of research on the application of transformers in skin lesion classification.  Materials and MethodsOver the period 2017-2023, this systematic review investigated the application of transformer-based models in skin lesion classification, focusing on 57 articles retrieved from prominent databases which are PubMed, Scopus, and Medline. The inclusion criteria encompass studies centering on transformer-based models for skin lesion classification, utilization of diverse datasets (dermoscopic images, clinical images, or histopathological images), publication in peer-reviewed journals or conferences, and availability in English. Conversely, exclusion criteria filter out studies not directly related to skin lesion classification, research applying algorithms other than transformer-based models, non-academic articles lacking empirical data, papers without full-text access, and those not in English.  ResultsOur findings underscore the adaptability of transformers to diverse skin lesion datasets, the utilization of pre-trained models, and the integration of various mechanisms to enhance feature extraction.  ConclusionOur Systematic review showed the implementation and the application of the Transformer models for skin lesion classification. Our study showed the research areas and future research ideas for the use of transformers on skin lesion classification.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Automating Individualized Patient Notification of Drug Recalls: Complex Challenges\nAbstract: BackgroundConsumer-level drug recalls usually require action by individual patients. FDA has public-facing outlets to inform consumers and healthcare professionals about drug safety information including recalls, but consumers may not be aware of them. Prescribers are not notified about which of their patients are affected. The process may lead some patients to stop taking their medications. Aim To leverage the FDAs Healthy Citizen prototype platform, which provides information about recalls, to automatically notify patients of relevant recalls.  MethodWe developed and evaluated an electronic notification system in the Primary Care and Cardiology practices at a large urban, academic medical center. Using structured interviews, we assessed qualitative feedback on the system and portal messaging from a convenience sample of 9 patients.  ResultsProgram Description The healthcare portal scanned the FDA Healthy Citizen Application Programming Interface nightly to detect new recalls, identified patients who had those medications in their electronic health record (EHR) medication list, and sent them a message through the EHR patient portal with a link to a customized FDA information display. Program Evaluation The system was technically functional, but it was not possible to trace a medication prescription from the EHR to specific lot numbers dispensed to that patient by a community pharmacy.  DiscussionLack of an accurate electronic audit trail from prescription to dispensed medication precludes clinical deployment of automated drug recall notification.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Correspondence: Recurrent ECSIT mutation encoding V140A triggers hyperinflammation and promotes hemophagocytic syndrome in extranodal NK/T cell lymphoma\nAbstract: Recurrent somatic mutation in the ECSIT gene encoding p.V140A was reported in 19.3% (17/88) extranodal natural-killer/T cell lymphoma (ENKTL) and was associated with hemophagocytic syndrome (HPS). However, another cohort of similar geographical descent also had the ECSITV140A mutation as germline in 20.0% (5/25) of ENKTL and none were somatic. The reanalysis of published data revealed that the reported somatic ECSITV140A could be germline as well. First-digit analysis on the IDs of sequencing read also found irregularity among the data that initially reported the somatic ECSITV140A mutation. As such, this study questions the only somatic genetic link of HPS in ENKTL and also introduces a simple well-known algorithm to detect data irregularity in voluminous genomic sequencing data.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hypothalamic Gliosis is Associated with Multiple Cardiovascular Disease Risk Factors\nAbstract: BackgroundHypothalamic gliosis is mechanistically linked to obesity and insulin resistance in rodent models. We tested cross-sectional associations between radiologic measures of hypothalamic gliosis in humans and clinically relevant cardiovascular disease risk factors, as well as prevalent coronary heart disease.  MethodsUsing brain MRI images from Framingham Heart Study participants (N=867; mean age, 55 years; 55% females), T2 signal intensities were extracted bilaterally from the region of interest in the mediobasal hypothalamus (MBH) and reference regions in the amygdala (AMY) and putamen (PUT). T2 signal ratios were created in which greater relative T2 signal intensity suggests gliosis. The primary measure compared MBH to AMY (MBH/AMY); a positive control ratio (MBH/PUT) also assessed MBH whereas a negative control (PUT/AMY) did not. Outcomes were BMI, HDL-C, LDL-C, fasting triglycerides, and the presence of hypertension (n=449), diabetes mellitus (n=66), metabolic syndrome (n=254), or coronary heart disease (n=25). Dietary risk factors for gliosis were assessed in a prospective analysis. Statistical testing was performed using linear or logistic regression.  ResultsGreater MBH/AMY T2 signal ratios were associated with higher BMI ({beta} = 21.5 [95% CI, 15.4- 27.6]; P<0.001), higher fasting triglycerides ({beta} = 1.1 [95% CI, 0.6-1.7]; P<0.001), lower HDL-C ({beta} = -20.8 [95% CI, -40.0 to -1.6]; P=0.034), and presence of hypertension (odds ratio, 1.2 [95% CI, 1.1-1.4]; P=0.0088), and the latter two were independent of BMI. Findings for diabetes mellitus were mixed and attenuated by adjusting for BMI. Metabolic syndrome was associated with MBH/AMY T2 signal ratios (odds ratio, 1.3 [95% CI, 1.1-1.6]; P<0.001). Model results were almost uniformly confirmed by the positive control ratios, whereas negative control ratios that did not test the MBH were unrelated to any outcomes (all P[&ge;]0.05). T2 signal ratios were not associated with prevalent coronary heart disease (all P>0.05), but confidence intervals were wide. Self-reported percentages of macronutrient intake were not consistently related to future T2 signal ratios.  ConclusionsUsing a well-established study of cardiovascular disease development, we found evidence linking hypothalamic gliosis to multiple cardiovascular disease risk factors, even independent of adiposity. Our results highlight the need to consider neurologic mechanisms to understand and improve cardiometabolic health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Efficacy and Safety of Beta Blockers for Patients with Myocardial Infarction in the Percutaneous Coronary Intervention Era: A Systematic Review and Meta-Analysis\nAbstract: BackgroundBeta-blockers are commonly prescribed to patients after MI. However, the evidence is based on studies conducted before the widespread use of PCI for treating MI. We conducted this meta-analysis to evaluate beta-blockers efficacy post-MI in the modern day and age.  MethodsWe conducted our search using and one clinical trial registry to get RCTs and propensity-matched observational studies comparing the use of beta-blockers after MI to control in post-MI patients. The primary outcome of our analysis was the likelihood of all-cause mortality.  ResultsOur analysis included 3 RCTs and 12 propensity-matched observational studies with a total study population of 102,794. Our results showed a statistically significant decrease in all-cause mortality in the beta-blocker group compared to the non-beta-blocker group (RR 0.63, 95% CI 0.47-0.83; p= 0.001). However, this decrease was not observed when only RCTs were considered (RR 0.91). Beta-blockers were also found to reduce the risk of MI and heart failure with RR of 0.86 (95% CI 0.75-1.00; p=0.05) and 0.84 (95% CI 0.73-0.97; p=0.02), respectively.  ConclusionBeta-blockers effectively reduce mortality and decrease the risk of MI and heart failure without a significant increase in adverse effects. Thus, our findings support the contemporary use of beta blockers in post-MI patients. However, more long-term studies need to be done to determine the sustained benefits of beta blockers in the context of evolving cardiac care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Metabolic Outcomes in Non-Alcoholic and Alcoholic Steatotic Liver Disease among Korean and American Adults: A Population-Based Multi-Cohort Study\nAbstract: Background and aimsThis study investigated the prevalence and causal relationships of chronic metabolic diseases (diabetes, hypertension, and dyslipidemia) with steatotic liver disease (SLD), specifically metabolically associated alcoholic liver disease (MetALD).  MethodsWe conducted a comprehensive analysis using cross-sectional data from the Korea National Health and Nutrition Examination Survey (KNHANES) from 2011 to 2021 and the National Health and Nutrition Examination Survey (NHANES) from 1999 to 2020. Longitudinal data from 2001 to 2014 from the Korean Genome and Epidemiology Study (KoGES) were used. Participants were categorized into the metabolic dysfunction-associated SLD (MASLD), MetALD, and ALD groups based on their hepatic steatosis index (HSI) and alcohol consumption. Logistic and Cox regression analyses were performed to assess the prevalence and incidence of chronic diseases.  ResultsIn both the KNHANES and NHANES cohorts, an increased HSI was significantly associated with a higher prevalence of chronic metabolic diseases. Longitudinal data from the KoGES cohort showed that MASLD and MetALD were significant predictors of chronic metabolic disease in both men and women. MetALD showed a higher hazard ratio for the development of chronic metabolic diseases than MASLD in Cox regression analysis.  ConclusionThis study highlighted the intertwined nature of SLD and metabolic health, with an emphasis on the role of MetALD. The significant association between MetALD and chronic metabolic diseases underscores the need for integrated management strategies that address both liver health and metabolic risk factors.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Blood N-glycomic signature of fibrosis in MASLD shows low levels of global \u03b12,3-sialylation\nAbstract: Background & AimsAlterations in the glycosylation of blood proteins affect protein functionality and have been linked to various diseases. Metabolic dysfunction- associated steatotic liver disease (MASLD) is a silent disease, of which progression to advanced disease stages including metabolic dysfunction-associated steatohepatitis (MASH), fibrosis and cirrhosis often goes unnoticed. As current non- invasive diagnostic tests lack specificity, the purpose of this work was to study total blood protein N-glycosylation in individuals with MASLD and various degrees of fibrosis as compared to healthy controls.  MethodsIn two independent cross-sectional cohort studies, blood N-glycosylation analysis was performed by mass spectrometry on released glycans of overall 132 MASLD patients and 99 age- and sex-matched healthy controls. Relationships between glycosylation traits and the disease spectrum of MASLD including fibrotic MASLD were investigated in comparison to healthy controls. Furthermore, publicly available transcriptomics datasets were used to explore glycosyltransferase expression in patients with MASLD.  ResultsGlobally lower 2,3-sialylation distinguished MASLD from healthy controls (OR [CI]=0.36; [0.18-0.67]; p-value=0.019, and 0.11 [0.04-0.24]; p-value<0.000001), as well as non-fibrotic MASLD from its fibrotic counterparts (OR: 0.13 [0.06-0.26]; p- value<0.0001), but showed no association with steatohepatitis activity. Hepatic ST3GAL6, a sialyltransferase responsible for N-glycan 2,3-sialylation, negatively associated with fibrosis progression, similar to the observed glycomic signature. Both glycomic and transcriptomic signatures were replicated in independent cohorts.  ConclusionsFibrotic MASLD is characterized by a global decrease of blood protein 2,3-sialylation and according decrease in hepatic 2,3-sialyltransferase expression, associating with disease progression. These findings suggest alterations in the N- glycan biosynthetic pathway and are potentially useful in the early diagnosis of fibrosis in MASLD.  Lay SummaryNon-invasive markers of fibrotic MASLD perform suboptimal. This research identified that changes in blood protein glycosylation coincide with fibrosis development, offering blood-based markers that could potentially replace a liver biopsy.  What You Need to KnowO_ST_ABSBACKGROUND AND CONTEXTC_ST_ABSThe majority of the plasma glycoproteins is synthesized in the liver and changes to their glycosylation are known to affect their function and to associate with liver disorders.  NEW FINDINGSMASLD patients exhibit lower 2,3-sialylation on the complete range of their blood protein N-glycans, which coincides with the histological appearance of fibrosis, mediated likely via downregulation of hepatic ST3GAL6.  LIMITATIONSWhile the findings of this study has could have implications for diagnosing fibrotic MASLD, the identified glycomic signature needs to be confirmed in a larger, ideally prospective patient cohort.  CLINICAL RESEARCH RELEVANCEBy identifying specific signatures in the blood protein N-glycome, this research offers potential non-invasive markers for early diagnosis and monitoring of fibrosis in MASLD. Non-invasive diagnosis could potentially lessen the need for liver biopsies, and allow for timely intervention and improved disease management, ultimately leading to improvement of patient outcomes and the reduction of liver-related morbidity and mortality.  BASIC RESEARCH RELEVANCEThe observed glycomic and transcriptomic signatures offer molecular-level insights into fibrosis development in MASLD. This paves the way for future research at the intersection of glycoscience and hepatology, that will offer deeper insights into the pathophysiology of this liver disease.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A pilot study to identify blood-based markers associated with response to treatment with Vedolizumab in patients with Inflammatory Bowel Disease\nAbstract: The inflammatory bowel diseases (IBD) known as Crohns disease (CD) and ulcerative colitis (UC) are chronic inflammatory diseases of the gastrointestinal tract believed to arise because of an imbalance between the epithelial, immune and microbial systems. It has been shown that biological differences (genetic, epigenetic, microbial, environmental, etc.) exist between patients with IBD, with multiple risk factors been associated with disease susceptibility and IBD-related phenotypes (e.g. disease location). It is also known that there is heterogeneity in terms of response to therapy in patients with IBD, including to biological therapies that target very specific biological pathways (e.g. TNF-alpha signaling, IL-23R signaling, immune cell trafficking, etc.). It is hypothesized that the better the match between the biology targeted by these advanced therapies and the predominant disease-associated pathways at play in each patient will favor a beneficial response. The aim of this pilot study was to identify potential biological differences associated with differential treatment response to the anti 4{beta}7 integrin therapy known as Vedolizumab. Our approach was to measure a broad range of analytes in the serum of patients prior to initiation of therapy and at the first clinical assessment visit, to identify potential markers of biological differences between patients at baseline and to see which biomarkers are most affected by treatment in responders. Our focus on early clinical response was to study the most proximal effects of therapy and to minimize confounders such as loss of response that occurs further distal to treatment initiation. Specifically, we performed targeted analyses of >150 proteins and metabolites, and untargeted analyses of >1100 lipid entities, in serum samples from 92 IBD patients (42 CD, 50 UC) immediately prior to initiation of therapy with vedolizumab (baseline samples) and at their first clinical assessment (14-week samples). We found lower levels of SDF-1a, but higher levels of PDGF-{beta}{beta}, lactate, lysine, phenylalanine, branched chain amino acids, alanine, short/medium chain acylcarnitines, and triglycerides containing myristic acid in baseline serum samples of responders as compared to non-responders. We also observed an increase in serum levels of CXCL9 and citrate, as well as a decrease in IL-10, between baseline and week 14 samples. In addition, we observed that a group of metabolites and protein analytes was strongly associated with both treatment response and BMI status, although BMI status was not associated with treatment response.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Outcome Dimensions and Measurement Approaches for Evaluating the Impact of China's Family Doctor Contract Services: A Scoping Review Protocol\nAbstract: BackgroundFamily doctor contract services in mainland China are designed to foster long-term relationships between family doctors and contracted residents, promoting the delivery of primary care services through teamwork and collaboration. By 2035, it is expected that the coverage of these services will exceed 75%, making it a key model for primary care in China. However, the outcome dimensions and measurement approaches used to evaluate the effectiveness of these services remain fragmented and lack a comprehensive framework. This scoping review aims to systematically investigate the outcome dimensions and measurement approaches previously used to evaluate the effectiveness of family doctor contract services in mainland China.  MethodsThis scoping review will be conducted in accordance with the JBI methodology for scoping reviews. We will search electronic databases, including CNKI, Wanfang, PubMed, the Cochrane Database of Systematic Reviews, JBI Evidence Synthesis, PROSPERO, and Google Scholar, for literature published since 2006. Eligible sources will include policy documents, quantitative studies, and qualitative studies that assess the outcomes of family doctor contract services. Data extraction will focus on the outcome dimensions and measurement approaches used in these evaluations. Two independent reviewers will screen and extract data from the literature, and any discrepancies will be resolved through group discussions with a third reviewer. Descriptive statistics will be used to analyze the extracted data, and the results will be presented through tables, charts, and a hierarchical tree diagram of outcome dimensions and measurement tools.  DiscussionThis scoping review will provide a comprehensive overview of the outcome dimensions and measurement approaches used to evaluate family doctor contract services in mainland China. It will help to identify gaps in the existing literature and offer a clearer framework for future evaluations of these services. By mapping out the outcome dimensions and tools, this review aims to contribute to improving the quality and effectiveness of family doctor contract services in China. The findings will be particularly valuable for policymakers and researchers focused on enhancing primary care systems.  Systematic review registrationRegistered in OSF on September 20, 2024 (osf.io/z3eju)\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Social media use and exposure to pro-tobacco content: a comparison of sexual identity and gender in young adults in California\nAbstract: IntroductionGiven the rapidly changing media landscape and tobacco marketplace, timely data on media consumption and exposure to pro-tobacco content across media channels among lesbian, gay, and bisexual (LGB) young adults is imperative for developing counter-messaging and public education campaigns for these individuals.  MethodsUsing 2023 data from young adults in California, this study examined how social media use differed across media channels for heterosexual and LGB young adults, by gender identity. Exposure to pro-tobacco content across media channels between heterosexual and LGB young adults, by gender identity was also compared.  ResultsFindings from a representative sample of young adults in California showed that more LGB young adults reported using Tumblr and fewer reported using Facebook and Snapchat, compared with heterosexual young adults, among both males and females. Additionally, social media use differed by gender identity. For example, use of Reddit was more common among LGB versus heterosexual females, but there were no differences by sexual identity among males. Exposure to tobacco marketing was more common among LGB females compared with heterosexual females, but this was not the case for males. Exposure to user-generated e-cigarette content, and self-reported visits to e-cigarette websites, were more common among LGB females compared to heterosexual females.  ConclusionsThese findings highlight the importance of treating LGB individuals as a heterogeneous group. As such, anti-tobacco campaigns designed for LGB individuals that leverage social media will want to consider which social media platforms are most used among their target audience, ensuring maximum campaign reach.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Epidemiological pattern of trauma among children 0 - 9 years in Cameroon\nAbstract: BackgroundIn low- and middle-income countries, trauma is the leading cause of death among youth and it is also a major cause of disability. Globally, more than 1,600 children and adolescents below the age of 19-years die every day from preventable injuries. Traffic-related injuries, falls, sports-related injuries, assaults, burns, and drownings are the most commonly reported causes of traumatic mortality among children. The mechanism of injury is always diverse in different contexts due to the differences in social determinants of health.  ObjectivesTo determine the epidemiological pattern of trauma among children 0 - 9 years in Cameroon.  MethodsThis is a retrospective analysis of prospectively collected data from the Cameroon Trauma Registry currently running in 10 pilot sites across seven of the ten regions of Cameroon. We retrieved data for all children aged 0 - 9 years from June 2022 to August 2023. Data was analyzed with respect to the demographics, injury characteristics and outcomes.  ResultsOf the 5,439 patients captured in the trauma registry, 267 (4.9%) were children aged 0-9 years. Over 50% (152/267) of the patients were males with 35% (93/267) from rural settings. The top injury mechanism was road traffic injuries (RTI) [137(52.1%)]. These injuries occurred on the streets [142(53.4%)] during leisure activities [205(78.5%)]. Majority of children [104(39%)] involved in RTI injuries were pedestrians and no prehospital care offered to 216(82.8%) of injured children. A total of 39 (16.9%) were discharged with major disability, 111 (48.1%) had limited ability to move and 5 (2.2%) demised or succumbed to their injuries. There was a significant association between injury activity and gender (P = 0.006). Unlike the females, majority of the males were discharged with major disability [21 (53.8%)].  ConclusionThis preliminary analysis highlights the burden of trauma among children aged 0 - 9 years and its contribution to the proportion of disabled persons in Cameroon. Leisure activities on the streets increased the number of pediatric injuries especially among males. It is therefore imperative to put in place or reinforce environmental interventions to reduce the burden of pediatric injuries.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A survey of Paediatric Radiology Artificial Intelligence\nAbstract: BackgroundArtificial intelligence (AI) applications in paediatric radiology present unique challenges due to diverse anatomy and physiology across age groups. Advancements in AI algorithms, particularly deep learning techniques, show promise in improving diagnostic accuracy.  ObjectivesTo survey trends in AI research in paediatric radiology. To evaluate use cases, tasks, research methodologies and underlying data. To identify potential biases and future directions.  MethodsA systematic search of paediatric radiology AI studies published from 2015 to 2021 was conducted following the PRISMA guidelines and the Cochrane Collaboration Handbook. The search included papers utilizing AI techniques for radiological diagnosis or intervention in patients aged under 18. Narrative synthesis was used due to methodological heterogeneity.  ResultsA total of 292 articles were included, with an increasing annual trend in the number of published articles. Neuroradiology and musculoskeletal radiology were the most common subspecialties. MRI was the dominant imaging modality, with segmentation and classification as the most common tasks. Retrospective cohort studies constituted the majority of research designs. Data quality and quantity varied, as did the choice of research design, data sources, and evaluation metrics.  ConclusionsAI literature in paediatric radiology shows rapid growth, with advancements in various subspecialties and tasks. However, potential biases and data quality issues highlight the need for rigorous research design and evaluation to ensure the generalisability and reliability of AI models in clinical practice. Future research should focus on addressing these biases and improving the robustness of AI applications in paediatric radiology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The impact of exercise training on the brain and cognition in T2DM, and its physiological mediators: a systematic review\nAbstract: BackgroundType 2 diabetes (T2DM) affects brain structure and function, and is associated with an increased risk of dementia and mild cognitive impairment. It is known that exercise training has a beneficial effect on cognition and the brain, at least in healthy people, but the impact of exercise training on cognition and the brain remains to be fully elucidated in patients with T2DM.  MethodsThis paper systematically reviews studies that evaluate the effect of exercise training on cognition in T2DM, and aims to indicate the most beneficial exercise modality for improving or preserving cognition in this patient group. In addition, the possible physiological mediators and targets involved in these improvements are narratively described in the second part of this review. Papers published up until the end of June 2024 were searched by means of the electronic database PubMed. Studies directly investigating the effect of any kind of exercise training on the brain or cognition in patients with T2DM, or animal models thereof, were included, with the exception of human studies assessing cognition only at one time point, and studies combining exercise training with other interventions (e.g. dietary changes, cognitive training, etc.).  ResultsFor the systematic part of the review, 24 papers were found to be eligible. 20 out of 24 papers (83.3%) showed a significant positive effect of exercise training on cognition in T2DM, of which four studies only showed a moderate significant effect. Four papers (16.7%) did not show a significant effect of exercise on cognition in T2DM, but two of them did show a positive trend. Similar effects were found for resistance and endurance exercise, with both possibly requiring a minimal intensity to reach cognitive improvement. In addition, BDNF, lactate, leptin, adiponectin, GSK3{beta}, GLP-1, the AMPK/SIRT1 pathway, and the PI3K/Akt pathway were identified as plausible mediators directly from studies investigating the effect of exercise training on the brain in T2DM.  ConclusionOverall, exercise training beneficially affects cognition and the brain in T2DM, with resistance and endurance exercise having similar effects. However, additional studies comparing the effect of different exercise intensities are needed to determine the optimal exercise intensity for cognitive improvement. Furthermore, we were able to define several mediators involved in the effect of exercise training on cognition in T2DM, but further research is necessary to unravel the entire process.  This review demonstrates a positive effect of exercise training on the brain in T2DM, but simultaneously emphasizes the need for additional studies on this topic. BDNF, lactate, leptin, adiponectin, GSK3{beta}, GLP-1, the AMPK/SIRT1 pathway, and the PI3K/Akt pathway were identified as factors mediating the effect of exercise on the brain in T2DM.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Introduction of the topic of snake bite and envenomation in medical curriculum using a problem-based learning approach\nAbstract: IntroductionSnake bite is a neglected tropical disease of Asia and African countries. The risk factors, disease burden, pathology, clinical management aspects of the condition deserve to be emphasized in the medical curriculum especially in the tropical countries. In Malaysia, there are at least 18 different species of venomous land snakes among which cobra bites and Malayan pit viper bites predominate. The coverage of snake bite envenomation in medical school curriculum is inadequate judging from the poor knowledge among health care providers. PBL is an instructional mode where \"triggers\" from a problem case is used to define learning objectives. PBL enables students to understand the relevance of underlying scientific knowledge and principles in clinical practice.  MethodsWe attempted the delivery of topic of snake bite to 100 students in Year 1 module \"Body reactions to Various Agents\" using a problem-based learning (PBL) approach. The PBL case was designed; conducted according to standard format. The students were evaluated during the first and second session according to standard format. A questionnaire on the various aspects of the case, group work and facilitator was circulated and survey was based on the Likert scale. Problem based question on the same topic was used in end of block examination to assess knowledge assimilation.  Results and conclusionThe study showed a positive response in the students attitude, perception and gain of knowledge on the topic of snake bite envenomation. Problem based learning was considered an enjoyable and well-suited model for the delivery of the topic. The paucity of student friendly and medically relevant literature in textbooks and E-resources was highlighted by the students. The student score for the PBL sessions was high while the marks scored for the problem -based question showed a significant positive association between the top-scorers of the year group and the PBQ marks (p > 0.05). The PBL method is proven to improve the affective skills in the students while the cognitive skills improvement is not enhanced.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Proteomic profiling of peripheral blood mononuclear cells reveals immune dysregulation and metabolic alterations in kidney transplant recipients with COVID-19\nAbstract: The emergence of the Coronavirus disease 2019 (COVID-19) pandemic in 2020 has profoundly impacted global health systems, particularly affecting vulnerable populations like kidney transplant recipients (KTRs).We prospectively collected blood samples from 17 PCR-confirmed COVID-19 KTR patients and 10 non-COVID-19 KTRs between May and September 2020. Using tandem mass tag-based quantitative proteomics, we characterized peripheral blood mononuclear cells (PBMCs) from KTRs alongside plasma protein biomarkers and lymphocyte counts, followed by bioinformatics analyses. Our study revealed significant proteomic alterations within PBMCs of SARS-CoV-2 infected KTRs, particularly in pathways associated with glycolysis, glucose metabolism, and neutrophil degranulation. Additionally, we observed an altered immune response marked by elevated cytokines and inflammatory mediators, coupled with decreased lymphocyte counts. Notably, patients with acute kidney injury (AKI) exhibited worse outcomes, including higher rates of ICU transfer and mechanical ventilation. Comparison of PBMC proteomic profiles between AKI and non-AKI patients highlighted distinct immune-related pathways, with AKI patients showing pronounced alterations in innate immune responses, particularly in neutrophil degranulation. Moreover, our analysis unveiled a negative correlation between T cell counts and neutrophil degranulation, suggesting potential implications for immune dysregulation in COVID-19. Our findings shed light on the complex proteomic landscape and immune responses in COVID-19-infected KTRs, emphasizing the critical need for studies focused on this population, especially in individuals with AKI. Furthermore, our observations provide valuable insights for further exploration of therapeutic interventions targeting immune dysregulation pathways in this vulnerable population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Telehealth during and beyond the COVID-19 Pandemic: Evidence from Licensed Dietitians in an Emerging Economy\nAbstract: BackgroundThe SARS-Cov-2 pandemic (COVID-19) sudden onset disrupted the direct access to face-to-face nutrition consultation fostering the rapid adoption of Telehealth by dietitians.  ObjectiveThis study investigates Telehealth use among Lebanese Licensed Dietitians (LDs) amid COVID-19, in the absence of national Telehealth practical guidelines (TPG), and offers insights on Telehealth application under uncertainties of pandemic event, economic crisis, and destructed infrastructure occurring simultaneously in Lebanon.  DesignA cross-sectional study during March 2023, using an anonymous online survey (44 questions), diffused through the Lebanese Order of Dietitians and social media platforms.  ParticipantsThe sample (n=94) consisted mostly of females (98.9%) and young dietitians (mean(SD) age: 30.54(6.41) years) having a mean(SD) of 7.89(5.7) years of experience. Most respondents identified clinical nutrition as their primary practice area (87.2%), mostly in weight management (84%).  Main outcome measuresTelehealth experience amid COVID-19 including tools utilized in remote consultations, barriers, facilitators, and perspectives of Telehealth use.  Statistical analysesDescriptive analysis (counts, frequencies) using SPSS version 28.  ResultsAlthough 48.4% of LDs reported using Telehealth prior COVID-19, this proportion increased to 97.8% during the pandemic. The most common tools used were WhatsApp (90.3%), Zoom (72.0%), and E-mails (41.9%). Reported barriers included bad internet connection (74.2%), patients preferring face-to-face consultation (61.3%), and patients lacking technical literacy (33.3%); benefits included scheduling and time flexibility (83.9%), decrease in practice-related costs (77.4%), and compliance with social distancing measures (53.8%). The majority agreed that Telehealth is needed (78.5%) and applicable in the Lebanese context (64.6%) and expressed the need for Telehealth trainings (78.5%) and TPG for nutrition care (74.2%).  ConclusionsThis study recognizes increasing use of Telehealth in Lebanon, warranting the development of Telehealth nutrition care infrastructure comprising national regulations and evidence-based practical guidelines to respond to the innovation in the healthcare industry, and to assure Telehealth sustainability in LDs routine practice.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Recommendations on surveillance for recurrence in asymptomatic patients following surgery in 16 common cancer types: a systematic review\nAbstract: ObjectivesTo identify and compare guidelines which make recommendations surveillance for the detection of recurrence for 16 common solid cancers after initial treatment with curative intent in asymptomatic patients.  DesignWe conducted a systematic review, combining search results from two electronic databases (MEDLINE, EMBASE) and one guideline organisation website (NICE), as well as using expert consultation and manual searching. Screening and data extraction were carried out by multiple reviewers. We collected data from each guideline on the recommendations for surveillance and the use of risk-stratification. Findings were compared between cancer types and regions. Text mining was used to extract statements commenting on the evidence for surveillance.  ResultsWe identified 123 guidelines across 16 cancer types. Almost all guidelines (n=115, 93.5%) recommend routine surveillance for recurrent disease in asymptomatic patients after initial treatment. Around half (n=59, 51.3%) recommend indefinite or lifelong surveillance. The most common modality of surveillance was cross-sectional imaging. Risk-stratification of the frequency, length, and mode of surveillance was widespread, with most of the guidelines (n=92, 74.8%) recommending that surveillance be adapted based on assessment of patient risk. More than a third of the included guidelines (n=50, 39.0%) provided incomplete or vague recommendations about surveillance. For fourteen of the included cancers, we found statements in the guidelines indicating that there is no evidence that surveillance improves survival.  ConclusionsAlthough specific details of follow-up schedules vary, common challenges were identified across the 16 included cancer types. These include heterogeneity between recommendations for the same cancer type, vague or non-specific recommendation and a lack of cited evidence to support use of surveillance to improve outcomes for patients. Challenges in generating evidence in this area remain, however, increased availability to linked health records may provide a way forward for researchers.  RegistrationProtocol published on PROSPERO in 2021 (ID: CRD42021289625)\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: AI-VOICE: A Method to Measure and Incorporate Patient Utilities Into AI-Informed Healthcare Workflows\nAbstract: BackgroundPatients are important participants in their medical care, yet artificial intelligence (AI) models are used to guide care with minimal patient input. This limitation is made partially worse due to a paucity of rigorous methods to measure and incorporate patient values of the tradeoffs inherent in AI applications.  This paper presents AI-VOICE (Values-Oriented Implementation and Context Evaluation), a novel method to collect patient values, or utilities, of the downstream consequences stemming from an AI models use to guide care. The results are then used to select the models risk threshold, offering a mechanism by which an algorithm can concretely reflect patient values.  MethodsThe entity being evaluated by AI-VOICE is an AI-informed workflow, which is composed of the patients health state, an action triggered by the AI model, and the benefits and harms accrued as a consequence of that action. The utilities of these workflows are measured through a survey-based, standard gamble experiment. These utilities define a patient-specific ratio of the cost of an inaccurate prediction versus the benefits of an accurate one. This ratio is mapped to the receiver-operator-characteristic curve to identify the risk threshold that reflects the patients values.  The survey instrument is made freely available to researchers through a web-based application.  ResultsA demonstration of AI-VOICE is provided using a hypothetical sepsis prediction algorithm.  ConclusionAI-VOICE offers an accessible, quantitative method to incorporate patient values into AI-informed healthcare workflows.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: End Stage Kidney Disease in Cystic Fibrosis\nAbstract: BackgroundCystic fibrosis (CF) is a multisystem autosomal recessive disease caused by mutations in the cystic fibrosis transduction regulator (CFTR). The CFTR is expressed in all renal tubular segments. Tubular functional abnormalities as well as renal histologic changes are recognized in people with cystic fibrosis (CF). Chronic kidney disease (CKD) occurs in CF at greater frequency than in the non-CF population. The prevalence and characteristics of end stage kidney disease (ESKD) in the cystic fibrosis population have not previously been described.  MethodsWe used data supplied by the US Renal Data System (USRDS) to compare persons with ESKD and CF with those with ESKD who did not have a diagnosis of CF. We used linear and logistic regression, propensity score-matched Kaplan-Meier survival curves, and log-rank tests.  ResultsThe prevalence of ESKD was approximately thirty times higher than predicted in the general US population. Diabetes was more frequently a diagnosis in people with CF, but was approximately half as frequently the primary cause of ESKD than in those without CF. Complications of transplantation, particularly of lung, were rarely the cause of ESKD in those without CF but were the second most frequent etiology of ESKD in people with CF. Drugs and medications, interstitial nephritis and acute kidney injury (AKI) were more frequent primary causes in those with CF. Hypertension, cystic kidney disease, and glomerulonephritis were less frequent in those with CF. Mortality and survival with ESKD were not significantly different between those with CF and ESKD and those with ESKD who did not have CF. Diabetes mellitus and complications of lung transplantation as the primary cause of ESKD, but not lung transplant status, were associated with significantly shorter survival with ESKD in people with CF.  ConclusionsPeople living with CF have a markedly higher prevalence of ESKD than the general United States population. The profile of primary causes of ESKD differed significantly from that of the non-CF population. Diabetes mellitus was approximately half as frequently the primary cause of ESKD in those with CF. Complications of solid organ transplant, particularly lung, were the second most frequent primary cause of ESKD in people with CF. Survival with ESKD was not significantly different between those who did and did not have CF. The diagnosis of diabetes mellitus, and complications of lung transplantation as the primary cause of ESKD, but not lung transplant status, were associated with significantly shorter survival with ESKD in people with CF. It is our aim that these findings will promote awareness of kidney disease in persons living with CF and will encourage prevention of acute kidney injury (AKI), early detection and intervention in CKD, and preemptive referral to nephrology and transplant centers.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cardiac Function Consequences of the Persistence of Acute Myocarditis Somatostatin-PET Criteria Four Months Post-Acute Phase\nAbstract: BackgroundSomatostatin-Positron Emission Tomography (PET) imaging of inflammatory cells is an effective approach for detecting Acute Myocarditis (AM), based on the Myocardial Uptake Volume (MUV) criteria of > 18 cm3. The current study further characterizes patients for whom this criterion persists at the 4-month Follow-Up (FU) from apparently uncomplicated AM.  MethodsTwenty-seven patients [median age 26.5, inter-quartile range: 21.9-31.9 years], underwent Cardiac Magnetic Resonance (CMR) and [68Ga]Ga-DOTA-TOC PET at the acute phase and 4.5 [4.2-5.0] months later. Patients with > 18 cm3 MUV (FU.PET+) at the 4-month follow-up were compared to FU.PET-patients.  ResultsAt 4 months, inflammation by CMR was only identified in two patients but in 11 patients by PET (FU.PET+ group), with 5 of these 11 patients exhibiting a baseline-to-4-months expansion in MUV. Ejection Fractions (EFs) at 4 months were generally lower in FU.PET+ than FU.PET-patients (Left Ventricular (LV).EF, 52.9 [48.6; 55.0] % vs. 56.0 [54.3; 57.8] %, p=0.001). In addition, the 5 FU.PET+ patients with expansion of the MUV had a worse LV.EF evolution (4-month follow-up minus baseline difference in LV.EF: (-5.0) [(-12.9)-(-1.0)] %) vs. + 3.1 [0.94-8.0] % for the other patients, p=0.004) and the highest plasma high-sensitivity troponin-Ic at 4-months (13.0 [7.5-22.00] ng/l vs. 3.0 [2.0-9.5] ng/l, p=0.045) suggestive of a more persistent active disease. In contrast, the evolution profile of the 6-remaining FU.PET+ patients was consistent with a longer recovery time as a consequence of a more severe initial insult (i.e. with lower LV.EF and higher MUV at baseline vs. the other patients, both p < 0.05).  ConclusionsMyocardial inflammation is detected by somatostatin-PET at 4 months from an apparently uncomplicated AM in as many as 41% of patients. It is associated with a poorer recovery of cardiac function, consistent with more persistent active disease or a more severe initial insult.  Clinical PerspectiveAlthough generally of mild severity, myocarditis may potentially involve dreaded complications such as heart failure, arrhythmia, and sudden cardiac death. We recently showed that the Somatostatin-positron emission tomography (PET) determination of inflammatory cell volume constitutes an alternative to cardiac magnetic resonance (CMR) imaging for detecting myocarditis at the acute phase. The present study shows that PET criteria of myocardial inflammation persist at four months from apparently uncomplicated myocarditis at a much higher rate than CMR (41% vs. 7% of patients). Moreover, this persistence is associated with a poorer recovery of cardiac function and is in line with two different evolution profiles--i.e., a more persistent active disease or a more severe initial insult. These new findings have the potential to improve monitoring and treatment adaptations for myocarditis patients.  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=109 SRC=\"FIGDIR/small/24314017v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (48K): org.highwire.dtl.DTLVardef@55a811org.highwire.dtl.DTLVardef@18cfb71org.highwire.dtl.DTLVardef@cfc4d1org.highwire.dtl.DTLVardef@82b247_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Severe Mitral Regurgitation in Paradoxical Low-Flow Low-Gradient Severe Aortic Stenosis\nAbstract: BackgroundPatients with paradoxical low-flow, low-gradient severe aortic stenosis (LFLGAS) exhibit low transvalvular flow rate (Q), while maintaining preserved left ventricular ejection fraction (LVEF). Concomitant severe mitral regurgitation (MR) contributes to the low flow state, adding complexity to diagnosis and management. This study aimed to examine the impact of severe MR on outcomes in paradoxical LFLGAS.  MethodsData from an institutional echo database identified 1,189 patients with adjudicated severe aortic stenosis (AVA[&le;]1.0 cm2), low transaortic gradients (mean gradient<40 mmHg), preserved LVEF ([&ge;]50%), and low flow rate (Q[&le;]210 ml/sec), to confirm paradoxical LFLGAS. Subgroups were based on MR severity (severe and non-severe). Clinical outcomes included all-cause mortality, aortic valve replacement (AVR), heart failure hospitalizations, and a composite outcome.  ResultsIn the severe MR group (n=80), patients had lower flow rates, increased LV dimensions and a more eccentric hypertrophy pattern compared to non-severe MR (n=1,109). Over a median 5-year follow-up, severe MR correlated with higher all-cause mortality (p=0.02) and AVR rates (p=0.012). After adjustment, severe MR was independently associated with increased all-cause mortality risk (HR=1.43, p=0.011) and composite outcome (HR=1.64, p<0.001). AVR significantly reduced mortality at every MR degree, with the most substantial impact in severe MR (HR=0.18, p<0.001). Propensity-adjusted models demonstrated a stronger AVR impact with increasing MR degree (p-for-interaction=0.044).  ConclusionsSevere MR in paradoxical LFLGAS is associated with adverse outcomes and distinctive LV remodeling. Aortic valve replacement improves survival across all MR grades, with greater impact in severe MR.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Artificial intelligence and omics-based autoantibody profiling highlights autoimmunity targeting ligand-receptor interaction in dementia.\nAbstract: Dementia is a neurodegenerative syndrome marked by the accumulation of disease-specific proteins and immune dysregulation, including autoimmune mechanisms involving autoantibodies. Current diagnostic methods are often invasive, time-consuming, or costly. This study explores the use of proteome-wide autoantibody screening (PWAS) for noninvasive dementia diagnosis by analyzing serum samples from Alzheimers disease (AD), dementia with Lewy bodies (DLB), and age-matched cognitively normal individuals (CNIs). Serum samples from 35 subjects were analyzed utilizing our original wet protein arrays that covers approximately 90% of human transcriptome, revealing elevated gross autoantibody levels in AD and DLB patients compared to CNIs. A total of 229 autoantibodies were differentially elevated in AD and/or DLB, effectively distinguishing between patient groups. Machine learning models showed high accuracy in classifying AD, DLB, and CNIs. Gene ontology analysis highlighted autoantibodies targeting neuroactive ligands/receptors in AD and lipid metabolism proteins in DLB. Notably, autoantibodies targeting neuropeptide B (NPB) and adhesion G protein-coupled receptor F5 (ADGRF5) showed significant correlations with clinical traits including Mini Mental State Examination scores, suggesting a role in dementia pathogenesis. The study demonstrates the potential of PWAS and AI integration as a noninvasive diagnostic tool for dementia, uncovering biomarkers that could enhance understanding of disease mechanisms. Limitations include demographic differences, small sample size, and lack of external validation. Future research should involve longitudinal observation in larger, diverse cohorts and functional studies to clarify autoantibodies roles in dementia pathogenesis and their diagnostic and therapeutic potential.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Plasma proteomics reveals the potential causal impact of extracellular matrix proteins on abdominal aortic aneurysm\nAbstract: BackgroundAbdominal aortic aneurysm (AAA) is a common and life-threatening vascular disease. Genetic studies have identified numerous associated loci, many potentially encoding plasma proteins. However, the causal effects of plasma proteins on AAA have not been thoroughly studied. We used genetic causal inference approaches to identify plasma proteins that have a potential causal impact on AAA.  MethodsCausal inference was performed using two-sample Mendelian randomization (MR). For AAA, we utilized recently published summary statistics from a multi-population genome-wide association (GWAS) meta-analysis including 39,221 individuals with, and 1,086,107 individuals without AAA from 14 cohorts. We used protein quantitative trait loci (pQTLs) identified in two large-scale plasma-proteomics studies (deCODE and UKB-PPP) to generate genetic instruments. We tested 2,783 plasma proteins for possible causal effects on AAA using two-sample MR with inverse variance weighting and common sensitivity analyses to evaluate the MR assumptions. Bayesian colocalization and gene ontology (GO) enrichment analyses provided additional insights.  ResultsMR identified 90 plasma proteins associated with AAA at FDR<0.05, with 25 supported by colocalization analysis. Among those supported by both MR and colocalization were previously experimentally validated proteins such as PCSK9 (OR 1.3; 95%CI 1.2-1.4; P<1e-10), LTBP4 (OR 3.4; 95%CI 2.6-4.6; P<1e-10) and COL6A3 (OR 0.6; 95%CI 0.5-0.7; P<1e-6). GO analysis revealed enrichment of proteins found in extracellular matrix (ECM, OR 7.8; P<1e-4), some with maximal mRNA levels in aortic tissue. Bi-directional MR suggested plasma level changes were not caused by liability to AAA itself. We then investigated whether variants responsible for expression changes in the aorta also influenced plasma levels and AAA risk. Colocalization analysis showed that an aortic expression quantitative trait locus (eQTL) for COL6A3, and a splicing quantitative trait locus (sQTL) for LTBP4 colocalized with their respective plasma pQTLs and AAA signals (posterior probabilities 0.84 and 0.89, respectively).  ConclusionsOur results highlight proteins and pathways with potential causal effects on AAA, providing a foundation for future functional experiments. These findings suggest a possible causal pathway whereby genetic variation affecting ECM proteins expressed in the aortic wall cause their levels to change in blood plasma, influencing development of AAA.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: SARS-CoV-2, the human placenta, and adverse perinatal outcomes\nAbstract: The relationship among timing and severity of COVID-19 during pregnancy, placental pathology, and adverse pregnancy outcomes is not well understood. We conducted a prospective cohort study of 497 pregnant patients with COVID-19 whose placentas underwent systematic pathologic examination. The main exposure was timing of COVID-19 during pregnancy (first or second versus third trimester). The primary outcome was composite placental pathology that included high grade maternal vascular malperfusion or greater than 25 percent perivillous fibrin deposition. There were 63 patients who had the composite placental pathology outcome. In adjusted analyses that controlled for maternal age, parity, active infection at delivery, interval from time of diagnosis to delivery and COVID-19 variant, timing of COVID-19 during pregnancy was not associated with risk of the composite placental pathology outcome. Among secondary COVID-19 related exposures we investigated, severity of disease and treatment for COVID-19 were associated with risk of the composite placental pathology outcome. In addition, patients with COVID-19 in the first nine months of the pandemic had the highest rate of the composite placental pathology outcome. In this large cohort, placental vascular pathology was common among COVID-19 cases but was unrelated to timing of COVID-19 during pregnancy or adverse pregnancy outcomes. These findings suggest that uncomplicated COVID-19 during pregnancy does not require intensive fetal surveillance or detailed pathologic examination of the placenta after delivery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Signals reported to Rucaparib: An Updated Comprehensive Disproportionality Analysis Using FDA Adverse Event Reporting System\nAbstract: Ovarian cancer currently ranks as the fourth most common cancer. This cancer is metastatic in nature and making it more challenging to manage. Prostate cancer is the one of the major causes of disease and death among men. Approximately 1.6 million men are diagnosed with prostate cancer. Rucaparib, a poly-ADP ribose polymerase inhibitor has been approved by United States Food and Drug Administration for management of ovarian cancer and prostate cancer. Rucaparib was approved by US Food and Drug Administration in the year 2016 for the treatment of ovarian cancer and 2020 for the treatment of prostate cancer. To assess the potential association between rucaparib and the identified signals, a disproportionality analysis of spontaneous reports is being conducted. Reports were taken from FAERS data base and retrospective case/non case study was conducted. Reporting Odds ratio (ROR), Relative Reporting Ratio (RRR), Chi Squared Value ({chi}2) and Proportional Reporting Ratio (PRR) and Drug Event (DE) were used to perform disproportionality analysis. 144 signals were considered as positive adverse drug reactions using the criteria {chi}2 >4, PRR >2, ROR >2 and DE [&ge;] 3. Through disproportionality analysis of the FAERS data, signal was identified between the signals-increased prostate specific antigen, decreased serum magnesium levels, decreased glomerular filtration rates, blood iron decreased and vitamin d decreased and rucaparib. The current investigation indicated that rucaparib may increase the incidence of the identified signals.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Risk for Alcohol Use Disorder in Relation to Individual Symptom Criteria: Do Polygenic Indices Provide Unique Information for Understanding Severity and Heterogeneity?\nAbstract: Alcohol Use Disorder (AUD) is a heterogenous category with many unique configurations of symptoms. Previous investigations of AUD heterogeneity using molecular genetics methods studied the association between genetic liability and individual AUD symptoms at the latent level or focusing on a small number of genetic variants. Notably, these studies did not investigate potential severity differences between symptoms in their genetic analyses. Therefore, the current study aimed to examine the genetic risk for individual AUD symptom criteria by using a polygenic risk score (PRS) approach to assess the relative severity of each AUD symptom and test for associates with AUD symptoms above and beyond a unidimensional AUD construct. An AUD PRS was created using summary statistics obtained from published genome-wide association studies (GWAS), and Multiple Indicators Multiple Causes (MIMIC) models were employed to examine the effect of the PRS on overall AUD severity as well as on individual symptoms after accounting for this overall effect. The phenotypic severity of AUD symptoms was highly correlated with the genetic severity of AUD symptoms (r = 0.78). Results of MIMIC models indicated that the AUD PRS significantly predicted the AUD factor. Regression paths testing the unique, direct effects of the PRS on individual AUD symptoms, independent of the latent AUD factor, were not significant. These results imply that PRSs derived from GWAS of AUD influence symptom expression through a single genetic factor that is highly correlated with the relative severity of individual symptoms when measured at the phenotypic level. Item-level GWAS of AUD symptoms are needed to further parse heterogeneous symptom expression and allow for more nuanced tests of these conclusions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of 10-valent pneumococcal conjugate vaccine on the epidemiology of otitis media with otorrhea among Bangladeshi children\nAbstract: In 2015, Bangladesh introduced the ten-valent pneumococcal conjugate vaccine (PCV10). This study evaluates the impact of PCV10 on pneumococcal otitis media (OM), a prevalent middle ear infection amongst children in low-and-middle income countries, including Bangladesh. We analyzed ear swabs from OM cases with otorrhea collected at the largest pediatric hospital in Dhaka, Bangladesh from April 2014 to March 2019. The study involved identifying pathogens and conducting pneumococcal serotyping using the Quellung reaction. Four years post PCV10 introduction, the rate of detection of pneumococcus among otorrhea cases decreased from 18.4% (164/892) in 2014-15 to 15.6% (581/3735) in 2018-19, reflecting a 15.4% reduction. Notably, vaccine serotypes (VTs) demonstrated a significant decline throughout the post-PCV years, with a 44.1% reduction compared to the pre-PCV period. Specific VTs like 14, 6B and 19F exhibited significant reductions of 60.2% , 57.5% and 42.9%, respectively. Conversely, non-vaccine serotypes (NVTs) showed non-significant increase of 8.6%; 35B showed a 70.1% increase. Administration of two or three doses of PCV10 provided 84.4% protection against OM cases caused by serotypes covered by PCV10. This is the first report from South Asia assessing PCV's impact on pneumococcal OM. It demonstrates a 15.4% reduction in pneumococcal isolation over four years and over 80% efficacy of PCV10 in preventing vaccine type pneumococcal OM cases. While some vaccine serotypes decreased significantly, the impact of PCV10 on overall pneumococcal OM cases was dampened by increasing isolation of non-vaccine serotypes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of 10-valent pneumococcal conjugate vaccine on the epidemiology of otitis media with otorrhea among Bangladeshi children\nAbstract: In 2015, Bangladesh introduced the ten-valent pneumococcal conjugate vaccine (PCV10). This study evaluates the impact of PCV10 on pneumococcal otitis media (OM), a prevalent middle ear infection amongst children in low-and-middle income countries, including Bangladesh. We analyzed ear swabs from OM cases with otorrhea collected at the largest pediatric hospital in Dhaka, Bangladesh from April 2014 to March 2019. The study involved identifying pathogens and conducting pneumococcal serotyping using the Quellung reaction. Four years post PCV10 introduction, the rate of detection of pneumococcus among otorrhea cases decreased from 18.4% (164/892) in 2014-15 to 15.6% (581/3735) in 2018-19, reflecting a 15.4% reduction. Notably, vaccine serotypes (VTs) demonstrated a significant decline throughout the post-PCV years, with a 44.1% reduction compared to the pre-PCV period. Specific VTs like 14, 6B and 19F exhibited significant reductions of 60.2% , 57.5% and 42.9%, respectively. Conversely, non-vaccine serotypes (NVTs) showed non-significant increase of 8.6%; 35B showed a 70.1% increase. Administration of two or three doses of PCV10 provided 84.4% protection against OM cases caused by serotypes covered by PCV10. This is the first report from South Asia assessing PCV's impact on pneumococcal OM. It demonstrates a 15.4% reduction in pneumococcal isolation over four years and over 80% efficacy of PCV10 in preventing vaccine type pneumococcal OM cases. While some vaccine serotypes decreased significantly, the impact of PCV10 on overall pneumococcal OM cases was dampened by increasing isolation of non-vaccine serotypes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of 10-valent pneumococcal conjugate vaccine on the epidemiology of otitis media with otorrhea among Bangladeshi children\nAbstract: In 2015, Bangladesh introduced the ten-valent pneumococcal conjugate vaccine (PCV10). This study evaluates the impact of PCV10 on pneumococcal otitis media (OM), a prevalent middle ear infection amongst children in low-and-middle income countries, including Bangladesh. We analyzed ear swabs from OM cases with otorrhea collected at the largest pediatric hospital in Dhaka, Bangladesh from April 2014 to March 2019. The study involved identifying pathogens and conducting pneumococcal serotyping using the Quellung reaction. Four years post PCV10 introduction, the rate of detection of pneumococcus among otorrhea cases decreased from 18.4% (164/892) in 2014-15 to 15.6% (581/3735) in 2018-19, reflecting a 15.4% reduction. Notably, vaccine serotypes (VTs) demonstrated a significant decline throughout the post-PCV years, with a 44.1% reduction compared to the pre-PCV period. Specific VTs like 14, 6B and 19F exhibited significant reductions of 60.2% , 57.5% and 42.9%, respectively. Conversely, non-vaccine serotypes (NVTs) showed non-significant increase of 8.6%; 35B showed a 70.1% increase. Administration of two or three doses of PCV10 provided 84.4% protection against OM cases caused by serotypes covered by PCV10. This is the first report from South Asia assessing PCV's impact on pneumococcal OM. It demonstrates a 15.4% reduction in pneumococcal isolation over four years and over 80% efficacy of PCV10 in preventing vaccine type pneumococcal OM cases. While some vaccine serotypes decreased significantly, the impact of PCV10 on overall pneumococcal OM cases was dampened by increasing isolation of non-vaccine serotypes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Effect of Firearm Laws on Pediatric Mortality in the United States\nAbstract: IntroductionFirearms are the leading cause of death in US children and adolescents, but little is known about whether legal policies may be responsible.  MethodsWe conducted difference-in-differences analysis on CDC WONDER data before and after McDonald v. Chicago, the landmark 2010 Supreme Court decision on firearms regulation. States were divided into three groups, based on legal actions taken before and since 2010, most permissive, permissive, and restricted. Firearm mortality trends before (1999-2010) and after (2010-2023) were determined and compared across the three groups for all intents and by intent (homicide and suicide). Within the most permissive state grouping, pediatric firearm mortality by 2013 urbanicity and by observed race and ethnicity were conducted. For each US state, pre-and- post 2010 all-intent pediatric firearm mortality incident rates were compared.  ResultsThere were 7130 excess pediatric firearms deaths in states with more permissive regulatory regimes than those with stricter frameworks, as well as higher rates of homicide and suicide. Non-Hispanic Black populations were disproportionately affected by these trends. Four states (California, Maryland, New York, and Rhode Island) had decreased pediatric firearm mortality after 2010, all of which were in the restrictive firearms law group.  ConclusionStates with more permissive firearm laws have experienced greater pediatric firearm mortality during the post-McDonald v. Chicago era.  KEY POINTS  QuestionDid states enacting permissive firearm laws after 2010--when McDonald v. Chicago was decided by the United States Supreme Court--subsequently experience higher rates of pediatric firearm mortality?  FindingsDifference-in-difference analysis found that state groups that enacted more permissive firearm laws after 2010 experienced >7,100 firearm deaths in children and adolescents ages 0-17 between 2010-2023 compared to restrictive law-enacting states, of which most (77.5%) were homicides. In the permissive states groups, increases occurred in all urbanicities. The largest increase occurred in non-Hispanic Black children and adolescents. Four states had statistical decreases in pediatric firearm mortality during the study period, all of which were in states which enacted restrictive firearm policies.  MeaningPermissive firearm laws contributed thousands of excess firearm deaths among children living in states with permissive policies. Future work should focus on determining which types of laws conferred the most harm and which the most protection.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: This is a quiz Premise Input: A Key to Unlocking Higher Diagnostic Accuracy in Large Language Models\nAbstract: PurposeLarge language models (LLMs) are neural network models trained on vast amounts of textual data, showing promising performance in various fields. In radiology, studies have demonstrated the strong performance of LLMs in diagnostic imaging quiz cases. However, the inherent differences of prior probabilities of a final diagnosis between clinical and quiz cases pose challenges for LLMs, as LLMs had not been informed about the quiz nature in previous literature, while human physicians can optimize the diagnosis, consciously or unconsciously, depending on the situation. The present study aimed to test the hypothesis that notifying LLMs about the quiz nature might improve diagnostic accuracy.  MethodsOne-hundred-and-fifty consecutive cases from the \"Case of the Week\" radiological diagnostic quiz case series on the American Journal of Neuroradiology website were analyzed. GPT-4o and Claude 3.5 Sonnet were used to generate top three differential diagnoses based on the textual clinical history and figure legends. The prompts included or excluded information about the quiz nature for both models. Two radiologists evaluated the accuracy of the diagnoses. McNemars test assessed differences in correct response rates.  ResultsInforming the quiz nature improved the diagnostic performance of both models. Specifically, Claude 3.5 Sonnets primary diagnosis and GPT-4os top 3 differential diagnoses significantly improved when the quiz nature was informed.  ConclusionInforming the quiz nature of cases significantly enhances LLMs diagnostic performances. This insight into LLMs capabilities could inform future research and applications, highlighting the importance of context in optimizing LLM-based diagnostics.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: AUGMENT: a framework for robust assessment of the clinical utility of segmentation algorithms\nAbstract: BackgroundEvaluating AI-based segmentation models primarily relies on quantitative metrics, but it remains unclear if this approach leads to practical, clinically applicable tools.  PurposeTo create a systematic framework for evaluating the performance of segmentation models using clinically relevant criteria.  Materials and MethodsWe developed the AUGMENT framework (Assessing Utility of seGMENtation Tools), based on a structured classification of main categories of error in segmentation tasks. To evaluate the framework, we assembled a team of 20 clinicians covering a broad range of radiological expertise and analysed the challenging task of segmenting metastatic ovarian cancer using AI. We used three evaluation methods: (i) Dice Similarity Coefficient (DSC), (ii) visual Turing test, assessing 429 segmented disease-sites on 80 CT scans from the Cancer Imaging Atlas), and (iii) AUGMENT framework, where 3 radiologists and the AI-model created segmentations of 784 separate disease sites on 27 CT scans from a multi-institution dataset.  ResultsThe AI model had modest technical performance (DSC=72{+/-}19 for the pelvic and ovarian disease, and 64{+/-}24 for omental disease), and it failed the visual Turing test. However, the AUGMENT framework revealed that (i) the AI model produced segmentations of the same quality as radiologists (p=.46), and (ii) it enabled radiologists to produce human+AI collaborative segmentations of significantly higher quality (p=<.001) and in significantly less time (p=<.001).  ConclusionQuantitative performance metrics of segmentation algorithms can mask their clinical utility. The AUGMENT framework enables the systematic identification of clinically usable AI-models and highlights the importance of assessing the interaction between AI tools and radiologists.  Summary statementOur framework, called AUGMENT, provides an objective assessment of the clinical utility of segmentation algorithms based on well-established error categories.  Key resultsO_LICombining quantitative metrics with qualitative information on performance from domain experts whose work is impacted by an algorithms use is a more accurate, transparent and trustworthy way of appraising an algorithm than using quantitative metrics alone. C_LIO_LIThe AUGMENT framework captures clinical utility in terms of segmentation quality and human+AI complementarity even in algorithms with modest technical segmentation performance. C_LIO_LIAUGMENT might have utility during the development and validation process, including in segmentation challenges, for those seeking clinical translation, and to audit model performance after integration into clinical practice. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Severity of lumbar spinal stenosis does not impact responsiveness to exercise-based rehabilitation\nAbstract: Spine pain is a prevalent and costly condition affecting up to 85% of individuals throughout their lifetime, and spinal stenosis is one of the most debilitating sources of spine pain. Although conservative management is the first line of treatment for spinal stenosis, severe cases often are directly referred to surgical intervention due to the belief that conservative strategies delay necessary treatment. However, there are no studies supporting the premise that individuals with more severe stenosis respond poorly to conservative management. The purpose of this study was to compare improvements in pain, disability, strength, medication usage, and patient goals in response to an exercise-based physical therapy program across 1,806 individuals with mild, moderate, or severe lumbar spine stenosis. Participants demonstrated significant improvements in all variables of interest (p<0.001), and 11.5% of participants reported cessation of narcotic use with treatment. There were no significant differences in treatment response across mild, moderate, or severe stenosis groups for any outcome (p>0.546). Exercise-based rehabilitation is as beneficial in the short term for individuals presenting for nonoperative care with severe stenosis compared to their milder counterparts. Future research is needed to evaluate long term durability and cost effectiveness of rehabilitation in this patient population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Physical therapy in patients with Parkinson's disease treated with Deep Brain Stimulation: a Delphi panel study\nAbstract: Although deep brain stimulation of the subthalamic nucleus (STN-DBS) induces motor benefits in people with Parkinsons disease (PwPD), the size and duration of the effects of STN-DBS on motor axial (e.g., postural instability, trunk posture alterations) and gait impairments (e.g., freezing of gait - FOG) are still ambiguous. Physical therapy (PT) effectively complements pharmacological treatment to improve postural stability, gait performance, and other dopamine-resistant symptoms (e.g. festination, hesitation, axial motor dysfunctions, and FOG) in PwPD who are non-surgically treated. Despite the potential for positive adjuvant effects of PT following STN-DBS surgery, there is a paucity of science available on the topic. In such a scenario, gathering the opinion and expertise of leading investigators worldwide was pursued to study motor rehabilitation in PwPD following STN-DBS. After summarizing the few available findings through a systematic review, we identified clinical and academically experienced DBS clinicians (n=21) to discuss the challenges related to PT following STN-DBS. A 5-point Likert scale questionnaire was used and based on the results of the systematic review along with a Delphi method. Thirty-nine questions were submitted to the panel - half related to general considerations on PT following STN-DBS, half related to PT treatments. Despite the low-to-moderate quality, the few available rehabilitative studies suggested that PT could improve dynamic and static balance, gait performance and posture. Similarly, panellists strongly agreed that PT might help in improving motor symptoms and quality of life, and it may be possibly prescribed to maximize the effects of the stimulation. The experts agreed that physical therapists could be part of the multidisciplinary team taking care of the patients. Also, they agreed on prescribing of conventional PT, but not massage or manual therapy. Our results will inform the rehabilitation and the DBS community to engage, publish and deepen this area of research. Such efforts may spark guidelines for PT following STN-DBS.  GRAPHICAL ABSTRACT  O_FIG O_LINKSMALLFIG WIDTH=179 HEIGHT=200 SRC=\"FIGDIR/small/24314037v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (35K): org.highwire.dtl.DTLVardef@1b99b3eorg.highwire.dtl.DTLVardef@7f0c89org.highwire.dtl.DTLVardef@1100f3eorg.highwire.dtl.DTLVardef@158e348_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Analysis of IL-4 Levels, IL-1a, Cortisol Hormone, and Blood Cell Number in Parkinsons Disease Patients Undergoing Dance-based Movement Therapy: A Preliminary Study.\nAbstract: IntroductionThe interplay between neuroinflammation and Parkinsons disease (PD) is still unclear, although several studies suggest that neuroinflammation plays an important role in the pathophysiological pathways of neurodegenerative disorders. Dance-based movement therapy has been studied as an adjuvant treatment for PD symptoms by modulating some inflammatory interleukins and improving the overall effect of pharmacological treatments.  ObjectiveTo evaluate the levels of Interleukin 4, Interleukin 1, cortisol hormone, and blood cell total numbers in PD subjects undergoing dance-based movement therapy.  MethodsTwenty-five participants were selected for this study. Seventeen subjects diagnosed with PD were divided into two groups: PD group (n=8) and PD+dance group (n=9). Another group was composed of age-matched healthy controls (n=8). The dance-based movement therapy was performed twice a week for 50-60 minutes/session over six months.  ResultsThe serum IL-4 levels were significantly lower in the PD group when compared to the healthy group, while the PD+Dance group showed similar levels to the healthy group. The levels of IL-1, cortisol, and blood cell count showed no statistical differences between groups.  ConclusionOur results suggest that regular practice of dance-based movement therapy may induce a neuroprotective effect by modulating the levels of IL-4 in people with PD similarly to healthy participants.  Trial registrationThe study was registered in the Brazilian registry of clinical trials: RBR-3bhbrb5.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diagnostic Utility of Electrophysiological Markers for Early and Differential Diagnosis of Alzheimers, Frontotemporal, and Lewy Body Dementias: A Systematic Review\nAbstract: BackgroundAn early and accurate diagnosis is crucial to provide optimal patient care in neurodegenerative diseases. Although an EEG shows advantages in availability and cost compared to the current diagnostic tools, it is not routinely used in clinical practice. Previous reviews have either focused on single disease populations and/or solely on resting state EEG. To evaluate the utility of EEG for early diagnosis and differential diagnosis, we conducted a systematic review across Alzheimers disease (AD), Frontotemporal Dementia (FTD) and Lewy Body Dementia (DLB).  MethodsWe searched databases Pubmed, Cochrane, Web of Science, and Scopus for articles published from 2000 to 2023 investigating resting-state and task-based EEG-markers in biomarker-proven AD, FTD and DLB.  ResultsOur search yielded a total of 12010 studies, of which 71 papers were eligible: 34 on AD, 18 on DLB and 9 on FTD. Slowing of the frequency spectrum was a common observation across diseases, achieving excellent sensitivity in AD and DLB. Research on FTD was limited and with varying results in the discrimination from healthy controls, although connectivity analysis and microstates are promising avenues. In differential diagnosis, both spectral and connectivity metrics show encouraging results. Task-based EEG emerges as a promising tool in early AD.  ConclusionEEG shows promise as a cost-effective, non-invasive tool for early detection and differential diagnosis. Future research should aim to collect standardized data from multicentric cohorts, across multiple diseases and stages, and explore the neural underpinnings of these diseases, to improve interpretability of the findings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Thiamine pyrophosphokinase-1 deficiency in neurons drives Alzheimer's multiple pathophysiological alterations\nAbstract: BackgroundThe mechanism driving multiple pathophysiological alterations in Alzheimers disease (AD) remains unclear. Thiamine deficiency, a well-known feature of AD, may contribute to these alterations.  MethodsThe expressions of four known genes associated with thiamine metabolism were studied in brain samples from patients with AD and other neurodegenerative disorders. The results were further demonstrated in AD and diabetic mouse and cellular models. The phenotypes of mice with conditional Thiamine pyrophosphokinase-1 (Tpk) knockout in brain excitatory neurons were investigated. The therapeutic effects of thiamine diphosphate supplement and Tpk delivery on cellular and mouse models were explored. Phase 2 clinical trial of benfotiamine, a thiamine derivative, plus donepezil was performed.  ResultsOnly TPK expression was inhibited in brain samples of AD patients, while none of thiamine-associated genes were significantly changed in other neurodegenerative disorders. TPK inhibition in the brains and neurons was verified in AD and diabetic mouse and cellular models. Mice with Tpk deletion in neurons exhibited all major pathophysiological alterations of AD, including amyloid deposition, Tau hyperphosphorylation, and brain atrophy. TPK expression restoration and thiamine diphosphate supplement ameliorated the pathophysiological and behavioral phenotypes in mouse and cell models with Tpk insufficiency. Benfotiamine delayed cognitive decline in mild-to-moderate AD patients with a dose-effect relationship, particularly with a significant attenuation of the deterioration in moderate AD patients by post hoc analysis.  ConclusionsTPK deficiency and hence thiamine diphosphate reduction in neurons are a decisive factor driving multiple pathophysiologic alterations of AD, unveiling a new direction for the disease mechanism and treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterization of Clinical MRI Findings in Moderately-Late Preterm Infants Diagnosed with Cerebral Palsy: A Single Center Retrospective Study\nAbstract: I.Cerebral Palsy is the most common movement disorder in childhood and is commonly associated with brain injury and prematurity. At least 10% of patients have a normal brain MRI and current practices suggest genetic testing may be indicated for those patients. However, given that prematurity itself is a risk factor for CP, which MRI patterns are present in premature infants and which genetic causes are present remains unclear. In the present study, a cohort of moderate-late preterm infants born between 32 and 34 weeks gestational age was analyzed to determine whether CP disease severity, comorbid conditions, and genetic testing are associated with particular MRI findings. We identified that comorbid conditions and CP severity are similar across imaging patterns regardless of the perceived severity of the imaging findings. Genetic diagnoses were identified in 13% of all patients. In patients with MRI concerning for injuries, over 20% had genetic testing sent. Abnormal MRI findings in moderate-late preterm infants with CP are common, but are not a strong predictor of disease severity and may be associated with underlying genetic causes that are underdiagnosed due to unclear practice guidelines.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pelvic Stability During Total Hip Arthroplasty: A Comparison of Traction and Standard Surgical Tables Using Augmented Reality Navigation\nAbstract: BackgroundTotal hip arthroplasty enhances quality of life by improving joint function. However, the success of this procedure heavily relies on precise acetabular cup positioning, which is insufficient using traditional placement guidelines. This insufficiency is evidenced by the persistent occurrence of dislocations, highlighting the critical need for enhanced pelvic alignment accuracy. Standard surgical tables present challenges in maintaining consistent pelvic positioning during the procedure, making it difficult to achieve optimal alignment.  PurposeThis study aimed to evaluate the effectiveness of a traction surgical table in stabilizing pelvic movements during total hip arthroplasty and compare it with the use of a standard surgical table.  MethodsThis retrospective study assessed 88 total hip arthroplasties performed using the AR-HIP (Zimmer Biomet Japan, Tokyo, Japan) system for real-time pelvic navigation. Procedures were performed using either a standard surgical table (n=48) or a traction surgical table (n=40). Pelvic alignment was monitored at multiple surgical stages, and stability was statistically analyzed to compare the efficacy of the two table types.  ResultsThe traction table significantly stabilized anteroposterior pelvic movements across all critical surgical stages (p<0.05), except during anterior capsular release. In contrast, procedures performed on the standard table exhibited less stability in anteroposterior pelvic movements, suggesting the superior performance of the traction table.  ConclusionsCompared with the standard table, the use of the traction table in total hip arthroplasty effectively controls anteroposterior pelvic movements and improves acetabular cup alignment. However, lateral pelvic stability remains uncontrolled using both table types, indicating a need for further technological advancements in surgical practice to improve the outcomes of total hip arthroplasty.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genome-wide Association Study of Social Isolation in 63 497 Japanese Individuals from the General Population\nAbstract: Social isolation, characterized by a lack of social connections with family, friends, and others, is associated with adverse health outcomes. However, the genetic contribution to the susceptibility to social isolation remains unclear. This study aimed to identify genetic loci associated with social isolation using the Lubben Social Network Scale (LSNS-6) in a Japanese population. The Tohoku Medical Megabank Community-Based Cohort Study was conducted between 2013 and 2016. The participants were genotyped using the Affymetrix Axiom Japonica Array. The LSNS-6 was used to assess familial and friend ties through six questions and social isolation statuses were defined as total scale, family subscale, and friend subscale. Genome-wide association studies (GWASs) were conducted using a generalized linear mixed model, adjusting for age, sex, and 10 genetic principal components. In total, 63 497 participants who completed genotyping and the LSNS-6 were included. The mean age was 59.4{+/-}11.9 years, and 41 126 (64.8%) were female. Significant genetic loci were identified in GWASs for the total scale (rs10736933 near ACADSB and HMX3) and friend subscale of LSNS-6 (rs1778366 near LINC02315 and LRFN5). This study provides the first genome-wide evidence of social isolation in the Japanese population, suggesting associations with ACADSB, HMX3, LINC02315, and LRFN5. These findings could enable personalized prevention and intervention for social isolation and related psychiatric disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: 3-Year Outcomes of Mitral Valve-in-Valve Therapy Using Balloon Expandable Transcatheter Valves in the United States\nAbstract: BackgroundMitral valve-in-valve (MViV) is a safe and effective therapy for severe bioprosthetic mitral degeneration associated with high one-year survival rates. Longer-term survival and reintervention rates are not well defined.  MethodsRetrospective analysis of patients undergoing transseptal MViV with SAPIEN 3 valve family for failed surgical bioprostheses from June 2015 to March 2024 in the Transcatheter Valve Therapy Registry with Centers for Medicare and Medicaid Services data linkage was performed. The primary outcomes were all-cause mortality, stroke, and reintervention. Kaplan Meier and Cox proportional hazards analysis of outcomes was performed according to Society of Thoracic Surgeons (STS) score and procedure status.  Results5,971 patients (72.9 {+/-} 11.4 years, 57.9% female) underwent MViV. Low (<4), intermediate (4-8), and high (>8) STS scores were present in 1310 (23.5%), 1960 (35.1%) and 2315 (41.5%) patients, respectively. 30-day mortality occurred in 0.9% of patients with low STS scores; 2.7%, intermediate; and 7.0%, high (p<0.001). Predicted mortality at 3 years was proportional to STS score at 15.8%, 23.3%, and 44.5% (p<0.001 for all comparisons). Stroke rates at 3 years were comparable except between low and high STS groups (7.6% vs. 11.4%, p=0.002). Mitral valve reintervention during 3 years of follow-up was similarly uncommon in all groups at 3.8, 3.0, and 2.8% (p=0.71), respectively. Elective procedures were associated with lower 3-year mortality compared to non-elective procedures (HR 0.51, [95% CI: 0.45, 0.58], p<0.001). Strongest predictors of 3-year mortality included current hemodialysis, cardiogenic shock on presentation, and immunocompromised state.  ConclusionThree-year survival after MViV is favorable in low and intermediate STS scores and elective procedures, whereas survival was significantly lower in high STS scores and non-elective procedures. These findings emphasize the importance of early identification and treatment of patients who may benefit from MViV. Reintervention rates at 3 years are low regardless of STS score.  Clinical PerspectivesO_ST_ABSWhat is new?C_ST_ABSO_LIThree-year survival after transseptal mitral valve-in-valve (MViV) is favorable in patients with low and intermediate Society of Thoracic Surgeons (STS) risk scores C_LIO_LIHigh STS risk score and non-elective procedure status are associated with higher 3-year mortality C_LIO_LIReintervention rates after MViV are low at 3 years regardless of STS score C_LI  What are the clinical implications?O_LIMViV is an effective therapy associated with favorable mid-term outcomes in carefully selected patients C_LIO_LIStrategies to treat patients before advanced comorbidities develop are needed to optimize longer-term outcomes following MViV C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diastolic dysfunction in aortic stenosis is associated with greater damping of left ventricular recoil, and not myocardial stiffness.\nAbstract: BackgroundAortic stenosis (AS) is associated with increasing severity of diastolic dysfunction as measured by conventional echocardiographic grading. The parameterized diastolic filling (PDF) method can describe diastolic function mechanistically, by analyzing filling using the physics of classical mechanics for spring recoil.  PurposeTo use the PDF method to describe the mechanics of how diastolic dysfunction manifests in AS.  MethodsPatients (n=73) undergoing echocardiography were included according to AS of varying severity (normal/mild AS: maximum Doppler velocity across aortic valve (Vmax) <3.0 m/s, moderate/severe AS: Vmax[&ge;]3.0 m/s). Analysis of pulsed wave Doppler transmitral E-waves was performed using freely available software for PDF analysis.  ResultsCompared to normal/mild AS (n=41), patients with moderate/severe AS (n=32) had a left ventricle with a greater interventricular septal thickness (p=0.02) and higher E/e (p=0.007), but similar left ventricular ejection fraction (p=0.10) and left atrial volume index (p=0.21). PDF analysis (48{+/-}9 E-waves per patient) showed that moderate/severe AS did not differ in myocardial stiffness (p=0.70), but had a higher myocardial viscoelasticity (p=0.02), higher load (p=0.04), longer derived time constant of isovolumetric pressure decay (tau, p=0.004), higher filling energy (p=0.02), higher peak driving (p=0.02) and resistive (p=0.004) force of filling, lower kinematic filling efficiency index (p<0.001), but no difference in the load-independent index of diastolic function (p=0.62).  ConclusionsAS was primarily associated with a greater damping of LV recoil (viscoelasticity) and load, but without a change in myocardial stiffness. Diastolic dysfunction in AS manifests with pathophysiological changes that are mechanistically consistent with a greater severity of diastolic dysfunction.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diastolic dysfunction in aortic stenosis is associated with greater damping of left ventricular recoil, and not myocardial stiffness.\nAbstract: BackgroundAortic stenosis (AS) is associated with increasing severity of diastolic dysfunction as measured by conventional echocardiographic grading. The parameterized diastolic filling (PDF) method can describe diastolic function mechanistically, by analyzing filling using the physics of classical mechanics for spring recoil.  PurposeTo use the PDF method to describe the mechanics of how diastolic dysfunction manifests in AS.  MethodsPatients (n=73) undergoing echocardiography were included according to AS of varying severity (normal/mild AS: maximum Doppler velocity across aortic valve (Vmax) <3.0 m/s, moderate/severe AS: Vmax[&ge;]3.0 m/s). Analysis of pulsed wave Doppler transmitral E-waves was performed using freely available software for PDF analysis.  ResultsCompared to normal/mild AS (n=41), patients with moderate/severe AS (n=32) had a left ventricle with a greater interventricular septal thickness (p=0.02) and higher E/e (p=0.007), but similar left ventricular ejection fraction (p=0.10) and left atrial volume index (p=0.21). PDF analysis (48{+/-}9 E-waves per patient) showed that moderate/severe AS did not differ in myocardial stiffness (p=0.70), but had a higher myocardial viscoelasticity (p=0.02), higher load (p=0.04), longer derived time constant of isovolumetric pressure decay (tau, p=0.004), higher filling energy (p=0.02), higher peak driving (p=0.02) and resistive (p=0.004) force of filling, lower kinematic filling efficiency index (p<0.001), but no difference in the load-independent index of diastolic function (p=0.62).  ConclusionsAS was primarily associated with a greater damping of LV recoil (viscoelasticity) and load, but without a change in myocardial stiffness. Diastolic dysfunction in AS manifests with pathophysiological changes that are mechanistically consistent with a greater severity of diastolic dysfunction.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association between Neonatal Necrotizing Enterocolitis and Neurodevelopmental Outcomes: A Comprehensive Systematic Review and Meta-Analysis\nAbstract: Preterm infants are at high risk for systemic inflammatory disorders, including sepsis, meningitis, bronchopulmonary dysplasia, and necrotizing enterocolitis (NEC). The developing brain of the premature newborn is especially susceptible to the cascade of inflammatory mediators elaborated in these conditions that cross the blood-brain barrier. NEC, a severe and potentially fatal condition of the gut that occurs in premature newborns, is a prime example of how an inflammatory reaction, perhaps initially localized, can become generalized and cause systemic harm. One such result is brain injury, especially to the cerebral white matter, which may lead to neurodevelopmental abnormality and dysregulated behavior. Numerous studies have documented an association between necrotizing enterocolitis and neurodevelopmental impairment (NDI), but to date, the brain and behavioral deficits associated with neonatal NEC are not fully understood. We performed a comprehensive systematic review and meta-analysis of existing literature to characterize brain injury and behavioral alterations associated with NEC. 7153 peer-reviewed published manuscripts were screened by two independent reviewers and evidence quality was assessed using GRADE criteria. Of these papers, 62 satisfied the criteria for our review (i.e., no case reports, meta-analyses, systematic reviews, or animal studies). Data from 32 papers using Bayley Scales of Infant and Toddler Development to assess infant outcomes were included in the meta-analysis. Our findings support neonatal necrotizing enterocolitis having deleterious effects on brain and behavioral development and impact on cognitive function, risk of cerebral palsy and motor impairment, educational achievement, behavior, and neuroanatomy. We discuss herein findings of both short-term outcomes (1-3 years) and long-term outcomes (until 13 years). Our meta-analysis also indicates that NEC has a moderate effect size on infant development, with consistent impairment across mental, cognitive, language and motor domains.  WHAT DO THE FINDINGS OF THIS REVIEW MEAN?In this review, we describe several short-term and long-term neurodevelopmental outcomes of preterm infants with NEC. These findings suggest that infants with NEC should be monitored with close developmental follow-up so that individuals can receive appropriate testing that may prompt therapies and qualify them to receive early intervention services.  HOW UP TO DATE IS THIS REVIEW?The review authors searched for studies published up to 2021. Abstracts with no data available were excluded, so this review does not consider any new findings published from 2022-2024.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Postpartum Depression During the COVID-19 Pandemic and Associated Factors: A Cross-Sectional Study\nAbstract: ObjectiveTo study the prevalence of maternal depressive symptoms in the immediate postpartum period ([&le;] 7 days postpartum) during the COVID-19 pandemic and to identify associated factors.  MethodsWe performed a cross-sectional analytical study. The study population consisted of postpartum women >18 years old enrolled at the Municipal University Hospital of Sao Bernardo do Campo. The Edinburgh Postnatal Depression Scale and a questionnaire on sociodemographic characteristics and clinical history were administered to 90 patients in the first week of the immediate postpartum period between June and December 2021.  ResultsAn Edinburgh Postnatal Depression Scale score > 10 was observed in 39 (43.3%) of the postpartum women. From a multivariate analysis, the factors associated with a score > 10 on the scale were: \"having no belief/spirituality\" with 83% (95% CI 1.20-2.81, p<0.006), \"having had more than one pregnancy\" with 50% (95% CI 0.29-0.89, p<0.02), \"having a previous episode of depression\" with 64% (95% CI 1.02-2.65, p<0.04), and \"having a previous episode of anxiety\" with 83% (95% CI 1.06-3.16, p<0.03). The other factors studied did not have statistical significance.  ConclusionWith the COVID-19 pandemic, an increase in the prevalence of depressive symptoms in the immediate postpartum period was observed. The postpartum women who scored > 10 on the EPDS had the following common associated factors: \"having no belief/spirituality\", \"having had more than one pregnancy\", \"having a previous episode of depression\", and \"having a previous episode of anxiety\". These findings indicate the need for greater attention from health professionals to these positive factors.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Enhancing ADHD Prediction in Adolescents through Fitbit-Derived Wearable Data\nAbstract: Attention-deficit/hyperactivity disorder (ADHD) is a prevalent neurodevelopmental condition characterized by a complex etiology. The diagnostic process for ADHD is often time-consuming and subjective in nature. Recent advancements in machine learning offer promising avenues for improving ADHD diagnosis automatically using various data sources. In this study, we harness Fitbit-derived physical activity measurements to investigate potential associations with ADHD and evaluate machine learning classifiers for their predictive accuracy in ADHD diagnosis. Our analysis involves a sample of 450 participants from the Adolescent Brain Cognitive Development (ABCD) study data release 5.0. We conduct correlation analyses to explore the connections between ADHD diagnosis and Fitbit-derived measurements, including sedentary time, resting heart rate, and energy expenditure. Subsequently, we employ multivariable logistic regression models to assess the predictive capability of these measurements for ADHD diagnosis. Furthermore, we train machine learning classifiers to achieve a diagnosis by automatically categorizing individuals into ADHD+ and ADHD-groups. Our correlation analysis unveils statistically significant associations between ADHD diagnosis and Fitbit-derived measurements, suggesting a potential link between physical activity patterns and ADHD. Importantly, multivariable logistic regression models demonstrate that some of the Fitbit measurements significantly predict ADHD diagnosis. Notably, our Random Forest machine learning classifier outperforms other classifiers with cross-validation accuracy (0.89), AUC (0.95), precision (0.88), recall (0.90), f1-score (0.89) and test accuracy (0.88), surpassing the performance of previous ADHD classification studies. These findings not only lay the groundwork for further exploration but also offer insights into the clinical integration of wearable data for a deeper understanding and improved identification of ADHD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Linguistic Dynamics: Women vs. the General Population in Reddit's ADHD Discussions\nAbstract: Understanding how language reflects the experiences of individuals with attention-deficit/hyperactivity disorder (ADHD) is important for developing targeted support strategies. This research investigates the linguistic patterns exhibited in discussions within women-centric and general ADHD population on Reddit, exploring how gender influences language use. By analyzing language, the study uncovers unique linguistic patterns and illuminates how women with ADHD express themselves, share experiences, and seek support compared to the general ADHD population. By leveraging deep learning-based embedding, clustering and named entity recognition, the study conducts a comprehensive analysis. Results reveal that women with ADHD emphasize themes like \"ADHD Awareness and Diagnosis\" and \"Emotional Well-being\". Conversely, the general population highlights \"Medication and Treatment\", and \"Work and Academic Challenges\". Statistical tests confirm significant differences in both linguistics and emotional expression between the two groups, emphasizing the importance of gender considerations in understanding ADHD language nuances and tailoring interventions accordingly.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The health, wellbeing and health service use of women attempting or planning pregnancy: a nationwide cross-sectional survey of Australian women\nAbstract: BackgroundHealth and wellbeing during the preconception period influence maternal and child health outcomes. We describe the sociodemographic and health characteristics of Australian women currently attempting pregnancy or planning to conceive in the next 12 months, compared with other women of reproductive age, to identify opportunities for preconception care.  MethodsA sub-analysis of survey data obtained in 2022 that included 874 responses from females aged 18-49 years was conducted. Socio-demographic characteristics, health and wellbeing status, and health service utilization data were described according to pregnancy intention.  ResultsOf 874 women, 64 (7.4%) reported currently attempting pregnancy and 45 (5.2%) reported planning to become pregnant in the next 12 months. Both groups of women were commonly married or in a de facto relationship. Women who were planning to become pregnant were more commonly aged 25-34 years (71.1%) compared to 18 to 24 years (20.0%) or aged 35 years or older (8.9%). They were also more likely to consult a chiropractor (OR 1.5). Women currently attempting pregnancy were less likely to not be in the paid workforce (OR 0.34) compared to working full time. They were also less likely to be using prescription-only pharmaceuticals (OR 0.30) and more likely to be consulting a Traditional Chinese medicine practitioner (OR 2.66) or a dietician (OR 2.11).  ConclusionThe findings of this study can be used for informing health service planning and policy that takes a whole-of-health-system approach when designing preconception health primary care interventions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: An unfortunate natural experiment in learning how to provide services to those in need. The case of Ukrainian war refugees with disabilities in Warsaw and Bucharest\nAbstract: When helping others, experience becomes important, especially in circumstances that involve interacting with a different culture--such as the ones implied in providing services to refugees. When disability is added to refuge, multiple types of experience become necessary, with the capacity for cross-sector collaboration being an asset. This paper explores the impact of the Russian invasion of Ukraine on the capacity of the Polish and Romanian organizations providing services to Ukrainian refugees in Warsaw and Bucharest, with a focus on disabled refugees. Based on 41 interviews with service providers/grass-roots organizations, it turns out that this unfortunate event served as a natural laboratory for practicing, acquiring, and increasing skills in multiple domains, leading to increased personal and institutional expertise. We inspect the differences between Warsaw and Bucharest, the first city having more experience in dealing with incoming flows of immigrants, the second being a newcomer in this respect. We also consider the distinction between public providers (public administration) and non-governmental organization entities, observing the upscaling of the latter. Implications for policy are considered within the framework of curtailing civic society under the illiberal wave.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Self-reported Health Literacy, Digital Literacy, and Barriers to accessing care at a Safety Net Breast Surgical Oncology Clinic\nAbstract: BackgroundSociodemographic factors, including language, education, race, and insurance status, significantly influence patient outcomes following breast surgery, especially in safety-net hospitals (SNHs) that serve vulnerable populations.  ObjectiveTo assess the sociodemographic composition of a breast surgical oncology clinic at an urban SNH and evaluate how these factors impact digital literacy, health literacy, and access to care.  MethodsEnglish and Spanish-speaking adult female patients at an urban SNH breast surgical oncology clinic between August and October 2022 completed a survey assessing digital and health literacy, barriers to care, and sociodemographic information. Descriptive statistics and comparative analyses were performed using Chi-squared and Fishers exact tests.  ResultsOf 127 invited patients, 95 (75%) completed the survey. The median age was 50 years. Fifty-six percent identified as Hispanic, 43% preferred Spanish, and 40% had less than a high school education. Health literacy was lower among Spanish-speaking, older, and less-educated patients. Digital literacy was also lower among these groups, with notable disparities in access to computers, the internet, and smartphones.  ConclusionSignificant disparities in health and digital literacy exist among vulnerable breast cancer patients at SNHs, particularly among Spanish-speaking, older, and less-educated individuals. Targeted interventions to improve education, access to digital resources, and supportive services are essential to ensure equitable care and improve health outcomes for these populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: AI-enabled CT-guided end-to-end quantification of total cardiac activity in 18FDG cardiac PET/CT for detection of cardiac sarcoidosis\nAbstract: Purpose[18F]-fluorodeoxyglucose ([18F]FDG) positron emission tomography (PET) plays a central role in diagnosing and managing cardiac sarcoidosis. We propose a fully automated pipeline for quantification of [18F]FDG PET activity using deep learning (DL) segmentation of cardiac chambers on computed tomography (CT) attenuation maps and evaluate several quantitative approaches based on this framework.  MethodsWe included consecutive patients undergoing [18F]FDG PET/CT for suspected cardiac sarcoidosis. DL segmented left atrium, left ventricular(LV), right atrium, right ventricle, aorta, LV myocardium, and lungs from CT attenuation scans. CT-defined anatomical regions were applied to [18F]FDG PET images automatically to target to background ratio (TBR), volume of inflammation (VOI) and cardiometabolic activity (CMA) using full sized and shrunk segmentations.  ResultsA total of 69 patients were included, with mean age of 56.1 {+/-} 13.4 and cardiac sarcoidosis present in 29 (42%). CMA had the highest prediction performance (area under the receiver operating characteristic curve [AUC] 0.919, 95% confidence interval [CI] 0.858 - 0.980) followed by VOI (AUC 0.903, 95% CI 0.834 - 0.971), TBR (AUC 0.891, 95% CI 0.819 - 0.964), and maximum standardized uptake value (AUC 0.812, 95% CI 0.701 - 0.923). Abnormal CMA ([&ge;]1) had a sensitivity of 100% and specificity 65% for cardiac sarcoidosis. Lung quantification was able to identify patients with pulmonary abnormalities.  ConclusionWe demonstrate that fully automated volumetric quantification of [18F]FDG PET for cardiac sarcoidosis based on CT attenuation map-derived volumetry is feasible, rapid, and has high prediction performance. This approach provides objective measurements of cardiac inflammation with consistent definition of myocardium and background region.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Acceptability of Overground Wearable Powered Exoskeletons for People with Spinal Cord Injury: a Multicenter Qualitative Study\nAbstract: BackgroundExoskeletons are used in rehabilitation centers for people with spinal cord injury (SCI) due to the potential benefits they offer for locomotor rehabilitation. The acceptability of exoskeletons is crucial to promote rehabilitation and to ensure a successful implementation of this technology. The objective was to explore the acceptability of overground wearable powered exoskeleton used in rehabilitation among people with SCI.  MethodsFourteen individuals with SCI (9 men, mean age 47 years [14,8], majority with traumatic and thoracic lesion (T6-T12)) who had utilized an exoskeleton in Canada or in France during their rehabilitation participated in a semi-structured interview. A thematic analysis using the Theoretical Framework of Acceptability was carried out.  ResultsParticipants were motivated to use an exoskeleton during their rehabilitation. They reported several perceived benefits to its use, including better walking pattern, increased endurance and greater muscle mass. They also experienced mild pain, notable concentration demands and fatigue. Most participants reported that using exoskeletons in their rehabilitation process was appropriate and relevant to them.  ConclusionsExoskeletons are generally well accepted by participants in this study. Adjustments in their use, such as conducting training sessions in obstacle-free environment and technological improvements to address the devices restrictive characteristics, heaviness, and massiveness are however still needed.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clonal Hematopoiesis and the Risk for Rheumatoid Arthritis\nAbstract: ObjectiveRheumatoid arthritis (RA) is a systemic autoimmune disease with complex pathogenesis involving the innate and adaptive immune system. Clonal hematopoiesis of indeterminate potential (CHIP) is defined by clonal proliferation of one hematopoietic stem cell and is typically asymptomatic. Both are common among older adults. CHIP is associated with multiple autoimmune diseases, but has not been thoroughly evaluated for its relationship with RA.  MethodsWe examined three large biobanks where CHIP status of participants has been determined from whole genome sequencing data. We ascertained cases of RA, seropositive RA (SPRA), and seronegative RA (SNRA) using established methods and used survival analysis to test whether CHIP status was predictive of incident disease. We combined the results of the three biobank studies using random effects meta-analysis. For validation, we performed deep, targeted sequencing of CHIP-causing genes in an established clinical cohort of 132 RA cases, 56 controls, and 544 external controls. We compared the rates of CHIP between cases and controls using logistic linear regression.  ResultsIn the UKBiobank and in meta-analysis, the presence of a large CHIP clone was associated with an increased risk for SPRA (HR = 2.57 with CI [1.46, 4.52] and p = 0.001) and RA (HR = 1.43 with CI [1.16, 1.75] and p = 7 x 10-4). Medium CHIP clones were associated with smaller increases in risk for SPRA and RA, and small CHIP clones carried no increased risk of any outcome. There were no associations detected between SNRA and CHIP of any size. In the clinical RA cohort, cases were more likely to have CHIP than controls after correcting for age, age2, and sex (OR: 2.08, HR [1.09, 3.83], p = 0.02).  ConclusionIn a meta-analysis combing data from three large biobanks, large CHIP clones were associated with an increased risk for incident SPRA and, to a lesser extent, increased risk for RA. Validating this biobank-based finding, in a well-phenotyped clinical cohort, cases had higher rates of CHIP than age-matched controls. The mechanism by which CHIP drives the increased risk for SPRA is not known, but if it were discovered, could inform early intervention for patients with CHIP to prevent RA or personalized therapy for patients with RA based on CHIP status.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Lived Experience of Infertility in Asian Americans: A Qualitative Study\nAbstract: ObjectiveTo identify psychosocial and cultural factors among Asian American patients diagnosed with infertility that may contribute to their disparate fertility outcomes.  DesignA cross-sectional qualitative interview study was conducted with women [&ge;]18-years-old who identified as Asian American and had a diagnosis of infertility. Semi-structured interviews were performed until thematic saturation was reached. The interviews were transcribed and coded. A codebook was developed to capture the grounded perspectives of participants. The web application Dedoose was utilized to conduct content analysis, identifying common themes and patterns.  ResultsAsian Americans voice the importance of having children, emphasizing the cultural expectation to procreate. They reported that infertility caused immense mental and emotional distress, resulting in feelings of disappointment and grief. Participants noted that it is not common in their culture to talk about infertility-related issues. Religion and naturopathic remedies played a large role in helping participants adjust to their infertility journeys. Participants stated that the infertility evaluation was complicated and one particular area of frustration was the lack of individually centered treatment. Interestingly, participants expressed desire to help other Asian women who are also struggling with infertility.  ConclusionInfertility is a difficult and complex experience for Asian American women. Parenthood is a strong expectation for people of Asian descent and results in emotional burden when complicated by infertility. Fertility concerns are considered taboo to openly discuss, which can cause additional feelings of isolation. Healthcare providers should work to address the culturally induced shame associated with infertility and provide more individualized care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: APOE4 impact on soluble and insoluble tau pathology is mostly influenced by amyloid-beta\nAbstract: The APOE4 allele is the strongest genetic risk factor for sporadic Alzheimers disease (AD). While APOE4 is strongly associated with amyloid-beta (A{beta}) accumulation, its relationship with tau accumulation is less understood. Studies evaluating the role of APOE4 on tau accumulation have shown conflicting results, particularly regarding the independence of these associations from A{beta} load. To clarify the relations between APOE4, A{beta} and tau, we examined three independent longitudinal cohorts (the Swedish BioFINDER-1, BioFINDER-2 and WRAP cohorts) in which participants had cross-sectional and longitudinal measures of tau tangles (tau-PET; temporal meta-ROI and entorhinal) or soluble p-tau (p-tau217), A{beta}-PET and APOE genotype. The study included a total of 1370 cognitively unimpaired (CU) and 449 mild cognitive impairment (MCI) subjects, followed longitudinally with tau-PET and p-tau217. APOE4 carriers accounted for 40.2-50% of the cohorts. Different linear regressions (cross-sectional) and linear mixed-effect models (longitudinal) with tau measures as outcomes were fitted to test the effect of APOE4 as independent predictor, as well as in combination with baseline A{beta} load or the interaction term between APOE4 and A{beta} load. All models included age, sex and cognitive status as covariates.  We found no independent effects of the APOE4 carriership on insoluble tau aggregates in either cohort (BioFINDER-2 or WRAP), both on cross-sectional and longitudinal tau-PET levels in the temporal meta-ROI, when A{beta} was present in the model (p=0.531-0.949). A{beta} alone was the best predictor of insoluble tau accumulation, and there was no interaction between APOE4 and A{beta} on tau-PET. Similarly, no independent effects of the APOE4 carriership on baseline (p=0.683-0.708) and longitudinal (p=0.188-0.570) soluble p-tau217 were observed when A{beta} was included in the model in BioFINDER-1 and WRAP. No interaction between APOE4 and A{beta} on soluble p-tau217 was observed. Furthermore, mediation analysis revealed that A{beta} load fully mediated most associations between APOE4 and tau (46-112%, either cross-sectional or longitudinal tau-PET or soluble p-tau217). In the largest cohort (BioFINDER-2), looking at APOE4 groups based on the number of {varepsilon}4 alleles, we found an interaction between APOE4 homozygotes only and A{beta} on tau-PET levels at baseline and over time.  In conclusion, although APOE4 is strongly associated with A{beta} aggregation, it seems to be minimally associated with longitudinal changes in soluble or insoluble p-tau levels at a given level of A{beta} pathology, confirming the primacy of A{beta} in driving tau pathology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bibliometric analysis of disaster nursing based on CiteSpace\nAbstract: BackgroundDisaster nursing as a response to natural disasters, accidents disasters and other emergencies important areas, on a global scale in recent years received wide attention and research. This study discusses the research status and development trend of disaster nursing in the past 10 years, to provide a reference for future research and practice.  MethodsLiterature in disaster nursing from 2013 to 2023 was searched using the Web of Science database, and CiteSpace 6.1.R6 software was used for visual analysis.  ResultsA total of 4865 articles were retrieved, identified, and presented with a trend of steady rise. The United States has the largest number and has significant influence in the field. Disaster preparedness, disaster resilience, and disaster nursing education are the research hotspots. The combination of disaster nursing and intelligent technology will be the future research trend.  ConclusionIn the last 10 years, research on disaster nursing has shown a diversified and comprehensive development trend. In the future, with the continuous impact of global climate change and the increasing social demand for disaster nursing, the research and practice of disaster nursing will pay more attention to interdisciplinary cooperation, technological innovation, and humanistic care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Feasibility, Acceptability, and Effectiveness of Group Antenatal Care on the Continuum of Care and Perinatal Outcomes in Sub-Saharan Africa: A Systematic Review and Meta-analysis Protocol\nAbstract: IntroductionIn sub-Saharan Africa, the predominant model of individualized, one-on-one antenatal care has not significantly improved perinatal outcomes. Although the benefits of group antenatal care have been demonstrated in developed countries, its feasibility, acceptability, and effectiveness in resource limited settings, particularly in sub-Saharan African countries, have yet to be fully investigated. However, pilot studies show promising evidence of its effectiveness in these areas. This systematic review and meta-analysis will, therefore, review and summarize available studies and provide comprehensive and robust evidence that tends to contribute to the ongoing efforts to implement group prenatal care models in low-resource settings.  Methods and analysisThis systematic review protocol adheres to the Preferred Reporting Items for Systematic Reviews and Meta-Analysis Protocols guidelines. A comprehensive literature search will be conducted across multiple electronic databases, including PubMed/MEDLINE, Web of Science, EMBASE, and CINHAL, to identify pertinent articles published from January 1, 2016, to June 30, 2024. Experimental studies (pre-post, quasi-experimental study, cluster randomized controlled trial), prospective cohort design, prospective comparative study, and qualitative and mixed method designs will be included in the review. Abstract and full-text screening will be conducted by three reviewers using Covidence, according to the eligibility criteria set. The Joanna Briggs Institute (JBI) Critical Appraisal Tools, specifically designed for JBI Systematic Reviews, will be utilized to assess the methodological quality of the included studies. Statistical heterogeneity will be assessed using the Higgins test. Meta-analysis will be performed using R version 3.6.1 software and STATA version 16; applying random effects models to determine the weights. Pre-specified subgroup analysis and sensitivity analysis will be conducted as necessary. The study results will be reported sequentially, beginning with the primary outcomes, followed by secondary outcomes, and important subgroup analyses.  Ethics and disseminationEthical approval is not applicable as no original data will be collected. The findings of this review will be disseminated through publication and conference presentations.  PROSPERO registration number CRD42024565501.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Applying item response theory to psychometrically evaluate and shorten the Negative Acts Questionnaire-Revised\nAbstract: Workplace bullying (WB) assessment often relies on the Negative Acts Questionnaire-Revised (NAQ-R). This study aimed to shorten and improve the NAQ-R using Item Response Theory (IRT) and address sex bias. IRT analysis from 867 Swedish employees (66% women) identified less-informative items. Based on this, a 13-item NAQ-R Short Form (NAQ-R-SF) was developed, demonstrating strong discrimination and validity. The new NAQ-R-SF showed a significant correlation with a primary WB measure (r = .57) and other relevant constructs, including individual factors like neuroticism and health quality, as well as work-related factors such as interpersonal conflicts and work performance. Sex bias was not found. IRT and validity evidence support the NAQ-R-SF as a robust tool for measuring WB, aligning with established WB constructs and individual differences.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Global trends in occupational disease reporting: a systematic review\nAbstract: BackgroundDisease reporting is often unreliable and faces many challenges, making it difficult to estimate the true burden of occupational diseases, defined as any disease that is caused by the work activity or environment. This study aimed to assess the global reporting and underreporting rate of occupational diseases, and to identify the factors affecting the underreporting of occupational diseases.  MethodsFollowing the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines, this study searched Medline (PubMed), CINAHL, EMBASE, Scopus, Web of Science, WHO Institutional Repository for Information Sharing (IRIS) database, Dimensions, and Google Scholar. We used search terms related to reporting and underreporting of occupational diseases or illnesses. The selected records were screened, and data extracted using the Covidence software tool. Screening and quality assessment were conducted by two independent researchers and finalized by a third researcher. The quality of the evidence was assessed with the Mixed Methods Appraisal Tool. This study is registered on PROSPERO, number CRD42023417814.  ResultsA total of 121 studies from 29 countries were identified, all coming from high-income and upper-middle-income countries. The incidence rate of occupational disease varied widely, ranging between 1.71 to 1,387 per 100,000 employees yearly. The highest number of annual cases was reported in the agricultural sector (ranging from 33 to 6,431), followed by the health sector (146 to 5,508), and then the construction sector (264). Two studies evaluated rates of underreporting, which varied from 50% to 95%. The main factor contributing to underreporting was employee concerns about job security.  ConclusionsThe results reveal a significant gap in the reporting of occupational diseases among high-income and low-middle-income countries. This review also identifies variations in reporting mechanisms across different countries. Our findings highlight the need to establish a national system for reporting occupational diseases that engages employers, employees, and healthcare providers.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Proof-of-Concept Large Language Model Application to Support Clinical Trial Screening in Surgical Oncology\nAbstract: IntroductionClinical trials are the gold standard for advancing the forefront of medical knowledge and rely on consistent patient accrual for success. However, patient screening for clinical trials is complex and resource intensive. There is a need to increase the scalability of trial recruitment while maintaining or improving upon the sensitivity of the current process. We hypothesized that we could use a state-of-the-art large language model, prompt engineering, and publicly available clinical trial data to predict patient eligibility for clinical trials from clinic notes. Here, we present pilot data demonstrating the accuracy of our tool in a cohort of patients being evaluated for pancreas cancer.  MethodsWe used a cohort of patients who were screened for clinical trials at a single institution for this study. We developed an LLM application using LangChain and the GPT-4o model to assist in clinical trial screening. Deidentified patient data from clinical notes and trial eligibility criteria from ClinicalTrials.gov were used as inputs. For each patient and trial, the model determined inclusion or exclusion with selected eligibility criteria as well as the trial overall. Model responses were graded programmatically against a human rater standard. We recorded time elapsed and cost of running each analysis.  ResultsOf the 24 patients in the test set, 19 were eligible for at least one trial. There were 43 eligible patient-trial matches in our data set. Our model correctly predicted 39 out of 42 (90.7%) of these matches. There were 105 individual eligibility criteria evaluated per patient for a total of 2520 binary criteria. GPT-4o agreed with the raters for 2438 out of 2520 (96.7%) binary eligibility criteria.  Sensitivity to overall trial eligibility by trial ranged from 87.5% to 100% for 8 out of 9 trials. The application incorrectly screened the single patient in the CA-4948 trial test set, leading to a sensitivity of 0% for this trial. Specificity ranged from 73.3% to 100% over all nine trials. The median cost for screening a patient was 0.67 USD (0.63-0.74). Median time elapsed was 137.66 seconds (130.04-146.04). Median total token usage across three assistants was 112,266.5 tokens (102982.0-122174.2).  ConclusionOverall, our model showed high efficiency and accuracy in selecting patients for appropriate clinical trials. Our results showed promise with a small cohort and future studies are needed to assess its accuracy with a larger sample of patients and trials. This model can be applied systematically to widen the surface area covered by the screening process as well as adapted to any set of clinical trials, opening the door for expansion to other surgical and medical disciplines.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Elevated blood glucose levels are associated with the progression of brain hypometabolism, and HDL-C and APOE4 add to this association\nAbstract: BackgroundBrain glucose hypometabolism has consistently been found in neurodegenerative disorders, including Alzheimers disease (AD). High blood glucose and HDL cholesterol (HDL-C) levels have also been linked to neurodegeneration and AD. However, there is limited understanding of the relationships between dementia-related risk factors in the brain and blood.  MethodsA linear mixed model was used to examine the relationship between blood glucose and HDL-C levels and the progression of brain hypometabolism, adjusting for APOE4 and other clinical covariates. The hypometabolic convergence index (HCI) was measured by fluorodeoxyglucose-18 (FDG) positron emission tomography (PET) in participants from the Alzheimers Disease Neuroimaging Initiative (ADNI). Data visualizations were generated to understand the joint effects of plasma glucose, HDL-C, and APOE4 on HCI.  ResultsThere were 336 individuals (781 observations), of whom 22.62% had AD. The majority were male (63.98%) and of white race, and 48.51% were carriers of APOE4. Over time, high blood glucose level was associated with the progression of brain glucose hypometabolism ({beta}=0.33, 95% CI: 0.02, 0.64, p<0.05). A high plasma HDL-C level ({beta}=1.22, 95% CI: 0.09, 2.35, p<0.05), more study visits ({beta}=1.67, 95% CI: 1.37, 1.98, p<0.001), and being an APOE4 allele carrier ({beta}=1.29, 95% CI: 0.15, 2.42, p<0.05) were also significant predictors of brain hypometabolism progression. APOE4 carrier status and number of visits account for the largest proportion of the variance from the fixed effects model. Random effects due to participant characteristics and fixed effects together accounted for 95.2% of the model variance. Subgroup analysis revealed that these effects were observed only in those without AD.  ConclusionHigh plasma glucose levels facilitated the progression of brain hypometabolism. The effect was more prominent in the APOE4 double-carriers with elevated HDL-C. Elevated blood glucose may reflect systemic insulin resistance, which could impair brain glucose uptake, resulting in brain hypometabolism. Controlling blood glucose and HDL-C levels in APOE4 carriers may improve brain metabolism, potentially delaying the onset of dementia.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic liability to insomnia and substance use disorders in patients with bipolar disorder\nAbstract: BackgroundInsomnia and substance use disorders (SUD) are common comorbidities of bipolar disorder (BD). Genome-wide association studies (GWAS) have uncovered shared genetic contributions to insomnia and BD as well as SUDs and BD. Using electronic health record (EHR) derived phenotypes (phecodes) and questionnaire data, the authors examined the relationship between insomnia genetic liability and SUDs in BD.  Methods40,839 participants from the Mayo Clinic Bipolar Disorder Biobank (BD Biobank; n=774) and Mayo Clinic Biobank (n=485 BD cases, n=39,580 controls) were included in the phecode analyses [insomnia, SUD, alcohol use disorder (AUD) and tobacco use disorder (TUD)]. 1789 cases were included in analyses of the BD Biobank questionnaire data, which included information on BD subtype and various SUDs. Logistic regression was used to test for associations between insomnia polygenic risk scores (PRS) and insomnia and SUD phenotypes in BD cases and controls.  ResultsInsomnia PRS was associated with the insomnia phecode in controls (OR=1.19, p=9.64e-33) but not in BD cases (OR=1, p=0.95). Associations between insomnia PRS and SUD phecodes were significant in BD cases and controls with the effect of the association between insomnia PRS and SUD being stronger in BD cases (interaction p=0.024). In the BD Biobank, the insomnia PRS was associated with increased odds of AUD (OR=1.19, p=4.26e-04), TUD (OR=1.21, p=1.25e-05) and cannabis use disorder (OR=1.16, p=4.19e-03).  ConclusionThe effect of genetic predisposition to insomnia on SUD may be stronger in BD cases than controls. This could have clinical treatment implications for individuals with BD and comorbid SUD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Identifying Proteomic Prognostic Markers for Alzheimer's Disease with Survival Machine Learning: the Framingham Heart Study\nAbstract: BackgroundProtein abundance levels, sensitive to both physiological changes and external interventions, are useful for assessing the Alzheimers disease (AD) risk and treatment efficacy. However, identifying proteomic prognostic markers for AD is challenging by their high dimensionality and inherent correlations.  MethodsOur study analyzed 1128 plasma proteins, measured by the SOMAscan platform, from 858 participants 55 years and older (mean age 63 years, 52.9% women) of the Framingham Heart Study (FHS) Offspring cohort. We conducted regression analysis and machine learning models, including LASSO-based Cox proportional hazard regression model (LASSO) and generalized boosted regression model (GBM), to identify protein prognostic markers. These markers were used to construct a weighted proteomic composite score, the AD prediction performance of which was assessed using time-dependent area under the curve (AUC). The association between the composite score and memory domain was examined in 339 (of the 858) participants with available memory scores, and in an independent group of 430 participants younger than 55 years (mean age 46, 56.7% women).  ResultsOver a mean follow-up of 20 years, 132 (15.4%) participants developed AD. After adjusting for baseline age, sex, education, and APOE {varepsilon}4+ status, regression models identified 309 proteins (P [&le;] 0.2). After applying machine learning methods, nine of these proteins were selected to develop a composite score. This score improved AD prediction beyond the factors of age, sex, education, and APOE {varepsilon}4+ status across 15 to 25 years of follow-up, achieving its peak AUC of 0.84 in the LASSO model at the 22-year follow-up. It also showed a consistent negative association with memory scores in 339 participants (beta = -0.061, P = 0.046), 430 independent participants (beta = -0.060, P = 0.018), and the pooled 769 samples (beta = -0.058, P = 0.003).  ConclusionThese findings highlight the utility of proteomic markers in improving AD prediction and emphasize the complex pathology of AD. The composite score may aid early AD detection and efficacy monitoring, warranting further validation in diverse populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Nocturia as a Risk Factor for Developing Frailty in Older Adults: Results of the Berlin Aging Study II\nAbstract: Background & AimThe current study examined cross-sectional and longitudinal associations between nocturia and frailty in a cohort of men and women aged 60 years and older, as evidence on this topic was lacking.  MethodsBaseline and follow-up data from the Berlin Aging Study II (n=1671) assessed on average 7.1 (IQR 6.2-8.7) years apart were analyzed. Self-reported nocturia was dichotomized into </[&ge;] 2 micturitions per night, and frailty was assessed using the Fried Frailty Phenotype. Covariables were identified a priori based on a review of the existing literature.  ResultsAt baseline, 70.2% of the participants were robust, 28.9% were pre-frail, and 0.9% were frail; 254 participants (23.6%) had self-reported nocturia. In longitudinal analyses, the prevalence and incidence of frailty at follow-up significantly increased when nocturia was present at baseline. Over the median follow-up of 7.1 years, there were 41 incident frailty cases (IR 5.15, 95% CI 3.79-7.00 per 1000 person-years). After adjusting for age, sex, morbidity burden, and baseline frailty status, baseline nocturia was associated with a 2.23-fold increased risk (95% CI 1.17-4.18) of frailty at follow-up.  ConclusionNocturia is linked to a higher risk of developing frailty in older adults, both women and men.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Don't Jump to Faulty Conclusions: Using the Synthetic Control Method to Evaluate the Effect of a Counterfactual Lockdown in Sweden\nAbstract: Several studies based on the Synthetic Control Method (SCM) link the many COVID-19 deaths in Sweden during the spring of 2020 to its decision not to lock down. These studies predominantly rely on a limited pre-intervention period and tend to focus on the very short run neglecting that Swedish health authorities emphasized that their public health strategy was designed for the long run. This paper handles these shortcomings expanding both the pre- and post-intervention period considerably using weekly mortality rates. I find no significant effect of the absence of lockdown on COVID-19 mortality neither in the short or long run. Using the timing of the winter holiday as a proxy for the extent/spread of COVID-19 in societies before lockdown - a variable which is unobservable due to limited testing - I suggest that the effect of lockdowns found in earlier studies using Sweden as a control are likely to be partially driven by unobserved variables rather than policies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: County by county estimation of deaths averted, infections averted, and cost savings of overdose prevention health centers in the United States\nAbstract: Overdose prevention health centers (OPHCs), also known as overdose prevention centers or safe injection centers, are an evidence-based strategy for people to use drugs in an environment monitored by health care professionals with access to drug use education, sterile supplies, and referral infrastructure to access higher levels of medical and behavioral health resources. Though still illegal under federal law throughout the United States, many legal or quasi-legal (including some in the United States) have operated since the 1980s (Beletsky, Baker et al. 2018). Using CDC overdose deaths and United States Census Bureau population data, we estimate over 14,000 deaths could be averted between 2020 and 2022 if 1 out of 20 injections had taken place at an OPHC. At this rate, over 100 HIV transmissions and 57,000 Hepatitis C Virus transmissions would have been averted as well. Almost 20 billion dollars in discounted lifetime costs to treat those infections could have been saved as well. This data supports OPHCs as a viable public health intervention to avert deaths and avoid infections.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: County by county estimation of deaths averted, infections averted, and cost savings of overdose prevention health centers in the United States\nAbstract: Overdose prevention health centers (OPHCs), also known as overdose prevention centers or safe injection centers, are an evidence-based strategy for people to use drugs in an environment monitored by health care professionals with access to drug use education, sterile supplies, and referral infrastructure to access higher levels of medical and behavioral health resources. Though still illegal under federal law throughout the United States, many legal or quasi-legal (including some in the United States) have operated since the 1980s (Beletsky, Baker et al. 2018). Using CDC overdose deaths and United States Census Bureau population data, we estimate over 14,000 deaths could be averted between 2020 and 2022 if 1 out of 20 injections had taken place at an OPHC. At this rate, over 100 HIV transmissions and 57,000 Hepatitis C Virus transmissions would have been averted as well. Almost 20 billion dollars in discounted lifetime costs to treat those infections could have been saved as well. This data supports OPHCs as a viable public health intervention to avert deaths and avoid infections.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multimodal BEHRT: Transformers for Multimodal Electronic Health Records to predict breast cancer prognosis\nAbstract: BackgroundBreast cancer is a complex disease that affects millions of people and is the leading cause of cancer death worldwide. There is therefore still a need to develop new tools to improve treatment outcomes for breast cancer patients. Electronic Health Records (EHRs) contain a wealth of information about patients, from pathological reports to biological measurements, that could be useful towards this end but remain mostly unexploited. Recent methodological developments in deep learning, however, open the way to developing new methods to leverage this information to improve patient care.  MethodsIn this study, we propose M-BEHRT, a Multimodal BERT for Electronic Health Record (EHR) data based on BEHRT, itself an architecture based on the popular natural langugage architecture BERT (Bidirectional Encoder Representations from Transformers). M-BEHRT models multimodal patient trajectories as a sequence of medical visits, which comprise a variety of information ranging from clinical features, results from biological lab tests, medical department and procedure, and the content of free-text medical reports. M-BEHRT uses a pretraining task analog to a masked language model to learn a representation of patient trajectories from data that includes data that is unlabeled due to censoring, and is then fine-tuned to the classification task at hand. Finally, we used a gradient-based attribution method -to highlight which parts of the input patient trajectory were most relevant for the prediction.  ResultsWe apply M-BEHRT to a retrospective cohort of about 15 000 breast cancer patients from Institut Curie (Paris, France) treated with adjuvant chemotherapy, using patient trajectories for up to one year after surgery to predict disease-free survival (DFS). M-BEHRT achieves an AUC-ROC of 0.77 [0.70-0.84] on a held-out data set for the prediction of DFS 3 years after surgery, compared to 0.67 [0.58-0.75] for the Nottingham Prognostic Index (NPI) and for a random forest (p-values = 0.031 and 0.050 respectively).  In addition, we identified subsets of patients for which M-BEHRT performs particularly well such as older patients with at least one lymph node affected.  ConclusionIn conclusion, we proposed a novel deep learning algorithm to learn from multimodal EHR data. Learning from about 15 000 patient records, our model achieves state-of-the-art performance on two classification tasks. The EHR data used to perform these tasks was more homogeneous compared to other datasets used for pretraining, as it exclusively comprised adjuvant treated breast cancer patients. This highlights both the potential of EHR data for improving our understanding of breast cancer and the ability of transformer-based architectures to learn from EHR data containing much fewer than the millions of records typically used in currently published studies. The representation of patient trajectories used by M-BEHRT captures their sequential aspect, and opens new research avenues for understanding complex diseases and improving patient care.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Collaborative Large Language Models for Automated Data Extraction in Living Systematic Reviews\nAbstract: ObjectiveData extraction from the published literature is the most laborious step in conducting living systematic reviews (LSRs). We aim to build a generalizable, automated data extraction workflow leveraging large language models (LLMs) that mimics the real-world two-reviewer process.  Materials and MethodsA dataset of 10 clinical trials (22 publications) from a published LSR was used, focusing on 23 variables related to trial, population, and outcomes data. The dataset was split into prompt development (n=5) and held-out test sets (n=17). GPT-4-turbo and Claude-3-Opus were used for data extraction. Responses from the two LLMs were compared for concordance. In instances with discordance, original responses from each LLM were provided to the other LLM for cross-critique. Evaluation metrics, including accuracy, were used to assess performance against the manually curated gold standard.  ResultsIn the prompt development set, 110 (96%) responses were concordant, achieving an accuracy of 0.99 against the gold standard. In the test set, 342 (87%) responses were concordant. The accuracy of the concordant responses was 0.94. The accuracy of the discordant responses was 0.41 for GPT-4-turbo and 0.50 for Claude-3-Opus. Of the 49 discordant responses, 25 (51%) became concordant after cross-critique, with an increase in accuracy to 0.76.  DiscussionConcordant responses by the LLMs are likely to be accurate. In instances of discordant responses, cross-critique can further increase the accuracy.  ConclusionLarge language models, when simulated in a collaborative, two-reviewer workflow, can extract data with reasonable performance, enabling truly  living systematic reviews.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reusable Generic Clinical Decision Support System Module for Immunization Recommendations in Resource-Constraint Settings\nAbstract: Clinical decision support systems (CDSS) are routinely employed in clinical settings to improve quality of care, ensure patient safety, and deliver consistent medical care. However, rule-based CDSS, currently available, do not feature reusable rules. In this study, we present CDSS with reusable rules. Our solution includes a common CDSS module, electronic medical record (EMR) specific adapters, CDSS rules written in the clinical quality language (CQL) (derived from CDC immunization recommendations), and patient records in fast healthcare interoperability resources (FHIR) format. The proposed CDSS is entirely browser-based and reachable within the users EMR interface at the client-side. This helps to avoid the transmission of patient data and privacy breaches. Additionally, we propose to provide means of managing and maintaining CDSS rules to allow the end users to modify them independently. Successful implementation and deployment were achieved in OpenMRS and OpenEMR during initial testing.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Correct deconfounding enables causal machine learning for precision medicine and beyond\nAbstract: Artificial intelligence holds promise for individualized medicine. Yet, predictive models in the neurobiomedical domain suffer from a lack of generalizability and replicability so that transitioning models from prototyping to clinical applications still poses challenges. Key contributors to these challenges are confounding effects; in particular the oftentimes purely statistical perspective on confounding. However, complementing these statistical considerations with causal reasoning from domain knowledge can make predictive models a tool for causal biomedical inference beyond associative insights. Such causal insights give answers to biomedical questions of how and why, arguably what most biomedical investigations ultimately seek for. Here, we suggest a 5-step approach for targeted, context-informed deconfounding. We exemplify the 5-step approach with a real-world neurobiomedical predictive task using data from the UK Biobank. The core of this approach constitutes a bottom-up causal analysis to identify a correct set of deconfounders and the appropriate deconfounding method for a given causal predictive endeavour. Using the 5-step approach to combine causal with statistical confounder considerations can make predictive models based on observational (big) data a technique comparable to Randomized Control Trials (RCTs). Through causally motivated deconfounding we aim at facilitating the development of reliable and trustworthy AI as a medical tool. In addition, we aim to foster the relevance of low performing or even null result models if they originate from a \"skilful interrogation of nature\", i.e. a deconfounding strategy derived from an adequate causal and statistical analysis. Ultimately, causal predictive modelling through appropriate deconfounding can contribute to mutual recursive feedback loops of causal insights across disciplines, scales and species that enable the field to disentangle the cause-effect structure of neurobiomedical mechanisms.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Morphology-based classification of sickle cell disease and \u03b2-thalassemia using a low-cost automated microscope and machine learning\nAbstract: Sickle cell disease (SCD) and {beta}-thalassemia are the most common monogenic diseases, disproportionately affecting low- and middle-income countries, where low-cost and accurate diagnostic tools are needed to reduce the global disease burden. Although the sickling test is commonly used to screen for the sickle mutation, it cannot distinguish between the asymptomatic sickle cell trait (SCT) and SCD, or identify {beta}-thalassemia. Here, we enhanced the inexpensive sickling test using automated microscopy and morphology-based machine learning classification to detect SCD, trait conditions (SCT and {beta}-thalassemia trait) and normal individuals with an overall area under receiver operating curve, sensitivity and specificity of 0.940 (95% confidence intervals: 0.938-0.942), 84.6% (84.2%-84.9%), and 92.3% (92.1%-92.4%), respectively. Notably, the sensitivity and specificity to detect severe disease (SCD) was over 97% and 98%, respectively, thus establishing a low-cost automated screening option for disease detection in low-resource settings. Furthermore, leveraging high-throughput microscopy, we generated an open-access dataset comprising over 300,000 images with 1.5 trillion segmented cells from 138 individuals in Canada and Nepal including individuals with sickle and/or {beta}-thalassemia mutations, to accelerate further research.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence of and risk factors for high-risk HPV and cervical cytological abnormalities in women living with HIV in Bali, Indonesia\nAbstract: BackgroundWomen living with HIV face a higher risk of developing cervical cancer compared to those without HIV. However, comprehensive cervical cancer screening programs for this population are still lacking in Indonesia. This has resulted in many cases of late-stage cervical cancer being diagnosed, especially in Bali, which has experienced an increase in cases of HIV and cervical cancer. This study aimed to determine the prevalence of and risk factors for cervical cytological abnormalities in women living with HIV in Bali and to explore their relationship with high-risk HPV (HR-HPV) types.  MethodsThis is a cross-sectional study with eligible participants recruited from outpatient HIV clinics in Bali. Between July to December 2023, participants were interviewed to collect demographic and historical medical information, followed by physical examination including collection of cervical swabs and blood samples. Pap smear sampling and swab collection using ThinPrep for cytology. HPV DNA was then identified by PCR and genotyped for HR-HPV 16,18,31,33,35,39,45,51,52,56,58,59,66,68. Blood samples were analyzed for CD4 and CD8 cell counts.  ResultsA total of 245 women with HIV at median age of 38 years old (24-50 years) and with median time of ARV therapy of 7 years (0-18 years) were enrolled. Only 239 participants were included in the analysis for their valid initial results. Overall, 26 (10.87%) of samples showed abnormal cytology including 6 (2.5%) ASC-H, 9 (3.8%) ASC-US, 4 (1.7%) H-SIL and 7 (2.9%) L-SIL. Of the 58 (24%) that tested positive for HPV DNA, 18 (31%) samples had abnormal cytology. HPV 18 was the most common genotype detected (n=16 or 28%). Bivariate analysis revealed a significant association between positive HPV DNA and abnormal cytology, with those testing HPV-positive having seven times higher risk of ASC-US or greater (PR=7.022;95%CI=3.223-15.295). Multivariate regression identified having HPV 18 infection as an independent risk factor for abnormal cytology (ExpB=9.029;p=0.007), and a history of Pap smear screening associated with reduced risk of HR-HPV infection (ExpB=0.358;p=0.013).  ConclusionIn our study, 10.87% of women living with HIV had abnormal cytology and 24% had positive HPV DNA tests. HPV 18 was associated with a greater risk of abnormal cytology compared to other high-risk HPV strains, but our sample size was small. History of pap smear was also shown to decrease the risk of HR-HPV infection. The results underscore the need for increased vaccination of younger women and screening of all women living with HIV in Indonesia in order to improve their cervical health outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prospects of HIV elimination among men who have sex with men: a systematic review of modeling studies\nAbstract: BackgroundDespite advances in HIV treatment and prevention, men who have sex with men (MSM) remain disproportionately affected by HIV worldwide. This systematic review summarizes the results of mathematical modeling studies that evaluated whether interventions might eliminate HIV in MSM populations by geographical setting, type of intervention(s), elimination definition, and model characteristics.  MethodsWe searched Embase and PubMed for modeling studies published between July 1, 2016 and August 7, 2023. Studies were included if they used a dynamic model to assess the impact of interventions on HIV transmission among MSM. Data were extracted on article information, study population, interventions, elimination definitions, model type, model structure, and calibration. The studies were critically appraised by evaluating the comprehensiveness of their models in addressing elimination.  FindingsOf the 2,732 identified records, 80 studies were included. MSM populations in only five of the eight Joint United Nations Programme on HIV/AIDS (UNAIDS) regions were modeled, with over half of the models considering MSM in the USA. Complex agent-based models were the most common overall, while simpler compartmental models predominated outside Western and Central Europe and North America. Thirty-five of the 80 studies defined elimination as reductions or thresholds in HIV incidence or prevalence, a reproduction number below one, or the elimination of racial disparities. Elimination was achieved in 32 out of 44 modeled scenarios, but the authors of only six of these 32 scenarios thought the interventions required to achieve elimination were feasible. The six feasible elimination scenarios were reported in compartmental models for few countries in Western Europe and Asia. Models in which elimination was achieved most commonly used a combination of interventions that included pre-exposure prophylaxis (PrEP) and/or test-and-treat, except in Africa, where PrEP was not included.  InterpretationModeling efforts to understand HIV elimination prospects among MSM outside Western and Central Europe and North America should be intensified. Various definitions of elimination reflect perspectives from both modeling and public health. To enhance study comparability and for models to contribute effectively to public health policy, the use of an elimination definition based on an incidence threshold would be the most valuable. Furthermore, by identifying gaps in current studies, we recommend novel research directions for modeling to inform a coordinated global response for HIV elimination among MSM.  FundingAidsfonds, EU.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prospects of HIV elimination among men who have sex with men: a systematic review of modeling studies\nAbstract: BackgroundDespite advances in HIV treatment and prevention, men who have sex with men (MSM) remain disproportionately affected by HIV worldwide. This systematic review summarizes the results of mathematical modeling studies that evaluated whether interventions might eliminate HIV in MSM populations by geographical setting, type of intervention(s), elimination definition, and model characteristics.  MethodsWe searched Embase and PubMed for modeling studies published between July 1, 2016 and August 7, 2023. Studies were included if they used a dynamic model to assess the impact of interventions on HIV transmission among MSM. Data were extracted on article information, study population, interventions, elimination definitions, model type, model structure, and calibration. The studies were critically appraised by evaluating the comprehensiveness of their models in addressing elimination.  FindingsOf the 2,732 identified records, 80 studies were included. MSM populations in only five of the eight Joint United Nations Programme on HIV/AIDS (UNAIDS) regions were modeled, with over half of the models considering MSM in the USA. Complex agent-based models were the most common overall, while simpler compartmental models predominated outside Western and Central Europe and North America. Thirty-five of the 80 studies defined elimination as reductions or thresholds in HIV incidence or prevalence, a reproduction number below one, or the elimination of racial disparities. Elimination was achieved in 32 out of 44 modeled scenarios, but the authors of only six of these 32 scenarios thought the interventions required to achieve elimination were feasible. The six feasible elimination scenarios were reported in compartmental models for few countries in Western Europe and Asia. Models in which elimination was achieved most commonly used a combination of interventions that included pre-exposure prophylaxis (PrEP) and/or test-and-treat, except in Africa, where PrEP was not included.  InterpretationModeling efforts to understand HIV elimination prospects among MSM outside Western and Central Europe and North America should be intensified. Various definitions of elimination reflect perspectives from both modeling and public health. To enhance study comparability and for models to contribute effectively to public health policy, the use of an elimination definition based on an incidence threshold would be the most valuable. Furthermore, by identifying gaps in current studies, we recommend novel research directions for modeling to inform a coordinated global response for HIV elimination among MSM.  FundingAidsfonds, EU.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Improving Retention and HIV Viral Suppression: A Cluster Randomised Pilot Trial of a Lay Counsellor Motivational Interviewing Training in South Africa\nAbstract: We piloted a Motivational Interviewing (MI) training program for lay counsellors in South Africa (SA) to assess its impact on retention and viral suppression among newly diagnosed individuals living with HIV (PLHIV) at 12 months post-diagnosis. We randomized eight primary healthcare clinics (PHC) in Johannesburg to either the intervention clinics (n=4) where all lay counsellors were supported for 12 months before the PLHIV enrolment or the standard of care (n=4 clinics). Overall, 548 adults ([&ge;] 18 years) PLHIV were recruited after HIV diagnosis from March 2020 to August 2021 (n=291 intervention, n=257 control). We conducted Poisson regression modelling to assess the intervention effect on patient attendance status (out of care - being [&ge;]28 days late for the last appointment) and viral suppression (<50 copies/ml) at 12 months, reporting risk ratios (RR) with 95% confidence intervals (CIs). Of the 548 eligible participants enrolled, 56.3% were [&ge;]28 days late (52.9% intervention vs 60.9% controls, RR 0.9, 95% CI: 0.7-1.0). Retention at 12 months positively correlated with baseline counselor MI skill levels (Cultivating change talk, RR 1.6, 95%CI: 1.1-2.5; Softening sustain talk, RR 1.5, 95%CI: 0.8-2.9; Empathy, RR 1.4, 95%CI: 1.0-1.8; Partnership RR 1.5, 95%CI: 1.2-1.9). Among those retained at 12 months, 65.3% of intervention participants were virally suppressed compared to 49.3% controls (RR 1.3, 95%CI: 1.0-1.7). Compared to control participants, the intervention group reported more positive counseling experiences, fewer concerns about HIV disclosure (RR 0.8 for high vs low-medium concerns, 95% CI: 0.7-1.0) and ART (RR 0.8, 95% CI: 0.7-1.0), and were more likely to express high confidence to take treatment in public (47.4% vs 28.8%, RR 1.4, 95% CI: 1.0-1.8) after counselling.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Derivation and validation of indices incorporating vasopressor dose and blood pressure values over time\nAbstract: RationaleThe blood pressure value below which the benefits of vasopressors clearly outweigh their disadvantages is uncertain.  ObjectivesThe main objective of this analysis was to investigate the statistical properties and potential utility of indices estimating the vasopressor dose-rates as a function of blood pressure values over time.  MethodsIn this single-center observational study, we collected blood pressure values from intensive care unit (ICU) monitors and norepinephrine dose-rates from infusion pumps corresponding to a derivation and a validation cohort. Patients included in each cohort were 18 years or older and received norepinephrine in the ICU. We defined and derived indices corresponding to vasopressor therapy above (>65 mmHg) and below (<60 mmHg) targets. We report the distribution of both indices over time from both cohorts as well as their associations with hospital mortality using logistic regression models adjusted for baseline variables.  ResultsBetween July 30 2020 and March 28 2022, 283 patients were included in the derivation cohort. The median ICU stay was 5 days (interquartile range [IQR] 2-10.5) and the median duration of norepinephrine therapy was 27.3 hours (IQR 13.9-54.2). The median cumulative time with a MAP below 60 mmHg was 0.9 hours (IQR 0.2-3.1), whereas the cumulative time with a MAP above 65 mmHg was 22.5 hours (IQR 10.9-40.4). Adjusting for prespecified baseline variables, the above target index was associated with hospital mortality (OR 1.6, 95% CI 1.2 -2.3) but not the below target index (OR 1.1 95% CI 0.8 - 1.5). Between May 5 2022 and December 16 2022, 83 patients were included in the validation cohort. The duration of ICU stay and the proportion of norepinephrine exposure above MAP target were consistent with the derivation cohort. The point estimates of the associations between each index and mortality were also consistent with the derivation cohort, but not statistically significant.  ConclusionIndices of vasopressor administration as a function of blood pressure suggest that during most of vasopressor therapy episodes, patients are treated above target. The association of these indices with patient outcomes remains uncertain but could be explored in larger datasets, and future clinical trials of target MAPs may consider measurement of these indices to adjust results for treatment adherence.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effect of Beta Blockers on Exercise Capacity, Diastolic Function, and Quality of Life in Patients with Heart Failure with Preserved Ejection Fraction: A Secondary Analysis of INDIE-HFpEF and RELAX\nAbstract: BackgroundThe use of beta blockers in patients with heart failure with preserved ejection fraction (HFpEF) is common, with about 75% of patients in recent landmark clinical trials on beta blockers. Though the implementation of this medication class is routine, there is sparse data to support their use. Furthermore, beta blocker effects on exercise capacity, diastolic function, and quality of life in HFpEF patients is unclear.  MethodsA retrospective cohort study was completed using patient-level data from two prior randomized trials. Cohorts were generated based on beta blocker use at the time of trial enrollment, demographic information was compared. Primary outcomes assessed were exercise capacity, diastolic function, and quality of life metrics. The results of baseline testing were utilized to avoid potential bias from each trials intervention.  ResultsAfter multivariate linear regression, HFpEF patients on beta blockers had no difference in exercise capacity (peak VO2 (mL/kg/min): 12.5 vs 13.5, P=0.933), diastolic function (average E/e: 16 vs 14, P=0.125; left atrial volume index (mL/m2): 47 vs 42, P=0.665; peak tricuspid regurgitation velocity (m/s): 2.85 vs 2.70, P=0.165), or quality of life survey scores (KCCQ: 54 vs 60, P=0.206; MLHFQ 44 vs 48, P=0.762) compared to those not taking beta blockers.  ConclusionsIn this secondary analysis of patient-level data, there was no association with beta blocker use and worsened exercise capacity, diastolic function, or quality of life in HFpEF patients. Randomized controlled trials are necessary to definitively determine the clinical and functional impact of beta blockers in HFpEF.  RESEARCH PERSPECTIVEO_LIIn this secondary analysis or INDIE-HFpEF and RELAX, there was no significant association with beta blocker use and worsened exercise capacity, diastolic dysfunction, or quality of life in HFpEF patients. C_LIO_LIWith little available evidence to suggest clinical or functional benefits from implementation of beta blockers in HFpEF, randomized controlled trials are warranted to more definitively evaluate the potential effects of this medication class. C_LIO_LIEvaluating unique HFpEF phenotypes with different comorbidity profiles would provide specific insights that could be translated to the clinical management of HFpEF patients. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subnational tailoring of malaria interventions for strategic planning and prioritization: experience and perspectives of five malaria programs\nAbstract: In the context of high malaria burden and insufficient resources, several national malaria programs (NMPs) used subnational tailoring (SNT) as a tool for evidence-informed decision-making on their national malaria strategic plans and funding requests. The SNT process included the formation of an SNT team, determination of criteria for targeting interventions, data assembly and review, stratification, application of targeting criteria to determine preliminary plans, mathematical modeling, finalization of intervention plans, and monitoring and evaluation of the eventual implemented plan, all under the leadership of the NMP. Analysis steps of SNT were supported by the World Health Organization (WHO) and other partners. As SNT was a new approach, this study used semi-structured interviews to understand the perspectives and experiences of personnel from five NMPs (Burkina Faso, Ghana, Guinea, Nigeria, and Togo) that undertook SNT between 2019 and 2023. Participants reported that SNT outputs were used to inform national strategic plans and prioritized plans, that the process incentivized improvements in data collection and data quality, and that NMPs were strongly motivated to grow their capacity to conduct more steps of the SNT analysis process internally. Major challenges included the lack of resources available to implement the full strategic plans as well as challenges with data quality and alignment of stakeholders. Participants reported a moderate to strong sense of ownership over the process and were eager to extend, adapt, and reuse the SNT process in the future. Among countries supported by WHO, SNT was well-accepted and allowed NMPs to successfully use evidence to inform their decision-making, advocate for themselves, and mobilize resources.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Single-Session Feasibility of a Wearable Music-based Rhythmic Auditory Stimulation Device to Improve Walking in Knee Osteoarthritis\nAbstract: ObjectiveWe examined the single-session feasibility of a wearable device to deliver a closed-loop music-based rhythmic auditory stimulation (RAS) walking intervention in people with knee osteoarthritis (OA).  MethodsFifteen participants with knee OA (age 70.0 {+/-} 8.6 years; BMI 29.4{+/-}5.9 kg/m2; 10 women) complete a supervised 30-minute walking session using a wearable music-based RAS device. The device included shoe-worn inertial sensors, headphones, and a proprietary algorithm embedded in a touchscreen control unit. The algorithm continuously assessed users gait and adjusted the tempo of the selected music to encourage improvements in gait quality. Spatiotemporal gait measures were collected using separate inertial sensors during the session. We examined change in gait during the session, participants report of exertion, and participant-reported acceptability.  ResultsOn average, participants showed [~]12%, 30%, and 15% increases in cadence, gait speed, and stride length, respectively without worsening variability or symmetry from before to during the RAS session. Of the 15 participants, 9/15, 11/15, and 9/15 showed [&ge;] 10% increase in cadence, gait speed, and stride length, respectively. Rating of Perceived Exertion was on average 13.3 (range 12-15). There were no serious adverse events and small increase in knee pain that resolved at the end of the session. Participants were highly accepting of the device and willing to use it at home for longer periods.  ConclusionA single-session feasibility study of a wearable closed-loop music-based RAS device in people with knee OA demonstrated increases in cadence and gait speed while safely walking at a moderate exercise intensity under supervision.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of cladribine on intrathecal and peripheral B and plasma cells\nAbstract: BackgroundCladribine is a deoxyadenosine analogue that can penetrate the blood-brain barrier. It is used to treat multiple sclerosis. However, the mechanistic understanding of the effect of this highly effective therapy on B cells and plasma cells in the central nervous system compartment is limited.  ObjectivesThe CLADRIPLAS study examined the effect of cladribine on peripheral and intrathecal B and plasma cell biology in people with MS.  MethodsThirty-eight people with progressive MS ineligible for- or rejecting-treatment with licenced therapies were recruited and supplied a baseline lumbar puncture. Those exhibiting gadolinium-enhancing or new/enlarging T2 magnetic resonance imaging lesions and/or elevated neurofilament levels were offered subcutaneous cladribine (Litak(R)). Seven people were eligible; one person died before treatment, and only five completed the first year of treatment. Twenty-two ineligible people were willing to provide a repeat lumbar puncture twelve months later.  ResultsThe CLADRIPLAS study found no evidence of a difference in the odds of a positive cerebrospinal fluid oligoclonal band (cOCB) result between the cladribine-treated and untreated group. This is probably explained by microarray and in vitro studies, which demonstrated that plasmablasts and notably long-lived plasma cells are relatively resistant to the cytotoxic effect of cladribine compared to memory B cells at physiological concentrations. This was consistent with the loss of intracellular deoxycytidine kinase during antibody-secreting cell differentiation.  DiscussionCLADRIPLAS indicates that cOCB are not rapidly eliminated in most people with MS. This may be explained by the relative lack of direct cytotoxic action of cladribine on long-lived plasma cells.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Thalamic burst and tonic firing selectively indicate patients' consciousness level and recovery\nAbstract: Patients with disorders of consciousness exhibit severe declines in arousal and awareness, alongside anomalous functional brain connections and aberrant neuronal activities1-4. Yet, the diagnostic error of patients consciousness states can reach up to forty percent5,6, resulting in a worse prognosis. Neuronal mechanisms underlying the disorders are indispensable for identifying objective and intrinsic markers of consciousness. As the principal relay station between the brainstem arousal nuclei and the cerebral cortex, the thalamus has been empirically inferred to maintain consciousness and wakefulness within the brain connectome7-12. Here, we investigated thalamic spiking, brain connections, consciousness states, and outcomes following deep brain stimulation in 29 patients. Our study reveals that thalamic activities can signal their consciousness states. Patients diagnosed with vegetative state/unresponsive wakefulness syndrome exhibited less active neurons with longer and more variable burst discharges compared to those in a minimally conscious state. Furthermore, as a direct deep brain stimulation site, neuronal profiles in the centromedian/parafascicular complex of the thalamus indicated whether electrostimulation here improved outcomes. Stronger tonic firing was associated with enhanced thalamocortical connections and better recovery outcomes in patients. These findings suggest that thalamic spiking signatures, including single-neuron burst discharge and tonic firing, selectively indicate the representation and alteration of consciousness. These findings provide direct neuronal and clinical evidence for understanding of thalamic contributions to disorders of consciousness.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Listening to Mom in the Neonatal Intensive Care Unit: A randomized trial of increased maternal speech exposure on white matter connectivity in infants born preterm\nAbstract: BackgroundEarly speech experiences have been proposed to contribute to the development of brain structures involved in processing spoken language. However, previous research has been limited to correlational studies. Here, we conducted an RCT with preterm neonates to determine whether increased exposure to maternal speech during NICU hospitalization is causally linked to structural white matter maturation.  MethodsWe enrolled 46 preterm neonates (24-31 weeks gestational age). Participants were randomly assigned to receive increased (T: n=21) or routine (C: n=25) exposure to mothers speech. The T-group heard 10-minute audio recordings of their mothers reading a childrens story two times/hour between 10pm-6am, increasing speech exposure by 2.67 hours/day. At near-term-equivalent age, we obtained two high-angular resolution diffusion MRI (scan 1 bvalue=700, scan 2 bvalue=1500) and quantitative T1 relaxometry scans. We assessed mean diffusivity (MD), pre-registered primary outcome (NCT02847689), of the left and right arcuate fasciculus, tracts implicated in language processing.  Secondary outcomes included fractional anisotropy (FA) and R1 (1/T1).  FindingsT- and C-groups were equivalent on medical and demographic variables. Compared to the C- group, the T-group demonstrated significantly lower MD in the left (scan 1: mean difference{Delta} =0.11, 95% CI:0.03 - 0.19; scan 2:{Delta} =0.13, 95% CI:0.04 - 0.21) but not right arcuate (scan 1:{Delta} =0.06, 95% CI: -0.23 - 0.15; scan 2:{Delta} =0.05, 95% CI:-0.05 - 0.13). The T-group also demonstrated significantly higher FA (scan 1:{Delta} = -0.02, 95% CI:-0.04 - -0.00; scan 2:{Delta} = -0.03, 95% CI:-0.06 - -0.00) and R1 ({Delta} =-0.02, 95% CI:-0.04 - -0.01) in the left but not right arcuate.  InterpretationPreterm neonates who experienced increased exposure to maternal speech during hospitalization demonstrated more mature microstructure of the left arcuate. Findings provide evidence for a causal link between speech experiences and brain development. Increasing speech exposure in the NICU may benefit preterm children.  Research in Context PanelO_ST_ABSEvidence before this studyC_ST_ABSObservational studies document the importance of early speech experience for language learning and brain development in term and preterm children. Children born preterm are at-risk for adverse language outcomes that have been attributed to alterations in brain development from limited exposure to speech in the neonatal intensive care unit (NICU). However, evidence that early speech experiences causally effect the development of brain structures relevant for language is lacking.  Added value of this studyThe Listening to Mom in NICU study is the first randomized controlled trial specifically designed to test the causal effects of maternal speech exposure on white matter brain development in neonates born preterm. This study demonstrates that speech experiences during neonatal development directly contribute to the maturation of the left arcuate fasciculus, a white matter tract implicated in language.  Implications of all the available evidenceStudy findings advance understandings for how early speech experiences contribute to neonatal brain development. This study also demonstrates that increasing exposure to speech via audio recordings among infants born preterm could serve as an inexpensive and scalable intervention to support recovery from alterations in brain development related to the NICU experience.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluation of a Mental Health Support Service for Performing Artists\nAbstract: BackgroundPerforming artists frequently face mental health challenges, with risk factors including performance pressure, industry competitiveness, and irregular work patterns. Barriers to seeking help encompass confidentiality concerns, fear of misunderstanding by clinicians, and scheduling conflicts due to peripatetic work.  AimsThis study aims to evaluate the accessibility, utilisation, and effectiveness of a Mental Health Support Service (MHSS) for performing artists.  MethodsA 12-month evaluation of a UK-wide MHSS for performing artists was conducted. 555 self-referred performers received 6-8 sessions of talking therapy from experienced professionals. Pre- and post-intervention mental health was assessed using PHQ-9 and GAD-7 scales. Quantitative data were analysed using paired t-tests, and qualitative feedback underwent thematic analysis.  Results240 performers completed pre- and post-intervention scores. Significant reductions in PHQ-9 (mean decrease 6.242, p<0.0001) and GAD-7 (mean decrease 6.225, p<0.0001) scores were observed post-intervention. Qualitative feedback (n=215) revealed high satisfaction, with 88% willing to recommend the service. Key themes included appreciation for tailored support and therapist-performer compatibility. Limited data on outcomes for global majority participants and gender differences necessitate further research.  ConclusionsThis evaluation of a mental health support service for performing artists reveals high satisfaction rates and willingness to recommend the service, highlighting the value of tailored interventions that address industry-specific challenges. The findings underscore the importance of developing sector-specific mental health standards and support systems, particularly for industries with high proportions of freelance workers, which could have broader implications for improving mental health support across diverse professional fields.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Molecular and Proteomic Profiles of Radioiodine Refractory Papillary Thyroid Cancer\nAbstract: BackgroundDespite the generally favorable prognosis of papillary thyroid cancers (PTCs) following thyroidectomy and potential radioactive iodine (RAI) therapy, approximately one-third of patients experiencing recurrence and metastasis eventually develop resistance to RAI, leading to a poor outcome. However, the mechanisms underlying RAI-refractoriness remain elusive. The present study aimed to assess the molecular and proteomic characteristics of RAI-refractory PTC (RR-PTC) to gain a deeper understanding of this condition.  MethodsThe medical records at our institution were reviewed for the selection and grouping of RR-PTC patients and RAI-sensitive controls. RR-PTC patients were divided into three subgroups: continuous RAI uptake (ID), loss of uptake at the first I-131 treatment (iDF) and RAI uptake lost gradually (iDG). Proteomic profiling and targeted next-generation sequencing were performed on formalin-fixed paraffin embedded primary lesions. The incidence of gene mutations and fusions was compared across groups. Bioinformatic analysis was subsequently conducted to identify the differentially expressed proteins and enriched pathways. The correlation of protein expression and gene variances was assessed.  ResultsA total of 48 PTC patients with recurrence and/or metastasis were included. The expression profiles of the RR-PTC and control groups were similar. In the subgroup comparison, enriched pathways related to MAPK and TNF signaling were associated with negative I-131 uptake and tumor tolerance with positive I-131 uptake. The BRAFV600E mutation was less common in the ID group, whereas the TERT promoter mutation was more common in the iDF group. NCOA4-RET fusion was more common in the ID group. In addition, four proteins were dysregulated in BRAF-mutated PTCs.  ConclusionThe present study constructed the first proteomic profile of RR-PTC. The proteins and pathways identified in the analysis may be promising biomarkers and drug targets. Gene alterations and fusions can aid in the early diagnosis of RR-PTC.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Molecular and Proteomic Profiles of Radioiodine Refractory Papillary Thyroid Cancer\nAbstract: BackgroundDespite the generally favorable prognosis of papillary thyroid cancers (PTCs) following thyroidectomy and potential radioactive iodine (RAI) therapy, approximately one-third of patients experiencing recurrence and metastasis eventually develop resistance to RAI, leading to a poor outcome. However, the mechanisms underlying RAI-refractoriness remain elusive. The present study aimed to assess the molecular and proteomic characteristics of RAI-refractory PTC (RR-PTC) to gain a deeper understanding of this condition.  MethodsThe medical records at our institution were reviewed for the selection and grouping of RR-PTC patients and RAI-sensitive controls. RR-PTC patients were divided into three subgroups: continuous RAI uptake (ID), loss of uptake at the first I-131 treatment (iDF) and RAI uptake lost gradually (iDG). Proteomic profiling and targeted next-generation sequencing were performed on formalin-fixed paraffin embedded primary lesions. The incidence of gene mutations and fusions was compared across groups. Bioinformatic analysis was subsequently conducted to identify the differentially expressed proteins and enriched pathways. The correlation of protein expression and gene variances was assessed.  ResultsA total of 48 PTC patients with recurrence and/or metastasis were included. The expression profiles of the RR-PTC and control groups were similar. In the subgroup comparison, enriched pathways related to MAPK and TNF signaling were associated with negative I-131 uptake and tumor tolerance with positive I-131 uptake. The BRAFV600E mutation was less common in the ID group, whereas the TERT promoter mutation was more common in the iDF group. NCOA4-RET fusion was more common in the ID group. In addition, four proteins were dysregulated in BRAF-mutated PTCs.  ConclusionThe present study constructed the first proteomic profile of RR-PTC. The proteins and pathways identified in the analysis may be promising biomarkers and drug targets. Gene alterations and fusions can aid in the early diagnosis of RR-PTC.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The effects of Autonomous Sensory Meridian Response (ASMR) on sleep quality improvement in adolescents\nAbstract: BackgroundIn recent years, there has been a notable surge in sleep-related challenges among adolescents. The emergence of Autonomous Sensory Meridian Response (ASMR) content across various social media platforms has sparked interest in its potential to address these issues. This study explored the therapeutic impact of ASMR on sleep problems in high school students.  MethodsThe study involved sixty participants, divided evenly into four groups: three intervention groups (A, B, C) and one control group. For five consecutive days, the intervention groups engaged in pre-sleep ASMR listening sessions lasting 10, 20, and 30 minutes, respectively. Sleep quality was evaluated using mobile application tools and the subjective Sleep Quality Scale.  ResultsThe analysis, performed utilizing repeated measures sphericity tests, revealed a significant correlation between ASMR intervention days and both objective sleep(P = 0.036) and effective sleep duration (P = 0.002). However, ASMR intervention did not significantly affect objective sleep efficiency or subjective sleep quality. These findings imply that ASMR interventions can significantly improve sleep issues in adolescents.  ConclusionsASMR has been extensively promoted as a potential remedy for sleep enhancement, this study substantiates its effectiveness in tackling adolescent sleep concerns.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beneficial vs harmful effects of pharmacological treatment of patent ductus arteriosus: A Bayesian meta-analysis\nAbstract: BackgroundRandomized controlled trials (RCTs) have failed to demonstrate beneficial effects of the pharmacological treatment of patent ductus arteriosus (PDA) in preterm infants. We conducted a Bayesian model averaged (BMA) meta-analysis of RCTs comparing pharmacological treatment of PDA with placebo or expectant treatment.  MethodsWe searched for RCTs including infants with gestational age (GA) [&le;]32 weeks and with a rate of open-label treatment of less than 25% in the control arm. Primary outcome was mortality and secondary outcomes included bronchopulmonary dysplasia (BPD). We calculated Bayes factors (BFs). The BF+/- is the ratio of the probability of the data under H+ (pharmacological treatment is beneficial) over the probability of the data under H- (pharmacological treatment is harmful).  ResultsFive RCTs were included (1341 infants). BMA showed strong evidence in favor of a harmful effect of medication for BPD (BF+/-=0.02) and BPD or death (BF+/- =0.03). When the two largest trials, which used early (<72 h) ibuprofen in infants with GA [&le;]28 weeks, were pooled, the BMA demonstrated moderate evidence in favor of higher mortality in the medication group (BF+/-=0.24).  ConclusionsEarly ibuprofen treatment of a PDA in extremely preterm infants may result in more complications than clinical benefit.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: RSV healthcare burden in adults before and since the emergence of the COVID-19 pandemic in 6 European countries\nAbstract: IntroductionRespiratory Syncytial Virus (RSV) is a major cause of morbidity in older adults. With the emergence of the coronavirus disease 2019 (COVID-19) and the subsequent changes in respiratory viral circulation, it is crucial to reassess RSV-associated healthcare burden in adults. This study assessed RSV-associated healthcare burden in adults in six European countries before and during the COVID-19 pandemic.  MethodsWe conducted a retrospective analysis using national hospital admissions data from Denmark, England, Finland, the Netherlands, Scotland, and regional surveillance data from the Valencia region (Spain). We included patients aged [&ge;]18 years hospitalised for respiratory tract infections (RTIs) from 2016 to 2023. We assessed RSV-coded and laboratory-confirmed hospitalisations, intensive care unit (ICU) admissions, in-hospital length of stay (LOS), and mortality.  ResultsRSV-associated hospitalisations significantly reduced during the 2020/2021 season across all countries, coinciding with strict COVID-19 preventive measures, but resurged in subsequent seasons. We observed the highest hospitalisation rates in adults aged [&ge;]85 years. RSV-coded hospitalisations were found to underestimate the true burden when compared with laboratory-confirmed cases. Underestimation factors ranged from 1.1 to 4.3 times across countries. No significant differences were observed in LOS or ICU admission rates for RSV-associated hospitalisations compared to RTIs.  DiscussionOur findings underscore the complex epidemiology of RSV in older adults. The differences between RSV-coded and laboratory-confirmed cases highlight the critical need for improved surveillance and diagnostic practices to better assess the true burden. Our findings could be vital for guiding public health strategies, particularly with the recent introduction of RSV vaccines for older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Uncovering Sex-Related Differences in Cerebrovascular Bypass Patency: An Institutional Review of 357 Direct Bypasses\nAbstract: IntroductionDemographics and comorbid conditions play a role in vascular health, yet their specific impact on cerebrovascular bypass patency remains unclear.  MethodsAn institutional database of 357 patients with intracranial bypass procedures between 08/2001-05/2022 was retrospectively reviewed. Patients with bypass for all causes (e.g., aneurysm, atherosclerotic disease, Moyamoya disease) were included. Medical history, surgical technique, and flow-related measurements (intraoperatively and on quantitative MRA at follow-up) were compared across biological sex and in relation to bypass patency.  ResultsOf 357 patients, 141 were male (39.5%) and 216 were female (60.5%) with average age 49.0+/-16.7. Bypass patency at last follow-up was 84.4% for men vs. 69.2% for women (p=0.001). Significant differences were seen in underlying diagnoses, with more aneurysm and Moyamoya cases represented in female sex (p<0.001); irrespective of diagnosis, lower patency rates were seen in women when considering bypass for aneurysm (p=0.032), Moyamoya disease (p=0.035), and for atherosclerotic disease (p=0.159). Medical comorbidities were seen at higher rates in men, with comorbidity score 2.7 vs. 2.1 (p<0.001). Cut flow was higher in men 59.2 vs. 51.1 (p=0.028), but no significant differences were seen in intraoperative bypass flow, cut flow index (CFI), or follow-up QMRA. After removing cases using interposition grafts, similar differences were redemonstrated. Propensity score matched analysis found females have a 2.71 higher chance of bypass occlusion after adjusting for CFI (p=0.017, 95% CI: 1.19-6.18).  ConclusionBiological sex appears to play a significant role in bypass patency, across diagnoses. Women were significantly less likely to have patent bypasses at last follow-up, despite having less medical comorbidities than men and despite having similar intraoperative and perioperative flows. Further study is required to better elucidate the influence of sex on long-term bypass patency.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cascaded Multimodal Deep Learning in the Differential Diagnosis, Progression Prediction, and Staging of Alzheimer's and Frontotemporal Dementia\nAbstract: Dementia syndromes are complex sequelae whose multifaceted nature poses significant challenges in the diagnosis, prognosis, and treatment of patients. Despite the availability of large open-source data fueling a wealth of promising research, effective translation of preclinical findings to clinical practice remains difficult. This barrier is largely due to the complexity of unstructured and disparate preclinical and clinical data, which traditional analytical methods struggle to handle. Novel analytical techniques involving Deep Learning (DL), however, are gaining significant traction in this regard. Here, we have investigated the potential of a cascaded multimodal DL-based system (TelDem), assessing the ability to integrate and analyze a large, heterogeneous dataset (n=7159 patients), applied to three clinically relevant use cases. Using a Cascaded Multi-Modal Mixing Transformer (CMT), we assessed TelDems validity and (using a Cross Modal Fusion Norm - CMFN) model explainability in (i) differential diagnosis between healthy individuals, AD, and three sub-types of frontotemporal lobar degeneration (ii) disease staging from healthy cognition to mild cognitive impairment (MCI) and AD, and (iii) predicting progression from MCI to AD. Our findings show that the CMT enhances diagnostic and prognostic accuracy when incorporating multimodal data compared to unimodal modeling and that cerebrospinal fluid (CSF) biomarkers play a key role in accurate model decision making. These results reinforce the power of DL technology in tapping deeper into already existing data, thereby accelerating preclinical dementia research by utilizing clinically relevant information to disentangle complex dementia pathophysiology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integrating Transfer Learning and Attention Mechanisms for Accurate ALS Diagnosis and Cognitive Impairment Detection\nAbstract: Amyotrophic lateral sclerosis (ALS) is a fatal neurological disease characterized by motor deterioration and cognitive decline, leading to respiratory failure. Early diagnosis is crucial but challenging due to the undefined risk population and the complexity of sporadic ALS. In this study, we used a dataset of 190 autopsy brain images from the Gregory Laboratory at the University of Aberdeen to develop Miniset-DenseSENet, a convolutional neural network combining DenseNet121 with a Squeeze-and-Excitation (SE) attention mechanism. Our model not only distinguishes ALS patients from control groups with 97.37% accuracy but also detects cognitive impairments, which are increasingly recognized as a critical but underdiagnosed feature of ALS. Miniset-DenseSENet outperformed other transfer learning models, achieving a sensitivity of 1 and specificity of 0.95. These findings suggest that integrating transfer learning and attention mechanisms into neuroimaging analysis could enhance clinical diagnostic capabilities, enabling earlier and more accurate diagnosis of ALS and cognitive impair-ment. This approach has the potential to improve patient stratification, guide clinical decision-making, and inform the development of personalized therapeutic strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Causal Association Between Blood Lipids and Breast Cancer in African Women: A Mendelian Randomization study\nAbstract: Blood lipids are associated with breast cancer. An increasing number of reports have attempted to explore the genetic connection between blood lipids and the risk of developing breast cancer. However, observational studies can be affected by confounding factors and reverse causation, which can compromise the reliability of the findings. We used univariate and multivariable two-sample mendelian randomization to explore the causal association between blood lipids and breast cancer. Summary-level data for lipid traits were obtained from the Africa Wits-INDEPTH partnership for Genomic Research (AWI-Gen) (N= 10,603, 58.5% of women). For breast cancer, we leveraged summary statistics from the most comprehensive Genome-wide Association Studies (GWAS) on breast cancer consisting of 18,034 cases and 22,104 controls of women of African ancestry. Our analysis suggests that genetically predicted triglycerides had a potential protective effect on breast carcinoma (OR = 0.73, 95% CI = 0.56, 0.95, FDR = 0.001). We found no evidence that genetically elevated levels of TC, HDL, and LDL may be associated with the risk of breast cancer TC (OR = 1.04; 95% CI, 0.93, 1.18; FDR = 0.029); HDL (OR = 1.29, 95% CI = 0.93, 1.79, FDR = 0.008); LDL (OR = 1.04, 95% CI = 0.90, 1.20, FDR = 0.036). Multivariate mendelian randomization analysis, which adjusted for the effects of TG, TC, LDL, and HDL, attenuated the observation of TG and breast cancer and also found no relationship between TC, HDL, LDL, and breast cancers. Furthermore, there was no evidence for a causal association between lipid traits and breast cancer subtypes. Our findings were robust in several sensitivity analyses. This study provides strong evidence that circulating TG may be associated with a decreased risk of breast cancer, while TC, LDL and HDL may not be related to the risk of breast cancer among African women.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Large-scale multi-omic analysis identifies noncoding somatic driver mutations and nominates ZFP36L2 as a driver gene for pancreatic ductal adenocarcinoma\nAbstract: Identification of somatic driver mutations in the noncoding genome remains challenging. To comprehensively characterize noncoding driver mutations for pancreatic ductal adenocarcinoma (PDAC), we first created genome-scale maps of accessible chromatin regions (ACRs) and histone modification marks (HMMs) in pancreatic cell lines and purified pancreatic acinar and duct cells. Integration with whole-genome mutation calls from 506 PDACs revealed 314 ACRs/HMMs significantly enriched with 3,614 noncoding somatic mutations (NCSMs). Functional assessment using massively parallel reporter assays (MPRA) identified 178 NCSMs impacting reporter activity (19.45% of those tested). Focused luciferase validation confirmed negative effects on gene regulatory activity for NCSMs near CDKN2A and ZFP36L2. For the latter, CRISPR interference (CRISPRi) further identified ZFP36L2 as a target gene (16.0 - 24.0% reduced expression, P = 0.023-0.0047) with disrupted KLF9 binding likely mediating the effect. Our integrative approach provides a catalog of potentially functional noncoding driver mutations and nominates ZFP36L2 as a PDAC driver gene.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Large-scale multi-omic analysis identifies noncoding somatic driver mutations and nominates ZFP36L2 as a driver gene for pancreatic ductal adenocarcinoma\nAbstract: Identification of somatic driver mutations in the noncoding genome remains challenging. To comprehensively characterize noncoding driver mutations for pancreatic ductal adenocarcinoma (PDAC), we first created genome-scale maps of accessible chromatin regions (ACRs) and histone modification marks (HMMs) in pancreatic cell lines and purified pancreatic acinar and duct cells. Integration with whole-genome mutation calls from 506 PDACs revealed 314 ACRs/HMMs significantly enriched with 3,614 noncoding somatic mutations (NCSMs). Functional assessment using massively parallel reporter assays (MPRA) identified 178 NCSMs impacting reporter activity (19.45% of those tested). Focused luciferase validation confirmed negative effects on gene regulatory activity for NCSMs near CDKN2A and ZFP36L2. For the latter, CRISPR interference (CRISPRi) further identified ZFP36L2 as a target gene (16.0 - 24.0% reduced expression, P = 0.023-0.0047) with disrupted KLF9 binding likely mediating the effect. Our integrative approach provides a catalog of potentially functional noncoding driver mutations and nominates ZFP36L2 as a PDAC driver gene.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prognostic Value of CD8+ T-Cells at the Invasive Margin is Comparable to Immune Score in Non-Metastatic Colorectal Cancer: Prospective Multicenter Cohort Study\nAbstract: BackgroundThe Immunoscore(R) is a validated tool for predicting colorectal cancer (CRC) prognosis, yet its adoption is impeded by complex commercial software and patient reimbursement challenges. Utilizing open-source methods, this study aimed to explore whether an immune cell score can be facilitated by focusing on single T-cell markers, to provide a simplified prognostic model in non-metastatic CRC.  MethodsA multicentric prospective cohort study was conducted in non-metastatic CRC patients who underwent curative surgical resection. CD3+ and CD8+ tumor infiltrating lymphocytes (TILs) were quantified in both invasive margin (IM) and tumor core (TC) using QuPath. A composite score, termed immune cell score, mirroring the methods employed for the Immunoscore(R), was calculated based on the TIL densities (CD3-IM, CD8-IM, CD3-TC, CD8-TC]. We used a split sample approach (70:30) to estimate adjusted hazard ratios of cancer-specific survival (CSS) in a training and a validation set. Classification and regression tree analysis (CART) was performed to select the most prognostic TIL. The model incorporating the CART-selected TIL was compared to a two-tiered immune cell score model for overall performance (Brier score) and discrimination (concordance probability estimate, CPE).  ResultsDuring a median follow-up time of 9.0 years, among 1260 patients, there were 203 CRC specific deaths. CART-selected CD8-IM was the most prognostic TIL at a cut-off of 231 cells/mm2. Patients with CD8-IMHi had better CSS than CD8-IMLow in both training (HR 0.58, 95% CI 0.40-0.84) and validation sets (HR 0.35, 95% CI 0.21-0.60). Brier scores of CD-8IM and immune cell score survival models were comparable in both training and validation cohort, whereas the survival discrimination of CD8-IM slightly outperformed the immune cell score in the validation set (CPE: CD8-IM 0.748, IS 0.730).  ConclusionA single TIL marker, specifically CD8-IM, provided prognostic information comparable to the immune cell score. Simplified and cost-effective TIL assessments could enhance their bench to bedside translation and may guide adjuvant therapy in early-stage CRC.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal analysis of genetic and environmental interplay in human metabolic profiles and the implication for metabolic health\nAbstract: BackgroundUnderstanding how genetics and environmental factors shape human metabolic profiles is crucial for advancing metabolic health. Variability in metabolic profiles, influenced by genetic makeup, lifestyle, and environmental exposures, plays a critical role in disease susceptibility and progression.  MethodsWe conducted a two-year longitudinal study involving 101 clinically healthy individuals aged 50 to 65, integrating genomics, metabolomics, lipidomics, proteomics, clinical measurements, and lifestyle questionnaire data from repeat sampling. We evaluated the influence of both external and internal factors, including genetic predispositions, lifestyle factors, and physiological conditions, on individual metabolic profiles. Additionally, we developed an integrative metabolite-protein network to analyze protein-metabolite associations under both genetic and environmental regulations.  ResultsOur findings highlighted the significant role of genetics in determining metabolic variability, identifying 22 plasma metabolites as genetically predetermined. Environmental factors such as seasonal variation, weight management, smoking, and stress also significantly influenced metabolite levels. The integrative metabolite-protein network comprised 5,649 significant protein-metabolite pairs and identified 87 causal metabolite-protein associations under genetic regulation, validated by showing a high replication rate in an independent cohort. This network revealed stable and unique protein-metabolite profiles for each individual, emphasizing metabolic individuality. Notably, our results demonstrated the importance of plasma proteins in capturing individualized metabolic variabilities. Key proteins representing individual metabolic profiles were identified and validated in the UK Biobank, showing great potential for predicting metabolic diseases and metabolic risk assessment.  ConclusionsOur study provides longitudinal insights into how genetic and environmental factors shape human metabolic profiles, revealing unique and stable individual metabolic profiles. Plasma proteins emerged as key indicators for capturing the variability in human metabolism and assessing metabolic risks. These findings offer valuable tools for personalized medicine and the development of diagnostics for metabolic diseases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ancestry and somatic profile predict acral melanoma origin and prognosis\nAbstract: Acral melanoma, which is not ultraviolet (UV)-associated, is the most common type of melanoma in several low- and middle-income countries including Mexico. Latin American samples are significantly underrepresented in global cancer genomics studies, which directly affects patients in these regions as it is known that cancer risk and incidence may be influenced by ancestry and environmental exposures. To address this, here we characterise the genome and transcriptome of 128 acral melanoma tumours from 96 Mexican patients, a population notable because of its genetic admixture. Compared with other studies of melanoma, we found fewer frequent mutations in classical driver genes such as BRAF, NRAS or NF1. While most patients had predominantly Amerindian genetic ancestry, those with higher European ancestry had increased frequency of BRAF mutations and a lower number of structural variants. These BRAF-mutated tumours have a transcriptional profile similar to cutaneous non-volar melanocytes, suggesting that acral melanomas in these patients may arise from a distinct cell of origin compared to other tumours arising in these locations. KIT mutations were found in a subset of these tumours, and transcriptional profiling defined three expression clusters; these characteristics were associated with overall survival. We highlight novel low-frequency drivers, such as SPHKAP, which correlate with a distinct genomic profile and clinical characteristics. Our study enhances knowledge of this understudied disease and underscores the importance of including samples from diverse ancestries in cancer genomics studies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Textual Triage: Assessing GPT4 for Classification of Free-Text Medication-Related Messages for Hypertension Management\nAbstract: Patient-generated free-text messages are a well-recognized source of clinical burden and burnout for clinicians. Machine learning approaches such as Large Language Models (LLMs) may be applied to alleviate this burden by automatically triaging and classifying messages, but their performance in this domain has not been fully characterized. In this study, we analyzed the effectiveness of GPT4 for classifying patient and provider messages for hypertension management through prompt engineering, comparing its performance to an alternative unsupervised generative statistical approach. The results of this study suggest GPT is promising for classification of medical-related messages even with very few guiding examples.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Drinking motives and alcohol sensitivity mediate multi-dimensional genetic influences on alcohol use behaviors\nAbstract: BackgroundGenetic influences account for a substantial proportion of individual differences in alcohol use behaviors (AUBs). However, multiple distinct sets of genes are linked to different AUBs, which may explain their dramatic variability in risk factors and manifestations. In this study, we explore whether intermediate neurobiological traits and alcohol-related cognitions mediate the relationship between polygenic scores (PGS) and multiple AUBs, with the aim to better understand processes captured by different genetic profiles.  MethodsUsing results from prior genome-wide association studies, we derived PGS for 6 AUBs in participants from Spit for Science, a longitudinal study of college students in the U.S. (n=4,549). Self-report measures included personality traits, alcohol expectancies, drinking motivations, and alcohol sensitivity measures as well as drinking frequency, drinking quantity, alcohol use disorder (AUD) symptoms, and maximum drinks in 24 hours. Using linear regression and multiple mediation models, we investigated the direct and indirect effects of PGS on AUBs.  ResultsIn univariable regression results, PGSs indexing broad AUB dimensions such as drinks per week (DPW) and AUD predicted higher levels of sensation-seeking and multiple drinking motives, while BeerPref PGSs (indexing a variable pattern of alcohol problems associated with a preference for beer) predicted higher negative urgency and lower alcohol sensitivity. Mediational models indicated strong direct and indirect effects of DPW PGSs on multiple AUBs via social/enhancement drinking motives and alcohol sensitivity, indirect effects of AUD PGSs on AUD symptoms via coping motives, and indirect effects of BeerPref PGS on all AUBs via the joint effect of mediators including alcohol sensitivity.  ConclusionsThese findings provide initial evidence that the genetic influences on different AUBs are associated with and partially mediated by intermediate neurobiological and cognitive factors, which may be more amenable to intervention. Greater focus on drinking motives and alcohol sensitivity is warranted in genetic research, as well as attention to the heterogeneous pathways linking genes to alcohol use outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Informing an Intervention to Improve Access to Community Pharmacist-Provided Injectable Naltrexone for Formerly Incarcerated Individuals in Wisconsin\nAbstract: In Wisconsin, opioid use disorder (OUD) is highly prevalent among individuals impacted by the criminal justice system. Medications for opioid use disorder (MOUD), including injectable naltrexone, are crucial for treating OUD and especially important for individuals transitioning out of correctional facilities and back into the community. Unfortunately, few formerly incarcerated individuals are able to access MOUD upon community reentry, remaining at high risk of overdose and rearrest. Community pharmacists are a promising resource for providing injectable naltrexone to formerly incarcerated individuals using this treatment option, but are underutilized during reentry planning and by formerly incarcerated individuals upon release. This is due, in large part, to several barriers that exist across the socioecological scale. Accordingly, this study utilized a participatory design process to inform an intervention that address these barriers and improves access to community pharmacist-provided injectable naltrexone for formerly incarcerated individuals upon community reentry. Three iterative focus groups were conducted with five community pharmacists who have experience providing injectable naltrexone and treating formerly incarcerated patients. The goals of each focus group were to: 1) discuss perceptions of existing barriers and prioritize barriers to be addressed, 2) discuss and rank potential interventions to address the prioritized barriers, and 3) discuss components and anticipated challenges related to the prioritized intervention. Focus groups were analyzed via deductive content analysis using a priori categories. Based on discussions of perceived impact and feasibility, the participants prioritized two barriers to be addressed: lack of awareness of community pharmacist-provided injectable naltrexone services and lack of interagency collaboration among primary care clinics, community pharmacies, and correctional facilities. The final intervention included pharmacist-led educational meetings with correctional providers and reentry staff. Several intervention components and anticipated challenges were also identified. Next steps include developing, implementing, and evaluating the efficacy of the intervention on improving access to community pharmacist-provided injectable naltrexone for formerly incarcerated individuals.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Associations of Genetic Variants in the Dopamine Transporter with Problematic Sexual Behavior and Reward Deficiency Syndrome\nAbstract: ObjectivesProblematic sexual behavior (PSB) is defined by recurrent sexual behaviors that are difficult to control, causing social and functional impairments. PSB can co-occur with reward deficiency syndrome (RDS), but this relationship remains unclear. RDS has been associated with the 10/10 genotype of 3 variable number tandem repeat (VNTR) in the dopamine transporter gene SLC6A3, which is implicated in the reward pathway. This study investigates the genetic relationship between PSB and RDS, testing their association with SLC6A3 3 VNTR genotype.  MethodsPSB patients from addiction treatment facilities (n=454), and comparison participants (with PSB=82; without PSB, n=888) were recruited. PSB was measured by the Sexual Addiction Screening Test-Revised (SAST-R) Core and RDS was measured using a composite variable from a custom test battery. DNA was collected from saliva and buccal swabs. Genotyping was performed using polymerase chain reaction (PCR), and regression analyses were conducted to investigate the association of SLC6A3 3 VNTR genotype with PSB and RDS.  ResultsThe 10/10 genotype of SLC6A3 3 VNTR was associated with RDS in a combined analysis of all groups, and with PSB only in comparison participants. In patients, rare SLC6A3 3 VNTR genotypes (3-, 6-, 8-, 11-repeat alleles) were associated with PSB. No genotype showed relationships to RDS in only PSB patients.  ConclusionsThe link of the 10/10 genotype to RDS indicates that PSB could be a manifestation of RDS in non-clinical populations; rare genotypes might be associated with clinical forms of PSB, together with comorbid psychopathology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Medication adherence and hospitalizations in older patients with coronary heart disease in Vietnam\nAbstract: AimThis study aimed to assess medication adherence among older people with coronary heart disease and its relationship with hospitalizations.  MethodsThis is a prospective cohort study conducted at the outpatient clinics of a major hospital in Vietnam from November 2022 to June 2023. Consecutive older patients with coronary heart disease were recruited and followed for 6 months. Medication adherence was defined using the five[item Medication Adherence Report Scale (MARS-5). Multivariable logistic regression models were applied to examine the impact of medication adherence on hospitalization due to cardiovascular disease (CVD) and all-cause hospitalization.  ResultsThere were 643 participants. They had a mean age of 73 (SD 8), and 74.3% were male. Overall, 76.4% (491/643) were classified as \"adherence\". Over 6 months follow-up, 23.3% of the participants admitted to hospital (9.2% were CVD-hospitalization). The CVD-hospitalization rate was significantly higher in the non-adherence group compared to the adherence group (13.8% versus 7.7%, p = 0.023, respectively). In logistic regression models, medication adherence was associated with a significant reduced odds of CVD hospitalization (adjusted OR 0.48, 95%CI 0.27 - 0.86). Medication adherence was also associated with a trend of reduced all-cause hospitalization (adjusted OR 0.75, 95%CI 0.49 - 1.15).  ConclusionsThis study showed a positive relationship between medication adherence and reduced risk of CVD hospitalization in older people with coronary heart disease. Healthcare providers should consider incorporating adherence assessment into the long-term care for older patients with coronary heart disease.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparison of the Ecological Footprints of administering Salbutamol by Metered-Dose Inhaler and by Nebulization in Emergency Treatment of Acute Asthma\nAbstract: BackgroundThe scientific evidence indicates little or no difference in the effectiveness or cost of using of metered-dose inhalers (MDIs) versus nebulization to treat acute asthma in the emergency department (ED). However, the use of MDIs raises questions of environmental impact. The objective of this study was to compare the carbon footprint of salbutamol administered by MDI versus nebulization.  MethodsApplying a life cycle assessment methodology, we quantified the resources extracted and pollutants emitted by each therapeutic option, from the factory production of medication and equipment to disposal by incineration. Each piece of inventory data was then translated into CO2-equivalent emissions (CO2eq) using the IPCC2021/GWP100 method. Results were estimated for the administration of 1 and 3 treatments of 800 {micro}g of salbutamol by MDI and 5 mg by nebulization (standard doses for adults and children [&ge;] 24 kg) and compared to the use of a subcompact car.  ResultsOne and three ED-administered treatments with salbutamol emit respectively 1.9 and 4.0 kg of CO2eq via MDI versus 0.9 and 1.0 kg via nebulization, which corresponds to 5.5 km and 11.6 km and to 2.7 km and 2.8 km traveled in a subcompact car. Each series of 8 inhalations from an MDI releases 1.1 kg of CO2eq due to emission of the hydrofluoroalkane propellent.  InterpretationConsidering the absence or minimal difference in clinical effectiveness, this study suggests that nebulization may be a more eco-efficient administration route than MDIs in the emergency treatment of asthma.  Trail registrationN/A  TAKE-HOME POINTSO_ST_ABSStudy questionC_ST_ABSWhat is the ecological footprint of metered-dose inhalers compared to nebulization for administering salbutamol when treating a patient with acute asthma in the emergency department?  ResultsNebulization was found to have half the carbon footprint of 1 MDI administration and one quarter of 3 MDI administrations.  InterpretationImplementing low-emission treatment protocols for acute asthma should be one of many avenues to explore to achieve net-zero greenhouse gas emissions in healthcare services.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Personal Involvement with Celiac Disease as a Motive for Research among Celiac Disease Researchers\nAbstract: IntroductionWe investigated the frequency of personal involvement with celiac disease (CeD) among CeD researchers and their motive to pursue CeD research, compared to researchers in inflammatory bowel disease (IBD) or type 1 diabetes (T1D) research.  MethodsAn online survey was sent to CeD, IBD and T1D researchers.  Results42% of CeD researchers had an involvement with their research interest, which was similar to T1D (51%) and significantly higher than the IBD respondents (27%, p<0.02).  DiscussionPersonal involvement is common among the CeD researchers. Personal involvement with the disease may be beneficial when conducting patient-oriented research.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: DrugOn: A Comprehensive Drug Ontology for Precision Oncology\nAbstract: IntroductionPrecision oncology and biomedical cancer research increasingly rely on tools to select optimal drugs targeting specific genetic alterations in cancer. A major challenge for bioinformatic tools supporting drug selection is to standardize different annotations (substance, drug name, drug class) to a common level, typically the drug class. While manual classification is time-consuming and potentially biased, existing resources often lack completeness, granularity, or mix up drug classes and drug targets. A structured, automatically built drug ontology such as DrugOn fills these gaps, improving decision support and data-driven research.  MethodsDrugOn integrates information from multiple sources to create a comprehensive drug ontology. It includes categories, molecular targets and additional annotations from DrugBank, ATC, MesH, KEGG and ClueIO. The combination of this data enables accurate identification of drug categories for each drug.  ResultsDrugOns effectiveness was demonstrated by classifying 336 drugs from CIViC. It agreed with manually curated database-derived classifications for 268 out of 282 drugs assessed in translational lymphoma research. In 54 cases, classification was not possible due to data gaps. DrugOn provides a REST API and a front-end application for ontology exploration and automated drug queries.  ConclusionDrugOn, a unified drug ontology, is derived from public datasets and refined by precise processing rules to ensure a reliable, updatable resource for drug information, in precision medicine. It uniquely categorizes drug classes and target proteins, and its structured format, complemented by an accessible API, allows for easy integration into data driven pipelines. Initially tailored for lymphoma research, DrugOns adaptable nature supports broader cancer research applications and potential data source expansions. DrugOn is accessible at https://mtb.bioinf.med.uni-goettingen.de/drugon-web.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multiband EEG signature decoded using machine learning for predicting rTMS treatment response in major depression\nAbstract: Major depressive disorder (MDD) is a global health challenge with high prevalence. Further, many diagnosed with MDD are treatment resistant to traditional antidepressants. Repetitive transcranial magnetic stimulation (rTMS) offers promise as an alternative solution, but identifying objective biomarkers for predicting treatment response remains underexplored. Electroencephalographic (EEG) recordings are a cost-effective neuroimaging approach, but traditional EEG analysis methods often do not consider patient-specific variations and fail to capture complex neuronal dynamics. To address this, we propose a data-driven approach combining iterated masking empirical mode decomposition (itEMD) and sparse Bayesian learning (SBL). Our results demonstrated significant prediction of rTMS outcomes using this approach (Protocol 1: r=0.40, p<0.01; Protocol 2: r=0.26, p<0.05). From the decomposition, we obtained three key oscillations: IMF-Alpha, IMF-Beta, and the remaining residue. We also identified key spatial patterns associated with treatment outcomes for two rTMS protocols: for Protocol 1 (10Hz left DLPFC), important areas include the left frontal and parietal regions, while for Protocol 2 (1Hz right DLPFC), the left and frontal, left parietal regions are crucial. Additionally, our exploratory analysis found few significant correlations between oscillation specific predictive features and personality measures. This study highlights the potential of machine learning-driven EEG analysis for personalized MDD treatment prediction, offering a pathway for improved patient outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mental health clinicians' information-seeking and use of Wikimedia platforms\nAbstract: Internet sites are increasingly being used to disseminate clinical resources to mental health clinicians. Wikimedia platforms (e.g., Wikipedia and Wikiversity) are open-source, freely available resources that are among the most visited websites and could be an effective way to disseminate mental health information. An important first step in learning how to optimize the impact of such dissemination efforts is to understand how and for what reasons practicing clinicians already engage with these resources. Using a convenience sample of 120 practicing mental health clinicians (82.5% female, 85.6% white, M age = 41.31), we assessed clinician- reported practices about where and how they seek information about psychological science on the internet. Our results showed that freely available resources related to mental health are not a primary source of information for mental health clinicians and that clinicians have low confidence in the veracity of information available through Wikipedia and Wikiversity. Clinicians shared strategies (e.g., implementing verification steps on Wiki platform pages) that could increase clinician confidence in the information provided and their likelihood of using these sites as resources. Overall, this study indicates that mental health clinicians are not regularly using Wiki sites for mental health-related questions, even though they are accessible, regularly updated, and increasingly reliable. Findings suggest that implementing verification steps on Wiki pages could increase clinicians confidence in the information provided and their likelihood in using these sites as resources, however, it remains unclear whether verification steps would lead to more frequent use or how such a system would be implemented through existing platforms. Results will help guide future dissemination efforts to increase the availability and utilization of evidence-based psychological science online for clinicians.  Author SummaryOver the past few decades, we have seen a boom in psychological research and innovation. However, the results of this work exist primarily behind academic firewalls, making it difficult for clinicians to access information describing advancements in their field. As clinicians are best positioned to immediately address the global mental health crisis, their inability to make use of the most up-to-date research has a significant, negative impact on the quality of available mental healthcare. Wikipedia and Wikiversity present a possible solution: they are among the most utilized information sites in the world and could be a great tool for providing mental health clinicians with evidence-based psychological resources. In this study, we surveyed clinicians about their online information-seeking habits and found that Wiki platforms are not a main source of information for clinicians, who reported low confidence in the quality of information on these sites. However, survey results also indicated that implementing verification steps on Wiki pages could increase clinicians confidence and willingness to use them. Our results provide guidance on how evidence-based psychological science can be made available on the internet in a way that will increase its utilization and best support clinicians.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Indirect costs and scientific impact at NIMH\nAbstract: The National Institutes of Health (NIH) awards additional funds for extramural research to support research infrastructure and administration, such that the total cost of a given research project depends on where it is conducted. We sought to understand whether greater indirects were associated with a greater scientific impact of NIH-funded work. The NIH RePORTER database was queried to retrieve all R01, R21, or R03-funded research proposals for which NIMH was listed as the primary funding source for proposals funded between 2012 and 2023. We applied multiple regression to examine the association between indirect rate and measures of scientific impact, including number of publications, their citation impact in terms of H-index per grant and total citations, and the number of patents associated with each grant. Of 5,143 projects, reflecting $9.85 billion, mean indirect rate was 47.9% (SD 16.2%). Greater indirect rate was associated with modest but statistically significantly greater number of publications (+0.30 per 10% increase in indirect rate, 95% CI 0.08-0.51); H-index at 5 years (+0.25 per 10% increase in indirect rate, 95% CI 0.18-0.33; Figure 1); and total citations (+29.71 per 10% increase in indirect rate, 95% CI 17.86-41.57). Each 10% increase in indirect rate was associated with a 20% increase in odds of patent filing (aOR 1.20, 95% CI 1.05-1.37). The results suggest small incremental benefits from conduct of research at higher-cost institutions and provide data for policymakers to consider in weighing the costs against potential benefits of work at such institutions.  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=200 SRC=\"FIGDIR/small/24314209v1_fig1.gif\" ALT=\"Figure 1\"> View larger version (20K): org.highwire.dtl.DTLVardef@321fe6org.highwire.dtl.DTLVardef@cc3523org.highwire.dtl.DTLVardef@b4bb67org.highwire.dtl.DTLVardef@17b71cf_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOFigure 1.C_FLOATNO Multiple linear regression model of association between indirect rate and H-index at five years  C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring a roadmap to achieving tobacco endgame in sub-Saharan Africa: A qualitative study among stakeholders from 12 countries\nAbstract: IntroductionTobacco endgame seeks to bring an end to tobacco use or drastically reduce prevalence to <5%. Discussions about tobacco endgame and the possible strategies to achieve this goal in Sub-Saharan African (SSA) are sparse. This study aimed to explore SSA tobacco control stakeholders perspectives about tobacco endgame and ascertain what strategies they perceive to be suitable for the region to achieve this.  MethodsThis was a qualitative study involving a purposive sample of 29 stakeholders interviewed via online platforms guided by a semi-structured interview schedule. Stakeholders were from academia, civil society, and government departments in 12 SSA countries. Interviews were conducted in English or French, transcribed verbatim (those in French were translated to English) and thematically analyzed with the aid of NVIVO v12.  ResultsThere is support for the adoption of tobacco endgame in SSA by tobacco control stakeholders in in the region due to the impact tobacco has on health, the environment and economy. Proposed endgame approaches for SSA were recommended to be Afrocentric which must be sensitive to cultural and regional dynamics. Stakeholders believed that the success of endgame strategies depends on political will, multi-sectoral collaboration, availability of resources, buy-in from the public and tobacco industry monitoring. Suggested endgame strategies were categorized into 5 themes: Product-focused (less addictive tobacco and regulation of novel products); User-focused (smoke-free generation, cessations supports and use of sports); Market/supply-focused (licensing of sellers, increase in taxes, control of illicit trade and alternative income for farmers); Institutional structure-focused (tobacco industry monitoring and regulation) and legislation implementation-focused (effective implementation of international treaties aimed at lowering tobacco use prevalence).  ConclusionThere is support for a tobacco endgame in SSA. Collaboration from various departments/ministries, and support from government and the public would be needed to make tobacco endgame a reality in SSA.  Key HighlightsO_LIDiscussion on how to end tobacco use (endgame) in Sub-Saharan African (SSA) is sparse. C_LIO_LITobacco control stakeholders in SSA are supportive of tobacco endgame for the region. C_LIO_LIAfrocentric endgame strategies sensitive to culture and countries peculiarities are needed. C_LIO_LIUser, product and supply focused, as well as institutional and legislation focused strategies have been proposed. C_LIO_LIProposed endgame strategies must include alternative income for farmers and cessation support. C_LIO_LISupport from SSA governments and the public, and tobacco industry monitoring are needed for successful implementation of tobacco endgame in SSA. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Amygdala subregional functional connectivity in Treatment-Resistant Depression\nAbstract: BackgroundTreatment resistance impacts almost 50% of depression patients, with amygdala dysfunction being widely implicated. The amygdala is a complex amalgamation of subnuclei with diverse functions but fMRI studies have typically focussed on identifying whole rather than subregional amygdala functional connectivity. This study used high resolution 3T fMRI data to investigate subregional alterations that may differentiate treatment-resistant cohorts from healthy individuals and depressed patients who respond to treatment.  MethodsResting-state fMRI data were obtained in 35 participants diagnosed with Treatment-Resistant Depression (TRD), 38 healthy control participants (HC), and 35 treatment-sensitive participants (TSD). Seed-based functional connectivity analyses of the three main subregions bilaterally (laterobasal, centromedial and superficial), as well as the whole amygdala, were performed and comparisons made between groups.  ResultsWe found connectivity differences in the right laterobasal amygdala subregion in TRD compared to both groups. TRD patients displayed hypoconnectivity to the right fusiform gyrus relative to HC whereas hyperconnectivity to the left inferior frontal gyrus relative to TSD was identified. No connectivity differences were found for the whole amygdala or any of the other subregions bilaterally.  LimitationsModest sample size and cross-sectional study design are limitations. A causal relationship between functional connectivity alterations and treatment resistance cannot be established.  ConclusionAltered connectivity of the right laterobasal subregion is a distinguishing feature of TRD. These alterations may underlie severe impairments in emotion processing and social functioning that are characteristic of TRD. These results emphasise the need for further investigation of the functional role of the amygdala subregions in depression.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prodrug BMP-7 attenuates pulmonary fibrosis through downregulation of bone marrow derived ApoE+ alveolar macrophage\nAbstract: BackgroundBone morphogenetic protein-7 (BMP-7) antagonises transforming growth factor-{beta} (TGF-{beta}). This study investigated the ability of a prodrug BMP-7, designed as micelle nanoparticles for nasal inhalation, to ameliorate pulmonary fibrosis in a bleomycin (BLM)-induced murine model.  Materials and MethodsFluorescently labelled BMP-7 was delivered to murine lungs via nasal inhalation. Thirty-eight C57BL/6J mice were divided into three groups: control, BLM and BLM with prodrug BMP-7. We then administered the prodrug BMP-7 and vehicle nasally every 72 hours for 21 days. Single-cell RNA sequencing was performed on bronchoalveolar lavage fluid (BALF) from 18 mice, divided into four groups: control, prodrug BMP-7 alone, BLM and BLM with prodrug BMP-7, to assess effects on alveolar macrophages (AM). The expression of ApoE+ AM was compared between normal and idiopathic pulmonary fibrosis (IPF) patients.  ResultsThe prodrug BMP-7 group showed reduced BALF inflammatory cells and significant fibrosis reduction compared to the BLM group. Western blot showed decreased levels of collagen I, -SMA and fibronectin in the prodrug BMP-7 group, along with downregulation of TGF-{beta}/SMAD signalling. ELISA indicated decreased levels of chemokines CXCL10 and CXCL2 in tissue and BALF. Single-cell RNA sequencing revealed a significant increase in bone marrow-derived ApoE+ AM in the BLM group, which was reduced with prodrug BMP-7. Additionally, ApoE+ expression was higher in IPF patients compared to controls.  ConclusionsProdrug BMP-7 shows potential as a therapeutic agent for pulmonary fibrosis by modulating ApoE+ AM.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Correlates of Self-Sampling Willingness for HPV-DNA Testing among Medically Underserved Rural Kenyan Women: A Mixed Methods Study\nAbstract: IntroductionCervical cancer is the leading cause of cancer-related deaths among Sub-Saharan African women, particularly in rural areas where screening rates are lower due to limited access to highly sensitive tests. This study aimed to investigate factors that might influence rural Kenyan womens willingness to self-collect samples for HPV-DNA testing.  MethodsThis study utilized data from a mixed-methods study in Bomet and Kericho Counties, including survey responses from 174 women and semi-structured interviews with a subset of 21 participants. Logistic regression was used to analyze quantitative data and theoretical thematic analysis for qualitative data.  ResultsThe surveyed women had a mean age of 45.2 years, were mainly uninsured (76%) and from low-income households (88.4%). Most participants had heard of cervical cancer (83.2%), yet only 6.4% had ever been screened. However, 76.9% expressed willingness to self-collect samples for HPV-DNA testing. Factors significantly associated with increased self-sampling willingness were cervical cancer awareness (OR=3.49, 95% CI=1.50-8.11), having health workers (OR=1.88, CI=1.23-2.86) and the news media (radio and television) (OR=2.63, CI=1.27-5.48) as primary sources of health information, and ever hearing about cervical cancer from the news media (OR=2.43, CI=1.07-5.51). Conversely, high cervical cancer stigma (OR=0.71, CI=0.57-0.88) and longer travel time of 30 to 120 minutes to the nearest health facility (OR=0.44, CI=0.20-0.93) were associated with decreased willingness. Interview data corroborated these findings.  ConclusionsCervical cancer screening uptake is notably low among rural Kenyan women in Bomet and Kericho Counties. Sample self-collection for HPV-DNA testing appears widely acceptable. A comprehensive approach involving educational outreach, health worker recommendation, and mass media campaigns could enhance cervical cancer screening via self- sampling, potentially reducing the burden of cervical cancer. Future research should employ implementation science methodologies to explore cervical cancer screening uptake via self- sampling, to inform population-based implementation strategies in Kenya.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Brain-Lung Immunotherapy Prognostic (BLIP) Score: A Novel Robust Tool for Prognostication in Non-Small Cell Lung Cancer Patients with Brain Metastases\nAbstract: BackgroundLung cancer remains the leading cause of cancer-related mortality, with brain metastases (BMs) significantly worsening prognosis and quality of life. The advent of immune checkpoint inhibitors (ICIs) has revolutionized the treatment landscape for non-small cell lung cancer (NSCLC). However, precise prognostic tools are essential to optimize clinical decision-making in this context.  MethodsThe Brain-Lung Immunotherapy Prognostic (BLIP) score was developed based on a retrospective cohort of NSCLC patients treated with ICIs at Karolinska University Hospital, Sweden. Prognostic factors were identified using both univariate and multivariate Cox regression analyses. Internal validation was conducted using bootstrap resampling, penalized Cox regression, k-fold cross-validation, and receiver operating characteristics (ROC) analysis. External validation was performed using an independent cohort from Sotiria Thoracic Diseases Hospital of Athens, Greece.  ResultsFrom a total cohort of 1844 patients screened across both study sites, 152 patients from Karolinska University Hospital and 116 from Sotiria Thoracic Diseases Hospital of Athens, Greece, were included in the final analysis. Key prognostic factors influencing outcomes included histology, actionable mutations, age at BM diagnosis, and the number of BMs. The BLIP score effectively stratified patients into two prognostic groups: \"Good\" and \"Poor\", with a median overall survival (OS) of 15 and 7 months, respectively (hazard ratio [HR]: 0.4; p < 0.0001). External validation confirmed these findings, showing a significantly lower risk of death for the \"Good\" group compared to the \"Poor\" group (HR: 0.49; p = 0.0063). The models robust prognostic performance was confirmed with an area under the ROC curve of 0.87, highlighting its accuracy in predicting survival outcomes.  ConclusionThe BLIP score provides a reliable, validated prognostic tool for NSCLC patients with BMs undergoing ICI therapy. By integrating both molecular and clinical variables, it offers significant improvements over existing models. Prospective validation could further support its use in personalized treatment strategies, improving clinical outcomes and patient management.  HighlightsO_LIThe BLIP score is a new prognostic tool for NSCLC. C_LIO_LIIt focuses on patients with brain metastases undergoing immunotherapy. C_LIO_LIThe score integrates clinical and molecular factors. C_LIO_LIInternal validation showed strong prognostic power and reliability. C_LIO_LIExternal validation confirmed effectiveness across diverse patient populations. C_LIO_LIKey factors include histology, actionable mutations, age, and brain metastases count. C_LIO_LIThe score stratifies patients into \"Good\" and \"Poor\" groups. C_LIO_LIThe BLIP score aids in personalized treatment decision-making. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Improved precision oncology question-answering using agentic LLM\nAbstract: Despite the widespread application of Large Language Models (LLMs) in biomedical research, their clinical adoption faces significant challenges. These challenges stem from concerns about the quality, accuracy, and comprehensiveness of LLM-generated answers. Most existing work has focused on fine-tuning LLMs based on foundation models, which have not yet fully addressed accuracy and reliability issues. In this work, we propose an agent-based approach that aims to make LLM-based systems clinically deployable for precision oncology, while mitigating common pitfalls such as hallucinations, incoherence, and \"lost-in-the-middle\" problems. To achieve this, we implemented an agentic architecture, fundamentally shifting an LLMs role from a simple response synthesizer to planner. This agent orchestrates a suite of specialized tools that asynchronously retrieve information from various sources. These tools include curated document vector stores encompassing treatment guidelines, genomic data, clinical trial information, drug data, and breast cancer literature. The LLM then leverages its planning capabilities to synthesize information retrieved by these tools, generating comprehensive and accurate responses. We demonstrate GeneSilico Copilots effectiveness in the domain of breast cancer, achieving state-of-the-art accuracy. Furthermore, the system showcases success in generating personalized oncotherapy recommendations for real-world cases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Awareness about the risk of hearing loss after ototoxic treatments in Swiss childhood cancer survivors\nAbstract: ObjectiveThe International Guideline Harmonization Group recommended childhood cancer survivors (CCS) exposed to ototoxic treatments be aware of the risk of hearing loss. We assessed awareness among adult CCS.  MethodsWe identified adults diagnosed with cancer <20 years who had received ototoxic treatments through the Swiss Childhood Cancer Registry (ChCR) and invited them to the HEAR-study. Participants completed a questionnaire and underwent pure-tone audiometry. Cancer and treatment data came from the ChCR. We used logistic regression to explore factors influencing awareness.  Results105 of 424 invited CCS participated (25%). 57% did not remember receiving information on hearing loss prior to the study. CCS who remembered being informed were more likely diagnosed after 1995 (OR: 4.5, 95% CI: 1.3-15.4), reported hearing problems (10.9, 2.6-45.1) and other late effects (4.1, 1.3-13.2), and treated with platinum chemotherapy only (10.8, 2.2-53.2) versus cranial radiotherapy only. 44% of participants had clinically relevant hearing loss according to SIOP-Boston ototoxicity scale.  ConclusionsOver half of CCS exposed to ototoxic treatments were unaware of their risk of hearing loss.  Practice ImplicationsEducating CCS about potential late effects of ototoxic treatments is important to allow early diagnosis and treatment, especially for those who had cancer longer ago and those exposed to cranial radiation.  HighlightsO_LIHalf of CCS exposed to ototoxic treatment were unaware of the risk of hearing loss (85/85) C_LIO_LICCS treated before 1995 were less often informed about the risk of hearing loss (84/85) C_LIO_LIInformation provision is key to effective monitoring and early intervention (77/85) C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Awareness about the risk of hearing loss after ototoxic treatments in Swiss childhood cancer survivors\nAbstract: ObjectiveThe International Guideline Harmonization Group recommended childhood cancer survivors (CCS) exposed to ototoxic treatments be aware of the risk of hearing loss. We assessed awareness among adult CCS.  MethodsWe identified adults diagnosed with cancer <20 years who had received ototoxic treatments through the Swiss Childhood Cancer Registry (ChCR) and invited them to the HEAR-study. Participants completed a questionnaire and underwent pure-tone audiometry. Cancer and treatment data came from the ChCR. We used logistic regression to explore factors influencing awareness.  Results105 of 424 invited CCS participated (25%). 57% did not remember receiving information on hearing loss prior to the study. CCS who remembered being informed were more likely diagnosed after 1995 (OR: 4.5, 95% CI: 1.3-15.4), reported hearing problems (10.9, 2.6-45.1) and other late effects (4.1, 1.3-13.2), and treated with platinum chemotherapy only (10.8, 2.2-53.2) versus cranial radiotherapy only. 44% of participants had clinically relevant hearing loss according to SIOP-Boston ototoxicity scale.  ConclusionsOver half of CCS exposed to ototoxic treatments were unaware of their risk of hearing loss.  Practice ImplicationsEducating CCS about potential late effects of ototoxic treatments is important to allow early diagnosis and treatment, especially for those who had cancer longer ago and those exposed to cranial radiation.  HighlightsO_LIHalf of CCS exposed to ototoxic treatment were unaware of the risk of hearing loss (85/85) C_LIO_LICCS treated before 1995 were less often informed about the risk of hearing loss (84/85) C_LIO_LIInformation provision is key to effective monitoring and early intervention (77/85) C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PanCNV Explorer: A pan-cancer database for copy number variations.\nAbstract: IntroductionCopy number variations (CNVs) are structural genomic alterations that involve changes in the number of copies of specific DNA regions. These variations can include deletions, duplications, and more complex rearrangements, and play a critical role in cancer progression by amplifying oncogenes, deleting tumor suppressor genes, or altering other key genomic regions. Despite the importance of CNVs in cancer biology, there is a lack of comprehensive resources that aggregate CNV data across multiple cancer types, impeding the exploration of their role in different malignancies. The PanCNV-Explorer was developed to fill this gap by providing a pan-cancer resource that integrates CNV data for over 21 cancer types.  MethodsThe PanCNV-Explorer was developed, utilizing data from repositories such as COSMIC, DepMap, DGV, and dbVAR. Amplifications and deletions can be visualized, with detailed chromosome-specific plots highlighting CNV patterns. In addition, a genome browser has been implemented to display regions of interest for searching for genes of potential relevance.  ResultsThe database contains over 5 million CNVs from 15,809 samples, spanning 21 primary cancer types. Pathogenic CNVs from ClinVar and DepMap were compared to benign data from DGV and dbVAR, allowing a comprehensive analysis across tissues. CNV patterns were visualized for individual cancers. We demonstrate with use cases, focusing on common oncogenes such as MYC and tumor suppressor genes such as TP53, the ability of the resource to search for cancer driver genes. For example, chromosome 12 in pancreatic cancer showed frequent amplifications in the region containing the KRAS oncogene. In another example, we show how driver gene candidates already described in certain cancer entities can also be found with high frequency in other entities.  ConclusionThe PanCNV-Explorer provides a valuable resource for pan-cancer CNV analysis, facilitating the exploration of CNV-driven tumor heterogeneity. The integrated visualization tools and genome browser enable detailed exploration of genomic regions, enhancing cancer research. As a valuable and easy-to-use platform that allows researchers to quantify and compare CNVs across cancer types, the PanCNV-Explorer is an essential tool for advancing cancer genomics research. The main page is available at https://mtb.bioinf.med.uni-goettingen.de/pancnv-explorer/.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Are Electromyography data a fingerprint for patients with cerebral palsy (CP)?\nAbstract: This study aimed to first investigate changes in electromyography (EMG) patterns after multilevel surgical treatment in patients with cerebral palsy (CP) and then to assess the connection between the measure of EMG and motor control indices and surgery outcomes. We analyzed retrospective EMG and gait data from 167 patients with CP before and after surgery and from 117 typically developed individuals as a reference group. The patients underwent at least one soft tissue surgery on their shank and foot muscles. Using Repeated Measures ANOVA, we examined the norm-distance (ND) of the kinematics, kinetics, and EMG patterns, in addition to the Kerpape-Rennes EMG-based Gait Index (EDI), EMG Profile Score (EPS), and Walking Dynamic Motor Control Index (DMC) before and after surgery. Participants were divided into different response groups (Poor, Mild, and Good gait quality) according to their pre- and post-treatment Gait Deviation Index (GDI), using the K-means-PSO clustering algorithm. The gait and EMG indices were compared between the responders using the nonparametric Mann-Whitney test. The ND for all kinematics and kinetics parameters significantly improved (p-value < 0.05) after the surgery. Regarding EMG, a significant reduction was only observed in the ND of the rectus femoris (p-value < 0.001) and soleus (p-value = 0.006). Among the indices, DMC was not altered post-operatively (p-value = 0.88). Although EDI and EPS were consistent across responders with a similar pre-treatment gait, a higher DMC was significantly associated with a greater improvement, particularly in patients with poor gait (p-value < 0.05). These findings indicate systematic changes in the EMG of patients with CP following surgery, which can also be demonstrated through indices. DMC is a measure that can potentially serve as a partial predictor of outcomes, particularly in patients with poor pre-operative gait. Future research should investigate the effects of different surgical strategies on the improvement of these patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Socio-economic patterns of diet, obesity, and biomarkers for cardiovascular disease among Indian adolescents\nAbstract: BackgroundThe impact of socioeconomic (SES) factors, maternal education and household wealth on diet and consequently on a host of cardiovascular disease (CVD) biomarkers is rarely examined among Indian adolescents, who are in a critical development phase. This study examines the socio-economic patterning of dietary behaviour and its correlation with overweight/obesity and CVD biomarkers among Indian adolescents aged 10 to 19 years.  MethodsWe use nationally representative data on dietary patterns and CVD biomarkers from the Comprehensive National Nutrition Dataset, a nationally representative survey of 35,830 adolescents conducted from 2016 to 2018. Dietary pattern is assessed using a summary indicator-Dietary Diversity Score based on 17 specific food groups. Overweight/obesity and the biomarkers, including the ratio of total cholesterol to high-density lipoprotein-cholesterol, serum triglycerides, hypertension, and pre-diabetic/diabetic, are analysed.  ResultsAdolescents from higher SES have higher dietary diversity than those from lower SES. This socio-economic patterning is concentrated on higher daily consumption of certain foods such as fats and oil, sugar and jaggery and those high in fats, sugar, and salt (HFSS) comprising-junk food, fried food, sweets, and aerated drinks among those from high SES and urban areas. This, in turn, may explain the concentration of overweight/obesity in this cohort. The SES gradient in diet, overweight/obesity, and associated CVD biomarkers among Indian adolescents remains positive for the household wealth index (worse health for the more economically advantaged) and urban dwellers. However, it is starting to shift towards negative for maternal education, resulting in an inverted U shape (better health for the lowest and highest socially advantaged, worse health for those in the middle).  ConclusionsThere is a clustering of overweight/obesity and CVD biomarkers among adolescents from urban and wealthier households that may be associated with increased consumption of HFSS in this cohort.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Using disease symptomatology to guide treatment in patients with central centrifugal cicatricial alopecia: introduction of C-CAT scoring tool\nAbstract: BackgroundCentral centrifugal cicatricial alopecia (CCCA) is a progressive scarring alopecia. No disease activity scale exists, making assessment of therapeutic intervention difficult.  ObjectiveThis study introduces the CCCA Clinical Assessment Tool (C-CAT), a novel scale that quantifies symptom severity to facilitate tailored treatment and track disease progression. Methods: A retrospective review of patients with CCCA were assessed on degree of pruritus, erythema, pain, disease progression, and scalp resistance, each scored from 0-2, over the course of a minimum of six months of therapy.  ResultsEighty-two patients were included. The average initial C-CAT score was 3.4, consistent with mild to moderate disease activity. After six months of treatment, 88% of patients had improvement in score, with 48% of all patients achieving remission. Intralesional kenalog injections and topical clobetasol were the most commonly used therapies. Patients required an average of 3.6 different treatments to achieve therapeutic response.  LimitationsThe subjective nature of some C-CAT components may lead to inter-rater variability.  ConclusionThe C-CAT provides a structured, quantitative method to assess CCCA severity, which facilitates tracking of disease improvement for the majority of patients with targeted therapy. This tool promotes personalized, symptom-based treatment and supports clinicians and patients in understanding this complex condition.  CAPSULE SUMMARYO_LIA novel central centrifugal cicatricial alopecia scoring tool demonstrates that established treatments quantitatively improve symptoms in most patients with central centrifugal cicatricial alopecia over 6 months. C_LIO_LIThe novel disease activity scale guides clinicians in structuring treatment based on specific symptomatology and aids patients in understanding progress. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring the role of Large Language Models in Melanoma: a Systemic Review\nAbstract: BackgroundLarge language models (LLMs) are gaining recognition across various medical fields; however, their specific role in dermatology, particularly in melanoma care, is not well- defined. This systematic review evaluates the current applications, advantages, and challenges associated with the use of LLMs in melanoma care.  MethodsWe conducted a systematic search of PubMed and Scopus databases for studies published up to July 23, 2024, focusing on the application of LLMs in melanoma. Identified studies were categorized into three subgroups: patient education, diagnosis and clinical management. The review process adhered to PRISMA guidelines, and the risk of bias was assessed using the modified QUADAS-2 tool.  ResultsNine studies met the inclusion criteria. Five studies compared various LLM models, while four focused on ChatGPT. Three studies specifically examined multi-modal LLMs. In the realm of patient education, ChatGPT demonstrated high accuracy, though it often surpassed the recommended readability levels for patient comprehension. In diagnosis applications, multi- modal LLMs like GPT-4V showed capabilities in distinguishing melanoma from benign lesions. However, the diagnostic accuracy varied considerably, influenced by factors such as the quality and diversity of training data, image resolution, and the models ability to integrate clinical context. Regarding management advice, one study found that ChatGPT provided more reliable management advice compared to other LLMs, yet all models lacked depth and specificity for individualized decision-making.  ConclusionsLLMs, particularly multimodal models, show potential in improving melanoma care through patient education, diagnosis, and management advice. However, current LLM applications require further refinement and validation to confirm their clinical utility. Future studies should explore fine-tuning these models on large dermatological databases and incorporate expert knowledge.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging the Genetics of Psychiatric Disorders to Prioritize Potential Drug Targets and Compounds\nAbstract: BackgroundGenetics has the potential to inform biologically relevant drug treatment and repurposing which may ultimately improve patient care. In this study, we combine methods which leverage the genetics of psychiatric disorders to prioritize potential drug targets and compounds.  MethodsWe used the largest available genome-wide association studies, in European ancestry, of four psychiatric disorders [i.e., attention deficit hyperactivity disorder (ADHD), bipolar disorder, depression, and schizophrenia] along with genes encoding drug targets. With this data, we conducted drug enrichment analyses incorporating the novel and biologically specific GSA-MiXeR tool. We then conducted a series of molecular trait analyses using large-scale transcriptomic and proteomic datasets sampled from brain and blood tissue. This included the novel use of the UK Biobank proteomic data for a proteome-wide association study of psychiatric disorders. With the accumulated evidence, we prioritize potential drug targets and compounds for each disorder.  FindingsWe reveal candidate drug targets shared across multiple disorders as well as disorder-specific targets. Drug prioritization indicated genetic support for several currently used psychotropic medications including the antipsychotic paliperidone as the top ranked drug for schizophrenia. We also observed genetic support for other commonly used psychotropics (e.g., clozapine, risperidone, duloxetine, lithium, and valproic acid). Opportunities for drug repurposing were revealed such as cholinergic drugs for ADHD, estrogens for depression, and gabapentin enacarbil for schizophrenia. Our findings also indicate the genetic liability to schizophrenia is associated with reduced brain and blood expression of CYP2D6, a gene encoding a metabolizer of drugs and neurotransmitters, suggesting a genetic risk for poor drug response and altered neurotransmission.  InterpretationHere we present a series of complimentary and comprehensive analyses that highlight the utility of genetics for informing drug development and repurposing for psychiatric disorders. Our findings present novel opportunities for refining psychiatric treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Understanding Embolus Transport And Source To Destination Mapping Of Thromboemboli In Hemodynamics Driven By Left Ventricular Assist Device\nAbstract: Left Ventricular Assist Devices (LVADs) are a key treatment option for patients with advanced heart failure, but they carry a significant risk of thromboembolic complications. While improved LVAD design, and systemic anticoagulation regimen, have helped mitigate thromboembolic risks, ischemic stroke due to adverse thromboembolic events remains a major concern with current LVAD therapies. Improved understanding of embolic events, and embolus movement to the brain, is critical to develop techniques to minimize risks of occlusive embolic events such as a stroke after LVAD implantation. Here, we address this need, and devise a quantitative in silico framework to characterize thromboembolus transport and distrbution in hemodynamics driven by an operating LVAD. We conduct systematic numerical experiments to quantify the source-to-destination transport patterns of thromboemboli as a function of: LVAD outflow graft anastomosis, LVAD operating pulse modulation, thromboembolus sizes, and origin locations of emboli. Additionally, we demonstrate how the resulting embolus distribution patterns compare and correlate with descriptors based solely on hemodynamic patterns such as helicity, vorticity, and wall shear stress. Using the concepts of size-dependent embolus-hemodynamics interactions, and two jet flow model for hemodynamics under LVAD operation as established in our prior works, we gain valuable insights on departure of thromboembolus distribution from flow distribution, and establish that our in silico model can generate deep insights into embolus dynamics which is not otherwise available from standard of care imaging and clinical data.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Morphometric variations of human mandible in Indian population: comparison between subjects having healthy and ankylosed temporomandibular joint\nAbstract: The temporomandibular joint (TMJ) helps to perform the functional activities of the oral cavity. Such activities often get affected by end-stage degenerative disorders such as TMJ ankylosis. Alloplastic reconstruction using TMJ implants helps to restore those activities. However, commercially available stock implants often suffer from fit discrepancies in Indian population. Therefore, this study is aimed to compare comparison between mandibular morphometry of subjects with healthy or normal TMJ joints (TMJN) and patients with TMJ ankylosis (TMJA) from the Indian population. Furthermore, the observed mandibular morphometry has also been compared with those of the other populations. In this study, the most useful anatomical parameters of mandible are measured from the CT-based reconstructed mandibles of 367 Indian subjects (199 healthy;168 ankylosis). Significant differences in ramus length (healthy males: 61.74{+/-}7.53 mm, ankylosis males: 46.81{+/-}10.35 mm; healthy females: 55.21{+/-}6.12 mm, ankylosis females: 41.77{+/-}8.57 mm) and condyle width (healthy males: 18.76{+/-}3.22 mm, ankylosis males: 22.67{+/-}5.56 mm; healthy females: 16.94{+/-}2.41 mm, ankylosis females: 21.31{+/-}4.65 mm) have been observed between mandibles of ankylosis and healthy subjects. Differences in ramus length (affected side: 43.87{+/-}9.51 mm; unaffected side: 55.34{+/-}7.12 mm) and condyle width (affected side: 23{+/-}4.68 mm; unaffected side: 17.99{+/-}2.81 mm) were also observed between affected and unaffected sides of mandibles for unilateral ankylosis patients. Ramus length in healthy subjects was found to be the most statistically significant parameter between mandibles of Indians and other populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterizing trachoma elimination using serology\nAbstract: Trachoma is targeted for global elimination as a public health problem by 2030. Measurement of IgG antibodies in children is being considered for surveillance and programmatic decision-making. There are currently no guidelines for applications of serology, which represents a generalizable problem in seroepidemiology and disease elimination. We collated Chlamydia trachomatis Pgp3 and CT694 IgG measurements (63,911 children ages 1-9 years) from 48 serosurveys, including surveys across Africa, Latin America, and the Pacific Islands to estimate population-level seroconversion rates (SCR) along a gradient of trachoma endemicity. We propose a novel, generalizable approach to estimate the probability that population C. trachomatis transmission is below levels requiring ongoing programmatic action, or conversely is above levels that indicate ongoing interventions are needed. We provide possible thresholds for SCR at a specified level of certainty and illustrate how the approach could be used to inform trachoma program decision-making using serology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Personal protective beliefs and behaviors during the COVID-19 pandemic at a large, multi-campus, public university in Pennsylvania: a cross-sectional survey\nAbstract: IntroductionThe COVID-19 pandemic impacted many higher education institutions. Understanding the personal protective beliefs and behaviors surrounding public health measures such as face masking, social distancing, and handwashing helps to inform public health outreach measures.  ObjectiveThis study evaluates the beliefs and occurrences of face masking, social distancing, and handwashing behaviors among people at a multi-campus, public university in Pennsylvania.  MethodsFrom October 5-November 30, 2021, a 10-minute REDCap survey was available to students, faculty, and staff 18 years of age and older at the Pennsylvania State University (PSU). Recruitment included targeted email, social media, digital advertisements, and university newspapers. 4,231 responses were received. Simple percentage associations between the selected factors and face masking behaviors as well as beliefs on the origin of the COVID-19 virus were made with IBM SPSS Statistics, version 29.0.2.0 (20).  ResultsOf 3,662 completed surveys, 65.2% of respondents were positive that facemasks prevented the transmission of airborne disease, 49.9% of the respondents stated that they wore facemasks always (27.9%), almost always (26.9%), or often (11.1%). 65.3% believed social distancing prevented transmission of COVID-19, 57.5% reported social distancing while on-campus or out in public (always: 18.8%, almost always: 20.3%, often: 18.4%). The response rate for some level of conscientiously washing hands for the 20 second duration was 87.5% (always: 26.0%, almost always: 31.9%, sometimes: 19.9%, only after being out in public: 4.9%, and only when convenient: 4.8%).  ConclusionsBeliefs in public health and safety measures during the COVID-19 pandemic did not always match the behaviors of individuals surveyed. Understanding barriers to performing behaviors or public health safety may help inform future areas for targeted intervention.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reduced Cortical Excitability is Associated with Cognitive Symptoms in Concussed Adolescent Football Players\nAbstract: American tackle football is associated with high rates of concussion, leading to neurophysiological disturbances and debilitating clinical symptoms. Previous investigations of the neurophysiological effects of concussion have largely ignored aperiodic neurophysiological activity. We examined whether concussion during a season of high school football is related to changes in aperiodic and periodic neurophysiological activity and whether any such changes are associated with clinical outcomes. Pre- and post-season resting-state MEG data were collected from 91 high school football players, of whom 10 were diagnosed with concussion. Data were source-imaged, frequency-transformed and parameterized, and linear mixed models were used to examine effects of concussion on pre-to-post-season changes in neurophysiological activity. Scores on the Post-Concussive Symptom Inventory were correlated with pre-to-post-season neurophysiological changes to determine their clinical relevance. Concussion was associated with increased aperiodic exponents in superior frontal cortices, indicating a relative reduction in cortical excitability. This slowing of aperiodic neurophysiology mediated concussion effects on raw delta and gamma power and was associated with worse cognitive concerns across participants. Pre-to-post-season changes in aperiodic-corrected alpha and theta rhythmic activity were also decreased in posterior cortices in instances of concussion. These findings indicate that concussion alters both the excitability and rhythmic signaling of the cortex, with differing spatial topographies and implications for clinical symptoms.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The GeoTox Package: Open-source software for connecting spatiotemporal exposure to individual and population-level risk\nAbstract: BackgroundComprehensive environmental risk characterization, encompassing physical, chemical, social, ecological, and lifestyle stressors, necessitates innovative approaches to handle the escalating complexity. This is especially true when considering individual and population-level diversity, where the myriad combinations of real-world exposures magnify the combinatoric challenges. The GeoTox framework offers a tractable solution by integrating geospatial exposure data from source-to-outcome in a series of modular, interconnected steps.  ResultsHere, we introduce the GeoTox open-source R software package for characterizing the risk of perturbing molecular targets involved in adverse human health outcomes based on exposure to spatially-referenced stressor mixtures. We demonstrate its usage in building computational workflows that incorporate individual and population-level diversity. Our results demonstrate the applicability of GeoTox for individual and population-level risk assessment, highlighting its capacity to capture the complex interplay of environmental stressors on human health.  ConclusionsThe GeoTox package represents a significant advancement in environmental risk characterization, providing modular software to facilitate the application and further development of the GeoTox framework for quantifying the relationship between environmental exposures and health outcomes.  By integrating geospatial methods with cutting-edge exposure and toxicological frameworks, GeoTox offers a robust tool for assessing individual and population-level risks from environmental stressors. GeoTox is freely available at https://niehs.github.io/GeoTox/.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bridging Language Gaps in Neurology Patient Education Through Large Language Models: a Comparative Analysis of ChatGPT, Gemini, and Claude\nAbstract: This study evaluates the capability to translate neurology patient education material using three Large Language Models (LLMs) - ChatGPT-4 Omni, Gemini 1.5 Pro, and Claude 3.5 Sonnet. Five neurological conditions (Bells palsy, multiple sclerosis, stroke, migraine, and epilepsy) were translated from English into Spanish, Urdu, and Arabic. The translations were assessed by physicians using four metrics: accuracy, clarity, comprehensiveness, and readability at a 6th grade level. Results showed that Claude outperformed both ChatGPT and Gemini overall, particularly excelling in Spanish and Urdu translations, while Gemini led in Arabic. All LLMs demonstrated superior performance in Spanish compared to Urdu and Arabic. This study highlights the potential of LLMs in enhancing patient education across languages, while also identifying areas for improvement in translation accuracy and readability.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Novel Machine Learning Based Framework for Developing Composite Digital Biomarkers of Disease Progression\nAbstract: BackgroundCurrent methods of measuring disease progression of neurodegenerative disorders, including Parkinsons disease (PD), largely rely on composite clinical rating scales, which are prone to subjective biases and lack the sensitivity to detect progression signals in a timely manner. Digital health technology (DHT)-derived measures offer potential solutions to provide objective, precise, and sensitive measures that address these limitations. However, the complexity of DHT datasets and the potential to derive numerous digital features that were not previously possible to measure pose challenges, including in selection of the most important digital features and construction of composite digital biomarkers.  MethodsWe present a comprehensive machine learning based framework to construct composite digital biomarkers for progression tracking. This framework consists of a marginal (univariate) digital feature screening, a univariate association test, digital feature selection, and subsequent construction of composite (multivariate) digital disease progression biomarkers using Penalized Generalized Estimating Equations (PGEE). As an illustrative example, we applied this framework to data collected from a PD longitudinal observational study. The data consisted of OpalTM sensor-based movement measurements and MDS-UPDRS Part III scores collected at 3-month intervals for 2 years in 30 PD and 10 healthy control participants.  ResultsIn our illustrative example, 77 out of 235 digital features from the study passed univariate feature screening, with 11 features selected by PGEE to include in construction of the composite digital measure. Compared to MDS-UPDRS Part III, the composite digital measure exhibited a smoother and more significant increasing trend over time in PD groups with less variability, indicating improved ability for tracking disease progression. This digital composite measure also demonstrated the ability to classify between de novo PD and healthy control groups.  ConclusionMeasures from DHTs show promise in tracking neurodegenerative disease progression with increased sensitivity and reduced variability as compared to traditional clinical scores. Herein, we present a novel framework and methodology to construct composite digital measure of disease progression from high-dimensional DHT datasets, which may have utility in accelerating the development and application of composite digital biomarkers in drug development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Distinct Longitudinal Clinical-Neuroanatomical Trajectories in Parkinson's Disease Clinical Subtypes: Insight Towards Precision Medicine\nAbstract: BackgroundParkinsons disease (PD) varies widely across individuals in clinical manifestations and course of progression. Identification and characterization of distinct biological subtypes could help explain this heterogeneity, identify the underlying pathophysiology, and predict disease progression across the subgroups of PD.  ObjectiveWe aimed to compare long-term trajectories of various motor and non-motor clinical features, as well as patterns of brain atrophy between PD subtypes, using longitudinally acquired brain MRIs.  MethodsData on 421 individuals with early-stage PD was retrieved from the Parkinsons Progression Markers Initiative (PPMI), with an average follow-up time of 8.2 years until February 2024. Participants were classified into three clinical subtypes at the de novo stage using a previously validated subtyping criteria based on major motor and non-motor classifiers (early cognitive impairment, REM sleep behavior disorder (RBD), dysautonomia):  mild-motor predominant (n=223),  intermediate (n=146), and diffuse-malignant (n=52). To investigate the pattern of brain atrophy, we used T1-weighted MRIs from a subset of the PPMI population with at least two MRIs obtained, which consisted of 134 PD individuals and 60 healthy controls. Deformation-based morphometry (DBM) maps were calculated and mixed effect models were used to examine the interaction between PD subtypes and rate of atrophy across brain regions, controlling for sex and age at baseline.  ResultsCompared to the  mild motor-predominant subtype, participants who were categorized as diffuse-malignant PD at baseline experienced greater worsening in motor severity (p=0.007), cognition (p<0.0001) and activities of daily living (ADL) (p<0.0001) after 8 years. Individuals with diffuse-malignant PD showed a significantly higher rate of atrophy across multiple brain regions, including precuneus, paracentral lobule, inferior temporal gyrus, fusiform gyrus, and lateral hemisphere of the cerebellum (corrected p<0.05).  ConclusionOur study revealed a distinct pattern of long-term progression in various motor and non-motor clinical outcomes between different subtypes of idiopathic PD. Furthermore, we demonstrated an accelerated atrophy pattern within several brain regions in the diffuse-malignant PD subtype. These findings suggest a more widespread and aggressive neurodegenerative process in a subgroup of people with PD, favoring the existence of diverse underlying pathophysiology with clinical relevance for future precision medicine in PD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Magnetic Resonance Imaging Data Phenotypes for the Parkinson's Progression Markers Initiative\nAbstract: The Parkinsons Progression Markers Initiative (PPMI) delivers multiple modality MRI (M3RI) and biomarker data for a comprehensive longitudinal study of Parkinsons Disease (PD). These provide quantitative indices of deep brain and cortical structure (T1-weighted MRI), microstructural integrity of brain tissue (diffusion-weighted imaging) and resting brain function (resting state functional MRI). Integrating and uniformly analyzing M3RI alongside non-imaging biological and clinical data is challenging due to the distinct nature of each modality. This study systematically organizes these complex data into a structured format, provides a PD-focused evaluation of the methodologies and evidence for technical robustness of the approach. The cohort encompasses 841 idiopathic PD, 309 genetic PD, 1364 presymptomatic PD and 240 control subjects at baseline with followup at a mean of 1.83 years.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The efficacy and  safety of Acupoint herbal patching in treating peptic ulcer: protocol for a systematic review sand meta-analysis\nAbstract: IntroductionPeptic ulcer (PU) is prone to recurrence and can have a prolonged course, significantly impacting patients quality of life. Clinical treatment commonly involves combating Helicobacter pylori(HP), reducing gastric acid secretion, and promoting gastric mucosal protection. Nevertheless, Western medicine often entails various adverse effects and long-term use. Consequently, numerous scholars have redirected their focus towards traditional Chinese medicine (TCM) for external treatments of PU due to its minimal toxicity, fewer side effects, and lower recurrence rates. This study aims to assess the efficacy and safety of Acupoint herbal patching (AHP) in treating PU, offering a foundation for future clinical investigations.  Methods and analysisThe computer will conduct a comprehensive search for relevant studies on the utilization of AHP in the management of PU from the inception of the database in various scholarly platforms including China Journal Network, Wanfang Database, Chongqing Wipo Database, China Biomedical Literature Database, PubMed, and Cochrane Library. Eligible literature will undergo meticulous scrutiny based on predefined criteria, with data extraction and quality assessment executed independently by two researchers. Meta-analysis utilizing RevMan 5.4.1 software will be employed to synthesize the collected data. The study will focus on the TCM Symptom Score Scale as the primary outcome measure, while secondary outcomes will encompass serum inflammatory factors, endoscopic findings, quality of life, recurrence rate, and adverse events. Furthermore, assessments on effectiveness, cure rate, and potential publication bias will be carried out. This investigation aims to assess the efficacy of AHP in the treatment of PU and its impact on enhancing the well-being of patients.  Ethics and disseminationSince the present work constitutes a literature review, it is important to note that ethical approval is deemed unnecessary. The outcomes of this investigation are intended for dissemination in a scholarly periodical subject to peer review.  PROSPERO registration numberCRD42023456995  STRENGTHS AND LIMITATIONS OF THIS STUDYA thorough examination of the literature will be undertaken across six electronic databases in both Chinese and English languages.  The methodology will adhere to the guidelines outlined in the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA).  Evaluation of the studies quality will be conducted utilizing the updated Cochrane Risk of Bias 2.0 tool.  Variations in patch locations and treatment protocols may introduce significant heterogeneity, posing challenges to the synthesis of data.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Efficacy and Safety of Acupuncture for Acute Gouty Arthritis: A Systematic Review and Network Meta-Analysis\nAbstract: Acute gouty arthritis (AGA) severely affects the quality of life of patients due to its persistent, recurrent, and debilitating characteristics. Acupuncture holds a pivotal role as a classical alternative therapy in managing gouty arthritis. This study aimed to assess the clinical effectiveness of various acupuncture methods used in conjunction with conventional medications for treating acute gouty arthritis. We conducted a search of seven English and Chinese databases up to February 10, 2024, and analyzed the data using R software version 4.4.0.The study included a total of 37 randomized controlled trials(RCT), encompassing 2,801 patients. The network meta-analysis (NMA) results are as follows: Fire acupuncture demonstrated the highest effectiveness in improving cure rates. Acupuncture combined with conventional medication was found to be the most effective for reducing VAS scores. Additionally, Acupuncture combined with conventional medication proved most effective in lowering uric acid levels. For reducing ESR, the combination of blood-letting therapy and conventional drugs showed the greatest efficacy. No statistically significant differences were found among the different interventions regarding the reduction of TCMSS and CRP levels. In conclusion, fire acupuncture showed the greatest overall effectiveness. Acupuncture with conventional medication best reduced VAS scores and uric acid levels, while blood-letting therapy combined with conventional drugs was most effective in lowering ESR.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: From Biobanking to Personalized Medicine: the journey of the Estonian Biobank\nAbstract: Large biobanks have set a new standard for research and innovation in human genomics and implementation of personalised medicine. The Estonian Biobank was founded a quarter of a century ago, and its biological specimens, clinical, health, omics, and lifestyle data have been included in over 800 publications to date. What makes the biobank unique internationally is its translational focus, with active efforts to conduct clinical studies based on genetic findings, and to explore the effects of return of results on participants. In this review we provide an overview of the Estonian Biobank, highlight its strengths for studying the effects of genetic variation and quantitative phenotypes on health-related traits, development of methods and frameworks for bringing genomics into the clinic, and its role as a driving force for implementing personalized medicine on a national level and beyond.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Upregulation of Reward Mesolimbic Activity via fMRI-Neurofeedback Improves Vaccination Efficiency in Humans\nAbstract: The placebo response is associated with a positive expectation of recovery. Recent studies in mice uncovered a potential underlying mechanism of placebo effects, by demonstrating the involvement of the dopaminergic mesolimbic pathway, previously implicated in reward expectation, in immune modulation. Yet, it is not known whether an analogous brain-immune regulatory mechanism exists in humans, and whether it employs conscious positive expectations. Here, we employed fMRI-neurofeedback to train healthy participants to increase their reward mesolimbic activity by using self-chosen mental strategies, followed by Hepatitis B Virus (HBV) vaccination. We found that stronger Ventral Tegmental Area (VTA) activity, but not control regions activation, was associated with higher post-vaccination HBV antibody titer. Interestingly, higher VTA activity before vaccination was associated with mental strategies characterized by positive expectation. Thus, our results establish a relationship between reward system activity, positive expectation and immunity in humans and reveal a potential neuropsychological mechanism for non-invasive immune modulation.  https://clinicaltrials.gov/study/NCT03951870.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Olfactory Bulb Volume and Asymmetry as Predictors of Executive Dysfunction in Adolescents with Congenital Heart Disease\nAbstract: Background and PurposeCommon sequelae for patients with congenital heart disease (CHD) are neurodevelopmental disabilities including executive function, attention, and socio-emotional deficits. Although these are common diagnoses for patients with CHD, limited research has investigated the mechanistic underpinnings of these findings. Our previous research examined the association between abnormal respiratory ciliary motion and brain abnormalities in infants with CHD. Results suggested that abnormal ciliary motion correlated to a spectrum of subtle dysplasia, notably within the olfactory bulb (OB)1. Our current study investigates whether OB anomalies predict neurodevelopmental outcomes for pediatric patients with CHD. We hypothesize that adolescents with CHD who exhibit aberrant morphological measurements in the OB are more likely to suffer from executive functional deficits.  Materials and MethodsA prospective, observational study of 54 CHD and 75 healthy subjects, ages 6-25 years old, was completed under the supervision of a senior pediatric neuroradiologist. T2 3D Space and T2 Blade 2MM MRI images were manually segmented to extract volumetric bilateral regions of the OB and cerebrospinal fluid (CSF) using ITK-SNAP. Imaging metrics were correlated to OB asymmetry, CSF to OB ratio, total CSF volume, total OB volume, and independent left and right CSF and OB volumes. Linear regression was used to evaluate MRI morphologic measurements with co-variates: CHD status, sex, MRI age, and segmenter. Executive function was determined by the Behavioral Rating Inventory of Executive Function (BRIEF) Parent Report and Delis-Kaplan Executive Function System (D-KEFS) for subjects ages 6-16. Cognition and olfactory function were measured with the NIH Toolbox Cognitive Battery and Odor Identification Test, respectively.  ResultsNo statistically significant results were reported between cohorts for asymmetry of OB, CSF to OB ratio, total CSF volume, total OB volume, nor between independent left and right CSF and OB volumes. Increased OB volume was associated with worse outcomes on the BRIEF Parent Report (p[&le;]0.03). Asymmetry of OB predicted poorer executive functioning as reported by parents on the BRIEF (p[&le;]0.05). Overall, the CHD cohort demonstrated worse scores on the BRIEF Parent Report compared to controls. Across groups, no significant association was reported for olfaction function measured by the NIH Toolbox Odor Identification Test on a limited subset of participants.  ConclusionAs survival rates for CHD improve, there is an increased risk of long-term neurodevelopmental impairments. Our findings identify adolescents who are at risk for executive dysfunction, particularly those showing increased OB volume and/or asymmetry of the OB. This is particularly concerning for the CHD population with atypical OB morphology, who also exhibit significantly poorer outcomes on the BRIEF Parent Report and face a higher overall risk. Increased OB volume and OB asymmetry are olfactory-based biomarkers that may help identify at-risk CHD patients earlier, enabling more timely intervention and support.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging the electronic health record to identify delivery of goal-concordant care\nAbstract: BackgroundGoal-concordant care (GCC) is recognized as the highest quality of care and most important outcome measure for serious illness research, yet there is no agreed-upon or validated method to measure it.  ObjectiveAssess feasibility of measuring GCC using clinical documentation in the electronic health record (EHR).  DesignRetrospective chart review study.  ParticipantsAdults with [&ge;]50% predicted six-month mortality risk admitted to three urban hospitals in a single health system. All participants had goals-of-care (GOC) discussions documented in the EHR 6 months before and 6 months after admission manually classified into one of four categories of goals: (1) comfort-focused, (2) maintain or improve function, (3) life-extension, or (4) unclear.  Main MeasuresPairs of physician-coders independently reviewed EHR notes from 6 months before through 6 months after admission to identify and classify care received between each documented GOC discussion into one of the four goals categories. Epochs between GOC discussions were then coded as goal-concordant if GOC and care received classifications were aligned, goal-discordant if they were misaligned, or uncertain if either classification was unclear or not documented. Coder inter-rater reliability was assessed using kappa statistics.  Key ResultsInter-rater reliability for classifying care received was almost perfect (95% interrater agreement; Cohens kappa=0.92; 95% CI, 0.86-0.99). Of 398 total epochs across 109 unique patients, 198 (50%) were goal-concordant, 112 (28%) were of uncertain concordance, and 88 (22%) were goal-discordant. Eighty (73%) patients received care of uncertain concordance during at least one epoch. Forty-eight (44%) patients received goal-discordant care during at least one epoch.  ConclusionsClinician chart review was a feasible method for measuring GCC and can inform natural language processing and machine learning methods to improve the clinical and research utility of this method. More work is needed to understand the driving factors underlying the high rate of uncertain concordance and goal-discordant care identified among this seriously ill cohort.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Language Modeling Screens Parkinson's Disease with Self-reported Questionnaires\nAbstract: Parkinsons disease (PD) is a growing public health challenge associated with the aging population. Current diagnostic methods rely on motor symptoms and invasive procedures, making early detection difficult. This study established a transferable artificial intelligence (AI) model, Quest2Dx, to analyze health questionnaires to enable low-cost and non-invasive PD diagnosis. Quest2Dx tackles the common challenges of missing responses and required specific modeling for each questionnaire by developing a novel language modeling approach to allow the model transfer across different questionnaires and to enhance the interpretability. Evaluated on the PPMI and Fox Insight datasets, Quest2Dx achieved AUROCs of 0.977 and 0.974, respectively, significantly outperforming existing methods. Additionally, cross-questionnaire validation achieved AUROCs of 0.920 and 0.952, respectively, from PPMI to Fox Insight and vice versa. Quest2Dx also identified key predictors from the list of questions to provide further insights. The validated technology elucidates a promising path for PD screening in primary-care settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Framing Major Depressive Disorder as a Condition of Network Imbalance at the Compartment Level: A Proof-of-Concept Study\nAbstract: BackgroundHypoactivity in the frontoparietal (FP) system and hyperactivity in the limbic system have been observed in major depressive disorder (MDD). Among the neuropathological theories of MDD, the cortico-limbic dysregulation model has been prominent, and it was recently extended and refined by the framework of imbalanced reciprocal suppression between the FP and limbic compartments. This research aims to examine this refined theory.  MethodsSixty MDD and sixty healthy control datasets, including structural magnetic resonance imaging and resting-state functional MRI (rsfMRI), were selected from the CAN-BIND database. The cerebral cortex in rsfMRI was parcellated by MOSI (modular analysis and similarity measurements). For each parcellated node, the mean amplitude of low-frequency fluctuation (mALFF) was computed. Correlation analyses were employed to construct an adjacency matrix between partitioned nodes and to examine the relationship between nodal power and nodal degree.  ResultsTwo-sample t-tests revealed that the limbic system in MDD was associated with a higher partition number and mALFF (p < 0.005). A negative correlation between nodal degree and nodal power was replicated (p < 1E-10), indicating that higher functional input may more effectively suppress regional neural activity. For FP nodal power and Limbic-FP connectivity, the MDD group exhibited a more negative correlation (stronger suppression), while for limbic nodal power and FP-Limbic connectivity, the MDD group showed a less negative correlation (weaker suppression).  ConclusionsConsistent with the inter-compartmental network imbalance framework, MDD is characterized by abnormal cortical signal organization and aberrant reciprocal suppression between the FP and limbic systems.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Early menarche and childbirth accelerate aging-related outcomes and age-related diseases: Evidence for antagonistic pleiotropy in humans\nAbstract: Aging can be understood as a consequence of the declining force of natural selection with age. Consistent with this the antagonistic pleiotropic theory of aging suggests that aging results from the trade-offs that promote early growth and reproduction. However, evidence for antagonistic pleiotropy in humans is largely lacking. Using Mendelian Randomization (MR), we demonstrated that later ages of menarche or first childbirth were genetically associated with longer parental lifespan, decreased frailty index, slower epigenetic aging, later menopause, and reduced facial aging. Moreover, later menarche or first childbirth were also genetically associated with a lower risk of several age-related diseases, including late-onset Alzheimers disease (LOAD), type 2 diabetes, heart disease, essential hypertension, and chronic obstructive pulmonary disease (COPD). We validated the associations between the age of menarche, childbirth, and the number of childbirths with several age-related outcomes in the UK Biobank by conducting regression analysis of nearly 200,000 subjects. Our results demonstrated that menarche before the age 11 and childbirth before 21 significantly accelerated the risk of several diseases, and almost doubled the risk for diabetes, heart failure, and quadrupled the risk of obesity, supporting the antagonistic pleiotropy theory. We identified 128 significant single nucleotide polymorphisms (SNPs) that influenced age-related outcomes, some of which were involved in known longevity pathways, including IGF1, growth hormone, AMPK, and mTOR signaling. Our study also identified higher BMI as a mediating factor in causing the increased risk of certain diseases, such as type 2 diabetes and heart failure, in women with early menarche or early pregnancy, emphasizing the importance of the thrifty gene hypothesis in explaining in part the mechanisms behind antagonistic pleiotropy. Our study highlights the complex relationship between genetic legacies and modern diseases, emphasizing the need for gender-sensitive healthcare strategies that consider the unique connections between female reproductive health and aging.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Sport Specialization , Injury and Illness: A Prospective Study of Elite Female Adolescent Soccer Players\nAbstract: ContextAlthough considerable cross-sectional evidence exists regarding the association between sport specialization and injury, sport-specific, prospective research is lacking. Similarly, sport specialization is associated with impairments in sleep and subjective well-being in youth athletes, but it is unknown whether this increases the risk of illness.  ObjectiveTo determine the relationship between sport specialization status and in-season injury and illness risk in elite female adolescent soccer players.  DesignProspective Cohort Study  SettingPre-season evaluation of maximal aerobic capacity (VO2max) and sport specialization, and in-season self-reporting of daily training load (session-rating of perceived exertion), injury and illness resulting in lost sport participation time.  Participants80 female youth soccer players (ages 13-18) from a local youth soccer organization.  Main outcome measuresSport specialization status, injury and illness incidence during two 4-month competitive soccer seasons. Athletes were considered specialized if they participated in soccer exclusively versus multiple sports during the year. Mixed effects logistic regression models were used to individual injury and illness (yes/no) during the study period, using sport specialization, age, and training load as fixed effects and individual athlete as a random effect.  ResultsSpecialized (n=46) athletes did not differ from non-specialized (n=34) athletes with respect to age, preseason physical activity, VO2max or in-season training load (all p>0.05). No difference was seen in the proportion of individuals from each group that reported an in-season injury (specialized = 19% v 17%, p=0.83) or illness (40% v 38%, p=0.82). After adjusting for age and training load, the individual injuries (OR= 0.86 [0.26, 2.8], p=0.81) and illnesses were not significantly predicted by specialization (OR= 1.06 [0.45, 2.5], p=0.89).  ConclusionsAfter adjusting for age and training load, sport specialization status was not associated with in-season injury or illness risk in elite female soccer players.  Key pointsO_LIPrior research regarding the associations between sport specialization and health outcomes has been primarily cross-sectional and failed to account for the confounding role of training load. C_LIO_LIAmong elite adolescent female soccer players with similar pre-season physical activity levels in-season training loads, sport specialization was not associated with injury or illness incidence across two competitive seasons. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diagnostic Performance of Systemic-Immune Inflammation Index for Overall and Complicated Acute Appendicitis: A Systematic Review and a Diagnostic Test Accuracy Meta-Analysis\nAbstract: BackgroundThis study aimed to analyze the systemic-immune inflammation index (SII)s diagnostic performance in diagnosing acute appendicitis (AA) and discriminating between complicated acute appendicitis (CAA) and non-complicated acute appendicitis (NCAA).  MethodsThis review was registered in PROSPERO (CRD42024587430). We included prospective or retrospective original clinical studies evaluating the diagnostic performance of SII in AA. A search was conducted in PubMed, Web of Science, Scopus, and OVID. Search terms and keywords were: (appendicitis OR appendectomy) AND (systemic-immune inflammation index OR SII). Two independent reviewers selected the articles and extracted relevant data. Methodological quality was assessed using the QUADAS2 index. A synthesis of the results, standardization of the metrics, four random-effect meta-analyses, and two Diagnostic Test Accuracy (DTA) meta-analyses were performed.  ResultsThirteen studies with data from 9083 participants, including 5255 patients with a confirmed diagnosis of AA and 3828 controls (CG), were included in this review. The random-effect meta-analysis of SII (AA vs. CG) included ten articles (3733 AA and 3510 controls) and resulted in a significant mean difference [95% CI] of 1072.46 [750.55,1394.37] (p<0.001). The random-effect meta-analysis of SII (CAA vs. NCAA) included nine articles (1116 CAA and 2984 NCAA) and resulted in a significant mean difference [95% CI] of 1294.2 [731.54,1856.86] (p<0.001). Subgroup meta-analysis for studies conducted in pediatric-only populations maintained statistical significance. The DTA meta-analysis (AA vs. CG) yielded a pooled sensitivity and specificity [95% CI] of 81.8 [75.2,86.9] % and 79.9 [68.2,88.1] %. The DTA meta-analysis (NCAA vs. CAA) resulted in a pooled sensitivity and specificity [95% CI] of 72.5 [49.6,87.6] % and 82.5 [65.1,92.2] %.  ConclusionsSII emerges as a robust tool for diagnosing AA and differentiating between NCAA and CAA. The retrospective nature of most of the included studies and their limited geographical distribution warrant further prospective multicenter studies to validate these findings.  FundingNone  RegistrationPROSPERO (CRD42024587430).\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cortico-thalamic tremor circuits and their associations with deep brain stimulation effects in essential tremor\nAbstract: Essential tremor (ET) is one of the most common movement disorders in adults. Deep brain stimulation (DBS) of the ventralis intermediate nucleus (VIM) of the thalamus and/or the posterior subthalamic area (PSA) has been shown to provide significant tremor suppression in patients with ET, but with significant inter-patient variability and habituation to the stimulation. Several non-invasive neuromodulation techniques targeting other parts of the central nervous system, including cerebellar, motor cortex, or peripheral nerves, have also been developed for treating ET, but the clinical outcomes remain inconsistent. Existing studies suggest that pathology in ET may emerge from multiple cortical and subcortical areas, but its exact mechanisms remain unclear. By simultaneously capturing neural activities from motor cortices and thalami, and hand tremor signals recorded via accelerometers in fifteen human subjects who have undergone lead implantations for DBS, we systematically characterized the efferent and afferent cortico-thalamic tremor networks. Through the comparisons of these network characteristics and tremor amplitude between DBS OFF and ON conditions, we further investigated the associations between different tremor network characteristics and the magnitude of DBS effect. Our findings implicate the thalamus, specifically the contralateral hemisphere, as the primary generator of tremor in ET, with a significant contribution of the ipsilateral hemisphere as well. Although there is no direct correlation between the cortico-tremor connectivity and tremor power or reduced tremor by DBS, the strength of connectivity from the motor cortex to the thalamus and vice versa at tremor frequency predicts baseline tremor power and effect of DBS. Interestingly, there is no correlation between these two connectivity pathways themselves, suggesting that, independent of the subcortical pathway, the motor cortex appears to play a relatively distinct role, possibly mediated through an afferent/feedback loop in the propagation of tremor. DBS has a greater clinical effect in those with stronger cortico-thalamo-tremor connectivity involving the contralateral thalamus, which is also associated with bigger and more stable tremor measured with an accelerometer. Interestingly, stronger cross-hemisphere coupling between left and right thalami is associated with more unstable tremor. Together this study provides important insights into a better understanding of the cortico-thalamic tremor generating network and its implication for the development of patient-specific therapeutic approaches for ET.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Enhancing the Diagnostic Efficacy of Right-to-Left Shunt Using Robot-Assisted Transcranial Doppler: A QI Project\nAbstract: BackgroundStroke is the leading cause of adult disability worldwide, with approximately 30% of strokes remaining cryptogenic. One potential etiology is a patent foramen ovale (PFO), which may contribute to stroke through paradoxical thrombo-embolism or in situ thrombo-embolus formation. Recent advancements in robot-assisted transcranial Doppler (raTCD) have shown increased sensitivity in detecting right-to-left shunt (RLS) compared to transthoracic echocardiography (TTE), particularly in detecting large shunts, which are associated with a higher risk of stroke.  MethodsWe conducted a retrospective quality improvement project at our regional stroke center to compare the performance of TTE and raTCD in identifying RLS in ischemic stroke patients. The study involved 148 patients admitted between February 2021 and February 2023. All patients underwent TTE and raTCD with agitated saline bubble contrast, with additional transesophageal echocardiography (TEE) at the treatment teams discretion. The primary metrics analyzed included differences in overall RLS detection and large RLS detection rates for raTCD, TTE and TEE.  ResultsraTCD detected RLS in 60.1% of patients compared to 37.2% with TTE (p = 0.00012), with a 42.6% detection rate for large shunts on raTCD versus 23.0% on TTE (p = 0.00053). The sensitivity and specificity of raTCD were 92% and 87.5%, respectively, compared to 78.57% and 71.43% for TTE, using TEE as the gold standard. Nine patients underwent PFO closure, all correctly identified with large shunts by raTCD, while TTE missed or underestimated the PFO size in 44% of the cases.  ConclusionraTCD significantly outperforms TTE in detecting RLS and large shunts, suggesting its integration into standard PFO workup protocols may enhance secondary stroke prevention. These findings support the adoption of raTCD as a complementary diagnostic tool alongside TTE and TEE for more accurate PFO detection and risk stratification.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Heterozygous loss-of-function variants in SPTAN1 cause a novel early childhood onset distal myopathy with chronic neurogenic features\nAbstract: BackgroundNeurogenetic disorders caused by pathogenic variants in four genes encoding non-erythrocytic spectrins (SPTAN1, SPTBN1, SPTBN2, SPTBN4) range from peripheral and central nervous system involvement to complex syndromic presentations. Heterozygous pathogenic variants in SPTAN1 are exemplary for this diversity with phenotypes spanning almost the entire spectrum.  MethodsThrough international collaboration we identified 14 families with genetically unsolved distal weakness and unreported heterozygous SPTAN1 loss-of-function variants including frameshift, nonsense and splice-acceptor variants. Clinical data, electrophysiology, muscle CT or MRI and muscle biopsy findings were collected and standardized. SPTAN1 protein, mRNA expression analysis and cDNA sequencing was performed on muscle tissue from two patients.  ResultsAll 20 patients presented with early childhood onset distal weakness. The severity varied both within families and between different families. Foot abnormalities ranged from hammer toes and pes cavus to distal arthrogryposis. Electrophysiology showed mixed myogenic and neurogenic features. Muscle MRI or CT in 10 patients showed fatty infiltration of the distal lower limb anterior compartment and/or selective involvement of the extensor hallucis longus muscle. Muscle biopsy revealed myopathic changes with mild dystrophic and chronic neurogenic changes in 7 patients. Finally, we provide proof for nonsense mediated decay in tissues derived from two patients.  ConclusionsWe provide evidence for the association of SPTAN1 loss-of-function variants with childhood onset distal myopathy in 14 families. This finding extends the phenotypic spectrum of SPTAN1 loss-of-function variants ranging from intellectual disability to distal weakness with a predominant myogenic cause.  KEY MESSAGES{diamond} SPTAN1 loss-of-function variants, including frameshift, nonsense and splice site variants cause a novel childhood onset distal weakness syndrome with primarily skeletal muscle involvement. {diamond}Hereditary motor neuropathies and distal myopathic disorders present a well-known diagnostic challenge as they demonstrate substantial clinical and genetic overlap. The emergence of SPTAN1 loss-of-function variants serves as a noteworthy example, highlighting a growing convergence in the spectrum of genotypes linked to both hereditary motor neuropathies and distal myopathies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comprehensive Analysis of Theoretical Models and Frameworks for Investigating Determinants of Breast Cancer Screening Participation: A Scoping Review\nAbstract: ObjectiveThis study aims to review and evaluate the effectiveness of various theoretical frameworks and models used over the past decade to explain the factors influencing BCS.  MethodsA scoping review method was used to search the CNKI, Wanfang, VIP, Chinese Biomedical Abstracts, Pubmed, Embase, Web of Science, Ovid, EBSCO, and Cochrane Library databases. After literature screening and data extraction, the research results were summarized.  Results55 studies were included and analyzed from the aspects of the application of theoretical models, explanatory effects, existing differences, commonalities and characteristics, and how to improve them.  ConclusionThe effectiveness of these models varies by context and population. TPB and HBM are among the most empirically supported models, offering strong predictive power and practical guidance for interventions. Integrated models provide a comprehensive approach, addressing a broader range of influencing factors and demonstrating enhanced predictive capabilities. Future research should focus on refining these models and incorporating digital health tools to improve their applicability and effectiveness.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biometry and volumetry in multi-centric fetal brain MRI: assessing the bias of super-resolution reconstruction\nAbstract: BackgroundSuper-resolution reconstruction (SRR) of fetal brain magnetic resonance imaging has the potential to enable the development of new imaging biomarkers to better study in utero neurodevelopment. However, potential biases in 2D biometric and 3D volumetric measurements due to different SRR techniques remain understudied.  PurposeTo assess the consistency of biometric and volumetric measurements across three hospitals using three widely used SRR pipelines.  Materials and MethodsThis retrospective study used T2-weighted (T2w) fetal brain MRI scans acquired in routine clinical practice at three hospitals. MRIs from each subject were reconstructed with each of the 3 SRR methods. Four experts did biometric measurements on each SRR volume blinded to the method used. Automated 3D volumetry was performed using a state-of-the-art segmentation method. A univariate analysis was first carried out with Friedman tests with post-hoc Wilcoxon rank-sum tests, and results were confirmed in a multivariate analysis accounting for the effect of gestational age and different raters, using a t-distributed generalized additive model. An additional qualitative evaluation was performed to assess how likely clinicians would be to use the current SRR volumes in their practice, and whether they would prefer it to low-resolution T2w acquisitions. Differences were assessed with Friedman tests and post-hoc Wilcoxon rank-sum tests.  Results84 healthy subjects were included in three gestational age groups ([21-28): 25.4{+/-}1.9, [28-32): 29.3{+/-}1.3, [32-36): 33.5{+/-}1.2). Statistically significant differences in biometric measurements were found, but consistently remained below voxel width (0.8 mm). Automated 3D volumetry revealed systematic but very small effects (<2.8%). The qualitative evaluation showed systematic differences between SRR methods for the perception of white matter intensity (p=0.02) and sharpness of the image (p=0.01).  ConclusionVariations in 2D and 3D quantitative measurements did not show any large systematic bias when using different SRR methods for radiological assessment in clinical routine across multiple centers, scanners, and raters.  SummaryDifferent super-resolution reconstruction methods for fetal brain MRI volumes lead to negligible variations in 2D or 3D quantitative measurements; this may help achieve larger sample sizes in prenatal development studies.  Key Results- In this multi-centric retrospective study, 252 super-resolution reconstructions (SRR) scans from 84 healthy subjects showed negligible variations in 2D in biometric measures (below the voxel with of 0.8 mm; p<0.001). - 3D measurements revealed small variations ranging from 0.8 % in supratentorial tissues (p<0.001) to 2.8% in the extra-cerebral cerebrospinal fluid (p<0.001). - Clinicians favored having both low resolution and SRR volumes available.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biometry and volumetry in multi-centric fetal brain MRI: assessing the bias of super-resolution reconstruction\nAbstract: BackgroundSuper-resolution reconstruction (SRR) of fetal brain magnetic resonance imaging has the potential to enable the development of new imaging biomarkers to better study in utero neurodevelopment. However, potential biases in 2D biometric and 3D volumetric measurements due to different SRR techniques remain understudied.  PurposeTo assess the consistency of biometric and volumetric measurements across three hospitals using three widely used SRR pipelines.  Materials and MethodsThis retrospective study used T2-weighted (T2w) fetal brain MRI scans acquired in routine clinical practice at three hospitals. MRIs from each subject were reconstructed with each of the 3 SRR methods. Four experts did biometric measurements on each SRR volume blinded to the method used. Automated 3D volumetry was performed using a state-of-the-art segmentation method. A univariate analysis was first carried out with Friedman tests with post-hoc Wilcoxon rank-sum tests, and results were confirmed in a multivariate analysis accounting for the effect of gestational age and different raters, using a t-distributed generalized additive model. An additional qualitative evaluation was performed to assess how likely clinicians would be to use the current SRR volumes in their practice, and whether they would prefer it to low-resolution T2w acquisitions. Differences were assessed with Friedman tests and post-hoc Wilcoxon rank-sum tests.  Results84 healthy subjects were included in three gestational age groups ([21-28): 25.4{+/-}1.9, [28-32): 29.3{+/-}1.3, [32-36): 33.5{+/-}1.2). Statistically significant differences in biometric measurements were found, but consistently remained below voxel width (0.8 mm). Automated 3D volumetry revealed systematic but very small effects (<2.8%). The qualitative evaluation showed systematic differences between SRR methods for the perception of white matter intensity (p=0.02) and sharpness of the image (p=0.01).  ConclusionVariations in 2D and 3D quantitative measurements did not show any large systematic bias when using different SRR methods for radiological assessment in clinical routine across multiple centers, scanners, and raters.  SummaryDifferent super-resolution reconstruction methods for fetal brain MRI volumes lead to negligible variations in 2D or 3D quantitative measurements; this may help achieve larger sample sizes in prenatal development studies.  Key Results- In this multi-centric retrospective study, 252 super-resolution reconstructions (SRR) scans from 84 healthy subjects showed negligible variations in 2D in biometric measures (below the voxel with of 0.8 mm; p<0.001). - 3D measurements revealed small variations ranging from 0.8 % in supratentorial tissues (p<0.001) to 2.8% in the extra-cerebral cerebrospinal fluid (p<0.001). - Clinicians favored having both low resolution and SRR volumes available.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal Monitoring of Glioblastoma Small Extracellular Vesicle Evolution Using a Nanodiagnostic to Detect Emergence of Glioma Stem Cells Driving Recurrent Disease\nAbstract: Assessing therapeutic response in glioblastoma (GBM) is a major factor limiting the clinical development of new and effective therapies. The intracranial location limits serial biopsies, and only provides an intermittent view of the tumor molecular profile from the initial resection. Liquid biopsy techniques, specifically small extracellular vesicle (sEV) analysis, have the potential to overcome these limitations by providing a window into the brain using peripheral blood. To address the need for monitoring tumor evolution and therapeutic resistance, we developed a GBM biomarker panel (ATP1B2, EAAT2, CD24, CD44, CD133 and EGFR) for multiplexed profiling of sEVs using an advanced GBM Extracellular vesicle Monitoring Phenotypic Analyzer Chip (GEMPAC). We successfully tracked patient response to treatment by monitoring changes in glioma stem cell markers on circulating sEVs. We propose that these results provide a strong rationale for using GBM sEVs as a serial monitoring tool in the future clinical management of GBM patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Relationship between Retinal Vessels and OCT-Derived Retinal Neural Parameters\nAbstract: ObjectiveTo investigate structural relationships between retinal vasculometry derived from color fundus photography (CFP) and neural parameters obtained from Optical Coherence Tomography (OCT) scans and validate their causal relationships.  DesignCross-sectional study  ParticipantsParticipants with fundus photographs data and OCT data in the UK Biobank cohort study  MethodsWe used the Retina-based Microvascular Health Assessment System (RMHAS) to extract retinal vascular measurements in the 6*6mm area centered on the macular region. OCT parameters were available from the UK Biobank. First, pairwise correlations between individual retinal layers and vascular parameters were investigated. Canonical correlation analysis (CCA) was then used to examine associations between sets of variables. Lastly, bidirectional two-sample Mendelian randomization was employed to investigate potential causal relationships.  Main Outcome MeasuresMeasurements of retinal vascular network and neural layers  ResultsData from 67,918 eyes of 43,029 participants were included. The Ganglion Cell-Inner Plexiform Layer (GC-IPL) thickness showed the strongest correlations with vascular Density and Complexity (r=0.199 for arterial Vessel Area Density and r=0.175 for Number of Segments). The Inner Nuclear Layer (INL) thickness showed positive correlations with Width (r=0.122) and Vessel Area Density (artery) (r=0.127). Mendelian randomization analysis indicated bidirectional causal relationships between retinal vascular features and layer thicknesses. Genetically predicted higher Vessel Density was associated with increased thickness across various retinal layers, with the strongest effect on Inner Segment/Outer Segment + Photoreceptor Segment thickness (standardized effect size 1.50, p<0.001). Genetically predicted increases in retinal layer thicknesses, particularly the Outer Plexiform Layer, were linked to higher Vessel Density (standardized effect size 0.45, p=0.002) and Fractal Dimension (standardized effect size 0.48, p<0.001).  ConclusionsThe positive associations of macular thickness with vascular Density and Caliber measurements were mainly attributable to their associations with GC-IPL and INL. Multidimensional relationships revealed by CCA revealed a complementary nature between the two sets of parameters, highlighting their value as a composite biomarker. Mendelian Randomization uncovered a bidirectional causal relationship that should provide insights into novel therapeutic approaches targeting both vascular and neuronal components.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: External validation of prognostic and predictive gene signatures in head and neck cancer patients\nAbstract: Head and neck squamous cell carcinomas (HNSCC) are aggressive and heterogenous tumors with a high fatality rate. Many gene signatures (GS) have been developed with both prognostic and predictive significance. We aimed to externally validate five published GS in a large European collection of HNSCC patients. Gene expression from 1097 treatment-naive HNSCC patients primary tumors was used to calculate scores for the five GS. Cox proportional hazard models were used to test the association between both 2-year overall survival and 2-year disease-free survival and the signature scores. The predictive role of GS was validated by comparing survival associations in patients receiving specific treatment (i.e., radiotherapy, systemic treatment) versus those who did not. We successfully externally validated all 5 GS, including two prognostic signatures, one signature as prognostic and predictive of sensitivity to systemic treatment, while signatures for cisplatin-sensitivity and radiosensitivity were validated as prognostic only.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-ancestry population attributable risk assessment of common genetic variation in Alzheimer's and Parkinson's diseases\nAbstract: Multiple scientific studies, mostly performed within European populations, have unraveled many of the genetic factors associated with Alzheimers disease (AD) and Parkinsons disease (PD) etiologies, improving our understanding of the molecular pathways implicated in the pathogenesis of these conditions. However, there is increasing evidence that the genetic architecture of these diseases differs across ancestral populations. This raises concerns about the efficacy of therapeutic interventions crafted around genetic targets prevalent only in European ancestry populations. Such interventions neglect potentially distinctive etiological profiles, including Latino, Black/African American, and East Asian populations. In the current study, we explore Population Attributable Risk (PAR) in AD and PD etiologies and assess the proportion of disease attributed to specific genetic factors across diverse populations. Leveraging data from genome-wide association studies across four ancestries, we explore distinct and universal therapeutic targets across diverse populations. Multi-ancestral genetics research is critical to the development of successful therapeutics and treatments for neurodegenerative diseases. By offering insights into genetic disparities, we aim to inform more inclusive and effective therapeutic strategies, advancing personalized healthcare.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-ancestry population attributable risk assessment of common genetic variation in Alzheimer's and Parkinson's diseases\nAbstract: Multiple scientific studies, mostly performed within European populations, have unraveled many of the genetic factors associated with Alzheimers disease (AD) and Parkinsons disease (PD) etiologies, improving our understanding of the molecular pathways implicated in the pathogenesis of these conditions. However, there is increasing evidence that the genetic architecture of these diseases differs across ancestral populations. This raises concerns about the efficacy of therapeutic interventions crafted around genetic targets prevalent only in European ancestry populations. Such interventions neglect potentially distinctive etiological profiles, including Latino, Black/African American, and East Asian populations. In the current study, we explore Population Attributable Risk (PAR) in AD and PD etiologies and assess the proportion of disease attributed to specific genetic factors across diverse populations. Leveraging data from genome-wide association studies across four ancestries, we explore distinct and universal therapeutic targets across diverse populations. Multi-ancestral genetics research is critical to the development of successful therapeutics and treatments for neurodegenerative diseases. By offering insights into genetic disparities, we aim to inform more inclusive and effective therapeutic strategies, advancing personalized healthcare.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the Joint Effects of Recurrent Copy Number Variants and Polygenic Scores on the Risk of Psychiatric Disorders in the iPSYCH2015 Case-Cohort Sample\nAbstract: The impact of rare recurrent copy number variants (rCNVs) and polygenic background attributed to common variants, on the risk of psychiatric disorders is well-established in separate studies. However, it remains unclear how polygenic background modulates the effect of rCNVs. Using the population-representative iPSYCH2015 case-cohort sample (N=96,599), we investigated the association between absolute risk of psychiatric disorders and carriage of rCNVs and polygenic scores (PGS), as well as the interaction effect between the two on disease risk.  Carriers of rCNVs with higher gene constraint scores had an increased absolute risk for autism, ADHD, and schizophrenia, but not depression, whereas an increase in PGS for each respective disorder was associated with higher absolute risk across all four disorders. Similarly, elevated absolute risks were observed with the increase of both PGS and gene constraints of rCNVs except in the case of depression. In contrast to some previous case-control studies, our joint analysis of rCNV groups and PGS revealed no indication of significant interactive effect between these two factors on disease risk. Also, we found no significant interactions of PGS with any of the most common individual rCNVs, except in the case of 16p13.11 duplication, which was found to attenuate the effect of ADHD-PGS on the absolute risk of ADHD.  This study advances our understanding of the interplay between rare and common important genetic risk factors for major psychiatric disorders and sheds light on the importance of population-based samples in implementing precision medicine.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dissecting the Reduced Penetrance of Putative Loss-of-Function Variants in Population-Scale Biobanks\nAbstract: Loss-of-function variants (LoFs) disrupt the activity of their impacted gene. They are often associated with clinical phenotypes, including autosomal dominant diseases driven by haploinsufficiency. Recent analyses using biobanks have suggested that LoF penetrance for some haploinsufficient disorders may be low, an observation that has important implications for population genomic screening. However, biobanks are also rife with missing data, and the reliability of these findings remains uncertain. Here, we examine the penetrance of putative LoFs (pLoFs) using a cohort of {approx}24,000 carriers derived from two population-scale biobanks: the UK Biobank and the All of Us Research Program. We investigate several possible etiologies for reduced pLoF penetrance, including biobank recruitment biases, annotation artifacts, missed diagnoses, and incomplete clinical records. Systematically accounting for these factors increased penetrance, but widespread reduced penetrance remained. Therefore, we hypothesized that other factors must be driving this phenomenon. To test this, we trained machine learning models to identify pLoFs with high penetrance using the genomic features specific to each variant. These models were predictive of penetrance across a range of diseases and pLoF types, including those with prior evidence for pathogenicity. This suggests that reduced pLoF penetrance is in fact common, and care should be taken when counseling asymptomatic carriers.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Digital phenotyping from wearables using AI characterizes psychiatric disorders and identifies genetic associations\nAbstract: Psychiatric disorders are complex and influenced by both genetic and environmental factors. However, studying the full spectrum of these disorders is hindered by practical limitations on measuring human behavior. This highlights the need for novel technologies that can measure behavioral changes at an intermediate level between diagnosis and genotype. Wearable devices are a promising tool in precision medicine, since they can record physiological measurements over time in response to environmental stimuli and do so at low cost and minimal invasiveness. Here we analyzed wearable and genetic data from a cohort of the Adolescent Brain Cognitive Development study. We generated >250 wearable-derived features and used them as intermediate phenotypes in an interpretable AI modeling framework to assign risk scores and classify adolescents with psychiatric disorders. Our model identifies key physiological processes and leverages their temporal patterns to achieve a higher performance than has been previously possible. To investigate how these physiological processes relate to the underlying genetic architecture of psychiatric disorders, we also utilized these intermediate phenotypes in univariate and multivariate GWAS. We identified a total of 29 significant genetic loci and 52 psychiatric-associated genes, including ELFN1 and ADORA3. These results show that wearable-derived continuous features enable a more precise representation of psychiatric disorders and exhibit greater detection power compared to categorical diagnostic labels. In summary, we demonstrate how consumer wearable technology can facilitate dimensional approaches in precision psychiatry and uncover etiological linkages between behavior and genetics.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Intravenous streptokinase for myocardial infarction: a reanalysis of the historical cumulative evidence using Trial Sequential Analysis\nAbstract: IntroductionCumulative meta-analysis of intravenous streptokinase for myocardial infarction has been used as a text-book example to show how the megatrials GISSI and ISIS-II were redundant and wasteful. We decided to reanalyse the dataset with Trial Sequential Analysis to account for statistical heterogeneity and the risk of bias of the historical trials to reassess whether GISSI and ISIS-II were justified or redundant.  MethodsWe extracted data from overviews published in 1982 and 1985 and trial reports on mortality outcomes. For the five largest trials conducted before GISSI and ISIS-II, we also extracted information on the used comparator, randomisation, blinding, dropout proportions, and the use of intention-to-treat analyses. We did random-effects cumulative meta-analyses with Trial Sequential Analysis considering diversity.  ResultsThe largest trials conducted before GISSI and ISIS-II had serious methodological differences and high risks of bias making a cumulative meta-analysis invalid by todays standards of evidence synthesis. The Trial Sequential Analysis showed that the monitoring boundary for a mortality benefit of streptokinase was reached during the ISAM trial. However, both GISSI and ISIS-II were launched before the ISAM trial was published. Focusing only on the cumulative assessment, the megatrials were potentially futile. Sensitivity analyses corroborated these results.  ConclusionOur Trial Sequential Analysis of the historical dataset of streptokinase for myocardial infarction found that conclusive evidence favouring streptokinase was established after the megatrials were launched. However, considering the methodological differences and risks of bias, such cumulative meta-analysis seems invalid. Accordingly, the megatrials were not wasteful.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Scaling-Up the Impact of Teledermoscopy on the Early Detection of Skin Melanoma using Convolutional Neural Networks with Mobile Apps\nAbstract: Advances in the cloud technology for secured distributed data storage, modern techniques for machine learning (ML), and access to large populations through mobile apps provide a unique opportunity for the healthcare industry professionals in the areas of early screening and medical diagnostics for certain diseases. This research study demonstrates the potential of ML using convolutional neural networks (CNN) for medical diagnostics of skin melanoma. Specifically, a comparison is presented between a shallow CNN (3-layers) with Resnet50 (50-layers) to classify open datasets of skin melanoma images as malignant or benign. Various ML performance metrics such as accuracy, recall, precision and receiver operating characteristic (ROC) are presented to recommend a deep learning model for the mobile app. Also, a novel framework is proposed for the scalability and adoption of ML-based medical diagnostics by large masses as a mobile app running on data-secure cloud platform. Using the open datasets, it is shown that skin cancer can be accurately diagnosed with a mobile phone app while maintaining patient privacy and data security.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and Determinants of E-Cigarette Use Among Diploma Students in a Vocational College: A Cross-Sectional Study\nAbstract: IntroductionThe prevalence of e-cigarette use is increasing globally, particularly among young adults which can predispose them to various health risks. This study aimed to determine the prevalence and factors associated with e-cigarette use among diploma students in a vocational college in a state in Malaysia.  MethodologyA cross-sectional study using probability proportionate to size sampling was conducted among 700 diploma students at a vocational college in Malaysia. A validated, self- administered questionnaire was distributed through the online method from April to May 2024. Bivariate analysis was done using Pearsons chi-square test or Fishers exact and simple logistic regression. Multivariable analysis was performed using multiple logistic regression for variables with a p<0.25 in the bivariate analysis. A value of p<0.05 was considered statistically significant, with a 95% confidence interval.  ResultsThe response rate was 87.7% with the prevalence of e-cigarette use was 29.0%. Factors significantly associated with e-cigarette use included male (aOR = 5.2, 95% CI: 2.7- 10.1), other races (aOR = 83.1, 95% CI: 2.2-3146.3), perceived e-cigarette aids in quit smoking (aOR = 1.6, 95% CI: 1.2-2.1), perceived e-cigarette does not contain the toxic chemicals found in conventional cigarette (aOR = 1.4, 95% CI: 1.0-2.0), having close friends who use conventional cigarette (aOR = 2.1, 95% CI: 1.0-4.1) or e-cigarette (aOR = 8.0, 95% CI: 2.3- 28.1), e-cigarette exposure on television (aOR = 2.1, 95% CI: 1.0-4.2), positive attitude towards e-cigarette (aOR = 1.2, 95% CI: 1.1-1.2), higher willingness to use (aOR = 1.2, 95% CI: 1.0-1.3), and higher intention to use (aOR = 1.4, 95% CI: 1.2-1.5).  ConclusionFactors associated with e-cigarette use among diploma students included being male, other races (Bumiputera Sabah and Sarawak), positive health risks perceptions, peer influence, and exposure to e-cigarettes on television. Targeted interventions addressing these factors may be more effective in changing social norms and reducing e-cigarette use among this population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subcortical imaging-derived phenotypes are associated with the risk of Parkinson's disease: A Mendelian Randomization Study\nAbstract: BackgroundThe abnormalities of subcortical structures, such as putamen and caudate, play a key role in the occurrence of Parkinsons disease (PD); however, whether and how imaging-derived phenotypes (IDPs) in subcortical structures are causally associated with the risk of PD remain poorly understood.  MethodsThe causal associations between subcortical IDPs from UK biobank and risk of PD were evaluated with bidirectional two-sample Mendelian randomization (MR) studies.  ResultsTotally five subcortical IDPs were found to be causally associated with the risk of PD. Among these IDPs, IDP 168 (Global volume of subcortical gray matter, OR = 1.38 [1.16, 1.63], P = 1.82 x 10-4), IDP 214 (Right putamen volume, OR = 1.31 [1.15, 1.50], P = 7.71 x 10-5) and IDP 1441 (T2* signal in right caudate, OR = 1.21 [1.09, 1.35], P = 5.23 x 10-4) were found to be associated with increased risk of PD. In contrast, IDP 1358 (Mean intensity in right caudate, OR = 0.72 [0.62, 0.85), P = 6.77 x 10-5) and IDP 1344 (Mean intensity in left caudate, OR = 0.76 [0.65, 0.88], P = 3.23 x 10-4) were associated with reduced risk of PD.  ConclusionsThe specific imaging features of the caudate and putamen are causally associated with altered risk of developing PD, thereby providing new insights into the development of novel predictive imaging biomarkers and therapies for PD patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Fine Mapping Coronary Artery Disease Loci in the UK Biobank Whole Genome Sequencing Data by Optimising Usage of the Cloud Based Research Analysis Platform\nAbstract: We conducted the first comprehensive association analysis of a coronary artery disease (CAD) cohort within the recently released UK Biobank whole genome sequencing dataset. We employed fine mapping tool PolyFun1 and pinpoint rs10757274 as the most likely causal SNP within the 9p21.3 CAD risk locus. Notably, we show that machine-learning (ML) approaches, REGENIE2 and VariantSpark3, exhibited greater sensitivity compared to traditional single-SNP logistic regression, uncovering rs28451064 in the 21q22.11 risk locus. Our findings underscore the utility of leveraging advanced computational techniques and cloud-based resources for mega-biobank analyses. Aligning with the paradigm shift of bringing compute to data, we demonstrate substantial resource optimisation (44% reduction) and performance gains (40% speedup) through compute architecture optimisation on UK Biobanks Research Analysis Platform and discuss three considerations for researchers implementing novel workflows to such datasets hosted on cloud-platforms. This study paves the way for harnessing mega-biobank-sized data through scalable, cost-effective cloud computing solutions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Surgical strategy for atrial functional mitral regurgitation with atrial fibrillation\nAbstract: BackgroundWith the growing prevalence of atrial fibrillation (AF), atrial functional mitral regurgitation (AFMR) combined with AF is expected to become a common clinical issue. We have summarized various surgical treatment strategies based on the degree of mitral regurgitation (MR) alongside rhythm control therapy for patients with AFMR and AF.  MethodsThis retrospective study included 145 patients with AF and MR from January 2017 to January 2023. 33 patients with AF and moderate AFMR were designated as the moderate atrial regurgitation (MAR) group. 56 patients with AF and severe AFMR were designated as the severe atrial regurgitation (SAR) group. The remaining 56 patients with AF and severe primary MR were designated as the severe primary regurgitation (SPR) group. All patients in the MAR group underwent thoracoscopic AF procedure via a unilateral approach. Patients in the SAR and SPR groups underwent mitral valvuloplasty plus the Cox Maze IV procedure (CMP IV). Descriptive characteristics and outcomes were analysed.  ResultsTwenty-three patients maintained sinus rhythm (SR) following thoracoscopic AF procedure in the MAR group at average 2.6{+/-}1.1 years follow-up. The degree of regurgitation improved in 26 patients, remained unchanged in 6 patients, and worsened in 1 patient. SR maintenance benefits MR reduction (P<0.0001) compared to the non-SR patients. There was no significant difference in the rate of SR maintenance following mitral valvuloplasty plus CMP IV between SAR (43 patients, 79.6%) and SPR (49 patients, 87.5%) groups. At the last follow-up, echocardiography in the SAR group showed 47 cases with no mitral regurgitation, 4 cases with mild regurgitation, and 1 case with moderate regurgitation. The left atrial diameter in the SAR group remained larger than in the SPR group (P<0.001).  ConclusionsRhythm control therapy is the cornerstone treatment for AFMR patients with AF. Thoracoscopic AF procedure is effective and minimally invasive for moderate AFMR patients with AF. For severe AFMR patients with AF, we recommend CMP IV plus mitral valvuloplasty for safety and effectiveness.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Behavioural changes in frontotemporal dementia and their cognitive and neuroanatomical correlates\nAbstract: Behavioural changes are a central feature of frontotemporal dementia (FTD); they occur in both behavioural-variant (bvFTD) and semantic dementia (SD)/semantic-variant primary progressive aphasia subtypes. In this study we addressed two current clinical knowledge gaps; (i) are there qualitative or clear distinctions between behavioural profiles in bvFTD and SD, and (ii) what are the precise roles of the prefrontal cortex vs. anterior temporal lobes in supporting social behaviour? Resolving these conundrums is crucial for improving diagnostic accuracy and for the development of targeted interventions to treat challenging behaviours in FTD. Informant questionnaires to assess behavioural changes included the Cambridge Behavioural Inventory-Revised and two targeted measures of apathy and impulsivity. Participants completed a detailed neuropsychological battery to permit investigation of the relationship between cognitive status (including social-semantic knowledge, general semantic processing and executive function) with behaviour change in FTD. To explore changes in regional grey matter volume, a subset of patients had structural MRI. Diagnosis-based group comparisons were supplemented by a transdiagnostic approach which encompassed the spectrum of bvFTD, SD and \"mixed\" or intermediate cases. Such an approach is sensitive to the systematic graded variation in FTD and allows the neurobiological underpinnings of behaviour change to be explored across the entire FTD spectrum. We found a wide range of behavioural changes across FTD. Although quantitatively more severe on average in bvFTD, as expected, the item-level analyses found no evidence for qualitative differences in behavioural profiles or \"behavioural double dissociations\" between bvFTD and SD. Comparisons of self and informant ratings revealed strong discrepancies in the perspective of the caregiver vs. patient. Logistic regression revealed that neuropsychological measures had better discriminative accuracy for bvFTD vs. SD than carer-reported behavioural measures. A principal component analysis of all informant questionnaire domains extracted three components, interpreted as reflecting: (1) apathy, (2) challenging behaviours and (3) activities of daily living. More severe apathy in both FTD subtypes was associated with (a) increased levels of impaired executive function and (b) anterior cingulate cortex atrophy. Questionnaire ratings of impaired behaviour did not correlate with either anterior temporal lobe atrophy or degraded social-semantic knowledge. Together, these findings highlight the presence of a wide range of behavioural changes in both bvFTD and SD, which vary by degree rather than quality. We recommend a transdiagnostic approach for future studies of the neuropsychological and neuroanatomical underpinnings of behavioural deficits in FTD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterizing Highly Fermentable Carbohydrate Foods in the Diets of Children with Disorders of Gut-Brain Interaction and Healthy Children\nAbstract: ObjectivesRestricting fermentable oligosaccharides, disaccharides, monosaccharides, and polyols (FODMAPs) intake can alleviate symptoms in children with gut-brain interaction disorders (DGBI). Due to the restrictive nature of the low FODMAP diet (LFD), the less restrictive FODMAP Gentle diet (FGD) has been suggested. However, the types of high FODMAP foods and carbohydrates commonly consumed by US children are unknown, as is the impact of the FGD on a typical diet. This project aimed to identify the high FODMAP foods and proportions of FODMAP carbohydrates consumed by children with DGBI and healthy children (HC), and to determine which usually ingested FODMAPs would be restricted on the FGD.  MethodsThree-day diet records from both HC and children with DGBI were analyzed to assess the type of high FODMAP foods and carbohydrates ingested. Results were compared between the groups. The ingested FODMAPs that would be restricted on the FGD was determined.  ResultsThe number of foods ingested daily was similar between children with DGBI and HC (12.3 {+/-} 4.2 vs 12.9 {+/-} 3.4, respectively); high FODMAP foods comprised most foods eaten in both groups. Children with DGBI (vs HC) ate less high FODMAP foods per day (6.5 {+/-} 2.3 vs 8.7 {+/-} 2.4, P<0.0001, respectively). Fructans were the most consumed FODMAP carbohydrate in both groups and children with DGBI (vs HC) consumed fewer fructans, lactose, fructose, and polyols (all P<0.0001). The top 3 food categories consumed in both groups were wheat-containing foods, dairy, and fruits and 100% fruit juices. In children with DGBI, 80.9% of the high FODMAP foods consumed would be limited on the FGD.  DiscussionChildren with DGBI consume significantly fewer high FODMAP foods and carbohydrates than HC. In both groups, the top consumed FODMAP carbohydrates are fructans, lactose, and fructose. A FODMAP Gentle diet would restrict a large majority of high FODMAP foods consumed by children with DGBI.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Americans in rural areas are less likely to receive stress management counseling from physicians: a national repeated cross-sectional study of the 2018 and 2019 National Ambulatory Medical Care Survey\nAbstract: Stress is a significant contributor to suicide ideation and attempts. This paper (1) describes the frequency of clinic visits in which physicians record stress management counseling; and (2) identifies visit-, physician-, and patient-related predictors of stress management counseling. We conducted a secondary analysis of the 2018 and 2019 National Ambulatory Medical Care Survey (NAMCS) clinic visit datasets. We identified clinic-, patient-, and physician-related predictors of stress management counseling. All analyses used weighted adjustment to account for the complex survey design. The weighted sample included 1,495,326,615 visits (unweighted (n=14,175) in 2018-2019. Combined, 1.32 per 100 visits (95% CI=0.72-1.92) included stress management counseling. Stress management counseling was less likely to occur when the visit occurred in a rural area (OR=0.22, 95% CI=0.09-0.53), among other characteristics. Stress management counseling rarely occurs during physician office visits in rural areas, despite rural areas suffering disproportionately worse health outcomes than urban areas.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-layered Diagnostic Protocol Improves Postsurgical Outcomes in Children with Drug-resistant Epilepsy And Focal Cortical Dysplasia Type 1\nAbstract: ObjectivesWe comprehensively characterised a large paediatric cohort with histologically confirmed focal cortical dysplasia (FCD) type 1 to demonstrate the role of advanced multimodal pre-surgical evaluation and identify predictors of postsurgical outcomes.  MethodsThis study comprised a systematic re-analysis of clinical, electrophysiological, and radiological features. The results of this re-analysis served as independent variables for subsequent statistical analyses of outcome predictors.  ResultsAll children (N = 31) had drug-resistant epilepsy with varying impacts on neurodevelopment and cognition (presurgical intelligence quotient (IQ)/developmental quotient scores: 32-106). Low presurgical IQ was associated with abnormal slow background electroencephalogram (EEG) activity and disrupted sleep architecture. Scalp EEG showed predominantly multiregional and often bilateral epileptiform activity. Advanced epilepsy magnetic resonance imaging (MRI) protocols identified FCD-specific features in 74.2% of patients (23/31), 17 of whom were initially evaluated as MRI-negative. In six out of eight MRI-negative cases, fluorodeoxyglucose positron emission tomography (FDG-PET) and subtraction ictal single-photon emission computed tomography co-registered to MRI (SISCOM) helped localise the dysplastic cortex. Sixteen patients (51.6%) underwent stereoelectroencephalography (SEEG). Twenty-eight underwent resective surgery, and three underwent hemispheral disconnection. Seizure freedom was achieved in 71.0% of patients (22/31) by the last follow-up, including seven of the eight MRI-negative patients. Anti-seizure medications (ASMs) were reduced in 21 patients, with complete withdrawal in 5 individuals. Seizure outcome was predicted by a combination of the following descriptors: age at epilepsy onset, epilepsy duration, long-term invasive EEG, and specific MRI, and PET findings.  SignificanceThis study highlights the broad phenotypic spectrum of FCD type 1, which spans far beyond the narrow descriptions of previous studies. Combining advanced MRI protocols with additional neuroimaging techniques helped localise the epileptogenic zone in many previously non-lesional cases. Complex multimodal presurgical approaches (including SEEG) could enhance postsurgical outcomes in these complex patients.  Key pointsO_LIThe phenotypic spectrum of paediatric patients with FCD type 1 spans beyond the narrow description of previous studies C_LIO_LIMRI-negative patients benefit from enhanced precision in localising the epileptogenic zone, facilitated by FDG-PET, SISCOM, and SEEG C_LIO_LIA complex multimodal presurgical approach could enhance postoperative seizure outcomes in patients with FCD type 1 C_LIO_LIPaediatric patients with suspected FCD type 1 should be referred to epilepsy surgery centres as soon as possible C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A novel alpha-synuclein G14R missense variant is associated with atypical neuropathological features\nAbstract: BackgroundParkinsons disease (PD) affects millions of people worldwide, but only 5-10% of patients suffer from a monogenic form of the disease with Mendelian inheritance. SNCA, the gene encoding for the protein alpha-synuclein (aSyn), was the first to be associated with familial forms of PD and, since then, several missense variants and multiplications of the SNCA gene have been established as rare causes of autosomal dominant forms of PD.  Aim and methodsA patient carrying aSyn missense mutation and his family members were studied. We present the clinical features, genetic testing - whole exome sequencing (WES), and neuropathological findings. The functional consequences of this aSyn variant were extensively investigated using biochemical, biophysical, and cellular assays.  ResultsThe patient exhibited a complex neurodegenerative disease that included generalized myocloni, bradykinesia, dystonia of the left arm and apraxia. WES identified a novel heterozygous SNCA variant (cDNA 40G>A; protein G14R). Neuropathological examination showed extensive atypical aSyn pathology with frontotemporal lobar degeneration (FTLD) and nigral degeneration pattern with abundant ring-like neuronal inclusions, and few oligodendroglial inclusions. Sanger sequencing confirmed the SNCA variant in the healthy, elderly parent of the patient suggesting incomplete penetrance. NMR studies suggest that the G14R mutation induces a local structural alteration in aSyn, and lower thioflavin T binding in in vitro fibrillization assays. Interestingly, the G14R aSyn fibers display different fibrillar morphologies as revealed by cryo-electron microscopy. Cellular studies of the G14R variant revealed increased inclusion formation, enhanced membrane association, and impaired dynamic reversibility of serine-129 phosphorylation.  SummaryThe atypical neuropathological features observed, which are reminiscent of those observed for the G51D aSyn variant, suggest a causal role of the SNCA variant with a distinct clinical and pathological phenotype, which is further supported by the properties of the mutant aSyn, compatible with the strain hypothesis of proteinopathies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Frequency and Potential Risk Factors Associated with the Development of Asymptomatic T2 Hyperintense Cervical Spine Lesions on MRI in Patients with Relapsing-Remitting Multiple Sclerosis\nAbstract: BackgroundMultiple sclerosis (MS) is one of the most common non-traumatic neurologic disorders affecting young adults in the United States. Brain MRI is an important tool for monitoring disease activity and treatment efficacy in people with MS. Spinal cord (SC) imaging has been less consistently used for monitoring inflammatory disease activity, and the frequency of clinically silent breakthrough disease in the SC is still unknown. Given the particular vulnerability of the cervical spinal cord (c-SC) to inflammatory demyelination, it is important to evaluate the necessity of routine c-SC scanning or to ascertain appropriate strategies for its monitoring, considering the burden of each scan on a person with MS, including scanner discomfort and cost.  ObjectiveTo determine how frequently follow-up magnetic resonance imaging (MRI) of the cervical spinal cord (c-SC) in patients with relapsing remitting multiple sclerosis (RRMS) reveals asymptomatic T2 hyperintense lesions, either in combination or in the absence of new MRI brain lesions, and to identify potential associated risk factors for developing such lesions.  MethodsPatients aged 18-65 years who were diagnosed with RRMS and were seen in longitudinal follow-up at the Johns Hopkins MS Center from January 1, 2014, to December 1, 2019, with an MRI brain and C spine performed during that period, were included. The results of up to four c-SC scans were considered during this study period. Asymptomatic new lesions were identified as new hyperintense T2 lesions, with or without enhancement, observed on MRI during routine follow-up surveillance. Univariate and multivariable-adjusted logistic regression (sex at birth, age, race, and current disease modifying therapy [DMT] category) were employed to identify factors associated with the development of an asymptomatic c-SC lesion for the first scan. Additionally, a mixed-effects logistic regression analysis was performed to assess factors associated with developing asymptomatic lesions across successive scans.  ResultsA total of 869 individuals were included in the cohort, contributing a median of 3 (interquartile range: 2,4) scans per person. The proportion of incidental asymptomatic lesions identified ranged from 4.8 to 12.1% across the four scans analyzed in the study. Among those with new lesions in the c-SC, roughly half also showed concomitant new activity on brain MRI. The multivariate model was notable for Black/African Americans having higher odds of an asymptomatic new lesion (OR= 3.26, 95% CI 0.79, 5.93, p<0.0001), a result that persisted in mixed effects logistic regression models (OR = 1.73, 95% CI = 1.27, 2.35, p = 0.001). Higher-efficacy therapies were associated with higher odds of detection of a new lesion in the mixed-effects model, an association that was not present when considering just the first scan results as the outcome.  ConclusionWhile the association of higher-efficacy therapy is presumed to be related to confounding by indication, Black/African American individuals with MS appear to be at higher risk of developing an asymptomatic c-SC lesion on MRI surveillance, which could suggest higher value of ordering asymptomatic screening imaging of the cord in this subpopulation. Ultimately, however, a very small percentage of the overall population of those with MS has a new cord lesion in the absence of symptoms, and half of those have a new lesion on screening brain MRI. These findings should motivate the creation and validation of predictive models to inform the utility cord imaging at a given timepoint for a given individual with MS, which could enhance healthcare quality and reduce costs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Precise interpretation and prioritization of sequence variants with Onkopus for supporting molecular tumor boards\nAbstract: One of the major challenges in precision medicine is the identification of pathogenic, actionable variants and the selection of personalized treatments. We present Onkopus, a variant interpretation framework, based on a modular architecture, for interpreting and prioritizing genetic alterations in cancer patients. We show that aggregation and harmonization of clinical databases, coupled with querying of these databases to varying associated biomarkers, can increase the number of identified therapeutic options. We present a protein analysis of mutated sites and show that protein characteristics can provide potential indicators for the functional impairment of variants of unknown significance. Variant interpretation systems like Onkopus have the potential to significantly enhance the performance of personalized treatments, as they reduce the time required for variant interpretation and manual evaluation of personalized treatments, while maintaining reproducibility and traceability. We provide a free public instance of Onkopus at https://mtb.bioinf.med.uni-goettingen.de/onkopus.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Epitranscriptome Mapping of m6A RNA Modifications in Glioma Tumor Tissue\nAbstract: Glioma represents the most common primary central nervous system (CNS) neoplasm in adults. IDH1 mutation is recognized as a hallmark alteration with important diagnostic and prognostic implications. There is considerable evidence for global DNA hypermethylation induced secondary to IDH mutation. However, there is limited understanding of the RNA methylation patterns and its role in glioma biology. In this study, we performed transcriptome wide profiling of N6-methyladenosine (m6A) modifications across IDH mutant (n = 8) and wild-type (n = 7) gliomas using Oxford Nanopore Technologies direct RNA sequencing platform. Our approach enabled high-depth coverage of native transcripts, revealing nearly twice as many full-length transcripts in IDH mutant gliomas compared to wild-type. Notable differences in alternative splicing were observed across glioma subtypes, with truncated and non-coding isoforms more prevalent in glioblastoma (GBM). We further identified significant changes in isoform usage within key metabolic (NAMPT, PKM) and immune (CD63, CD151, CD81) pathways. Chromosomal distribution of m6A sites showed a higher prevalence of m6A modifications in IDH mutant gliomas, with the most pronounced differences on chromosomes 19 and 16. Further stratification by TERT, MGMT, and TP53 mutations revealed similar patterns of increased m6A site numbers in mutant groups, highlighting the importance of integrating epigenomic and epitranscriptomic data in glioma research. These findings highlight the role of m6A modifications in the metabolic reprogramming unique to IDH mutant gliomas, providing insights into potential mechanisms of tumorigenesis and therapeutic resistance.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dental health of childhood cancer survivors. A report from the Swiss Childhood Cancer Survivor Study (SCCSS)\nAbstract: BackgroundCancer and its treatments can affect dental health of childhood cancer survivors. We aimed to evaluate prevalence of dental problems in survivors, compare them to their siblings, and investigate cancer-related risk factors.  MethodsAs part of the population-based Swiss Childhood Cancer Survivors Study, we sent questionnaires inquiring about dental problems to survivors aged 5-19 years and their siblings. We retrieved cancer-relevant information from the Swiss Childhood Cancer Registry and used logistic regressions to compare dental problems between survivors and siblings and to investigate cancer-related risk factors.  ResultsWe included 735 survivors and 144 siblings. Almost half of survivors and siblings reported at least one dental problem. Compared to siblings, survivors had a greater risk for hypo- or microdontia (OR 1.7; 95%CI 0.9-3.2) and enamel hypoplasia (2.2; 0.8-6.0), but similar risk for cavities or cavity-related tooth loss (0.8; 0.6-1.3). Chemotherapy was associated with enamel hypoplasia (3.0; 1.2-10.4), cavities or cavity-related tooth loss (1.5; 1.0-2.3), and gum problems during (23.0; 9.4-76.2) and after (4.6; 2.0-13.5) treatment. Hematopoietic stem cell transplantation (HSCT) was related to hypo- or microdontia (5.4; 2.6-10.7), cavities or cavity-related tooth loss (2.1; 1.2-3.6), and gum problems during treatment (2.0; 1.2-3.6). For hypo- or microdontia and cavities, associations with treatment were driven by patients diagnosed <5 years.  ConclusionChildhood cancer patients treated with chemotherapy or HSCT, especially at a young age, were at higher risk for dental problems. Regular dental check-ups guided by healthcare teams and dental hygiene habits can mitigate risks and promote survivors long-term dental health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Unmasking Neuroendocrine Prostate Cancer with a Machine Learning-Driven 7-Gene Stemness Signature that Predicts Progression\nAbstract: Prostate cancer (PCa) poses a significant global health challenge, particularly due to its progression into aggressive forms like neuroendocrine prostate cancer (NEPC). This study developed and validated a stemness-associated gene signature using advanced machine learning techniques, including Random Forest and Lasso regression, applied to large-scale transcriptomic datasets. The resulting 7-gene signature (KMT5C, MEN1, TYMS, IRF5, DNMT3B, CDC25B and DPP4) was validated across independent cohorts and patient-derived xenograft (PDX) models. The signature demonstrated strong prognostic value for progression-free, disease-free, relapse-free, metastasis-free, and overall survival. Importantly, the signature not only identified specific NEPC subtypes, such as large-cell neuroendocrine carcinoma, which is associated with very poor outcomes, but also predicted a poor prognosis for PCa cases that exhibit this molecular signature, even when they were not histopathologically classified as NEPC. This dual prognostic and classifier capability makes the 7-gene signature a robust tool for personalized medicine, providing a valuable resource for predicting disease progression and guiding treatment strategies in PCa management.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Fusion of middle ear optical coherence tomography and computed tomography in three ears\nAbstract: ImportanceMiddle ear OCT imaging in patients has not previously been directly compared to a standard of care clinical 3D imaging technology such as CT. This represents the first such comparison and provides new insight into OCTs capabilities, strengths and limitations.  ObjectiveTo qualitatively compare the capabilities of middle ear OCT to CT in normal and pathological ears on representative slices in co-registered OCT and CT datasets.  Design, Setting, and ParticipantsOne normal middle ear, one ear affected by traumatic injury and one ear with cholesteatoma were imaged with both OCT and high-resolution clinical temporal bone CT. Participants were drawn from the patient population of a tertiary otology clinic. CT and OCT images were aligned using rigid co-registration with manual landmark selection.  Main Outcomes and MeasuresImages were analyzed qualitatively for field of view, resolution, shadowing, artefacts, soft tissue and bony tissue contrast and presentation of diagnostically important features.  ResultsIn the three imaged ears, OCT was capable of visualizing many of the important features indicative of middle ear pathology. When compared to CT, OCT was found to exhibit a limited field of view (FOV) largely confined to the mesotympanum and subject to shadowing from bony structures. However, OCT could resolve soft tissue features that were not readily apparent in the CT images, to have a higher resolution than CT and to provide excellent anatomical fidelity with CT which allowed OCT images to be accurately co-registered with CT images.  Conclusions and RelevanceThe results support a role for middle ear OCT in otological diagnostics. While OCT is not capable of replacing CT due to its limited FOV and inability to image through thick bony tissues, it can visualize many signs of pathology including some soft tissue features that are difficult to visualize with CT. Given OCTs ability to image in real-time, its compatibility with in-office imaging and its lack of ionizing radiation, it may, despite its limitations compared to CT, be an appealing imaging modality for many applications in middle ear diagnostics.  Key PointsO_ST_ABSQuestion (1 sentence)C_ST_ABSWhat are the strengths and limitations of middle ear optical coherence tomography (OCT) imaging compared to computed tomography (CT) in real-world clinical imaging scenarios?  Finding (1-2 sentence)OCT and CT imaging produce complementary diagnostic information with CT offering unobstructed images of bony anatomy and OCT providing the ability to visualize soft tissue.  Meaning (1 sentence)OCT, CT and fused OCT/CT imaging can each provide useful, complementary diagnostic information in clinical otology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Molecular Diagnosis of Heart Allograft Rejection Using Intra-Graft Targeted Gene Expression Profiling: the heart HistoMX system\nAbstract: Background and aimsTissular gene expression profiling has the potential to refine the diagnosis of cardiac allograft rejection. Contrary to whole-transcriptome approaches, targeted molecular profiling applicable to formalin-fixed paraffin-embedded (FFPE) endomyocardial biopsies (EMB) can be easily implemented in clinical practice. We aimed to develop and validate the first rejection molecular diagnostic system dedicated to heart transplantation (HTx).  MethodsAn international multicenter study was designed, building a deep phenotyped cohort of HTx recipients recruited between 2011 and 2021 at 4 referral centers. Detailed donors, recipients, clinical, immunological, biological, and histological parameters were collected. EMBs were graded according to international working formulations. Tissue gene expression was analyzed on FFPE-EMB using the consensus Banff Human Organ Transplant gene set. Molecular classifiers of antibody-mediated (AMR) and acute cellular rejection (ACR) were built. Discrimination and calibration were assessed in the development and validation sets (NCT06436027).  ResultsA total of 591 biopsies were included: 188 AMR (pAMR1(I+): n=51; pAMR1(H+): n=58; pAMR2-3: n=79), 289 ACR (1R n=174; 2-3R n=115) and 114 matched non-rejection cases. Biopsies were split in a derivation (n=476) and a validation set (n=115). AMR top significant transcripts were related to the IFN-gamma inducible pathway, endothelial activation, and monocyte-macrophage recruitment. ACR was characterized by transcripts related to T-cell receptor, CD3 receptor activation, and CD28 signaling. ACR and AMR molecular rejection models were strongly associated with the pathology severity of rejection and accurately identified rejection in the derivation (ROC-AUC: AMR=0.831, ACR:=0.837) and validation sets (ROC-AUC: AMR=0.812; ACR=0.849). Calibration was adequate. The robustness of the molecular classifiers were reinforced by various sensitivity analyzes. An automated report was developed to enhance the reproducibility and clinical applicability of the molecular analysis.  ConclusionsIn this study, the first tissue-based rejection molecular diagnostic system applicable to FFPE- EMB and dedicated to heart transplantation rejection was developed and internally validated. This tool has the potential to refine the diagnosis of rejection.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Non-invasive epidermal proteome assessment-based diagnosis and molecular subclassification of psoriasis and eczematous dermatitis\nAbstract: BackgroundImmunologic heterogeneity is known to exist within both eczematous dermatitis and psoriasis; however, selection of molecularly targeted therapies for individual patients generally does assess for or incorporate such information about patient-specific immune changes.  ObjectiveWe sought to develop a rapid, non-invasive method for obtaining and analyzing epidermal protein biomarkers from skin and utilize this methodology to dissect immunologic heterogeneity in both psoriasis and eczematous dermatitis.  MethodsWe optimize and evaluate detergent-based immune profiling system (DIPS) which utilizes a combination of two detergents to solubilize full-thickness epidermis when applied to the skin with an applicator. Downstream proteomic profiling of this material allows high-throughput immunologic characterization of immune biomarkers.  ResultsDIPS was performed on 43 patients with psoriasis and 27 patients with eczematous dermatitis. This approach was found to be painless, nonscarring, and enabled rapid turnaround from sample collection to data output. We used this approach to accurately differentiate psoriasis and eczema using a limited set of proteins and to identify cases of eczema/psoriasis overlap with non-canonical molecular profiles. Additionally, we measured patient-specific cytokine profiles in eczema that correlated with response to IL-4R blockade.  ConclusionDIPS is a promising new non-invasive cutaneous immune profiling approach that can deconvolute immune heterogeneity amongst patients with both psoriasis and eczematous dermatitis.  Clinical ImplicationDIPS has potential applications in both research and day-to-day dermatologic practice and may help personalize diagnosis and medication selection in patients with inflammatory skin diseases.  Capsule summaryDetergent-based immune profiling system (DIPS), a novel non-invasive approach for molecular evaluation of skin disease, is described and evaluated in psoriasis and eczematous dermatitis\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessment effectiveness of 'Nilee Vyema brochure on knowledge of breastfeeding, kangaroo mother care and hygiene practice among mothers in central Tanzania. A study protocol.\nAbstract: BackgroundPrematurity is a challenge affecting child health worldwide and mothers who are the sole care providers of preterm infants post discharge must possess the necessary knowledge to be able to properly care for their preterm infant at home.  ObjectiveThe main objective of this study will be to assess the effectiveness of NILEE VYEMA brochure on knowledge of breastfeeding, kangaroo care and hygiene among mothers with preterm infants in central Tanzania. A sample of 112 mothers with preterm infants will be recruited from two randomly selected regional hospitals in central Tanzania in 2024. A quasi pre-test post-test experimental design will be used and the Nilee Vyema brochure will be adapted from several literatures. Both the control group and intervention group will be given the pretest questionnaire to assess baseline knowledge. The control group will receive routine education lecture based on breastfeeding, kangaroo mother care and hygiene topics while the intervention group will receive both routine education in conjunction with the Nilee Vyema brochure. Interventional sessions will include lectures on breastfeeding, kangaroo mother care and hygiene to influence the knowledge and skills of these mothers in caring for their preterm. After the intervention, both groups will be given the pretest questionnaire which will assess end-line knowledge.  AnalysisData will be analyzed using SPSS (version 20) for descriptive statistics to describe the characteristics of the study samples and inferential statistics to test the effectiveness of the brochure before and after intervention. Furthermore, chi-square test will be used to describe the relationship between categorical variables at p < 0.05.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Examining Age-Dependent Patterns in Academic Bullying Behaviors\nAbstract: Academic bullying is a pervasive and longstanding issue that negatively affects all fields of science. While influential factors such as scientific discipline, sex, and ethnicity have been investigated, the impact of perpetrators age on the contextual behaviors of academic bullying has not been thoroughly studied. Our cross-sectional global survey of academic bullying, involving 2,390 participants, provides evidence that age significantly influences the contextual behaviors of academic bullying. Our results revealed that the youngest perpetrators (aged 25-35) exhibit significantly less abusive behavior compared to other age categories (36 and older). Additionally, the lowest percentage of abusive behavior was observed in the youngest group, while the highest was found in the older groups (aged 56-65). Our comprehensive analysis on the potential influence of the perpetrators academic position, ethnicity, or sex on their age group revealed no significant impact. These findings have strong implications for the development of more customized academic bullying training, policy development, and monitoring strategies, ultimately benefiting the scientific community at large in many aspects including evolution of science and improving the mental health of the academic workforce.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Opioids Diminish the Placebo Antidepressant Response: A Post Hoc Analysis of a Randomized Controlled Ketamine Trial\nAbstract: BackgroundThe endogenous opioid system is thought to play a role in the placebo antidepressant response. A recent trial comparing the rapid antidepressant effects of ketamine versus placebo in surgical patients, some of whom were on chronic opioid therapy, revealed a substantial placebo effect. This finding provided an opportunity to test the hypothesis that opioid agonist exposure interacts with placebo antidepressant responses.  MethodsThis post hoc analysis utilized data from a previously reported randomized, anesthesia-blinded, placebo-controlled trial of intravenous ketamine in depressed patients undergoing routine surgery. Mixed-effects models were used to determine whether baseline opioid use influenced antidepressant responses to the trial interventions, as measured by the Montgomery-[A]sberg Depression Rating Scale (MADRS) over 1 to 14 days post-treatment.  ResultsThe analysis showed that baseline opioid use significantly reduced post-treatment depression severity in patients who received placebo, but not in those who received ketamine. This reduction was independent of baseline depression severity, baseline pain intensity, and ethnicity. Additionally, there was negligible correlation between postoperative pain intensity and depression severity.  LimitationsThis analysis was unregistered and conducted on a small sample; the findings need to be confirmed by prospective controlled studies.  ConclusionsOpioid use at baseline attenuated the placebo antidepressant response independently of pain in depressed patients who received the study treatment under general anesthesia for routine surgery. The antidepressant response was preserved in opioid users who received intravenous ketamine.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Can health information and decision aids decrease inequity in health care? A systematic review on the equality of their effectiveness\nAbstract: ObjectivesSystematic review of studies evaluating evidence-based health information (EBHI) and decision aids (DAs) in terms of the extent to which inequity-producing factors have been considered and how these factors affect access to health-related information and informed decision-making.  Study designSystematic review of randomised controlled trials.  MethodsSystematic searches were performed in the Cochrane Library, PubMed, Embase, PsycINFO, CINAHL, ERIC and PSYNDEX from inception to May 2023 to identify evaluation studies of EBHI and DAs that take into account factors associated with unequal opportunities as defined by PROGRESS Plus. Information on the effect of these factors was extracted and analysed in terms of outcomes relevant to the decision-making process.  ResultsFew studies have examined the impact of EBHI/DAs on outcomes relevant to decision-making with respect to inequity-producing factors. In our final synthesis,12 studies were included. A positive association between the effectiveness of the intervention and the disadvantage status could be found twice and a negative association in three studies. Overall, most of the studies found no difference in knowledge gain, decision conflict and shared decision-making (SDM) between those advantaged and disadvantaged in terms of ethnicity, gender, education, age, income, health literacy, numeracy or socioeconomic status (SES). However, few trials examined this effect and the effect was considered solely in subgroup analyses that were probably underpowered, so asymmetries between these groups may not have been detected in the existing designs.  ConclusionEBHI and DAs have been shown to be effective in promoting decision-making and thus in improving health care. To improve health care equitably, greater attention needs to be paid to methodological requirements in evaluations to fully capture potential differences in access to health-related information between individuals or in populations within the target groups of EBHI/DAs.  PROSPERO registrationCRD42018103456  What is already known?O_LIThere is evidence that EBHI and DAs do not reach certain patient groups because while being developed and evaluated they do not adequately take into account differences in access to health-related information between different social groups. C_LIO_LIThere is insufficient evidence whether EBHI and DAs are equally effective for people with factors that are more or less associated with equal access to health information. C_LI  What the study addsO_LIA systematic review of evaluation studies of EBHI and DAs to consider factors that lead to inequity and analysis of how these factors influence the intervention effects in terms of access to health-related information and outcomes relevant for decision-making. C_LI  How this study might affect research, practice or policy?O_LIOur research makes a valuable contribution to more equitable health care by stressing critical inequality factors that may influence informed decision-making with the help of EBHI and DAs. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Characterization of motor function recovery using muscle synergies in stroke patients undergoing upper limb rehabilitation\nAbstract: In stroke rehabilitation, muscle synergies have been investigated to provide information on the level of upper limb motor impairment, but not yet for explaining motor recovery after therapy. In this study, we analysed muscle synergies parameters extracted from 62 people with stroke who underwent a specific upper limb treatment (20 sessions, 1h/day, 5d/week, 4 weeks) consisting of virtual reality, robotic or conventional treatment. Overall, participants improved upper limb motor function (Fugl-Meyer Assessment Upper Extremity-FMA-UE: {Delta}= 7.14 {+/-} 7.46, p< 0.001) but the number of muscle synergies of the impaired side (N-aff) did not change after treatment (N-aff: T0= 8.8 {+/-} 1.5; T1=8.7 {+/-} 1.4; p=0.374). Then, we stratified the sample into Responder (No.=34) and Non-Responder (No.=28) participants, based on the Minimal Clinical Important Difference value of FMA-UE ({Delta} >5 points). We investigated merging and fractionation indexes in both subgroups and only the Responder subgroup significantly decreased the percentage of merged muscle synergies (p=0.004). No significant changes in the fractionation index resulted in either subgroup.  Finally, we identified vocabularies of affected upper limb motor synergies, before (No. 13 synergies) and after treatment (No. 14 synergies), and in unaffected upper limb (No. 16 synergies). We identified upper limb motor functions associated with each muscle synergy in each vocabulary based on the muscles represented in the muscle synergy. There were no differences in motor functions characterizing Responder patients. However, after therapy, both Responder and Non-Responder subgroups were characterized by the same distribution of motor functions across muscle synergies observed in the unaffected limb.  Trial registrationThe trial is registered in ClinicalTrial.gov, identifier number NCT03530358 (https://clinicaltrials.gov/study/NCT03530358).  Key messagesO_LIRehabilitation therapy for the upper limb induces reduction of muscle synergies merging in people with stroke expressing clinically important improvement of motor function. This muscular pattern is in accordance with motor control mechanisms underpinning functional recovery. C_LIO_LIMotor function of the affected upper limb at baseline did not characterize the muscular profile of patients responding to rehabilitation treatment (Responder). C_LIO_LIAfter therapy, all patients regardless the amount of motor function improvement (i.e., Responder, Non-Responder) express a muscular profile of the affected upper limb like the unaffected upper limb. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Unveiling the Psychological Traits of Multi-Marathoners: Insights from TIPI Personality Trait Analysis\nAbstract: ObjectivesMulti-marathoners, athletes dedicated to completing 100 or more marathons, represent a unique subculture within endurance sports. This study uses the Ten Item Personality Inventory (TIPI) test to explore their psychological traits. The study aims to identify the unique personality profiles of multi-marathoners and understand their implications for participation, performance, and well-being.  MethodsTIPI was used to describe personality and provide valuable insights into the tendencies for certain personality traits. TIPI was conducted via an online cross-sectional survey distributed to the multi-marathon community, which received 593 responses, 56% men (n=331, average age = 53.87 years, SD = 9.91), 44% women (n=261, average age = 54.06, SD 10.56) from 22 countries. One respondent identified as another gender and was not included in the gender-based analysis. Cronbachs Alpha and Guttmans Lambda 6 were calculated to assess the internal consistency of the survey, and the results were statistically analysed using Mann-Whitney U tests, ANOVA Aligned Rank Transform (ART) tests, and Wilcoxon rank- sum post-hoc tests to highlight differences in emotional stability, openness, conscientiousness, extraversion, and agreeableness. Normative TIPI data from the original TIPI study served as a dataset for comparison. Additionally, Spearmans {rho} based correlation was used to explore relationships between personality traits and other related variables from the multi-marathoner community collected from a previous study.  ResultsThe findings reveal distinctive personality traits among multi-marathoners. Compared to the general population, results show multi-marathoners displayed higher levels of conscientiousness (F (1,591) = 2.42, p < 0.001 for gender), indicating strong self-discipline, organisation, and goal-oriented behaviour. They exhibited lower levels of emotional stability (F (1,591) = 5.525, p < 0.001 for age group) and openness (F (1,591) = 2.54, p < 0.001 for age group), suggesting challenges in stress management and adaptability. Following significant results from the ANOVA ART tests, the Wilcoxon rank-sum post-hoc analysis revealed a significant gender difference in agreeableness, with women exhibiting higher levels of agreeableness compared to men (W = 50809, p<0.00091). However, after applying the Bonferroni statistical correction, no significant differences were found between genders in conscientiousness or emotional stability. Additionally, there were no significant differences in personality traits across different age groups after applying the statistical correction. These findings suggest that while gender differences in agreeableness are robust, age-related differences in personality traits were not statistically significant in this study.  ConclusionThis study offers insights into the psychological traits of multi-marathoners, highlighting their high conscientiousness and lower emotional stability. Contrary to the initial hypotheses, no significant differences were found in openness, and age-related differences in personality traits were not statistically significant after applying the Bonferroni statistical correction. These findings suggest that while multi-marathoners possess distinct personality traits, the relationship between these traits and their engagement in endurance sports is more complex than initially anticipated. These insights can guide the development of interventions to foster resilience and sustained participation, enhancing their overall experience and success in multi-marathoning. Longitudinal studies to track changes in personality traits and explore effective psychological interventions for this unique athletic community would allow further insight.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clinical Utility and Outcomes of Targeted Next-Generation Sequencing in Pediatric Respiratory Tract Infections: A Nine-Month Retrospective Study at a North Chinese Hospital\nAbstract: Background/ObjectivesChildren are at increased risk for respiratory tract infections (RTIs) due to their developing pulmonary functions and immune systems, highlighting the necessity of accurate and rapid pathogen diagnostic methods.  MethodsIn this study, 940 pediatric hospitalized patients with RTIs were included to evaluate the clinical utility and outcomes of 107-pathogen targeted next-generation sequencing (tNGS) panel by comparing it with CMTs.  ResultsOur study demonstrated that tNGS exhibited significantly higher sensitivity in pathogen detection compared to CMTs, with a detection rate of 91.38%. tNGS was capable of identifying a broader range of pathogens, including low-abundance and RNA viruses frequently missed by CMTs, and it was able to detect mixed infections, whereas CMTs typically identified only a single pathogen. Treatment adjustments based on tNGS results led to clinical improvements in the majority of patients, with 35.32% experiencing escalated treatment plans and 29.04% experiencing de-escalated treatment plans. Additionally, the analysis revealed significant variations in pathogen prevalence across different age groups and seasons, highlighting the need for tailored diagnostic, treatment, and prevention strategies.  ConclusionsThe findings highlight the potential of tNGS to improve clinical outcomes in pediatric RTIs by providing more accurate and comprehensive pathogen detection.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Brain tumor MRI classification and identification using an image classification model via Convolutional Neural Networks\nAbstract: Malignant brain tumors are generally classified to be extremely aggressive and often can be fatal when not met with immediate action. Glioblastoma Multiforme is the most common type of malignant tumor found in the brain and is extremely aggressive. For this reason, advanced detection of malignant brain tumors is necessary for optimal mitigation. Conversely, the classification of tumors during Medical Resonance Imaging can be difficult due to bodily movements resulting in the movement of the tumor. The movement of the tumor can disrupt targeted radiotherapy and can also, at times, result in treatments about radiotherapy damaging healthy areas of the brain rather than areas of the tumor. This study proposes a novel deep learning system that can identify tumors from MRI images; which can be helpful for the case of early detection, as well as being able to track tumors during active imaging; resulting in higher efficiency with targeted radiotherapy. This is done utilizing Convolutional Neural Networks (CNNs) created via deep learning frameworks. With the image identification of tumors; 97% accuracy was achieved with optimization. The tumor-classification deep learning system achieved an accuracy of 98%. Further testing is required for optimization; with this optimization, higher accuracy can be reached.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Memory for Music (M4M) protocol for an international randomized controlled trial: Effects of individual intensive musical training based on singing in non-musicians with Alzheimer's disease\nAbstract: IntroductionThe number of people living with dementia is increasing worldwide. Alzheimers disease (AD) is the most common type of dementia. It typically manifests itself initially with cognitive impairment in the memory domain, and gradually progresses towards affecting all activities of daily living. Active music interventions, particularly singing, may improve mood, social behaviour, and quality of life. However, little is known about their effects on cognition, although some studies have provided promising results. The M4M project aims to fill this gap in research by measuring the effects of learning new songs on cognitive functioning. Specifically, M4M will examine memory for new songs in non-musician adults with AD after undergoing intensive versus minimal individual musical training based on singing novel songs.  Methods and analysisHome-dwelling adults with AD, 65 years or older, will receive 5 months of intensive intervention (2x/week) and 5 months of minimal intervention (1x/month). In a crossover design, participants will be randomized to receive either the intensive or minimal intervention first, with 2 months between the intervention periods. Participants will receive individual music lessons to learn new songs, provided by a music instructor with adequate training. The main outcomes will be measured at the beginning and end of each intervention period. General cognition will be measured with the Alzheimers Disease Assessment Scale - Cognitive (ADAS-cog) by an assessor blinded to the randomisation. Participants memory for music will be measured using the N400 component of electroencephalographic event-related potentials in response to music stimuli. Additional outcomes evaluated during intervention sessions include mood and musical performance observations. With 113 participants randomised, the trial will have 80% power to detect clinically meaningful effects. Relations between mood, memory for music, and cognitive abilities will be examined, with sex, age, AD stage, previous musical training, and education as covariates. M4M will be conducted in close collaboration between academic researchers, service providers, and service users to ensure relevance and applicability.  Ethics and disseminationDissemination of findings will apply to local, national, and international levels. The study has been approved by the Regional Committees for Medical and Health Research Ethics in Norway.  Trial registrationClinicalTrials.gov, NCT06611878.  Strength and limitations- Based on recent data suggesting that individuals with advanced dementia can learn new songs, our study moves beyond reminiscence-based therapy since the participants will be actively involved in musical training based on singing to learn novel songs - The study focuses on home-dwelling older adults with dementia. This is becoming more and more important, as interventions that can prolong the period of independent living outside care facilities are urgently needed - By using EEG technology that is portable, inexpensive, non-invasive, less demanding for participants than other brain imaging examinations, performed in a naturalistic setting, this study will reach people who are less mobile or live in remote areas, thus improving generalisability. - As a multinational trial conducted in urban and rural settings in high- and middle-income countries, results will be relevant across diverse societies. - Due to the nature of the intervention, participants cannot be blinded.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Polygenic Risk Underlies Youth Psychopathology and Personalized Functional Brain Network Topography\nAbstract: ImportanceFunctional brain networks are associated with both behavior and genetic factors. To uncover clinically translatable mechanisms of psychopathology, it is critical to define how the spatial organization of these networks relates to genetic risk during development.  ObjectiveTo determine the relationship between transdiagnostic polygenic risk scores (PRSs), personalized functional brain networks (PFNs), and overall psychopathology (p-factor) during early adolescence.  DesignThe Adolescent Brain Cognitive Development (ABCD) StudySM is an ongoing longitudinal cohort study of 21 collection sites across the United States. Here, we conduct a cross-sectional analysis of ABCD baseline data, collected 2017-2018.  SettingThe ABCD Study(R) is a multi-site community-based study.  ParticipantsThe sample is largely recruited through school systems. Exclusion criteria included severe sensory, intellectual, medical, or neurological issues that interfere with protocol and scanner contraindications. Split-half subsets were used for cross-validation, matched on age, ethnicity, family structure, handedness, parental education, site, sex, and anesthesia exposure.  ExposuresPolygenic risk scores of transdiagnostic genetic factors F1 (PRS-F1) and F2 (PRS-F2) derived from adults in Psychiatric Genomic Consortium and UK Biobanks datasets. PRS-F1 indexes liability for common psychiatric symptoms and disorders related to mood disturbance; PRS-F2 indexes liability for rarer forms of mental illness characterized by mania and psychosis.  Main Outcomes and Measures(1) P-factor derived from bifactor models of youth- and parent-reported mental health assessments. (2) Person-specific functional brain network topography derived from functional magnetic resonance imaging (fMRI) scans.  ResultsTotal participants included 11,873 youths ages 9-10 years old; 5,678 (47.8%) were female, and the mean (SD) age was 9.92 (0.62) years. PFN topography was found to be heritable (N=7,459, 57.06% of vertices h2 pFDR<0.05, mean h2=0.35). PRS-F1 was associated with p-factor (N=5,815, r=0.12, 95% CI [0.09-0.15], p<0.001). Interindividual differences in functional network topography were associated with p-factor (N=7,459, mean r=0.12), PRS-F1 (N=3,982, mean r=0.05), and PRS-F2 (N=3,982, mean r=0.08). Cortical maps of p-factor and PRS-F1 regression coefficients were highly correlated (r=0.7, p=0.003).  Conclusions and RelevancePolygenic risk for transdiagnostic adulthood psychopathology is associated with both p-factor and heritable PFN topography during early adolescence. These results advance our understanding of the developmental drivers of psychopathology.  Key PointsQuestion: What is the relationship between transdiagnostic polygenic risk scores (PRSs), personalized functional brain networks (PFNs), and overall psychopathology (p-factor) during early adolescence?  Findings: In this cross-sectional analysis of the Adolescent Brain Cognitive Development (ABCD) StudySM (N=11,873, ages 9-10), we found that a PRS of common psychopathology in adulthood (PRS-F1) was associated with p-factor during early adolescence. Interindividual differences in p-factor, PRS-F1, and PRS-F2 (capturing rarer psychopathology in adulthood) were all robustly associated with PFN topography.  Meaning: Polygenic risk for transdiagnostic adulthood psychopathology is associated with both p-factor and PFN topography during early adolescence.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Polygenic Risk Underlies Youth Psychopathology and Personalized Functional Brain Network Topography\nAbstract: ImportanceFunctional brain networks are associated with both behavior and genetic factors. To uncover clinically translatable mechanisms of psychopathology, it is critical to define how the spatial organization of these networks relates to genetic risk during development.  ObjectiveTo determine the relationship between transdiagnostic polygenic risk scores (PRSs), personalized functional brain networks (PFNs), and overall psychopathology (p-factor) during early adolescence.  DesignThe Adolescent Brain Cognitive Development (ABCD) StudySM is an ongoing longitudinal cohort study of 21 collection sites across the United States. Here, we conduct a cross-sectional analysis of ABCD baseline data, collected 2017-2018.  SettingThe ABCD Study(R) is a multi-site community-based study.  ParticipantsThe sample is largely recruited through school systems. Exclusion criteria included severe sensory, intellectual, medical, or neurological issues that interfere with protocol and scanner contraindications. Split-half subsets were used for cross-validation, matched on age, ethnicity, family structure, handedness, parental education, site, sex, and anesthesia exposure.  ExposuresPolygenic risk scores of transdiagnostic genetic factors F1 (PRS-F1) and F2 (PRS-F2) derived from adults in Psychiatric Genomic Consortium and UK Biobanks datasets. PRS-F1 indexes liability for common psychiatric symptoms and disorders related to mood disturbance; PRS-F2 indexes liability for rarer forms of mental illness characterized by mania and psychosis.  Main Outcomes and Measures(1) P-factor derived from bifactor models of youth- and parent-reported mental health assessments. (2) Person-specific functional brain network topography derived from functional magnetic resonance imaging (fMRI) scans.  ResultsTotal participants included 11,873 youths ages 9-10 years old; 5,678 (47.8%) were female, and the mean (SD) age was 9.92 (0.62) years. PFN topography was found to be heritable (N=7,459, 57.06% of vertices h2 pFDR<0.05, mean h2=0.35). PRS-F1 was associated with p-factor (N=5,815, r=0.12, 95% CI [0.09-0.15], p<0.001). Interindividual differences in functional network topography were associated with p-factor (N=7,459, mean r=0.12), PRS-F1 (N=3,982, mean r=0.05), and PRS-F2 (N=3,982, mean r=0.08). Cortical maps of p-factor and PRS-F1 regression coefficients were highly correlated (r=0.7, p=0.003).  Conclusions and RelevancePolygenic risk for transdiagnostic adulthood psychopathology is associated with both p-factor and heritable PFN topography during early adolescence. These results advance our understanding of the developmental drivers of psychopathology.  Key PointsQuestion: What is the relationship between transdiagnostic polygenic risk scores (PRSs), personalized functional brain networks (PFNs), and overall psychopathology (p-factor) during early adolescence?  Findings: In this cross-sectional analysis of the Adolescent Brain Cognitive Development (ABCD) StudySM (N=11,873, ages 9-10), we found that a PRS of common psychopathology in adulthood (PRS-F1) was associated with p-factor during early adolescence. Interindividual differences in p-factor, PRS-F1, and PRS-F2 (capturing rarer psychopathology in adulthood) were all robustly associated with PFN topography.  Meaning: Polygenic risk for transdiagnostic adulthood psychopathology is associated with both p-factor and PFN topography during early adolescence.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Implementation of Male-Specific Motivational Interviewing in Malawi: An Assessment of Intervention Fidelity and Barriers to Scale-Up\nAbstract: IntroductionTreatment interruption (TI), defined as >28 days late for ART appointment, is one of the greatest challenges in controlling southern African HIV epidemics. Negative client-provider interactions remain a major reason for TI and barrier for return to care, especially for men. Motivational interviewing (MI) facilitates client-driven counseling and improves client-provider interactions by facilitating equitable, interactive counseling that helps clients understand and develop solutions for their unique needs. Fidelity of MI counseling in resource-constrained health systems is challenging.  MethodsWe developed a male-specific MI curriculum for Malawian male TI clients. Four psychosocial counselors (PCs, a high-level Malawian counseling cadre) received a 2.5-day curriculum training and job-aid to guide MI counseling approaches. They participated in monthly phone-based discussions with their manager about MI-based solutions to challenges faced. PCs implemented the MI curriculum with men >15 years who were actively experiencing TI. Clients were found at home (through tracing) or at the facility (for those who returned to care on their own). MI counseling sessions were recorded, transcribed, translated into English, and coded in Atlas.ti v9. MI quality was assessed using a modified version of the validated Motivational Interviewing Treatment Integrity tool. The tool has two measures: 1) counts of key MI behaviors throughout the session (questions, reflections, etc.); and 2) overarching scores (using a five-point scale) that characterize three MI dimensions for an entire counseling session (cultivating change talk, partnership, and empathy).  Results44 MI sessions were recorded and analyzed between 4/1/22-8/1/22. 64% of counseling sessions focused on work and travel as the main reason for TI. 86% of sessions yielded client-driven, tailored solutions for overcoming TI. PCs implemented multiple MI behaviors very well: asking questions, giving information, simple reflections, and client affirmation. Few PCs used complex reflection, emphasized autonomy, or sought collaboration with clients. Among overarching MI dimensions, HCWs scored high in partnership (promoting client-driven discussions) and cultivating change talk (encouraging client-driven language and behavior change confidence) but scored sub-optimal in empathy. Only 5 sessions had confrontational/negative PC attitudes.  ConclusionsPCs implemented MI with fidelity and quality resulting in tailored, actionable plans for male re-engagement in HIV treatment in Malawi.  Clinical Trial NumberNCT05137210 and NCT04858243\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Effects of Adverse Life Events on Brain Development in the ABCD Study: A Propensity-weighted Analysis\nAbstract: Longitudinal studies of the effects of adversity on human brain development are complicated by the association of stressful events with confounding variables. To counter this bias, we apply a propensity-weighted analysis of the first two years of The Adolescent Brain Cognitive DevelopmentSM (ABCD) Study(R) data, employing a machine learning analysis weighted by individuals propensity to experience adversity. Data included 338 resting-state functional connections from 7190 youth (46% female), divided into a training group (80%) and an independent testing group (20%). Propensity scores were computed using 390 variables to balance across two-year adverse life event exposures. Using elastic net regularization with and without inverse propensity weighting, we developed linear models in which changes in functional connectivity of brain connections during the two-year period served as predictors of the number of adverse events experienced during that same period. Haufes method was applied to forward-transform the backward prediction models. We also tested whether brain changes associated with adverse events correlated with concomitant changes in internalizing or externalizing behaviors or to academic achievement. In the propensity-weighted analysis, brain development significantly predicted the number of adverse events experienced during that period in both the training group ({rho}=0.14, p<0.001) and the independent testing group ({rho}=0.10, p<0.001). The predictor indicated a general pattern of decreased functional connectivity between large-scale networks and subcortical brain regions, particularly for cingulo-opercular and sensorimotor networks. These network-to-subcortical functional connectivity decreases inversely associated with the development of internalizing symptoms, suggesting adverse events promoted adaptive brain changes that may buffer against stress-related psychopathology. However, these same functional connections were also associated with poorer grades at the two-year follow-up. Although cortical-subcortical brain developmental responses to adversity potentially shield against stress-induced mood and anxiety disorders, they may be detrimental to other domains such as academic success.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Functional Connectivity Alterations in Asymptomatic Familial Early-Onset Alzheimer's Disease Caused by APP Duplication\nAbstract: BACKGROUND AND OBJECTIVESAutosomal dominant mutations of Alzheimers Disease (AD) are highly penetrant allowing to characterize the asymptomatic phase of this devastating condition. We investigated brain-wide functional alterations in the asymptomatic phase of autosomal dominant early-onset AD (ADEOAD) and explored whether a functional brain fingerprint of the disease can be found prior to clinical manifestation.  METHODSIn this cross-sectional study fourteen asymptomatic APP-dup carriers and eight APP-dup non-carriers from the same kindred underwent neurological and neuropsychological examination and resting-state fMRI scanning. The functional connectome of each participant was constructed based on 264 pre-defined brain regions, which were classified into seven different sensory (Visual and Somatomotor) and association (Default, Frontoparietal, Ventral Attention, Dorsal Attention, Limbic) cortical networks. Time courses were extracted from all regions in each participant and brain-wide Fishers z-transformed Pearson correlation (z(r)) from each region to all other regions was calculated, resulting in a 264 x 264 connectivity matrix per participant. These matrices were used for network similarity and connectome-based predictive modelling (CPM) analyses aimed to characterize age-dependent functional connectivity alterations within the carriers group that reflect their position along the neurodegeneration trajectory.  RESULTSComparing individual connectomes within the carriers group to the average connectome in the non-carrier group, we found that network similarity between groups decreased in an age-dependent manner. With age the APP-dup connectome diverged from the non-carriers connectome, with this difference being driven primarily by alterations in association networks and specifically involving the Default and Frontoparietal networks. Moreover, decreases in network similarity of association networks correlated with decreased performance on a visuospatial memory task. Using CPM, we found that in this family, carriers age can be predicted independent of the non-carriers control group and that this prediction is based mainly on connections within and between association networks.  DISCUSSIONFunctional connectivity was used to assess the progress of AD pathology in asymptomatic carriers of an autosomal-dominant deterministic gene. Our results show that in asymptomatic APP-dup carriers, aging is associated with functional connectivity alterations that preferentially involve association networks. Understanding these alterations might lay the foundation for development of novel diagnostic markers and assist in determining the appropriate timing of therapeutic interventions in ADEOAD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Functional Connectivity Alterations in Asymptomatic Familial Early-Onset Alzheimer's Disease Caused by APP Duplication\nAbstract: BACKGROUND AND OBJECTIVESAutosomal dominant mutations of Alzheimers Disease (AD) are highly penetrant allowing to characterize the asymptomatic phase of this devastating condition. We investigated brain-wide functional alterations in the asymptomatic phase of autosomal dominant early-onset AD (ADEOAD) and explored whether a functional brain fingerprint of the disease can be found prior to clinical manifestation.  METHODSIn this cross-sectional study fourteen asymptomatic APP-dup carriers and eight APP-dup non-carriers from the same kindred underwent neurological and neuropsychological examination and resting-state fMRI scanning. The functional connectome of each participant was constructed based on 264 pre-defined brain regions, which were classified into seven different sensory (Visual and Somatomotor) and association (Default, Frontoparietal, Ventral Attention, Dorsal Attention, Limbic) cortical networks. Time courses were extracted from all regions in each participant and brain-wide Fishers z-transformed Pearson correlation (z(r)) from each region to all other regions was calculated, resulting in a 264 x 264 connectivity matrix per participant. These matrices were used for network similarity and connectome-based predictive modelling (CPM) analyses aimed to characterize age-dependent functional connectivity alterations within the carriers group that reflect their position along the neurodegeneration trajectory.  RESULTSComparing individual connectomes within the carriers group to the average connectome in the non-carrier group, we found that network similarity between groups decreased in an age-dependent manner. With age the APP-dup connectome diverged from the non-carriers connectome, with this difference being driven primarily by alterations in association networks and specifically involving the Default and Frontoparietal networks. Moreover, decreases in network similarity of association networks correlated with decreased performance on a visuospatial memory task. Using CPM, we found that in this family, carriers age can be predicted independent of the non-carriers control group and that this prediction is based mainly on connections within and between association networks.  DISCUSSIONFunctional connectivity was used to assess the progress of AD pathology in asymptomatic carriers of an autosomal-dominant deterministic gene. Our results show that in asymptomatic APP-dup carriers, aging is associated with functional connectivity alterations that preferentially involve association networks. Understanding these alterations might lay the foundation for development of novel diagnostic markers and assist in determining the appropriate timing of therapeutic interventions in ADEOAD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dominant harmonic pattern as an ictal marker of the epileptogenic zone in focal neocortical epilepsy\nAbstract: ObjectiveThe ictal Harmonic pattern (H pattern), produced by the non-linear characteristics of EEG waveforms, may hold significant potential for localizing the epileptogenic zone (EZ) in focal epilepsy. However, further validation is needed to establish the H patterns effectiveness as a biomarker for measuring the EZ.  MethodsWe retrospectively enrolled 131 patients diagnosed with drug-resistant focal epilepsy, all of whom had complete stereo-electroencephalographic (SEEG) data. From this cohort, we selected 85 patients for outcome analysis. We analyzed the morphological and time-frequency (TF) features of the H pattern using TF plots. A third quartile (Q3) threshold was applied to classify channels expressing either dominant (ChanneldH pattern) or non-dominant H patterns (Channelnon-dH pattern). We then examined associations between the morphological features of the H pattern and patients clinical characteristics, as well as the correlations between the extent of channel removal and seizure outcomes.  ResultsWe found no significant correlations between the morphological features of the ictal H pattern and clinical factors, including lesional MRI findings, epileptic onset patterns, epilepsy type, pathology, or surgical outcomes. The non-localizable H pattern appeared exclusively in patients with non-focal onset patterns. Notably, the proportion of ChanneldH pattern was higher in the seizure-onset zone (SOZ) compared to the early propagation zone. The seizure-free group demonstrated significantly higher removal proportions of ChanneldH pattern, both within and outside the SOZ (p = 0.014; p = 0.036), with AUCs of 0.606 and 0.660, respectively, in a seizure freedom prediction model. Survival analysis confirmed that complete removal of these regions correlated with long-term seizure freedom (p = 0.008; p = 0.028). Further subgroup analysis showed a significant correlation in neocortical epilepsy (p = 0.0004; p = 0.011), but not in mesial temporal lobe epilepsy. Additionally, multivariate analysis identified the complete removal of ChanneldH pattern as the only independent predictor for seizure freedom (p = 0.022; OR 6.035, 95% CI 1.291-28.211).  ConclusionsOur study supports the notion that the dominance of the ictal H pattern, regardless of its morphology, serves as a novel biomarker for the EZ in focal epilepsy. The non-linearity in EEG waveforms provides new insights into understanding ictal spreading propagation and offers potential improvements for surgical planning in neocortical epilepsy.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Network Medicine Approach to Investigating ME/CFS Pathogenesis in Severely Ill Patients: A Pilot Study\nAbstract: This pilot study harnessed the power of network medicine to unravel the complex pathogenesis of Myalgic Encephalomyelitis/Chronic Fatigue Syndrome (ME/CFS). By utilizing a network analysis on whole genome sequencing (WGS) data from the Severely Ill Patient Study (SIPS), we identified ME/CFS-associated proteins and delineated the corresponding network-level module, termed the SIPS disease module, together with its relevant pathways. This module demonstrated significant overlap with genes implicated in fatigue, cognitive disorders, and neurodegenerative diseases. Our pathway analysis revealed potential associations between ME/CFS and conditions such as COVID-19, Epstein-Barr virus (EBV) infection, neurodegenerative diseases, and pathways involved in cortisol synthesis and secretion, supporting the hypothesis that ME/CFS is a neuroimmune disorder. Additionally, our findings underscore a potential link between ME/CFS and estrogen signaling pathways, which may elucidate the higher prevalence of ME/CFS in females. These findings provide insights into the pathogenesis of ME/CFS from a network medicine perspective and highlight potential therapeutic targets. Further research is needed to validate these findings and explore their implications for improving diagnosis and treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Network Medicine Approach to Investigating ME/CFS Pathogenesis in Severely Ill Patients: A Pilot Study\nAbstract: This pilot study harnessed the power of network medicine to unravel the complex pathogenesis of Myalgic Encephalomyelitis/Chronic Fatigue Syndrome (ME/CFS). By utilizing a network analysis on whole genome sequencing (WGS) data from the Severely Ill Patient Study (SIPS), we identified ME/CFS-associated proteins and delineated the corresponding network-level module, termed the SIPS disease module, together with its relevant pathways. This module demonstrated significant overlap with genes implicated in fatigue, cognitive disorders, and neurodegenerative diseases. Our pathway analysis revealed potential associations between ME/CFS and conditions such as COVID-19, Epstein-Barr virus (EBV) infection, neurodegenerative diseases, and pathways involved in cortisol synthesis and secretion, supporting the hypothesis that ME/CFS is a neuroimmune disorder. Additionally, our findings underscore a potential link between ME/CFS and estrogen signaling pathways, which may elucidate the higher prevalence of ME/CFS in females. These findings provide insights into the pathogenesis of ME/CFS from a network medicine perspective and highlight potential therapeutic targets. Further research is needed to validate these findings and explore their implications for improving diagnosis and treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: VAREANT: a bioinformatics application for gene variant reduction and annotation\nAbstract: The analysis of high-quality genomic variant data may offer a more complete understanding of the human genome, enabling researchers to identify novel biomarkers, stratify patients based on disease risk factors, and decipher underlying biological pathways. Although the availability of genomic data has sharply increased in recent years, the accessibility of bioinformatic tools to aid in its preparation is still lacking. Limitations with processing genomic data primarily include its large volume, associated computational and storage costs, and difficulty in identifying targeted and relevant information. Here, we present VAREANT, an accessible and configurable bioinformatic tool to support the preparation of variant data into a usable analysis-ready format. Designed to simplify the data pre-processing workflow, VAREANT enables the curation of targeted variant datasets. VAREANT is comprised of three standalone modules: (1) Pre- processing, (2) Variant Annotation, (3) Artificial Intelligence (AI) / Machine Learning (ML) Data Preparation. Pre-processing supports the fine-grained filtering of complex variant datasets to eliminate extraneous data. Variant Annotation allows for the addition of variant metadata from public annotation databases for subsequent analysis and interpretation. AI/ML Data Preparation supports the user in creating AI/ML-ready datasets suitable for immediate analysis with minimal pre-processing required. We have successfully tested and validated our tool on numerous variable-sized datasets and implemented VAREANT in two case studies involving patients with CVDs. Efficiently extracting relevant variants into an AI/ML ready format using tools like VAREANT has important scientific implications, such as producing targeted and high-quality datasets and helping reduce overall computational costs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Erythropoietin single nucleotide polymorphisms are associated with anemia and dyslipidemia in a cardiovascular disease population\nAbstract: Human erythropoietin (EPO) is an essential erythropoietic cytokine and recombinant biological therapeutic in anemia in chronic kidney disease. Single nucleotide polymorphisms (SNPs) in EPO have been linked to anemia and diabetic microvascular complications but no other cardiovascular comorbidities like dyslipidemia or hypertension. Here identified a clinical cohort of cardiovascular patients with anemia, dyslipidemia, hypertension, type-2 diabetes, or heart failure with preserved ejection fraction. Sanger sequencing was used for genotyping three EPO SNPs (rs1617640, rs507392 and rs551238), which were compared to clinical outcomes with SNPstat and clinical parameters profiles by student t-test. Nonstandard clinical chemistry measures of plasma EPO, hepcidin, transferrin, and ferritin were determined by ELISA. In the additive model, the C allele of rs1617640 was associated with lower EPO and anemia. In the recessive model, the SNP rs507392 genotype of GG was associated with dyslipidemia, which was associated with lower EPO in plasma and elevated total cholesterol and low-density lipoproteins. Interestingly, the G allele of rs507392 was found to be associated with hypertension, but only in females. Here we show that the SNPs in EPO are a potential risk factor for anemia, dyslipidemia, and hypertension in cardiovascular disease patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Development and evaluation of patient-centred polygenic risk score reports for glaucoma screening\nAbstract: BackgroundPolygenic risk scores (PRS), which provide an individual probabilistic estimate of genetic susceptibility to develop a disease, have shown effective risk stratification for glaucoma onset. However, there is limited best practice evidence for reporting PRS and patient-friendly reports for communicating effectively PRS are lacking. Here we developed patient-centred PRS reports for glaucoma screening based on the literature and evaluated them with participants using a qualitative research approach.  MethodsWe first reviewed existing PRS reports and literature on probabilistic risk communication. This informed the development of a draft glaucoma screening PRS report for a hypothetical high risk individual from the general population. We designed three versions of the report to illustrate risk using a pictograph, a pie chart and a bell curve. We then conducted semi-structured interviews to assess preference of visual risk communication aids, understanding of risk, content, format and structure of the reports. Participants were invited from an existing study, which aims to evaluate the clinical validity of glaucoma among individuals >50 years from the general population. Numeracy and literacy levels were assessed.  ResultsWe interviewed 12 individuals (50% female, 42% university education). Numeracy (mean 2.1{+/-}0.9, range 0-3), graph literacy (mean 2.8{+/-}0.8, range 0-4) and genetic literacy (mean 24.2{+/-}6.2, range -20-+46) showed a range of levels. We analysed the reports under three main themes: visual preferences, understanding risk and reports formatting. The visual component was deemed important to understanding risk, with the pictograph being the preferred visual risk representation, followed by the pie chart and the bell curve. Participants expressed preference for absolute risk in understanding risk, along with the written content explaining the results. The importance of follow-up recommendations and time to glaucoma onset were highlighted. Participants expressed varied opinions in the level of information and the colours used, which informed revisions of the report.  ConclusionsOur study revealed preferences for reporting PRS information in the context of glaucoma screening, to support the development of clinical PRS reporting. Further research is needed to assess PRS communication in other contexts and with other target audiences (e.g. referring clinicians), and its potential psychosocial impact in the wider community.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Deep Learning Model for Patient Subtyping and Survival Analysis in Kidney Disease Trajectory\nAbstract: Chronic kidney disease (CKD) is a global public health problem, affecting over 10% of the general population worldwide. CKD patients face an increased risk of progressing to end-stage kidney failure (ESKF), which is associated with higher hospitalization rates and cardiovascular mortality. The estimated glomerular filtration rate (eGFR) is a key indicator of kidney function and a critical predictor of CKD progression. However, existing predictive models often fail to incorporate the dynamic changes in eGFR over time, leading to less accurate forecasts of disease progression. In this study, we develop a novel deep learning model, the time-dependent LSTM (TdLSTM), to improve the prediction of eGFR and time-to-ESKF by effectively handling time-varying variables and irregular measurement time intervals in longitudinal study. Our method captures the evolving patterns of CKD progression, enabling more accurate predictions of patient outcomes. The specifically designed survival time estimate approach yields accurate predictions of the time of reaching the end stage of the disease. We trained and validated the TdLSTM model using data from two cohorts of CKD patients, demonstrating its superiority over existing models in predicting CKD progression and identifying distinct patient subtypes with varying progression rates. The proposed TdLSTM model enhances our ability to predict CKD outcomes by integrating temporal information into the predictive process, ultimately generating better prediction accuracy on the redefined time-varying evaluation metrics such as AUC and concordance index.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gastrointestinal Dysmotility, Autonomic Function and Small Intestinal Bacterial Overgrowth Among People with Well-Controlled HIV\nAbstract: IntroductionGastrointestinal dysfunction, including microbiome changes and increased translocation across a compromised gastrointestinal barrier plays a role in the chronic inflammation experienced by people with HIV (PWH). It is unknown whether autonomic neuropathy (AN) may contribute to these mechanisms by altering gastrointestinal motility.  MethodsThis is a cross-sectional study of 100 PWH and 89 controls. All participants underwent assessment of gastrointestinal transit times using a wireless motility capsule (WMC). All PWH and a subset of controls also underwent: a standardized battery of autonomic function tests summarized as the Modified Composite Autonomic Severity Score (MCASS) and its adrenergic, cardiovagal and sudomotor sub-scores, breath testing for small intestinal bacterial overgrowth (SIBO), and the Patient Assessment of Upper Gastrointestinal Disorders Symptoms (PAGI-SYM) and Composite Autonomic Symptom Score 31 (COMPASS-31) questionnaires.  ResultsPWH displayed shorter gastric emptying times (GET) and longer small bowel and colonic transit times (SBTT, CTT) compared to controls. Among PWH, GET was associated with PAGI-SYM score. The MCASS and its sudomotor sub-score (reflecting peripheral sympathetic function) were associated with SBTT but not GET or CTT. PWH with prolonged SBTT (>6h) were more likely to have SIBO.  ConclusionGastrointestinal motility is altered in PWH. This study provides preliminary evidence that changes in autonomic function may influence SBTT in PWH and that prolonged SBTT may contribute to the development of SIBO. Future studies are needed to more fully elucidate the pathophysiologic links between HIV-associated AN, altered gastrointestinal motility, the gastrointestinal microbiome, chronic inflammation, and resulting morbidity and mortality among PWH.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interest in and preference for long-acting injectable PrEP among men who have sex with men, trans* individuals, and cis-gender heterosexual women: a global systematic review and meta-analysis\nAbstract: BackgroundLong-acting injectable HIV pre-exposure prophylaxis (LAI-PrEP) offers potentials for expanding PrEP coverage and improving public health outcomes. This study synthesises global evidence on the prevalence and determinants of interest in and preference for LAI-PrEP among men-who-have-sex-with-men (MSM), trans* individuals, and cis-gender heterosexual women.  MethodsWe conducted a global systematic review and meta-analysis, building on quantitative studies from a previous review (January 1, 2010, to September 27, 2021) and new studies published in PubMed, Web of Science, and Embase (September 27, 2021, to December 31, 2023). Studies presenting data on LAI-PrEP interest, preference, and their determinants were included. Data were assessed for risk of bias and publication bias. We used a random-effects meta-analysis to pool prevalence of LAI-PrEP interest and preference, and narratively synthesized their determinants across all key populations. This study is registered with PROSPERO, CRD42023488350.  FindingsWe included 41 articles (18 from the previous systematic review and 23 from the new search). 74% (95%CI 71-78) of MSM showed interest in using LAI-PrEP and 37% (95%CI 29-44) of them preferring LAI-PrEP over other HIV prevention methods. The prevalence of interest and preference were even higher among current oral PrEP users (77% (95%CI 70-84), and 43% (95%CI 28-58), respectively). Interest in LAI-PrEP among trans* individuals was similarly high at 72% (95%CI 67-78), with one study reported that 57% of transgender women preferred for LAI-PrEP. Cis-gender heterosexual women also showed a high preference for LAI-PrEP (55%, 95%CI 40-70)). Overall, people who have more resources and who are already aware and using oral PrEP are likely more interested in LAI-PrEP when it becomes available.  InterpretationContinued research is essential to effectively deploy LAI-PrEP and address HIV prevention gaps. As more countries adopt LAI-PrEP, understanding its impact and reaching underserved populations will be critical to maximising public health benefits.  FundingNone.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of Antiretroviral Therapy on Anemia, Hepatotoxicity, and Immune Reconstitution Inflammatory Syndrome in HIV-Tuberculosis Co-Infected Patients\nAbstract: IntroductionHIV continues to pose a significant global health challenge, causing gradual immune system decline and, if left untreated, progressing to AIDS. Although antiretroviral therapy (ART) has transformed the treatment landscape for HIV, it is frequently associated with adverse effects, including anemia, hepatotoxicity, and immune-related issues such as Immune Reconstitution Inflammatory Syndrome (IRIS), particularly in patients co-infected with tuberculosis (TB).  Materials and methodsIn this prospective cohort study, 400 ART-naive, HIV-positive patients undergoing anti-tuberculosis therapy (ATT) at King Georges Medical University, Lucknow, India, were enrolled. The study evaluated the occurrence of opportunistic infections (OIs), ART regimen effectiveness, and key laboratory markers, including CD4 counts and hemoglobin levels.  ResultsTB emerged as the most common OI, affecting 20.25% of the participants, with anemia present in 85% of the cohort. The prevalence of IRIS was notably higher in patients with a positive tuberculin skin test (20.6%) compared to those with a negative test (7.4%). Patients with IRIS exhibited significantly lower CD4 counts and hemoglobin levels compared to those without IRIS.  ConclusionThis study underscores the importance of integrated management approaches for HIV patients co-infected with TB, focusing on the complex interaction between immune status, ART effectiveness, and comorbidities like anemia and hepatotoxicity. Properly addressing these factors is crucial for improving patient outcomes in this high-risk population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neural correlates of \u03b2-lactam exposure in intensive care unit patients: an observational, prospective cohort study\nAbstract: BackgroundB-Lactam-induced neurotoxicity in critical care patients can compromise clinical outcomes. Despite the growing use of therapeutic drug monitoring (TDM) for {beta}-lactams, clear toxicity thresholds remain undefined, leaving clinicians uncertain about dosing adjustments when adverse effects occur. Identifying a relevant and easily detectable neurophysiological biomarker for {beta}-lactam exposure would improve monitoring and prevent serious complications.  MethodsIn a prospective multicenter, non-interventional study, we analysed electroencephalographic (EEG) signals of 56 patients hospitalized in intensive care units (ICUs) receiving continuous infusions of five {beta}-lactams (meropenem, piperacillin/tazobactam, cefepime, cefotaxime, or ceftazidime). We applied a time frequency decomposition on these EEG data to investigate quantitatively the power of neural dynamics across frequencies ranging from 1 to 45 Hz. We used a multivariate pattern decoding method to correlate the {beta}-lactam exposure and Sepsis-related Organ Failure Assessment (SOFA) scores with the neural activity.  Results{beta}-lactam exposure correlated with increased {beta}-low {gamma} neural dynamics (20-40 Hz) (p < 0.001, FDR corrected), independent of other clinical factors or medications. B neural activity was most pronounced in central electrodes (C3 : r = 0.20, p < 0.01; C4 : r = 0.26, p < 0.01) and the right frontal electrode (Fp2 : r = 0.12, p = 0.02). Lower {theta}- activity (3.5-5 Hz and 12-18 Hz) was associated with higher SOFA scores (p < 0.001, FDR corrected). No significant correlations were observed between other drugs (opioids, antiseizure medications, psychotropics) and {beta} or {theta}- dynamics.  ConclusionsThese results suggest that {beta} neural dynamics represent a potential biomarker for {beta}-lactam exposure in ICU patients. They highlight the potential of quantitative EEG and advanced multivariate decoding methods to identify subtle neurophysiological features that are otherwise difficult to detect.  Trial registrationClinicalTrials.gov ID NCT03339869. Registered 14 September 2017.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Sex disparities in outcome of medication-assisted therapy of opioid use disorder: Nationally representative study\nAbstract: QuestionThe opioid epidemic causes massive morbidity, and males have substantially greater overdose mortality rates than females. It is unclear whether there are sex-related disparities at different stages in the trajectory of opioid use disorders, in \"real world\" settings.  GoalTo determine sex disparities in non-medical opioid use (NMOU) at the end of outpatient medication-assisted treatment (MAT), using nationally representative data.  DesignObservational epidemiological study of publicly funded outpatient MAT programs in the national \"Treatment episode data set-discharges\" (TEDS-D) for 2019.  ParticipantsPersons aged [&ge;]18 in their first treatment episode, in outpatient MAT for use of heroin or other opioids (N=11,549). The binary outcome was presence/absence of NMOU.  ResultsIn univariate analyses, males had significantly higher odds of NMOU, compared to females (odds ratio=1.27; Chi2 [df:1]=39.08; uncorrected p<0.0001; p=0.0041 after Bonferroni correction). A multivariable logistic regression detected a male>female odds ratio of 1.19 (95%CI=1.09-1.29; p<0.0001), adjusting for socio-demographic/clinical variables. Several specific conditions were revealed in which males had greater odds of NMOU compared to females (e.g., at ages 18-29 and 30-39; corrected p=0.012, or if they used opioids by inhalation; corrected p=0.0041).  ConclusionsThis nationally representative study indicates that males have greater odds of NMOU in their first episode of MAT, indicating more unfavorable outcomes. The study reveals specific socio-demographic and clinical variables under which this sex disparity is most prominent.  Highlights*It is unclear if there are sex-related disparities in outcomes for outpatient opioid medication-assisted therapy (MAT), in large-scale \"real world\" settings.  *In this nationally representative \"real world\" study, adult males had significantly greater odds of non-medical opioid use (NMOU) in the month prior to discharge from their first MAT episode compared to females, adjusting for socio-demographic and clinical variables. Males were at higher risk than females for this undesirable outcome under several conditions (e.g., in younger age categories, or if their route of NMOU was by inhalation.  *Sex disparities in MAT outcomes occur under specific conditions that can be examined and potentially addressed, with the goal of improving personalized approaches for OUD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: In-Hospital and Long-Term Outcomes in Spontaneous Coronary Artery Dissection (SCAD) with Concurrent Cardiac Arrest: A Systematic Review and Meta-Analysis\nAbstract: BackgroundSpontaneous coronary artery dissection (SCAD) is increasingly recognized as an important cause of myocardial infarction (MI). However, our understanding of clinical characteristics that predispose patients to worse outcomes, such as concurrent sudden cardiac arrest (CA), remains limited.  ObjectiveWe performed a systematic review and meta-analysis of studies assessing clinical outcomes among SCAD patients with aconcurrent CA.  MethodsThis study was performed according to PRISMA guidelines. PubMed, Cochrane, and Scopus were systematically searched using relevant search terms, such as \"Spontaneous Coronary Artery Dissection\", \"Ventricular Tachycardia\", \"Ventricular Fibrillation\", \"Sudden Cardiac Death\" and \"Cardiac Arrest\". The search was conducted from database inception to July 2024. Studies assessing the clinical outcomes of SCAD patients with concurrent CA were included. RevMan 5.4 was used for meta-analysis.  ResultsAfter removal of duplicates, 269 studies underwent screening, out of which 10 studies were included (n= 3978 patients, 357 with CA). In-hospital mortality, post-discharge mortality, recurrent MI and recurrent SCAD occurred in 20%, 3%, 12% and 9% of SCAD patients with CA, respectively. When compared to SCAD patients without CA, SCAD patients with CA were at significantly higher risk of in-hospital mortality (RR = 6.75, 95% CI [4.50, 10.14], I2= 0%), post-discharge mortality (RR = 5.86, 95% CI [1.72, 19.91], I2=0%), recurrent MI (RR =3.31, 95% CI [2.03, 5.39], I2=56%), recurrent SCAD (RR = 1.91, 95% CI [1.11, 3.27], I2= 43%), acute heart failure (RR = 4.82, 95% CI [3.22, 7.20], I2=42%), and cardiogenic shock (RR = 6.11, 95% CI [4.07, 9.19], I2=64%). Out of a pooled 24 implanted cardiac defibrillators (ICDs) and 11 wearable cardiac defibrillators (WCDs), there was only one appropriate and one inappropriate ICD discharge recorded over the follow-up period.  ConclusionIn this cohort, SCAD with concurrent CA was associated with worse in-hospital and long-term outcomes including in-hospital and post-discharge mortality, acute heart failure, and recurrent MI and SCAD. There was a low long-term rate of administered defibrillator therapies among patients discharged from the hospital with an ICD or WCD. Further research is needed to better delineate optimal management approaches toward this high-risk patient population, including secondary prevention of sudden cardiac death.  Graphical abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=128 SRC=\"FIGDIR/small/24314406v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (26K): org.highwire.dtl.DTLVardef@1a8fc84org.highwire.dtl.DTLVardef@15a5ec2org.highwire.dtl.DTLVardef@34baborg.highwire.dtl.DTLVardef@5cd2d7_HPS_FORMAT_FIGEXP  M_FIG C_FIG\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Depression Incidence in Patients with Hypertension in a Single Outpatient Center\nAbstract: IntroductionHypertension and depression are both highly prevalent in the United States and each condition is commonly managed in the outpatient setting. This study aims to investigate the incidence of depression in patients who are diagnosed with hypertension.  MethodsA retrospective cohort study was conducted analyzing 9,240 adult patients at a single center outpatient clinic between 2019 and 2022. Blood pressure and PHQ-9 from the latest outpatient visit were recorded. Demographic data associated with hypertension were also obtained. Bivariate statistical analysis was performed. Multivariate linear and logistic regression models were adjusted for co-morbid conditions.  ResultsOut of the 9,240 patients studied, 3,694 (40%) had a diagnosis of hypertension. Patients with hypertension were more likely to be older (61.96 {+/-} 14.95 vs 39.85 {+/-} 15.61, p=0.000), male (37% vs 33%, p =0.002) and black (45.2% vs 23.3%, p<0.001) compared with those without a diagnosis of hypertension. The mean PHQ-9 score was higher in patients with hypertension than in those without (2.97 {+/-}4.66 vs 2.70 {+/-} 4.93, p=0.000). Patients with hypertension were more likely to have uncontrolled depression defined as PHQ-9 score >4 (22.55% vs 19.4%, p<0.001) even when adjusted for co-morbid conditions (adj OR 1.216 95% CI 1.06 -1.34 p=0.005).  ConclusionsIn this cohort of patients, a diagnosis of hypertension was associated with an increased rate of uncontrolled depressive symptoms. Hence patients with hypertension should be screened using validated PHQ-9 tools in the outpatient setting and offered appropriate treatment for depression.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Acute myocardial infarction, 90 Cardiovascular proteins and Paroxysmal ventricular tachycardia: a Mendelian randomization study\nAbstract: BackgroundPrevious studies have shown that acute myocardial infarction (AMI) may be associated with paroxysmal ventricular tachycardia (PVT). However, the causal effect between AMI and PVT, and whether cardiovascular proteins act as a mediator remain unclear.  MethodsThe genetic data of AMI, 90 Cardiovascular proteins (CVPs) and PVT were obtained from large-scale genome-wide association studies (GWAS). The Mendelian randomization analysis was applied to evaluate the casual association among the AMI, CVPs and PVT. The inverse variance weighting casual effect was regarded as main statistical method. We further investigated whether CVPs take a mediating role in the pathway from AMI to PVT.  ResultsThere were three positive, including ESM-1 (OR 1.139, 95%CI 1.034-1.255, P-FDR=0.014), GAL (OR 1.105,95%CI 1.025-1.191, P-FDR=0.015) and PRL (OR 1.084, 95%CI 1.004-1.170, P-FDR=0.038), and four negative, including FAS (OR 0.928, 95%CI 0.885-0.974, P-FDR=0.009), LEP (OR 0.938, 95%CI 0.891-0.987, P-FDR=0.018), TNF-R1 (OR 0.930, 95%CI 0.883-0.979, P-FDR=0.014) and TNF-R2 (OR 0.928, 95%CI 0.883-0.974, P-FDR=0.009), casual effects between genetic liability of AMI on CVPs. We identified two positive, including IL-27 (OR 1.371, 95%CI 1.010-1.861, P-FDR=0.045) and MMP-12 (OR 1.330, 95%CI 1.035-1.709, P-FDR=0.045), and two negative, including LEP (OR 0.614, 95%CI 0.384-0.981, P-FDR=0.045) and TF (OR 0.714, 95%CI 0.514-0.992, P-FDR=0.045), casual effects between genetic liability of CVPs on PVT. In addition, the AMI played a positive casual effect on PVT (OR 1.736, 95%CI 1.300-2.318, P-FDR<0.001) mediating by LEP with 5.71%.  ConclusionsThe AMI was casually correlated to PVT, and LEP acted as a mediator in the pathway from AMI to PVT.  Key MessagesO_ST_ABSWhat is already known on this topic?C_ST_ABSPrevious retrospective and prospective clinical studies have suggested that attention should be paid to the risk of subsequent malignant ventricular arrhythmias, including ventricular tachycardia and ventricular fibrillation, in patients with acute myocardial infarction.  What this study adds?We used Mendelian randomization to demonstrate the genetic relationship between acute myocardial infarction and paroxysmal ventricular tachycardia, and found that leptin mediated the occurrence of paroxysmal ventricular tachycardia in clinical patients with acute myocardial infarction for the first time. In addition, we also found a large number of cardiovascular proteins closely genetically related to acute myocardial infarction or paroxysmal ventricular tachycardia,  How this study might affect research, practice or policy?Our research provides a new insight which means that appropriate serological detection or intervention for patients with acute myocardial infarction can predict or prevent the occurrence of secondary malignant ventricular arrhythmias and reduce the mortality of patients with acute myocardial infarction in the future. Also, the cardiovascular proteins detected by Mendelian randomization analysis are helpful for the diagnosis and prevention of the two.    O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=108 SRC=\"FIGDIR/small/24314334v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (41K): org.highwire.dtl.DTLVardef@1614ba4org.highwire.dtl.DTLVardef@ad2ce7org.highwire.dtl.DTLVardef@15f296eorg.highwire.dtl.DTLVardef@9924a6_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOGraphical Abstract.C_FLOATNO C_FIG We carefully analyzed the causal relationship among AMI, 90 CVPs and PVT in the complicated MR analysis. We found three positive (ESM-1, GAL and PRL) and four negative casual effects (FAS, LEP, TNF-R1 and TNF-R2) between genetic liability of AMI on CVPs. There were two positive (IL-27 and MMP-12) and two negative (LEP and TF) casual effects between genetic liability of CVPs on PVT. The AMI played a positive casual effect on PVT mediating by LEP with 5.71%. We identified two positive (Dkk-1 and PDGF_subunit_B) and two negative (RAGE and SPON1) casual effects between genetic liability of CVPs on AMI, and thee positive (IL-1ra, MCP-1 and TIE2) casual effects between genetic liability of CVPs on PVT. AMI, acute myocardial infarction; PVT, paroxysmal ventricular tachycardia; CVPs, cardiovascular proteins; AGRP, agouti-related protein; ESM-1, endocan; FAS, tumor necrosis factor receptor superfamily member 6; GAL, galactose-alpha-1,3-galactose; LEP, leptin; PRL, placental growth factor; TNF-R1, tumor necrosis factor receptor 1; TNF-R2, tumor necrosis factor receptor 2; IL-27, interleukin-27; MMP-12, matrix metalloproteinase-12; TF, tissue factor; Dkk-1, dickkopf-related protein 1; PDGF_subunit_B, platelet-derived growth factor subunit B; RAGE, receptor for advanced glycosylation end products; SCF,stem cell factor; SPON1, spondin-1; IL-1ra, interleukin-1 receptor antagonist protein; MCP-1, monocyte chemotactic protein 1; TIE2, angiopoietin-1 receptor.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Oral Testosterone Therapy in Hypogonadal Men: A Comprehensive Systematic Review and Meta-Analysis of Safety, Efficacy, and Secondary Health Outcomes\nAbstract: ObjectiveTo conduct a systematic review and meta-analysis to evaluate the safety and efficacy of oral testosterone therapy in hypogonadal men. The primary outcome is the assessment of safety, focusing on cardiovascular risks, liver toxicity, and prostate safety. Secondary outcomes include evaluations of bone mass, cardiovascular benefits, cognitive function, and potential reductions in mortality.  MethodsA systematic search was conducted using databases such as PubMed, Embase, and Cochrane Library, identifying peer-reviewed studies published until August 2024. The search included randomized controlled trials (RCTs), cohort studies, and large clinical trials. The studies involved a total of 3,183 hypogonadal men. Data were extracted and analyzed to assess primary and secondary outcomes. Statistical methods for meta-analysis included fixed-effects and random-effects models to calculate pooled estimates and assess heterogeneity.  ResultsThe analysis included 21 studies, encompassing a total of 3,183 hypogonadal men. Oral testosterone therapy demonstrated a safety profile comparable to other testosterone replacement therapies (TRT). No significant increase in liver toxicity was observed, supported by studies showing no liver damage after long-term oral testosterone undecanoate (TU) administration. Cardiovascular safety results were mixed; some studies noted minor increases in systolic blood pressure, but there was no consistent evidence of a significant increase in major cardiovascular events compared to other TRT forms. The prostate safety profile was consistent with existing TRT modalities, with only minor increases in prostate-specific antigen (PSA) levels noted.Secondary outcomes were generally favorable: bone density improved, fat mass was reduced, and there were indications of cognitive benefits, although these findings varied across studies. However, the evidence for mortality reduction was inconclusive, with no strong data supporting a significant effect of oral testosterone on reducing mortality.  ConclusionOral testosterone therapy appears to be a safe and effective treatment for hypogonadal men, with a risk profile comparable to other TRT forms. It offers potential benefits in bone health and cognitive function but requires careful monitoring of cardiovascular health and prostate safety during treatment. The findings suggest that oral testosterone therapy can be a valuable option for hypogonadal men, though long-term studies are needed to better understand its full range of effects, particularly concerning mortality and cardiovascular outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Red blood cell distribution as Potential Predictor of Mortality in Diabetic Foot Patients\nAbstract: BackgroundRed blood cell distribution width (RDW) reflects the heterogeneity of red blood cell volume, which reflects the variable width of red blood cell (RBC). RDW has been proved as predictor of mortality among several diseases. The purpose of this study is to analyze the relationship between RDW and mortality of diabetic foot patients.  MethodsWe first collect clinic data from the public database MIMIC-III. Kruskal Wallis rank sum test was used to analyze the association between RDW and DF mortality, and to evaluate the relationship between them. Univariate and multivariate logistic regression analysis was used for determining the risk factors and prognosis of DF patients.  ResultsA total of 283 patients were included in this study, with an average age of 64.0 [54.0,70.5] years, including 193 males and 90 females. We divided RDW into three groups (high, moderate and low) according to RDW tertiles and then compared the mortality of the three groups. The high RDW group (RDW > 16.8%) had significant higher mortality (P = 0.031). In multivariate logistic regression analysis, RDW, SOFA score and APS are risk factors for death in diabetic foot. After adjusting for confounding factors in model II, RDW remains a particularly strong predictor of mortality.  ConclusionsA total of 283 patients were included in this study, with an average age of 64.0 [54.0,70.5] years, including 1We confirm that RDW is an independent predictor of mortality in DF patients,and the higher the RDW, the higher the mortality of DF patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Patient-centered Transcriptomic and Multimodal Neuroimaging Determinants of Clinical Progression, Physical Activity and Treatment Needs in Parkinson Disease\nAbstract: Parkinsons disease is a complex and multifactorial disorder, but how its biological and clinical complexity emerge from molecular to macroscopic brain interactions remains poorly understood. Here, we use a personalized multiscale generative brain model to characterize direct spatiotemporal links between genes and multimodal neuroimaging-derived biological factors in PD. We identified a set of genes modulating PD-associated longitudinal changes in dopamine transporter level, neuronal activity, dendrite density and tissue atrophy. Inter-individual heterogeneity in the gene-mediated biological mechanisms is associated with five distinct configurations of PD motor and non-motor symptoms. Although characterized by distinctive biological pathways, all the symptom configurations are associated with cell cycle processes. Notably, the protein-protein interaction networks underlying these configurations revealed distinct hub genes including MYC, CCNA2, CCDK1, SRC, STAT3 and PSMD4. We also uncovered the biological mechanisms associated with physical activities performance in PD, and observed that leisure and work activities are principally related to neurotypical cholesterol homeostasis and inflammatory response processes, respectively. Finally, patient-tailored in silico gene perturbations revealed a set of putative disease-modifying drugs with potential to effectively treat PD, most of which are associated with dopamine reuptake and anti-inflammation. Our study constitutes the first self-contained multiscale approach providing comprehensive insights into the complex multifactorial pathogenesis of PD, unravelling key biological modulators of physical and clinical deterioration, and serving as a blueprint for optimum drug selection at personalized level.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Current infectious disease research practices with forcibly displaced people in the top ten low- and middle-income host countries: A Systematic Review\nAbstract: Infectious disease research is essential for disease prevention and management within refugee camps and informal settlements. We aim to assess the state of infectious disease research with displaced communities in the top ten refugee-hosting low- and middle-income countries. We searched three journal databases for primary research that explicitly included refugees or was conducted in a refugee camp, informal settlement, or displaced people-serving hospital and focused directly on an infectious disease following PRISMA guidelines. Forty studies (out of 1,179) met the inclusion criteria. Common research challenges included population mobility, limited external validity, and low recruitment. No studies included the community in the initial study conception or investigated the research impact on the community. Community involvement was often through community health workers (45%). Of the 18 studies that studied a resource-based intervention, 20% explicitly noted that the intervention was unsustainable. Such context-specific considerations are vital in research with displaced communities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Large Language Model-based Approach for Analyzing Covariates of Health Equity in Registered Research Projects\nAbstract: Large language models (LLMs) have made significant advancements in natural language processing, offering broad applications in multiple domains. This study explores the use of the GPT-3.5 LLM to conduct efficient and robust computational analysis of registered research projects on the All of Us platform. Specifically, we explore the association between projects pursuing health equity research and: the projects use of demographic categories (which All of Us enables), the multi-institutional composition of the team leading the project, and the involvement of R2 institutions (compared to only R1 institutions). We demonstrate the utility of GPT-3.5 in automating tasks ranging from generating Python scripts for extracting attributes from free text (such as project description and goals) to identifying and classifying institutions as R1 and R2, and summarizing project details into Unified Medical Language System (UMLS)-coded medical keywords. These contributions significantly reduced manual workload, allowing researchers to focus on more in-depth analysis. Our results reveal health equity insights not readily available in the original All of Us research hub. Specifically, we find a strong positive association between the use of demographic data and projects focused on health equity, while other associations such as health equity projects conducted by institutions were positive but weaker and more dependent on specific project topics.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Sedentary Habits and Obesity: The Role of TV, Unemployment, and White-Collar Work on Obesity in Reproductive-Aged Women in Bangladesh\nAbstract: IntroductionIn Bangladesh, overweight and obesity are increasingly alarming, especially among women. Thus, this paper aims to explore whether television watching, white-collar jobs, and unemployment are working as sedentary behavior to increase overweight and obesity in Bangladesh.  Data and methodsWe utilized cross-sectional data from the Bangladesh Demographic and Health Survey, 2017-2018. The dependent variable of the study was the nutritional status of women using three different measures: body mass index (BMI), Asian body mass index (ABMI), and tri-ponderal mass index (TMI). The frequency of watching television (TV) and types of employment were the two predictors of overweight and obesity in this study. The Multilevel Ordered Logistic Regression Analysis was used in this study.  ResultsWomen who have watched television at least once a week are more likely to have a BMI [&ge;]25 and become overweight (30.3%) and obese (9.3%) than those who did not watch TV at all (20.1% and 3%). This same pattern of BMI is discernible among unemployed women (28.7% and 8.2%) compared to women in agricultural work (16% and 2.9%). Professional women have the highest risk of being overweight and obese (35.4% and 10.9%). The pattern of overweight and obese is consistent for ABMI and PMI. However, these indicators (ABMI & PMI) report a higher prevalence of overweight and obesity than BMI.  ConclusionIn this era of technology, TV watching, and other technology will increase with time. More and more women are engaging in white-collar jobs or looking for jobs. In these circumstances, policymakers need to focus on how this use of technology can decrease overweight and obesity among women. More studies need to be conducted to explore the effect of other sedentary behaviors and take steps based on those studies to reduce the increasing rate of overweight and obesity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The family as a health producer: household composition and health behaviours in a Southern Europe population\nAbstract: ObjectivesIn the context of rapid transformations in family structures, understanding how household composition can affect adults health behaviours is crucial, particularly when considering the potential role of such close social relationships in shaping those behaviours. This paper documents how household structure relates to individual health behaviours.  Study designWe pooled cross-sectional data from the Portuguese National Health Interview Surveys of 2014 and 2019, covering 26,000+ households.  MethodsLinear and logistic regression models were used to assess the association between different household compositions (single dwelling adults, single parents, couples with or without children) and adherence to the Mediterranean diet, frequency of physical activity, likelihood of risky alcohol consumption, and smoking, distinguishing between men and women.  ResultsPeople living alone and single parents were significantly less likely to adhere to the Mediterranean diet than individuals living in couple. Single dwellers had significantly higher likelihood of engaging in risky alcohol consumption or being smokers than individuals living in couple and/or with children. Analyses by gender revealed that women in couples with children were less likely to practice physical activity than women in couples without children; this difference was not observed among men.  ConclusionsOverall, family contexts strongly correlate with individual health behaviours, with people living alone or in single-parent households appearing at higher risk of having less healthy diets, risky alcohol consumption, and smoking. This study identifies key target groups for policies aiming to improve population health (behaviours) including, critically, single dwellers and single parent households.  Key massagesO_ST_ABSWhat is already known on this topicC_ST_ABSSocial relationships, particularly within the family, play a significant role in shaping individuals health behaviors. With rapid changes in family structures, understanding how household composition influences adult behaviors is crucial.  What this study addsThis study reveals that single dwellers generally exhibit unhealthier behaviors, except in the case of physical activity. Additionally, it highlights that having children tends to promote healthier lifestyles among couples.  How this study might affect research, practice, or policyThe findings underscore the importance of considering household composition in health interventions and policy development. Specifically, attention may need to be directed towards individuals living alone and single-parent households to address potential health disparities and promote healthier behaviors.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Amyloid and tau PET in relation to longitudinal change in subjective cognitive complaints among cognitively normal individuals\nAbstract: Background and ObjectivesSubjective cognitive complaints often precede declines in objective measures of cognitive performance and may facilitate the early diagnosis of cognitive impairment. This study examined whether amyloid and tau pathology are associated with level and longitudinal change in subjective cognitive complaints among cognitively normal individuals, and compared these associations to those observed with objective neuropsychological measures of verbal episodic memory performance.  MethodsAmyloid and tau pathology were measured by 11C-Pittsburgh compound B (PiB) and 18F-flortaucipir (FTP) PET scans, respectively. FTP PET regions of interest (ROIs) included the entorhinal cortex, hippocampus, parahippocampal gyrus, and inferior temporal gyrus. Subjective cognitive complaints were assessed using the Cognitive Failures Questionnaire (CFQ). California Verbal Learning Test (CVLT) immediate and long-delayed free recall scores were used to quantify objective memory performance. We examined the association of PET measures with rates of change in CFQ and verbal memory within 5 years of the PET scans using linear mixed effects models.  ResultsWe analyzed data for 92 cognitively normal participants in the Baltimore Longitudinal Study of Aging (BLSA). In analyses that included both amyloid positivity and regional tau burden as predictors greater parahippocampal tau standardized uptake value ratio (SUVR) was associated with higher CFQ, indicating greater subjective cognitive complaints (estimate = 0.178, SE = 0.0821, p = 0.033). Greater entorhinal tau SUVR corresponded to an attenuated increase in CFQ over time (estimate = -0.064, SE = 0.0296, p = 0.035), whereas greater hippocampal tau SUVR was associated with a steeper longitudinal decline in memory (estimate = -0.0293, SE = 0.0135, p = 0.032).  DiscussionIndividuals with higher levels of tau pathology may experience greater levels of subjective cognitive complaints. Such associations are detectable among cognitively normal individuals even in the absence of marked neuropathology-associated differences in neuropsychological assessments of verbal episodic memory, suggesting that subjective cognitive complaints may serve as early indicators of accumulating cerebral tau pathology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Acute Kidney Injury and Perioperative complications based on modality of nephrectomy for the treatment of kidney cancer\nAbstract: BackgroundNephrectomy, either partial or radical, is a key treatment for kidney cancer. The surgical approach--open, laparoscopic, or robot-assisted--can influence perioperative outcomes. This study evaluates acute kidney injury (AKI) and perioperative complications across these modalities.  MethodsWe conducted a retrospective analysis using the National Inpatient Sample (NIS) of 2020-2021 to examine 12,676 kidney cancer patients who underwent nephrectomy. Patients were stratified by surgical approach: open, laparoscopic, and robot-assisted. Primary outcomes included AKI incidence, length of stay, and intra- and post-operative complications. Multivariable regression models adjusted for confounding variables, including age, sex, race, Charlson Comorbidity Index (CCI), hospital region, and teaching status.  ResultsPatients undergoing open nephrectomy had the highest AKI rates, particularly for radical nephrectomy (22.13% vs. 16.52% for robotic, p < 0.001). Similarly, patients treated with open surgery had longer hospital stays and higher rates of complications, including pulmonary (7.71% vs. 4.17%, p < 0.001) and vascular (12.11% vs. 4.01%, p < 0.001) in radical nephrectomy. Multivariate analysis confirmed the increased risk of AKI and complications in open nephrectomy, with robotic-assisted surgery demonstrating the best perioperative outcomes.  ConclusionOpen nephrectomy, whether partial or radical, is associated with higher AKI rates and perioperative complications compared to laparoscopic and robot-assisted surgeries. Robot-assisted nephrectomy, with its lower complication rates and shorter hospital stays, may be the preferred approach when feasible. Further efforts to expand access to minimally invasive techniques could improve outcomes for kidney cancer patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: STRIVE-ON: Safety and ToleRability of GTX-104 (Nimodipine Injection for IV Infusion) ComparEd with Oral Nimodipine in Patients Hospitalized for Aneurysmal Subarachnoid Hemorrhage (aSAH): a Prospective, Randomized Trial (STRIVE-ON)\nAbstract: Oral nimodipine is the only drug approved in North America for treatment of patients with aneurysmal subarachnoid hemorrhage (aSAH). However, bioavailability is variable and frequently poor, leading to fluctuations in peak plasma concentrations that cause dose-limiting hypotension. Furthermore, administration is problematic in patients who cannot swallow capsules. An oral liquid formulation exists but causes gastrointestinal complications. An intravenous nimodipine formulation (GTX-104) has been developed that has bioavailability approaching 100% and is not affected by feeding or gastointestinal absorption. GTX-104 causes less hypotension and has more consistent peak plasma concentrations than oral nimodipine in healthy human volunteers.  Herein we describe the protocol of a prospective, randomized, open-label safety and tolerability study of GTX-104 compared to oral nimodipine in patients with aSAH (STRIVE-ON, NCT05995405). Inclusion and exclusion criteria match the prescribing information for oral nimodipine and include adult patients with aSAH of all Hunt and Hess grades who can receive investigational product within 96 hours of aSAH. Subjects at imminent risk of death are excluded. Subjects are randomized 1:1 to GTX-104 or oral nimodipine for up to 21 days. The primary endpoint is the proportion of subjects in each group with clinically significant hypotension, defined as hypotension requiring any medical treatment, with a reasonable likelihood of being due to investigational product as determined by an independent, blinded endpoint adjudication committee. No statistical analysis of the endpoint is planned. Secondary endpoints include all episodes of hypotension, all adverse events, delayed cerebral ischemia, rescue therapy and suicidal ideation. Clinical and health economic outcomes include quality of life using the EQ-5D-3L, modified Rankin scale at 30 and 90 days after aSAH and hospital resource use. The planned sample size is 100 subjects across 25 sites in the United States and Canada.  DETAILS PAGEO_LIWe confirm that manuscript complies with all instructions to authors. C_LIO_LIWe confirm that authorship requirements have been met and the final manuscript is approved by all authors. C_LIO_LIWe confirm that this manuscript has not been published elsewhere and is not under consideration by another journal. It is planned to post it on C_LIO_LIWe confirm adherence to ethical guidelines and indicate ethical approvals and use of informed consent. C_LIO_LIAll conflicts of Interest for all authors are disclosed. C_LIO_LIWe confirm the use of the Standard Protocol Items: Recommended for Interventional Trials (SPIRIT) checklist. C_LIO_LIThe source of funding for the study is disclosed. It is Acasti Pharma. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Dynamics of serum BDNF After Aerobic Exercise in Subacute Stroke Patients: A Sub-Analysis of the randomized controlled Phys-Stroke trial\nAbstract: During the very early phase of stroke recovery, the brain is hypothesized to be in a neuroplastic state that is responsive to external stimuli. Here, brain-derived neurotrophic factor (BDNF) is thought to play an important role. BDNF, a member of the neurotrophin family, is implicated in processes such as synaptogenesis and long-term potentiation. Post-stroke, reduced BDNF levels are observed compared to the healthy population. An intervention that has been shown to elevate BDNF is Aerobic exercise. Yet, the impact of aerobic exercise in stroke patients remains unclear. This sub-analysis of the multicenter, randomized, controlled Physical Fitness Training in Patients with Subacute Stroke trial aimed to investigate serum BDNF dynamics and the effects of a four-week aerobic exercise intervention on long- term BDNF levels.  Data from 200 patients, with missing data imputed, revealed a modest increase in serum BDNF levels up to three months post-stroke (22.6 ng/ml, 95% CI 19.2 to 26) which plateaued until six months (24.3 ng/ml, 95% CI 20.6 to 27.9). Despite higher baseline BDNF levels in the exercise group, no treatment effect was observed until six months (training 24.6 ng/ml, 95% CI 20.2 to 29 vs relaxation: 24.3 ng/ml, 95% CI 19.8 to 28.8, p = 0.95). A sex-related interaction was identified in the relaxation group, with female patients exhibiting higher BDNF increases until end of follow up (20.9 ng/ml, 95% CI 15.7 to 26.2 (males) vs 31.0 ng/ml, 95% CI 22.9 to 39.0 (females), p = 0.039). Dose-response analyses and associations with recurrent events yielded no substantial differences.  While serum BDNF levels increased early after stroke in the first three months, aerobic exercise did not demonstrate a significant impact on BDNF levels within this dataset. Further investigations with more measurements during the early subacute phase are warranted to elucidate the interplay between exercise, BDNF, and recovery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetics of Motor Neuron Disease in New Zealand\nAbstract: Motor neuron disease (MND) is a group of neurodegenerative diseases characterised by adult-onset progressive degeneration of motor neurons, of which amyotrophic lateral sclerosis (ALS) is the most common. MND is clinically heterogenous with complex aetiology, being caused by or associated with over 40 different genes, along with multiple environmental risk factors. Although New Zealand has one of the highest incidence and mortality rates of MND globally, the reasons for this are yet to be determined.  In light of this lack of systematic genetic MND research in New Zealand, we sought to identify the frequencies of genetic variants in known MND-linked genes in people in New Zealand with MND. A total of 184 participants were enrolled; 149 with a clinical diagnosis of MND and 35 who were clinically unaffected but at risk of familial MND. Of the 149 affected, 128 had sporadic MND, and 21 had familial MND. Participants DNA was screened for genetic variation in 46 MND-associated genes using a combination of Sanger sequencing, Illumina single nucleotide polymorphism (SNP) microarray, repeat-primed PCR for C9orf72, and an Invitae gene panel.  Clinical phenotypes of participants with MND recapitulated the trends seen in European reference populations with both males, and individuals with spinal onset, having earlier disease onset. Thirty three of the 184 participants (17.9%) carried known pathogenic variants; the majority had C9orf72 hexanucleotide repeat expansion (24/34), and the remainder had previously reported pathogenic genetic variants in SOD1 (9/34; p.(Ile114Thr) and p.(Glu101Gly)). All NZ SOD1 p.(Ile114Thr) cases (n=4) were distantly related (identical-by- descent) to one another and a cluster of >30 MND cases from Australia with the same variant. Variants of interest were identified in 14 participants, of which splicing variants DCTN1:c.279+1G>C and ATP13A2 p.(Lys804=) are subject to ongoing study. Of the pathogenic variants, 48.4% were identified in pre-symptomatic unaffected individuals with a family history, highlighting the importance of offering cascade testing and symptom surveillance for families, particularly as gene-specific treatments are becoming available.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Investigating the oxidative stress-vascular brain injury axis in mild cognitive impairment of the Alzheimer type\nAbstract: Oxidative stress, an imbalance between production and neutralization of reactive oxygen species, can damage brain cells and contribute to cognitive decline in Alzheimer disease (AD) continuum. Levels of glutathione (GSH), the most prevalent endogenous brain antioxidant, can be assessed with magnetic resonance spectroscopy (MRS) and serves as a brain-oxidative stress index. Since the relationship between GSH and vascular-brain injury is unknown in the AD continuum, we address this gap in mild cognitive impairment (MCI) of the AD type. 3T MRI/MRS data were obtained from 31 MCI participants. GSH and total N-acetylaspartate (tNAA; neuroaxonal integrity marker) were measured in posterior cingulate cortex (PCC) and frontal white matter (FWM). Cerebrovascular injury was assessed using white matter hyperintensity (WMH) volume. Global and regional brain tissue integrity were assessed using normalized brain (NBV) and hippocampal volumes, respectively. Levels of tNAA, GSH/total creatine (tCr), and tNAA/tCr were higher in PCC than FWM. Significant associations were reported in FWM between GSH/tCr and tNAA/tCr, and between GSH and both WMH and NBV. Our results suggest that oxidative stress contributes to vascular-brain injury in MCI of the AD type.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Emergency admission plasma D-dimer and Prothrombin activity in acute ischemic stroke with large artery occlusion\nAbstract: BackgroundThe coagulation system is intrinsically linked to pathological mechanism and progression of ischemic stroke. However, the role of preoperative coagulation function in determining the functional outcomes of acute ischemic stroke patients following large artery occlusion (AIS-LVO) has not been extensively evaluated in peer-reviewed literature.  MethodsWe utilized logistic regression analyses, complemented by the construction of receiver operating characteristic (ROC) curves, to identify significant predictive factors for poor prognosis following EVT. Additionally, subgroup analyses were conducted to further assess the prognostic efficacy of coagulation function across different subgroups.  ResultsA total of 607 patients were enrolled, with 335 (55.19%) experiencing an unfavorable outcome. Multivariate regression analysis identified preoperative D-dimer and PTA as independent predictors of 3-month prognosis. After adjusting for confounders, elevated preoperative D-dimer levels ([&ge;]715 mg/L), identified by cut-off value, were a significant predictor of poor prognosis, with 2.51-fold higher risk compared to the normal range. Conversely, elevated PTA levels ([&ge;]85.5%) were significantly and inversely associated with poor prognosis, indicating a reduced risk of 0.39 times. Furthermore, the combination of elevated D-dimer and reduced PTA demonstrated a synergistic effect, markedly increasing the risk of poor outcomes in AIS-LVO patients. Subgroup analyses revealed that failed recanalization, comorbid diabetes, and non-middle cerebral artery (MCA) occlusion significantly influence the predictive value of D-dimer and PTA for clinical outcomes.  ConclusionElevated admission D-dimer and reduced PTA levels are an independent predictor of poor prognosis in patients with AIS-LVO, and there is a synergistic interaction between the two variables.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Normative trajectories of extra-axial cerebrospinal fluid during childhood and adolescence defined in a clinically-acquired MRI dataset\nAbstract: BackgroundExtra-axial cerebrospinal fluid (eaCSF) refers to the CSF in the subarachnoid spaces that surrounds the brain parenchyma. Benign enlargement of the subarachnoid space (BESS), a condition marked by increased eaCSF thickness, has been associated with macrocephaly and may be associated with subdural collections. However, diagnosis of BESS is complicated by the lack of age-specific normative data which hinders rigorous investigation of its clinical associations. Growth charts of eaCSF could shed light on normal CSF dynamics while also providing a normative benchmark to assist the diagnosis of BESS and other associated conditions.  MethodsWe accessed clinically-acquired T1w MRI scans from 1226 pediatric patients to form a clinical control cohort. Nine scans from subjects with a diagnosis of BESS from a board-certified pediatric neuroradiologist were also reviewed. SynthSeg was used to segment each T1w scan into various tissue types, including eaCSF. Growth charts of eaCSF were modeled using the clinical control cohort. The confirmed BESS cases were then benchmarked against these charts to test the performance of eaCSF growth charts.  ResultseaCSF thickness varied nonlinearly with age, steadily decreasing from birth to two years, then trending upwards in early adolescence. Seven of the nine patients with a clinical diagnosis of BESS were above the 97.5th percentile for their age for at least one eaCSF measure. Centile scores were able to distinguish BESS cases from controls with an area under curve (AUC) greater than 0.95.  DiscussioneaCSF thickness evolves in a dynamic pattern throughout childhood and adolescence. Patients with BESS can be differentiated from clinical controls using computational measurements of eaCSF thickness paired with normative modeling. Our findings demonstrate the feasibility of computational extraction of eaCSF with a potential point of clinical relevance, delineation of BESS diagnosis. Enhanced understanding of normative eaCSF is critical in further investigations its clinical associations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Caesarean myomectomy is not a risk factor for blood products transfusion among pregnant individuals with fibroids: a retrospective cohort study.\nAbstract: BackgroundUterine fibroids are common benign tumors during reproductive age. Among pregnant individuals with uterine fibroids, myomectomy at the time of cesarean delivery (CD) allows individuals to avoid a second surgery later in life.  ObjectiveTo examine the safety of myomectomy performed at the time of CD and the factors that increase the risk of greater blood loss in cesarean myomectomy.  Study designThis was a retrospective cohort study of all cesarean myomectomies (CM) performed at a tertiary care center in Toronto, Ontario between January 1, 2012, and June 1, 2019. The study group included individuals who had CM, and the control group included individuals with fibroids who had a CD without removing their fibroids. The primary outcome was the rate of blood products transfusion. Secondary outcomes were the need for hysterectomy and estimated blood loss (EBL). Subgroup analyses were performed for fibroid size, previous CD, and elective vs urgent CD. Logistic regression analysis was performed to assess for confounders.  ResultsOverall, 110 CM were compared with 152 CD. The overall transfusion rate for CM was 7.3% compared to 0.7% in the control group (p = 0.005). All procedures requiring transfusion from both groups were performed < 370/7 weeks of gestation. In logistic regression analysis, performing a myomectomy was not associated with a higher risk for transfusion. The only factors associated with transfusion were preterm birth (aOR 14.43, p=0.049) and low pre-operative hemoglobin (aOR 0.90, p=0.02). The median reported EBL was 800 mL for CM and 700 mL for controls (p<0.001). No individuals in either group required concomitant hysterectomy. Subgroup analysis showed that fibroid size [&ge;]5cm and previous CD were not associated with increased risk of transfusion among those who had a CM, while urgent CM was significantly associated with the need for transfusion (p=0.02).  ConclusionThis study demonstrates that the transfusion rate was not significantly higher in those undergoing CM at term, compared to those with fibroids undergoing CD without a myomectomy.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Single-cell RNA sequencing reveals immunosuppressive pathways associated with metastatic breast cancer\nAbstract: Metastatic breast cancer remains largely incurable, and the mechanisms underlying the transition from primary to metastatic breast cancer remain elusive. We analyzed the complex landscape of primary and metastatic breast cancer using scRNA-seq data from twenty-three female patients with either primary or metastatic disease to elucidate the genetic and molecular mechanisms underlying changes in the metastatic tumor ecosystem. We identify specific subtypes of stromal and immune cells critical to forming a pro-tumor microenvironment in metastatic lesions, including CCL2+ macrophages, cytotoxic T cells with an exhausted gene signature, and FOXP3+ regulatory T cells. Analysis of cell-cell communication highlights a marked decrease in tumor-immune cell interactions in metastatic tissues, likely strengthening the immunosuppressive microenvironment. In contrast, primary breast cancer samples displayed increased activation of the TNF- signaling pathway via NF-kB, indicating a potential therapeutic target. Our study comprehensively characterizes the transcriptional landscape encompassing primary and metastatic breast cancer.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Colorectal Cancer Screening in Adults 45-49: Provider Availability, CT Colonography Access, and Screening Rates\nAbstract: BackgroundThe US Preventive Services Task Force updated colorectal cancer (CRC) screening guidelines in 2021, recommending screening for adults aged 45-49. This study aimed to evaluate CRC screening prevalence among this newly eligible population and examine associations with healthcare provider supply and CT colonography facility availability in 2022.  MethodsUsing 2022 Behavioral Risk Factor Surveillance System data (n=25,592), we estimated CRC screening prevalence among adults aged 45-49. We examined associations between screening rates and state-level healthcare provider supply using 2021-2022 Area Health Resources File data. Spearman rank-order correlations assessed relationships between provider supply, CT colonography facility availability, and screening prevalence.  ResultsOverall CRC screening prevalence was 34.5% (95% CI: 33.4%-35.8%). Endoscopic tests were most common (74.9%), followed by stool-based tests (9.3%) and CT colonography (0.5%). Significant variations in screening modalities were observed across sociodemographic factors. Gastroenterology physician supply positively correlated with overall CRC screening prevalence ({rho}=0.42, P=.002) and endoscopy screening prevalence ({rho}=0.39, P=.005). CT colonography facility availability weakly correlated with CT colonography screening prevalence ({rho}=0.18, P=.22).  ConclusionsCRC screening rates among newly eligible adults aged 45-49 appear to be suboptimal in 2022. Disparities in screening methods across sociodemographic factors highlight potential access barriers. The association between gastroenterology physician supply and screening rates emphasizes the importance of addressing projected workforce shortages. Targeted efforts are needed to increase CRC screening uptake in this age group and ensure equitable access to screening services.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A diagnostic protein assay for differentiating follicular thyroid adenoma and carcinoma\nAbstract: Differentiating follicular thyroid adenoma (FTA) from carcinoma (FTC) remains challenging due to similar histological features separate from invasion. In this study, we aim to develop and validate DNA and protein-based classifiers for FTA/FTC differentiation. We collected 2443 samples from 1568 patients across 24 centers and applied next-generation sequencing, as well as discovery and targeted proteomics. Machine learning models were developed and compared utilizing DNA and/or protein features. The discovery protein-based model (AUC 0.899) outperformed the gene-based model (AUC 0.670). Consequently, we generated a protein-based model with targeted mass spectrometry and further validated it in three independent testing sets. The 24-protein-based model achieved high performance in the retrospective sets (AUC 0.871 and 0.853) and the prospective fine-needle aspiration biopsies (AUC 0.781). The classifier notably illustrated a 95.7% negative predictive value for ruling out malignant nodules. This study offers a promising protein-based approach for differential diagnosis of FTA and FTC.  HighlightsO_LIGenetic and proteomic profiling of follicular thyroid tumors from 1568 patients across 24 centers C_LIO_LIAI model based on proteins (AUC 0.899) outperformed that based on gene mutations (AUC 0.670) for differentiation of FTA and FTC C_LIO_LIValidation of the protein model in two retrospective cohorts (AUCs: 0.871, 0.853) and a prospective (AUC 0.781) C_LIO_LIThe protein model has 95.7% negative predictive value for ruling out malignant nodules C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: An Automation Framework for Clinical Codelist Development Validated with UK Data from Patients with Multiple Long-term Conditions\nAbstract: BackgroundCodelists play a crucial role in ensuring accurate and standardized communication within healthcare. However, preparation of high-quality codelists is a rigorous and time-consuming process. The literature focuses on transparency of clinical codelists and overlooks the utility of automation.  Method and Automated Framework DesignHere we present a Codelist Generation Framework that can automate generation of codelists with minimal input from clinical experts. We demonstrate the process using a specific project, DynAIRx, producing appropriate codelists and a framework allowing 1future projects to take advantage of automated codelist generation. Both the framework and codelist are publicly available.  Use-case: DynAIRxDynAIRx is an NIHR-funded project aiming to develop AIs to help optimise prescribing of medicines in patients with multiple long-term conditions. DynAIRx requires complex codelists to describe the trajectory of each patient, and the interaction between their conditions. We promptly generated{approx} 200 codelists for DynAIRx using the proposed framework and validated them with a panel of experts, significantly reducing the amount of time required by making effective use of automation.  Findings and ConclusionThe framework reduced the clinician time required to validate codes, automatically shrunk codelists using trusted sources and added new codes for review against existing codelists. In the DynAIRx case study, a codelist of{approx} 9600 codes required only 7-9 hours of clinicians time in the end (while existing methods takes months), and application of the automation framework reduced the workload by >80%.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Association between national action and trends in antibiotic resistance: an analysis of 73 countries from 2000 to 2023\nAbstract: BackgroundThe worlds governments have agreed both global and national actions to address the challenge of antimicrobial resistance. This raises the importance of understanding to what degree national action so far has been effective. Answering this question is challenged by variation in data availability and quality as well as disruptive events such as the COVID-19 pandemic. We investigate the association between a survey of self-reported action based on the first Global Database for Tracking Antimicrobial Resistance (TrACSS) survey and trends in multiple indicators related to the DPSEEA framework leading up to the survey.  Methods and findingsWe apply regression methods across 73 countries between actions in 2016 and the trend in indicators of health system development (drivers), antibiotic use (pressures, ABU), absolute rates of resistance (state, ABR) and relative rates of resistance (exposure, Drug Resistance Index, DRI) from 2000 to 2016. We find that action is consistently associated with improved linear and categorical trend in health systems, ABU, ABR and DRI. Reductions are associated with relatively high levels of action (0-4) for ABU (median 2.8, 25-75% quartile 2.6-3.3), ABR (3.0, 2.4-3.4), and DRI (3.5, 3.1-3.6). These associations are robust to the inclusion of other contextual factors such as health system and socio-economic status, human population density, animal production and climate. Since 2016, a majority of both Low-Middle Income Countries (LMICs) and High-Income Countries (HICs) report increased action on repeated questions, while one third of countries report reduced action. The main limitations in interpretation are heterogeneity in data availability and the recency of action.  ConclusionsOur findings highlight the importance of national action to address the domestic situation related to antibiotic resistance and indicate the value of both incremental changes in reducing adverse outcomes and the need for high levels of action in delivering improvements.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Refined selection of individuals for preventive cardiovascular disease treatment with a Transformer-based risk model\nAbstract: ObjectiveTo develop and validate the Transformer-based Risk assessment survival model (TRisk), a novel deep learning model, for prediction of 10-year risk of cardiovascular disease (CVD) in both the general population and individuals with diabetes.  DesignProspective open cohort study design.  SettingPrimary and secondary care in England as provided by Clinical Practice Research Datalink (CPRD) Gold  ParticipantsAn open cohort of 3 million adults aged 25 to 84 years was identified using linked primary and secondary electronic health records from 291 and 98 general practices in England and were used for model development and validation, respectively (i.e., general population cohort). Additionally, a second cohort of patients with diabetes was extracted. At study entry, patients in both cohorts were free of CVD and not prescribed statins.  MethodsTRisk utilised all diagnosis, medication, procedure, and clinical test data up to study entry in linked longitudinal primary and secondary care electronic health records for prediction of 10-year risk of CVD. Discrimination, calibration, and decision curve analyses were conducted to investigate predictive performance. The proposed model was also compared against QRISK3 and a deep learning derivation model of QRISK3 (DeepSurv). Additional analyses compared discriminatory performance in other age groups, by sex, and across categories of socioeconomic status.  Main outcome measuresIncident cardiovascular disease recorded in either linked general practice or hospital admission datasets provided by CPRD Gold.  ResultsTRisk demonstrated superior discrimination (C-index in the general population: 0.910; 95% confidence interval [CI]: 0.906 to 0.913). TRisks performance was found to be less sensitive to population age range than the benchmark models and outperformed other models also in analyses stratified by age, sex or socioeconomic status. All models were overall well-calibrated. In decision curve analyses, TRisk demonstrated greater net benefit than benchmark models across the range of relevant thresholds. At both the recommended 10% risk threshold and the 15% risk threshold, TRisk reduced both the total number of patients classified at high risk (by 22% and 35% respectively) and the number of false negatives as compared with currently recommended strategies. TRisk similarly outperformed other models in patients with diabetes. Compared with the widely recommended treat-all policy approach for patients with diabetes, TRisk at a 10% risk threshold would lead to deselection of 24% of individuals with a small fraction of false negatives (0.2% of cohort).  ConclusionTRisk enabled a more targeted selection of individuals at risk of CVD compared to benchmark statistical and deep learning models, in both the general population and patients with diabetes. Incorporation of TRisk into routine clinical care would allow a reduction in the number of treatment-eligible patients by approximately one-third while preventing at least as many events as with currently adopted approaches.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Emergency department revisits at thirty days are modestly explained by caregiver burden: a prospective cohort study\nAbstract: Structured AbstractO_ST_ABSImportanceC_ST_ABSCaregivers play a protective role in emergency department (ED) care transitions. When the demands of caregiving result in caregiver burden, ED returns can ensue.  ObjectiveWe developed models describing how caregiver burden may predict ED revisits and admissions up to thirty days after discharge.  DesignThis prospective cohort study nested within the LEARNING WISDOM clinical trial included older adults and their caregivers who underwent a transition of care from one of four EDs in Quebec, Canada between January 1st, 2019, and December 21st, 2021.  SettingThis study occurred within an integrated health multi-site organization consisting of four acute care hospitals.  ParticipantsPatients aged 65 years or older who were discharged back to the community from the ED observation unit after being triaged to a stretcher on their index visit.  ExposureCaregiver burden, as collected using the brief twelve-item Quebec French version of the Zarit Brief Burden Interview (ZBI).  Main Outcomes and MeasureRevisits to the ED were defined as a return to any ED in the 4- hospital network within 3, 7, or 30 days of the index visit. Admissions were return visits to the ED within 30 days resulting in hospitalization.  ResultsAmong 1,409 caregiver-patient dyads, ZBI scores averaged 7.33 (SD = 7.11). Most caregivers were women (69%). Caregivers were most often spouses (48%) of patients or children of patients (38%). Among all patients, 5.3% returned to the ED within 3 days, 9.4% returned within 7 days, 20.7% returned within 30 days and 6.2% were admitted within 30 days. Each point increase on the ZBI scale was associated with a 2.8% increase in the odds of a 30-day revisit to the ED (p = 0.03), but not in models with shorter time windows, nor for admissions. ZBI scores on 30-day ED revisits were moderated by the COVID-19 pandemic waves: the first inter-wave period attenuated the association.  Conclusions and RelevanceCaregiver burden may modestly predict ED revisits over 30 days. Future studies may enhance the management of ED revisits by predicting the longitudinal impact of caregiver burden on ED use in older adults.  Trial Registration: https://clinicaltrials.gov/ct2/show/NCT04093245  Key pointsO_ST_ABSQuestionC_ST_ABSCan caregiver burden predict emergency department (ED) revisits and admissions within 30 days of discharge among older adults?  FindingsIn this prospective cohort study, higher caregiver burden was associated with a modest increase in the likelihood of 30-day ED revisits, though not with shorter-term revisits or admissions.  MeaningReducing caregiver burden may help prevent returns to the ED within 30 days among community-dwelling older adults.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Air cleaning reduces incident infections in day care - an interventional crossover study\nAbstract: BackgroundWhile possibility of airborne transmission in the spread of common respiratory infections, there is no consensus on the relative importance of airborne infection route in real-life. This study aimed to investigate the significance of the airborne transmissions and the effectiveness of air cleaning in reducing infections among children in daycare.  MethodsA cross-over study was conducted in four daycare centers in Helsinki. All children attending the daycare were invited to participate (n = 262) and the sole inclusion criterion was that the children were expected to stay in the same day care center for the two-year duration of the study. 51 subjects were included in the final analysis. Clean air flow rate was increased by 2.1-2.9 times compared to baseline mechanical ventilation of the premises. The effect of intervention was assessed using negative binomial regression.  ResultsThe intervention reduced incident infections from 0.95 to 0.78 infections per child per month among the children (primary outcome) in daycare. The reduction attributed to intervention in the statistical model was 18.0 % (95% CI 2.1-31.3 %, p = 0.028).  ConclusionsWe observed a significant decrease in incident infections without implementing any other infection mitigation strategies but air cleaning. Our results challenge the current paradigm which emphasizes fomite and contact transmission and infection control measures that target these pathways. As ventilation and air cleaning can only affect particles able to float in the air stream, our results support the significance of airborne transmission among common respiratory pathogens as well as air cleaning as an infection control measure.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Specific Within-Domain Cognitive Impairments Predict Depression Severity Six-Months After Stroke\nAbstract: BackgroundFollowing stroke, chronic cognitive impairments across multiple domains have been associated with depression. Currently, it is unknown if specific subtypes of cognitive impairments differentially relate to post-stroke depression severity. This study aimed to explore the differential associations between within-domain cognitive impairment to depression severity six-months after stroke.  MethodParticipants (n = 385, Age M = 73.86 years [SD = 12.51], National Institutes of Health Stroke Severity M = 6.83 [SD = 6.01]) were recruited from an acute stroke ward. Participants completed a self-report mood measure (Hospital Anxiety and Depression Scale; HADS) and a stroke-specific cognitive assessment (Oxford Cognitive Screen; OCS). Separate multiple regressions predicting depression were conducted across 1) OCS domain-specific cognitive impairments of language, memory, attention, praxis, numeracy and executive function, and 2) the novel subtask-specific impairments within each OCS domain. Anxiety severity and years of education attained were included as covariates.  ResultsWithin-domain impairments that were uniquely associated with depression severity were calculation (b(.57) = 1.44, 95% CI [0.31, 2.56], p = .012), episodic memory (b(.52) = 1.36, 95% CI [0.34, 2.37], p = .009), picture naming (b(.45) = 1.18, 95% CI [0.31, 2.06], p = .008), number writing (b(.46) = 2.54, 95% CI [0.26, 2.07], p = .012), and visuospatial attention (b(.35) = 1.24, 95% CI [0.54, 1.93], p = .001). Analysis in pooled multiply imputed data (N = 430) corroborated complete case analysis findings.  ConclusionsSpecific within-domain cognitive impairments have differential relationships with post-stroke depressive symptomology. Accommodating for these impairments in post-stroke depression interventions may potentially enhance therapeutic outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Trajectories of mHealth-tracked mental health symptoms and their predictors in chronic pelvic pain\nAbstract: BackgroundFemale chronic pelvic pain disorders (CPPDs) affect 1 in 7 women worldwide and are characterized by psychosocial comorbidities, including reduced quality of life and 2-10 fold increased risk of depression and anxiety. Despite its prevalence and morbidity, CPPDs are often inadequately managed with few patients experiencing relief from any medical intervention. Characterizing mental health symptom trajectories and lifestyle predictors of mental health is a starting point to enhancing patient self-efficacy in managing symptoms. Here, we investigate the association between mental health, pain, and physical activity (PA) in females with CPPD and demonstrate a method for handling multi-modal mobile health (mHealth) data.  MethodThe study sample included 4,270 person-level days and 799 person-level weeks of data from CPPD participants (N=76). Participants recorded PROMIS global mental health (GMH) and physical functioning, and pain weekly for 14 weeks using a research mHealth app, and moderate-to-vigorous PA (MVPA) was passively collected via activity trackers.  Data analysisWe used penalized functional regression (PFR) to regress weekly GMH-T (GMH-T) on MVPA and weekly pain outcomes, while adjusting for baseline measures, time in study, and the random intercept of the individual. We converted 7-day MVPA data into a single smooth using spline basis functions to model the potential non-linear relationship.  ResultsMVPA was a significant, curvilinear predictor of GMH-T (p<0.001), independent of pain measures and prior psychiatric diagnosis. Physical functioning was positively associated with GMH-T, while pain was negatively associated with GMH-T ({beta}=2.24, {beta}=-1.16, respectively; p<0.05).  ConclusionThese findings suggest that engaging in MVPA is beneficial to the mental health of females with CPPD. Additionally, this study demonstrates the potential of ambulatory mHealth-based data combined with functional models for delineating inter-individual and temporal variability.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploiting pleiotropy to enhance variant discovery with functional false discovery rates\nAbstract: The cost of acquiring participants for genome-wide association studies (GWAS) can limit sample sizes and inhibit discovery of genetic variants. We introduce the surrogate functional false discovery rate (sfFDR) framework which integrates summary statistics of related traits to increase power. The sfFDR framework provides estimates of FDR quantities such as the functional local FDR and q-value, and uses these estimates to derive a functional p-value for type I error rate control and a functional local Bayes factor for post-GWAS analyses (e.g., fine mapping and colocalization). Compared to a standard analysis, sfFDR substantially increased power (equivalent to a 60% increase in sample size) in a study of obesity-related traits from the UK Biobank, and discovered eight additional lead SNPs near genes linked to immune-related responses in a rare disease GWAS of eosinophilic granulomatosis with polyangiitis. Collectively, these results highlight the utility of exploiting related traits in both small and large studies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Powerful mapping of cis-genetic effects on gene expression across diverse populations reveals novel disease-critical genes\nAbstract: While disease-associated variants identified by genome-wide association studies (GWAS) most likely regulate gene expression levels, linking variants to target genes is critical to determining the functional mechanisms of these variants. Genetic effects on gene expression have been extensively characterized by expression quantitative trait loci (eQTL) studies, yet data from non-European populations is limited. This restricts our understanding of disease to genes whose regulatory variants are common in European populations. While previous work has leveraged data from multiple populations to improve GWAS power and polygenic risk score (PRS) accuracy, multi-ancestry data has not yet been used to better estimate cis-genetic effects on gene expression. Here, we present a new method, Multi-Ancestry Gene Expression Prediction Regularized Optimization (MAGEPRO), which constructs robust genetic models of gene expression in understudied populations or cell types by fitting a regularized linear combination of eQTL summary data across diverse cohorts. In simulations, our tool generates more accurate models of gene expression than widely-used LASSO and the state-of-the-art multi-ancestry PRS method, PRS-CSx, adapted to gene expression prediction. We attribute this improvement to MAGEPROs ability to more accurately estimate causal eQTL effect sizes (p < 3.98 x 10-4, two-sided paired t-test). With real data, we applied MAGEPRO to 8 eQTL cohorts representing 3 ancestries (average n = 355) and consistently outperformed each of 6 competing methods in gene expression prediction tasks. Integration with GWAS summary statistics across 66 complex traits (representing 22 phenotypes and 3 ancestries) resulted in 2,331 new gene-trait associations, many of which replicate across multiple ancestries, including PHTF1 linked to white blood cell count, a gene which is overexpressed in leukemia patients. MAGEPRO also identified biologically plausible novel findings, such as PIGB, an essential component of GPI biosynthesis, associated with heart failure, which has been previously evidenced by clinical outcome data. Overall, MAGEPRO is a powerful tool to enhance inference of gene regulatory effects in underpowered datasets and has improved our understanding of population-specific and shared genetic effects on complex traits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Effects of respite services on fluctuations in caregivers' stress: A pilot study using a daily diary\nAbstract: ObjectivesFamily caregivers for people with dementia report daily fluctuations in stress levels. Much prior research on caregivers daily stress fluctuations has used a daily diary method. However, only a few studies have used this method with family caregivers to examine the effects of respite services. This study aimed to use a daily diary method to assess the effects of respite services on stress and depression in family caregivers.  MethodsParticipants included 13 family caregivers of persons with dementia using respite services in rural areas of Japan. Participants completed self-administered questionnaires every day for seven days, including the use or non-use of respite services, cognitive and daily living function, depression, and stress appraisal. Generalized linear mixed models with data nested within persons were used for the analysis.  ResultsFew significant effects of services were found on caregivers depression and stress appraisals at the between-person level. However, within-person level analyses using generalized mixed models showed that respite services significantly reduced stress appraisal.  ConclusionThe findings demonstrate the stress-buffering effect of respite service for caregivers and the applicability of a daily diary method to the small sample.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Low Responsiveness of Machine Learning Models to Critical or Deteriorating Health Conditions\nAbstract: Machine learning (ML) based mortality prediction models can be immensely useful in intensive care units. Such a model should generate warnings to alert physicians when a patients condition rapidly deteriorates or their vitals are in highly abnormal ranges. Before clinical deployment, it is important to comprehensively assess models ability to recognize critical patient conditions. We develop testing approaches to systematically assess models ability to respond to serious medical emergencies. Using generated test cases, we found that statistical machine-learning models trained solely from patient data are grossly insufficient and have many dangerous blind spots. Specifically, we identified serious deficiencies in the models responsiveness, i.e., the inability to recognize severely impaired medical conditions or rapidly deteriorating health. For in-hospital mortality prediction, the models tested using our synthesized cases fail to recognize 66% of the test cases involving injuries. In some instances, the models fail to generate adequate mortality risk scores for all test cases. We also applied our testing methods to assess the responsiveness of 5-year breast and lung cancer prediction models and identified similar kinds of deficiencies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Low Responsiveness of Machine Learning Models to Critical or Deteriorating Health Conditions\nAbstract: Machine learning (ML) based mortality prediction models can be immensely useful in intensive care units. Such a model should generate warnings to alert physicians when a patients condition rapidly deteriorates or their vitals are in highly abnormal ranges. Before clinical deployment, it is important to comprehensively assess models ability to recognize critical patient conditions. We develop testing approaches to systematically assess models ability to respond to serious medical emergencies. Using generated test cases, we found that statistical machine-learning models trained solely from patient data are grossly insufficient and have many dangerous blind spots. Specifically, we identified serious deficiencies in the models responsiveness, i.e., the inability to recognize severely impaired medical conditions or rapidly deteriorating health. For in-hospital mortality prediction, the models tested using our synthesized cases fail to recognize 66% of the test cases involving injuries. In some instances, the models fail to generate adequate mortality risk scores for all test cases. We also applied our testing methods to assess the responsiveness of 5-year breast and lung cancer prediction models and identified similar kinds of deficiencies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Exploring the potential benefits and challenges of artificial intelligence for research funding organisations: a scoping review\nAbstract: BackgroundArtificial Intelligence (AI) is at the forefront of todays technological revolution, enhancing efficiency in many organisations and sectors. However, in some research environments, its adoption is tempered by the risks AI poses to data protection, ethics, and research integrity. For research funding organisations (RFOs), although there is interest in the application of AI to boost productivity, there is also uncertainty around AIs utility and its safe integration into organisational systems and processes. The scoping review explored:  What does the evidence say about the current and emerging use of AI?;  What are the potential benefits of AI for RFOs? and  What are the considerations and risks of AI for RFOs?  MethodsA scoping review was undertaken with no study, language, or field limits. Due to the rapidly evolving AI field, searches were limited to the last three years (2022-2024). Four databases were searched for academic and grey literature in February 2024 (including 13 funding and professional research organisation websites). A classification framework captured the utility and potential, and considerations and risks of AI for RFOs.  Results122 eligible articles revealed that current and emerging AI solutions could potentially benefit RFOs by enhancing data processes, administration, research insights, operational management, and strategic decision-making. These solutions ranged from AI algorithms to data management platforms, frameworks, guidelines, and business models. However, several considerations and risks need to be addressed before RFOs can successfully integrate AI (e.g., improving data quality, regulating ethical use, data science training).  ConclusionWhile RFOs could potentially benefit from a breadth of AI-driven solutions to improve operations, decision-making and data management, there is a need to assess organisational  AI readiness. Although technological advances could be the solution there is a need to address AI accountability, governance and ethics, address societal impact, and the risks to the research funding landscape.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Alcohol, smoking, and brain structure: common or substance specific associations\nAbstract: Alcohol use and smoking are common substance-use behaviors with well- established negative health effects, including decreased brain health. We examined whether alcohol use and smoking were associated with the same neuroimaging-derived brain measures. We further explored whether the effects of alcohol use and smoking on the brain were additive or interactive.  We leveraged a cohort of 36,309 participants with neuroimaging data from the UK Biobank. We used linear regression to determine the association between 354 neuroimaging-derived brain measures and alcohol use defined as drinks per week, pack years of smoking, and drinks per week x pack years smoking interaction. To assess whether the brain associations with alcohol are broadly similar or different from the associations with smoking, we calculated the correlation between z-scores of association for drinks per week and pack years smoking.  Results indicated overall moderate positive correlation in the associations across measures representing brain structure, magnetic susceptibility, and white matter tract microstructure, indicating greater similarity than difference in the brain measures associated with alcohol use and smoking. The only evidence of an interaction between drinks per week and pack years smoking was seen in measures representing magnetic susceptibility in subcortical structures. The effects of alcohol use and smoking on brain health appeared to be additive rather than multiplicative for all other brain measures studied. 97% (224/230) of associations with alcohol and 100% (167/167) of the associations with smoking that surpassed a p value threshold are in a direction that can be interpreted to reflect reduced brain health. Our results underscore the similarity of the adverse associations between use of these substances and neuroimaging derived brain measures.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of residual intimal flap displacement post-TEVAR on TBAD haemodynamics in compliant, patient-specific CFD simulations informed by MRI\nAbstract: We propose a novel formulation of a moving boundary method to account for the motion of the intimal flap (IF) in a TBAD post-thoracic endovascular aortic repair using patient-specific compliant computational fluid dynamics simulations. The simulations were informed by non-invasive 4DMRI sequences. Predicted flow waveforms, aortic wall and IF displacements were validated against in vivo 4DMRI and cine MRI data. The patient-specific simulation showed that at peak systole, the dynamic interplay between high IF displacement and high transmural pressures promoted true lumen compression and false lumen expansion, while luminal patterns were reversed at the deceleration phase. High vorticity and swirling flow patterns were observed throughout the cardiac cycle at the primary entry tear, the descending aorta and proximal to the visceral aortic branches, correlating with high relative residence time, which could indicate an increased localised risk of aortic growth proximal to the IF. A rigid IF simulation revealed significant discrepancies in haemodynamic metrics, highlighting the potential mispredictions when using a rigid wall assumption to assess disease progression. Simulations assuming a more compliant IF highlighted increased risks of visceral branches malperfusion and localised aortic wall degeneration. The study underscores the necessity of patient-specific-compliant IF simulations for accurate TBAD hemodynamic assessments. These insights can improve disease understanding and inform future treatment strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Stroke recognition in medical emergency calls:A novel sensitivity definition as basis for developing AI decision support\nAbstract: BackgroundThe sensitivity of emergency medical communication centers (EMCC) for stroke detection varies widely. However, few studies offer detailed insights into the entirety of prehospital pathways in patients with stroke. Therefore, this study aimed to lay the foundation for artificial intelligence (AI) decision support tools in EMCCs by exploring their ability to detect strokes in medical emergency calls, describe a novel method for stroke sensitivity calculation in the EMCC, and identify factors associated with stroke recognition during a call.  MethodsIn total, 1,164 patients with stroke in the catchment area of Bergen EMCC in 2018 and 2019 were included, and a dataset from the EMCC was established manually and linked with data from the Norwegian Stroke Registry (NSR) for analysis. Descriptive statistics, Chi-square test for categorical variables, Mann-Whitney U test for continuous variables, and multivariate logistic regression (LR) were performed on data obtained from patients primarily assessed by EMCC (n=838).  ResultsUsing a novel method, we found a stroke detection sensitivity of 76.8% in our study, compared to the 63.4% when using the traditional sensitivity detection method. LR analysis showed a positive association between stroke suspicion and ischemic strokes (odds ratio [OR]=0.317 [0.209-0.481]; p<0,001, with ischemic stroke as the reference) and wake-up strokes (OR=1.716 [1.110-2.653]; p=0.015). Among the NSR symptoms, only aphasia/dysarthria was positively associated with stroke suspicion (OR=1.600 [1.087-2.353]; p=0.017), while leg paresis (OR=0.609 [0.390-0.953]; p=0.009) and vertigo (OR=0.376 [0.204-0.694]; p=0.002) were negatively associated.  ConclusionsThis study introduced a novel and more accurate method for calculating EMCC stroke sensitivity, which is relevant for developing decision support tools, such as AI. Moreover, we identified factors of particular interest for future EMCC research that are relevant to developing AI decision-support tools.  Clinical trialshttps://clinicaltrials.gov/study/NCT04648449\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Current Status of Health Care Bioethics Committees in Chile: Suggestions for Improvement in Public Health Management\nAbstract: This study examines the current functioning of Health Care Bioethics Committees (HBCs) in Chile, with the objective of providing recommendations for improving public health care management. Through a comprehensive literature review and a case analysis of the  Hospital Clinico de la Universidad de Chile, the structure, functions and challenges of the CEA are explored. The research reveals the importance of the multidisciplinary composition of the committees, the need for continuing education in bioethics, and the relevance of the consultative role in ethical decision making. The results suggest that the effectiveness of CABs does not necessarily depend on the number of members or the length of their terms of office, but on the quality of their training and experience. It is concluded that for adequate health care management, it is essential to strengthen the role of the CEA in the ethical education of health care personnel and in the development of institutional regulations, as well as to improve their visibility and accessibility within the Chilean health care system.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and Factors Associated with Puerperal Sepsis Among Postnatal Women at a Tertiary Referral Hospital in Western Uganda\nAbstract: BackgroundPuerperal sepsis remains one of the leading causes of maternal mortality and morbidity in Uganda.  AimThis study assessed the prevalence and factors associated with puerperal sepsis among postpartum women at Fort portal Regional Referral Hospital located in western Uganda.  MethodsA cross-sectional design was employed in the study. We conducted a records review of the patient files of 180 postnatal mothers who were admitted at Fort Portal Regional Referral Hospital from 20 February, 2024 to 01 April, 2024. A data abstraction checklist was used to collect data from participant files based on strict inclusion and exclusion criteria. Data was entered in Microsoft Excel and exported to STATA17 for data analysis. Descriptive analysis and logistic regression analysis were performed to determine the prevalence of puerperal sepsis and determinants. Bivariate and multivariate logistic regression analysis was conducted for significant factors presented as Adjusted Odds Ratios (aOR) at p[&le;]0.05.  ResultsThe median age of participants was 25.5 years (1QR=20-30) and the majority (77%) had primary education. The prevalence of postnatal sepsis was 24%. Duration of hospital stay [aOR=2.30; 95%CI (1.552-3.398); p=<0.001], history of antepartum hemorrhage [aOR=29.09; 95% CI (1.182-716.38); p=0.039] and Anemia [aOR=0.01; 95% CI (0.001-0.218); p=0.004] were identified as factors associated with puerperal sepsis among postnatal women upon multivariate logistic regression.  ConclusionPuerperal sepsis was common in our setting. This study found that mode of delivery, duration of hospital stay, anemia, and Antepartum hemorrhage, were the determining factors contributing to puerperal sepsis, infection prevention measures during cesarean sections, and reducing the length of hospital stay would prove to be beneficial in the prevention of sepsis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Integrating health care and early years support for children and young people living in deprivation: A cost effectiveness analysis of a novel integrated clinic in Birmingham, UK\nAbstract: BackgroundIncreased use of emergency and secondary care by children and young people, especially in deprived populations, drive increased costs in health and social care systems in rich country settings, without necessarily delivering quality care.  AimTo assess the potential cost-effectiveness of the Sparkbrooks Children Zone (SCZ), a pilot clinic for children and young people which integrates health and early years support in a highly deprived area of Birmingham, the UKs second city, compared with standard primary care.  MethodsA decision-analytic model taking healthcare and partial social care perspective was developed using best available, though limited, evidence from aggregated data of an ongoing pilot, published literature, expert opinions and assumptions. Effectiveness was measured as proportion of patients attending the emergency department. Deterministic and probabilistic sensitivity analyses were performed to assess the impact of parameter uncertainties.  ResultsThe integrated SCZ clinic may potentially be cost-effective based on this preliminary model-based analysis. The SCZ had lower proportion of patients attending emergency department, 0.017 compared with 0.029 for standard primary care, reducing proportion of emergency department visits by 0.012. The average cost of SCZ was {pound}66.22 compared with {pound}110.36 for standard primary care, leading to a cost-saving of {pound}44.08 per patient. This potential reduction in total costs resulting from fewer referrals to childrens social care and secondary medical services, including the emergency department. Extensive sensitivity analysis supported the indications that the intervention was likely to be cost-effective.  ConclusionThe SCZ pilot shows potential in integrating health and social care within a community setting, with Its early years services likely enhancing the cost-effectiveness of the SCZ compared to standard primary care. Further robust data and trial evaluation are essential to confirm these findings, ensuring the scalability and sustainability of such programs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cost-effectiveness of a 4 days-a-week triple therapy in persons living with HIV: an ancillary study of the ANRS 170 QUATUOR noninferiority trial\nAbstract: BackgroundANRS 170 QUATUOR study (NCT03256422) demonstrated the noninferiority of a triple antiretroviral therapy (ART) taken 4 days a week (4/7-days) compared to a triple therapy taken 7 days a week (7/7-days) for persons living with HIV and with suppressed viremia. We aimed at investigating corresponding cost-effectiveness issues.  MethodsAll persons involved in the primary analysis of the QUATUOR noninferiority trial were considered (N=636, 318 per arm) in this cost-effectiveness study. Time horizon was the first 48 weeks of the trial. Effectiveness was considered as the noninferiority of the 4/7-days strategy, main criterion of the trial primary analysis. Direct health resource costs (year2022{euro}) were considered and included costs for ART, laboratory tests, co-medications, hospitalizations, and medical consultations. Analyses were based on 10,000 simulations replicating the trial. Additional analyses explored the national impact of spreading the 4/7-days strategy all over France. Sensitivity analyses included considering treatment success as effectiveness, and various proportions of persons adopting the 4/7-days strategy.  FindingsThe mean individual total costs amounted to {euro} 5,049 [95% confidence interval: 4,798-5,345] and {euro} 8,089 [7,706-8,527] in the 4/7-days and 7/7-days arm, respectively. Corresponding ART costs were {euro} 3,678 [3,593-3,763] and {euro} 6,450 [6,301-6,596], respectively (p<0.0001), and constituted the single cost element with a statistical difference between the two strategies. Considering noninferiority as the effectiveness criterion in a health economic perspective, the 4/7-day strategy provided average savings of {euro} 3,013 [2829-3196] in ART costs per individual and per year. Adopting the 4/7-days regimen in 20% of the potential recipients in France was estimated to provide annual savings of {euro} 61,752,467 [61,569,005; 61,925,136].  InterpretationThe 4/7-day strategy dominates the 7/7-day strategy since it spares substantial ART costs while maintaining treatment effectiveness. Study results support generalizing the adoption of 4/7-days triple ART regimens in France, when possible.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Neural Correlates of Alcohol Approach Bias: New Insights from a Whole-Brain Network Analysis Perspective\nAbstract: Alcohol approach bias, a tendency to approach rather than to avoid alcohol and alcohol-related cues regardless of associated negative consequences, is an emerging key characteristic of alcohol use disorder (AUD). Reaction times from the Approach-Avoidance Task (AAT) can be used to quantify alcohol approach bias. However, only a handful of studies have investigated the neural correlates of implicit alcohol approach behavior. Graph Theory Analysis (GTA) metrics, specifically, weighted global efficiency (wGE), community detection, and inter-community information integration were used to analyze functional magnetic resonance imaging (fMRI) data of an in-scanner version of the AAT from 31 heavy drinking Veterans with AUD (HDV) engaged in out-patient treatment and 19 healthy Veterans as controls (HC). We found a functional imprint of alcohol approach bias in HDVs. HDVs showed significantly higher wGE values for approaching than for avoiding alcohol, indicating that their brain was more efficiently organized or functionally set to approach alcohol in the presence to alcohol-related external cues. In contrast, Brains of HCs did not show such a processing advantage for either the approach or avoid condition. Further post-hoc analyses revealed that HDVs and HCs differed in how they implemented top-down control when approaching/avoiding alcohol and in how the fronto-parietal control network interacted with subsystems of the default mode network. These findings contribute to understanding the complex neural underpinnings of alcohol approach bias and lay the foundation for developing more potent and targeted interventions to modify these neural patterns in AUD patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Longitudinal Changes in Lifestyle Behaviors and Cardiovascular Health During the Transition to Fatherhood: The Dad Bod Study Rationale and Design\nAbstract: BackgroundDespite the importance of the transition to fatherhood as a critical life stage among young adult men, much remains unknown about the factors predictive of ideal cardiovascular health (CVH) and how CVH is impacted as young men face new roles and responsibilities associated with fatherhood.  MethodsTo address this gap, the Dad Bod Study is a prospective, longitudinal and observational study designed to examine how fatherhood affects young mens CVH. A total of 125, first-time prospective fathers (men, 19-39 years) will be enrolled and followed over 1.5 years. Metrics of the American Heart Associations \"Lifes Essential 8\" as well as demographic, social, and psychosocial factors will be collected at four time points ((baseline (during the pregnant partners 2nd trimester) 1-month postpartum, 6-months postpartum, and 1-year postpartum). The primary aims are to measure predictors of CVH among first-time fathers and describe longitudinal changes in CVH. A secondary aim is to identify best practices for recruitment, retention, and remote data collection in this population.  SummaryThe Dad Bod Study offers a novel examination of CVH among first-time fathers, exploring how new paternal roles and responsibilities impact cardiovascular health. Findings may provide key insights into critical CVH behaviors and risk factors to monitor, preserve, and improve as young men transition to fatherhood.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Tirzepatide for Lipodystrophy\nAbstract: BackgroundLipodystrophy encompasses a group of rare disorders associated with severe metabolic disease. These disorders are defined by abnormal fat distribution, with near-total (generalized lipodystrophy, GL) or partial (partial lipodystrophy, PL; i.e. familial partial lipodystrophy, FPLD) absence of adipocyte mass leading to a decreased ability to store lipids safely. Excess lipids are more likely to be stored in non-adipose tissues, which leads to the metabolic manifestations. We have recently shown that glucagon-like peptide-1 agonists are associated with metabolic improvements in FPLD. We hypothesized that tirzepatide, a dual incretin, may also lead to metabolic improvement in patients with lipodystrophy.  MethodsObservational cohort of patients with PL or GL who received tirzepatide clinically were tracked in the context of ongoing natural history studies.  ResultsSeventeen patients received tirzepatide, 14 with FPLD (ages within 30-74 years; 12 female 2 male). After a median 8.7 months of follow-up, BMI (median{Delta} -1.7; range -5.9 to 0.9 kg/m2; p=0.008), HbA1c (median{Delta} -1.1%; range -6.3 to -0.1%; p<0.001), triglycerides [median{Delta} - 65 mg/dL (-0.73 mmol/L); range -3820 to 43 mg/dL (-43.2 to 0.49 mmol/L); p=0.003] and total daily insulin requirements (median{Delta} -109; range -315 to 0 units/day; p=0.002) were significantly reduced. Three patients with acquired GL (Ages within 35-64 years; all female) also demonstrated a robust response to tirzepatide with reduced BMI (22.2->20.9; 26.2->25.4; 19.5->17.6 kg/m2), HbA1c (8.5%->7.0%; 10.2%->7.8%; 9.1%->6.5%), triglycerides (91->80; 641->293; 1238->100 mg/dL or 1.03->0.90; 7.24->3.31; 14.0->1.13 mmol/L), and total daily insulin requirement (85->0; 0->0; 1000->750 units/day). Three patients did not tolerate dose escalation due to gastroesophageal reflux.  ConclusionsTirzepatide may be an effective treatment for patients with lipodystrophy.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impact of Losartan on Portal hypertension and Liver Cirrhosis: A Systematic Review\nAbstract: BackgroundPortal hypertension, a complication of chronic liver disease, results from elevated pressure between the portal vein and the inferior vena cava. While non-selective beta-blockers are established for reducing portal pressure, the efficacy of losartan, an angiotensin II receptor blocker, remains debated. This study evaluated losartans impact on portal pressure and clinical outcomes in patients with cirrhosis and portal hypertension.  ObjectivesTo appraise evidence on the role of losartan in reducing portal pressure and associated clinical outcomes in cirrhotic patients with portal hypertension.  MethodsA comprehensive literature search was conducted in PubMed, Cochrane Library, Medline, and Web of Science. All the research and review of literature was conducted within the time period from August 20th, 2024 till August 31st, 2024 (within 1 month of submission of the paper). The Risk of Bias Visualization Tool (Robvis 2.0) and ROBINS-I were used to assess study quality. Data was extracted and analyzed using Microsoft Excel.  ResultsAmong 426 potential studies, 12 met the inclusion criteria. Both losartan and propranolol reduced hepatic venous pressure gradient (HVPG), with some studies suggesting a more pronounced effect of losartan. Meta-analysis found no significant difference in HVPG reduction (p = 0.22), but losartan significantly reduced wedged hepatic venous pressure (WHVP) compared to propranolol (p = 0.03). Losartan also affected mean arterial pressure, renal function, and hepatic fibrosis.  ConclusionsLosartan shows potential in treating portal hypertension by reducing portal pressure and fibrosis. It may be particularly beneficial for patients unresponsive to beta-blockers, addressing both hemodynamic and structural components, and improving sodium handling in complex cases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reducing Functional Dysconnectivity in Schizophrenia Spectrum Disorders\nAbstract: BackgroundAs a condition of dysconnectivity, schizophrenia spectrum disorders (SSD) are characterized by positive, negative, and cognitive symptoms. To improve these symptoms in SSD, physical exercise interventions show promise. We examined if reductions of functional dysconnectivity following exercise therapy are associated with clinical improvements in SSD and explored potential genetic underpinnings.  MethodsThe study utilized data from the ESPRIT C3 trial, investigating the effects of aerobic exercise versus flexibility, strengthening, and balance training on different health outcomes in individuals with SSD. Functional dysconnectivity in 23 patients relative to a healthy reference sample, was assessed both pre- and post-intervention. Changes of functional dysconnectivity after exercise and their clinical relevance were evaluated. An imaging transcriptomics approach was used to study the link between changes in functional dysconnectivity and gene expression profiles.  ResultsWe observed substantial reductions of functional dysconnectivity on the whole-brain level linked to enhanced gene expression mainly in oligodendrocytes. With regard to the clinical implications, decreases of dysconnectivity in the default-mode network were associated with improvements in global functioning. Reductions of dysconnectivity within the salience network were linked to improvements in symptom severity. Lastly, reductions of functional dysconnectivity in language regions such as Brocas area were related to cognitive benefits.  ConclusionsOur study supports a recent theory of oligodendrocyte pathology in SSD and suggests that reducing functional dysconnectivity in the default-mode, salience, and language network reflect a potential therapeutic target to improve global functioning, total symptom severity, and cognitive impairments in post-acute SSD.  Trial name: ESPRIT C3  Registry: International Clinical Trials Database, ClinicalTrials.gov Registration number: NCT03466112  URL: https://clinicaltrials.gov/ct2/show/NCT03466112?term=NCT03466112&draw=2&rank=1\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: ChatGPT-o1 and the Pitfalls of Familiar Reasoning in Medical Ethics\nAbstract: Large language models (LLMs) like ChatGPT often exhibit Type 1 thinking--fast, intuitive reasoning that relies on familiar patterns--which can be dangerously simplistic in complex medical or ethical scenarios requiring more deliberate analysis. In our recent explorations, we observed that LLMs frequently default to well-known answers, failing to recognize nuances or twists in presented situations. For instance, when faced with modified versions of the classic \"Surgeons Dilemma\" or medical ethics cases where typical dilemmas were resolved, LLMs still reverted to standard responses, overlooking critical details. Even models designed for enhanced analytical reasoning, such as ChatGPT-o1, did not consistently overcome these limitations. This suggests that despite advancements toward fostering Type 2 thinking, LLMs remain heavily influenced by familiar patterns ingrained during training. As LLMs are increasingly integrated into clinical practice, it is crucial to acknowledge and address these shortcomings to ensure reliable and contextually appropriate AI assistance in medical decision-making.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multi-omics integration prioritizes potential drug targets for multiple sclerosis\nAbstract: Background and ObjectivesMultiple sclerosis (MS) is a chronic autoimmune disease with limited treatment options. Thus, drug discovery and repurposing are essential to enhance treatment efficacy and safety.  MethodsWe obtained summary statistics for protein quantitative trait loci (pQTL) of 2,004 plasma proteins and 1,443 brain proteins, a genome-wide association study (GWAS) of MS susceptibility with 14,802 cases and 26,703 controls, and expression quantitative trait loci (eQTL) for 8,000 genes in peripheral blood and 16,704 genes in brain tissue. Our integrative analysis included a proteome-wide association study to identify MS-associated proteins, followed by summary-data-based Mendelian randomization (SMR) to determine causal associations. We used the HEIDI test and Bayesian colocalization analysis to distinguish pleiotropy from linkage. Proteins passing SMR, HEIDI, and colocalization analyses were considered potential drug targets. We further conducted pathway annotations, protein-protein interaction (PPI) network analysis, and examined mRNA levels of these targets.  ResultsWe identified hundreds of MS-associated proteins in plasma and brain, confirming the causal roles of 18 proteins (nine in plasma and nine in brain). Among these, we found 78 annotated pathways and 16 existing non-MS drugs targeting six proteins. We also discovered intricate PPIs among seven potential drug targets and 19 existing MS drug targets, as well as PPIs of four targets across plasma and brain. Combining expression data, we identified two targets adhering to the central dogma of molecular biology.  DiscussionWe prioritized 18 potential drug targets in plasma and brain, elucidating the underlying pathology and providing evidence for drug discovery and repurposing in MS.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and Determinants of Prehospital Impression of Stroke in Ischemic Stroke Patients\nAbstract: BACKGROUNDEmergency Medical Services (EMS) clinicians are front-line in evaluating patients with stroke in the community. Their ability to correctly identify stroke influences downstream management decisions. We sought to use a large national database of prehospital clinical data to determine risk factors associated with missed EMS stroke identification.  METHODSRetrospective study examining EMS evaluation of adults with Emergency Department (ED) stroke diagnosis. We leveraged the ESO Data Collaborative research dataset containing EHR data from 2019-2022 that has a subset of encounters with linked hospital diagnostic codes. Our primary outcome was the presence of an EMS diagnosis of stroke. We evaluated the association between demographic and clinical variables with EMS stroke identification using Pearson {chi}2 test for demographic variables and multivariable GLM for clinical variables with adjustment for demographic variables.  RESULTSWe identified 34,504 EMS encounters for patients with ED stroke diagnosis. Of these, 11,077 (32.1%) strokes had missed EMS stroke identification and instead had an EMS impression of \"Generalized Weakness\" (25.9%), \"Altered Level of Consciousness\" (24.9%), and \"Dizziness\" (7.2%). Patients more likely to have missed prehospital stroke identification were of Black race (p=0.0001) and Hispanic ethnicity (p=0.0001). Clinical variables associated with higher risk of missed EMS stroke identification were suspected alcohol or drug use (RR 1.48, 95% CI 1.37-1.59), low GCS (RR 1.17, 95% CI 1.10-1.24), tachycardia (RR 1.05, 95% CI 1.01-1.09), and hypotension (RR 1.47, 95% CI 1.34-1.61).  CONCLUSIONSApproximately 1-in-3 patients transported by EMS did not have their stroke identified in the prehospital setting. Factors associated with lower odds of missed EMS stroke identification provide a starting point for future performance improvement initiatives.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neighborhood deadwood and yard rewilding modulate commensal microbiota and inflammatory signals among urbanites\nAbstract: BackgroundGlobal ecosystem deprivation is linked to reduced microbial diversity and diminished immunological resilience. Urban rewilding and decomposing plant matter have been suggested to reverse this deprivation and support human health.  MethodsWe rewilded 21 urban private yards with vegetation and deadwood. Control yards (15) were analyzed for comparison. We collected microbial samples and used vegetation and deadwood inventories, landcover data and questionnaires to determine the effects of rewilding and living environment on skin and salivary microbiota, gene pathways and cytokine levels (IL-6, IL-10). Samples were collected before the rewilding in summer and three months later in autumn.  FindingsRewilding preserved skin microbial richness in comparison to control group, including previously health-associated Alpha- and Gammaproteobacteria, despite the normal seasonal decline and less outdoor time in autumn. Deadwood abundance within 200-m radii associated directly to beta diversity of skin microbiota and Gammaproteobacterial taxonomies.  In saliva, deadwood was directly associated with the diversity of functional gene pathways, which in turn was negatively associated with pleiotropic IL-6 levels. Rewilding was associated with a decrease in L-histidine degradation and an increase in Mycobacteriaceae.  InterpretationSince both yard rewilding and neighborhood deadwood preserved rich commensal microbiota and reduced pro-inflammatory signals, decomposing plant matter, not just plant richness, seems to be crucial for ecosystem services that contribute to health. Since deadwood abundance was associated to reduced pro-inflammatory signals, it may be a suitable indicator of environment supporting immunological resilience.  Our findings provide an incentive for future strategic investments for planetary health.  FundingStrategic Research council Finland.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Leveraging Pretrained Vision Transformers for Automated Cancer Diagnosis in Optical Coherence Tomography Images\nAbstract: This study presents a novel approach to brain cancer detection based on Optical Coherence Tomography (OCT) images and advanced machine learning techniques. The research addresses the critical need for accurate, real-time differentiation between cancerous and noncancerous brain tissue during neurosurgical procedures. The proposed method combines a pre-trained Vision Transformer (ViT) model, specifically DiNOV2, with a convolutional neural network (CNN) operating on Grey Level Co-occurrence Matrix (GLCM) texture features. This dual-path architecture leverages both the global context capture capabilities of transformers and the local texture analysis strengths of GLCM + CNNs. The dataset comprised OCT images from 11 patients, with 5,831 B-frame slices used for training and validation, and 1,610 slices for testing. The model achieved high accuracy in distinguishing cancerous from noncancerous tissue, with 99.7% {+/-} 0.1% accuracy on the training dataset, 99.4% {+/-} 0.1% on the validation dataset and 94.9% accuracy on the test dataset. This approach demonstrates significant potential for achieving and improving intraoperative decision-making in brain cancer surgeries, offering real-time, high-accuracy tissue classification and surgical guidance.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Single Versus Repeated Intravenous Oncolytic Virus Infusions: Implications for Rationalised Scheduling of Therapy in Hepatocellular Carcinoma.\nAbstract: BackgroundOncolytic virus (OV) immunotherapy stands to widely improve patient outcomes in multiple solid malignancies. However, to date, the scheduling of OV therapy, with single versus multiple infusions on consecutive days, has not been correlated with immunological or clinical response. In hepatocellular carcinoma (HCC) patients, where the background liver is frequently chronically injured, repeated dosing may have deleterious implications, resulting in off-target immune-mediated damage, thereby tipping the balance between favourable clinical response and hepatotoxicity. As such, elucidation of the optimum dosing regime is necessary to ensure therapy, whilst limiting damage to the background liver.  MethodsHerein, we expand upon our previous experience in neoadjuvant OV therapy to compare the immunological response from single versus repeated doses of reovirus in cancer patients. The impact of OV immunotherapy on HCC outcomes was examined in vivo following a high fat diet or induced liver fibrosis in the context of an abnormal background liver. Furthermore, we assess, in a syngeneic model of HCC, the potential immune-mediated toxicity of single versus multiple virus infusions in combination with PD-1 and PD-L1 blockade.  ResultsClinical trial data indicate that a single dose of reovirus is equivalent or superior to repeat doses in achieving: (a) induction of an inflammatory cytokine/chemokine response; (b) peripheral blood immune cell activation; and (c) migration of activated CD8+ CTLs. Repeated doses on consecutive days do not improve the amplitude or duration of the immune response following virus infusion. Furthermore, repeated viral dosing leads to an unwanted influx of activated T cells into background liver. An increase in PD-L1 expression on T cells resulting from a single virus dose was observed. Combination therapy of reovirus plus anti-PD-L1, but not anti-PD-1, limited tumour growth and extended survival in vivo.  ConclusionsA single dose of oncolytic virus is equivalent or superior to multiple consecutive doses in inducing an anti-tumour immune response. Combination immune checkpoint blockade with anti-PD-L1 holds potential to maximise the beneficial effects of a single dose, whilst simultaneously avoiding undesirable toxicities in the background liver in the context of HCC.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Natural Language Processing Algorithms Outperform ICD Codes in the Development of Fall Injuries Registry\nAbstract: BackgroundStandardized registries are commonly built using administrative codes assigned to patient encounters, such as the International Classification of Diseases (ICD) codes. However, fall patients are often coded using subsequent injury codes, such as hip fractures. This necessitates manual screening to ensure the accuracy of data registries. Herein, we aimed to automate the extraction of fall incidents and mechanisms using Natural Language Processing (NLP) and compare this approach with the ICD method.  MethodsClinical notes for patients with fall-induced hip fractures were retrospectively reviewed by medical experts. Fall incidences were detected, annotated, and classified among patients who had fall-induced hip fracture (case group). The control group included patients with hip fracture without any evidence of fall. NLP models were developed using the annotated notes of the study groups to fulfill two separate tasks: fall occurrence detection and fall mechanism classification. The performances of the models were compared using accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1-score, and area under the ROC curve (AUC-ROC).  ResultsA total of 1,769 clinical notes were included in the final analysis for the fall occurrence task, and 783 clinical notes were analyzed for the fall mechanism classification task. The highest F1 score using NLP for fall occurrence was 0.97 (specificity=0.96; sensitivity=0.97) and for fall mechanism classification was 0.61 (specificity=0.56; sensitivity=0.62). NLP could detect up to 98% of the fall occurrences and 65% of the fall mechanisms accurately compared to 26% and 12%, respectively, by ICD codes.  ConclusionOur findings showed promising performance with a higher accuracy of NLP algorithms compared to the conventional method for detecting fall occurrence and mechanism in developing disease registries using clinical notes. Our approach can be introduced to other registries that are based on large data and are in need for accurate annotation and classification.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comparative analysis of RNA expression in a single institution cohort of pediatric cancer patients\nAbstract: ImportanceGenomic analyses solely focused on detecting mutations do not benefit most pediatric cancer patients. Alternate genomic approaches are needed to identify additional treatment biomarkers and therapeutic targets.  ObjectiveTo evaluate the performance of our Comparative Analysis of RNA Expression (CARE) pipeline in nominating druggable targets in pediatric patients with difficult-to-treat or rare cancers.  Design, Setting, and ParticipantsOur cohort study, the Comparative Analysis of RNA Expression to Improve Pediatric and Young Adult Cancer Treatment (CARE IMPACT), was conducted collaboratively by the UC Santa Cruz Treehouse Childhood Cancer Initiative and Stanford University School of Medicine. From June 4, 2018, to September 24, 2020, UCSC Treehouse obtained and processed RNA sequencing (RNA-Seq) data for 35 tumor samples from 33 children and young adults with a relapsed, refractory or rare cancer. Each tumor RNA-Seq dataset underwent CARE analysis to reveal activated cancer driver pathways and nominate treatment options. We compare the CARE pipeline to other gene expression outlier detection approaches and discuss challenges and opportunities for the clinical implementation of RNA-Seq-based gene expression outlier detection for pediatric cancer patients.  ExposuresPatients underwent tumor RNA-Seq analysis and standard-of-care tumor DNA profiling. UCSC Treehouse compared each patients tumor RNA-Seq profile with over 11,000 uniformly analyzed tumor profiles from public data repositories. These comparisons reveal candidate cancer genes and pathways that represent potential therapeutic targets.  Main Outcome(s) and Measure(s)Proportion of patients for whom CARE provided useful clinical and biological information for patient care. Impact of comparator cohort choice on outlier findings.  ResultsOf our 33 patients, 31 (94%) had CARE IMPACT findings of potential clinical significance. These findings were implemented in 5 patients, 3 of which had defined clinical benefit. We demonstrated that composition of comparator cohorts determines which outliers are detected and that large and diverse cohorts containing data from tumors similar to the patients produce the most clinically relevant outlier results.  Conclusions and RelevanceComparative RNA-Seq analysis may identify additional cancer driver pathways and druggable targets in patients with rare or difficult-to-treat pediatric cancers relative to standard-of-care DNA profiling. This study highlights the clinical utility of CARE for pediatric tumors and underscores the need for further evaluation of this approach to improve patient outcomes.  Key PointsO_ST_ABSQuestionsC_ST_ABSIs tumor RNA expression information useful for the clinical care of children with difficult-to-treat or rare cancers? How does choice of comparator cohort impact RNA expression results?  FindingsIn this cohort of 33 pediatric patients, Comparative Analysis of RNA Expression provided useful clinical information for all patients; three of five patients who received treatment derived clinical benefit. We demonstrate the impact of comparator cohort composition on RNA outlier analysis.  MeaningTumor RNA expression information reveals useful information for the clinical care of pediatric cancer patients. Choice of comparator cohort size and composition impacts gene expression outlier detection.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Replication of a GWAS signal near HLA-DQA2 with acute myeloid leukemia using a disease-only cohort and external population-based controls\nAbstract: Acute myeloid leukemia (AML) is the most common type of acute leukemia in adults. Its risk factors include rare and highly penetrant somatic mutations. Genome-wide association studies (GWAS) have also identified four common inherited variants associated with AML risk, but these findings have not yet been confirmed in many independent datasets. Here, we performed a replication study with 567 AML cases from the Leucegene cohort and 1,865 controls from the population-based cohort CARTaGENE (CaG). Because genotypes were generated using different technologies in the two datasets (e.g. low- vs. high-coverage whole-genome sequencing), we applied stringent quality-control filters to minimize type I errors. We showed using data reduction methods (e.g. principal component analysis [PCA] and uniform manifold approximation and projection [UMAP]) that our approach successfully integrated the Leucegene and CaG genetic data. We replicated the association between cytogenetically normal (CN)-AML and rs3916765, a variant located near HLA-DQA2 (odds ratio [95% confidence interval] = 1.88 [1.21-2.93], P- value=0.005). The effect size of this association was stronger when we restricted the analyses to AML patients with NPM1 mutations (odds ratios >2.35). We found HLA- DOB to be the most significantly upregulated gene in Leucegene participants with the CN-AML protective A-allele at rs3916765. We further found that several HLA class II genes are also differentially expressed albeit at lower statistical significance. Our results confirm that a common genetic variant at the HLA locus associates with AML risk, providing new opportunities to improve disease prognosis and treatment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: NXPE1 alters the sialoglycome by acetylating sialic acids in the human colon\nAbstract: Mild periodic acid Schiff staining (mPAS) of human colonic tissue has been used to answer a variety of fundamental questions in germline and somatic genetics. mPAS staining is known to reflect sialic acid O-acetylation, but a full accounting of the genes contributing to sialoglycome diversity is incomplete. Using haplotypes derived from whole genome sequencing, we identified a region on chromosome 11 that is associated with inherited differences in mPAS staining. Of the genes in this region, only NXPE1 haplotypes correlated perfectly with mPAS staining in the original cohort used for whole genome sequencing, as well as in a validation cohort. Transcriptomic analysis suggested that one common allele of NXPE1, with a single base pair substitution in its promoter region, greatly reduces expression of the gene. Genetic manipulation of NXPE1 expression confirmed this conclusion and caused changes to modified sialic acid levels. Finally, high-performance liquid chromatography (HPLC) confirms that enzymatically active NXPE1 is capable of transferring an acetyl group from acetyl coenzyme A to sialic acid in vitro. These findings suggest that NXPE1 is the long-sought gene responsible for differences in colon mPAS staining and may be the prototype of a new family of sialic acid O-acetylation-modifying genes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Differential prediction performance between Caribbean- and Mainland-subgroups using state-of-the-art polygenic risk scores for coronary heart disease: Findings from the Hispanic Community Health Study/Study of Latinos (HCHS/SOL)\nAbstract: BackgroundCoronary heart disease (CHD) is a leading cause of death for Hispanic/Latino populations in the United States. We evaluated polygenic risk scores (PRS) with incident myocardial infarction (MI) in a Hispanic/Latino study sample.  MethodsWe leveraged data from the Hispanic Community Health Study/Study of Latinos (HCHS/SOL) to assess four CHD-PRS from the PGS catalog, derived using multiple methods (LDpred, AnnoPred, stacked clumping and thresholding, and LDPred2). We evaluated associations between each standardized PRS and time to adjudicated incident MI, adjusted for age, sex, first 5 principal components, and weighted for survey design. Concordance statistics (c-index) compared predictive accuracy of each PRS with, and in addition to, traditional risk factors (TRF) for CHD (obesity, hypercholesterolemia, hypertension, diabetes, and smoking). Analyses were stratified by self-reported Caribbean- (Puerto Rican, Dominican or Cuban) and Mainland- (those of Mexican, Central American, or South American) heritage subgroups.  ResultsAfter 11 years follow-up, for 9055 participants (mean age (SD) 47.6(13.1), 62.2% female), the incidence of MI was 1.0% (n = 95). Each PRS was more strongly associated with MI among Mainland participants. LDPred2 + TRF performed best among the Mainland subgroup; HR=2.69, 95% CI [1.71, 4.20], c-index = 0.897, 95% CI [0.848, 0.946]; a modest increase over TRF alone, c-index = 0.880, 95% CI [0.827, 0.933]. AnnoPred + TRF performed best among the Caribbean sample; c-index = 0.721, 95% CI [0.647, 0.795]; however, was not significantly associated with rate of MI (HR=1.14, 95% CI [0.82, 1.60]).  ConclusionPRS performance for CHD is lacking for Hispanics/Latinos of Caribbean origin who have substantial proportions of African genetic ancestry, risking increased health disparities. AnnoPred, using functional annotations, outperformed other PRS in the Caribbean subgroup, suggesting a potential strategy for PRS construction in diverse populations. These results underscore the need to optimize cumulative genetic risk prediction of CHD in diverse Hispanic/Latino populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Somatic mitochondrial DNA mutations are a source of heterogeneity among primary leukemic cells\nAbstract: Somatic mitochondrial DNA (mtDNA) mutations are prevalent in tumors, yet defining their biological significance remains challenging due to the intricate interplay between selective pressure, heteroplasmy, and cell state. Utilizing bulk whole-genome sequencing data from matched tumor and normal samples from two cohorts of pediatric cancer patients, we uncover differences in the accumulation of synonymous and nonsynonymous mtDNA mutations in pediatric leukemias, indicating distinct selective pressures. By integrating single-cell sequencing (SCS) with mathematical modeling and network-based systems biology approaches, we identify a correlation between the extent of cell-state changes associated with tumor-enriched mtDNA mutations and the selective pressures shaping their distribution among individual leukemic cells. Our findings also reveal an association between specific heteroplasmic mtDNA mutations and cellular responses that may contribute to functional heterogeneity among leukemic cells and influence their fitness. This study highlights the potential of SCS strategies for distinguishing between pathogenic and passenger somatic mtDNA mutations in cancer.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=197 SRC=\"FIGDIR/small/24314381v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (61K): org.highwire.dtl.DTLVardef@157755aorg.highwire.dtl.DTLVardef@d979d6org.highwire.dtl.DTLVardef@1cdf2e3org.highwire.dtl.DTLVardef@54010_HPS_FORMAT_FIGEXP  M_FIG C_FIG HighlightsO_LINonsynonymous and synonymous mtDNA SNVs are subject to different selective pressures among pediatric leukemias C_LIO_LIThe distribution of mtDNA SNV VAFs among individual leukemic cells can provide evidence for selective pressure C_LIO_LIThe impact of mtDNA SNVs on gene expression is correlated with selective pressure C_LIO_LISomatic mtDNA SNVs associated with cell state changes are a source of heterogeneity among leukemic cells C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Detecting Wolff-Parkinson-White from Lead-I ECG Using Transfer Learning and Wavelets\nAbstract: Wolff-Parkinson-White (WPW) syndrome is a congenital heart defect that can trigger ventricular fibrillation and sudden cardiac death. Expert inspection of a 12- lead clinical electrocardiogram (ECG) or a Holter record is the standard approach for detecting WPW syndrome. Smartwatches that acquire lead-I ECGs can enable automated detection of WPW episodes in out-of-hospital settings and prevent adverse outcomes. In this work, we explore deep-learning solutions to identify WPW syndromes on lead-I ECG. Scarcity of labeled ECG data for WPW and other cardiac conduction disorders poses a major challenge for training data-driven methods. Moreover, generalizability of such methods to external patient population remains unexplored. To address these challenges, first we implement and compare multiple existing strategies from time-domain augmentations on the lead-I ECG to transfer learning of Imagenet-models for ECG wavelet transformations. Training and holdout validation of these methods are conducted using about 14,000 ECGs from PTB-XL, a publicly available ECG dataset. Moreover, we explore generalization of these methods by external validation on the data from 140 patients from the Tongji Hospital ECG Database. While these methods achieve 88% sensitivity and 99% specificity in identifying a lead-I ECG with evident WPW, and an area under the receiver-operating curve (AUC) of 0.99 on the holdout set from PTB-XL, the sensitivity drops to 58% with an AUC of 0.88 on the external validation. Finally, we propose a novel data augmentation strategy by incorporating labeled data from an umbrella super-class of cardiac conduction disorders, instead of WPW alone, thus naturally reducing the data imbalance for model training. We apply these models as zero-shot transfer learning for discriminating WPW from normal ECG. While this approach achieves similar performance during holdout validation, it also demonstrates strong performance on the external Tongji dataset with sensitivity 0.78 and AUC 0.91. This result shows significant generalizability of the proposed method and highlights the potential of deep-learning solutions in monitoring WPW syndrome with lead-I ECG in outof-hospital general populace settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Loss-of-function of RNA-binding protein PRRC2B causes translational defects and congenital cardiovascular malformation\nAbstract: Alternative splicing generates variant forms of proteins for a given gene and accounts for functional redundancy or diversification. A novel RNA-binding protein, Pro-rich Coiled-coil Containing Protein 2B (PRRC2B), has been reported by multiple laboratories to mediate uORF-dependent and independent regulation of translation initiation required for cell cycle progression and proliferation. We identified two alternative spliced isoforms in human and mouse hearts and HEK293T cells, full-length (FL) and exon 16-excluded isoform {Delta}E16. A congenital heart disease-associated human mutation-mimicry knock-in of the equivalent variant in the mouse genome leads to the depletion of the full-length Prrc2b mRNA but not the alternative spliced truncated form {Delta}E16, does not cause any apparent structural or functional disorders. In contrast, global genetic inactivation of the PRRC2B gene in the mouse genome, nullifying both mRNA isoforms, caused patent ductus arteriosus (PDA) and neonatal lethality in mice. Bulk and single nucleus transcriptome profiling analyses of embryonic mouse hearts demonstrated a significant overall downregulation of multiple smooth muscle-specific genes in Prrc2b mutant mice resulting from reduced smooth muscle cell number. Integrated analysis of proteomic changes in Prrc2b null mouse embryonic hearts and polysome-seq and RNA-seq multi-omics analysis in human HEK293T cells uncover conserved PRRC2B-regulated target mRNAs that encode essential factors required for cardiac and vascular development. Our findings reveal the connection between alternative splicing regulation of PRRC2B, PRRC2B-mediated translational control, and congenital cardiovascular development and disorder. This study may shed light on the significance of PRRC2B in human cardiovascular disease diagnosis and treatment.  Discovery bullet pointsO_LIPRRC2B has two alternative splicing isoforms, full-length and exon 16-skipped ({Delta}E16) mRNAs in humans and mice. C_LIO_LIFull-length Prrc2b KO mice show no apparent cardiac phenotypes, while double KO of full-length and {Delta}E16 causes patent ductus arteriosus and neonatal lethality in mice. C_LIO_LIMulti-omics analyses of Prrc2b double KO mice suggest changes in SMC cell abundance and dysregulation of translation of specific proteins in E18.5 embryos. C_LIO_LICRISPR-Cas9-mediated KO of PRRC2B in human cells reduces the translation of heart and valve development-related mRNAs. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pulsed Field Ablation of Small Vessel-Related Arrhythmias: A New Catheter and Methods\nAbstract: ObjectivesSome arrhythmia targets are located in the epicardium or deep myocardium, which could be reached through the vascular approach. However, it is difficult to deliver ablation catheters to the distal vessels and their branches. In small vessels, the energy released is limited, and the risk of ablation is increased. The objective of this study was to design a linear catheter with pulsed field energy that is suitable for ablation in the distal vessels and to verify its efficacy and safety in canines.  MethodsA total of eight canines were randomly assigned to two observation groups: a 48-hour group (N=4) and a 30-day group (N=4). A 3 F 10-pole pulsed field ablation catheter was employed to ablate in the great cardiac vein, the middle cardiac vein, the anterior interventricular vein, and the distal small branches of the cardiac venous system. The characteristics of the ablation lesions were observed both grossly and microscopically.  ResultsThe surgical procedure was completed successfully. Pulsed field energy can travel through the fatty tissue to form a lesion in the cardiomyocytes. The mean depth of the lesion in the 30-day group (2.37{+/-}0.53 mm) was found to be reduced by 39% (P<0.001) in comparison to that observed in the 48-hour group (3.92{+/-}0.62 mm). Additionally, a transition zone of incomplete injury was discerned in the junction area of the 48-hour group. Canines exhibited no adverse effects intraoperatively nor postoperatively, and no appreciable damage was observed in the adjacent small arteries or the surrounding organs.  ConclusionThe pulsed field energy from small blood vessels can cause lasting, continuous lesions to the myocardium and is safe to use. The 3 F liner pulsed field ablation catheter has been proven to be efficacious and safe, with promising indications for future application.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pruritus and its Association with Cancer and Mortality in Dermatomyositis and Polymyositis: A Nationwide Cohort Study in Taiwan from 2005 to 2022\nAbstract: BackgroundPruritus is the most common initial symptom reported by patients with dermatomyositis and polymyositis. However, there is limited data regarding the impact of pruritus on cancer and mortality in patients with dermatomyositis and polymyositis.  ObjectiveTo investigate the associations of pruritus to cancer and mortality in patients with dermatomyositis and polymyositis.  MethodsThis nationwide, population-based retrospective cohort study included adult dermatomyositis and polymyositis patients from Taiwans National Health Insurance Research Database between 2005 and 2022. Sex- and age-matched pruritic patients, identified by over six weeks of antipruritic medication use, and nonpruritic patients were analyzed. The primary outcome was cancer occurrence or all-cause mortality.  ResultsAmong 919 matched pairs of pruritic and non-pruritic patients, cancer was observed in 19.96% in the long-term pruritic group, 14.63% in the short-term pruritic group, and 10.34% in the nonpruritic group (p<0.0001). All-cause mortality was documented at 30.37% in the long-term pruritic group, 29.69% in the short-term pruritic group, and 37.76% in the nonpruritic group (p<0.0001). Pruritus was associated with an increased risk of cancer (hazard ratio 1.492, 95% confidence interval 1.093-2.036), and a lower risk of all-cause mortality (hazard ratio 0.489, 95% confidence interval 0.419-0.571).  ConclusionThis population-based study revealed pruritus appeared to be associated with increased cancer risk and decreased all-cause mortality. Thus, pruritus may serve as a pragmatic factor for risk stratification and tailored treatment strategies in dermatomyositis and polymyositis. Comprehensive cancer screening is recommended for patients with dermatomyositis or polymyositis, particularly those presenting with pruritus, whereas patients without pruritus may require vigilant management for potentially life-threatening complications and comorbidities.  Key pointsO_LIPrevious single-institutional studies and studies with small cohorts reported conflicting data regarding the impact of pruritus on cancer and mortality in patients with dermatomyositis and polymyositis C_LIO_LIPruritus in dermatomyositis and polymyositis appeared to be associated with increased cancer risk and decreased all-cause mortality. C_LIO_LIOur findings suggest that pruritus may serve as a pragmatic factor for risk stratification and tailored treatment strategies in dermatomyositis and polymyositis. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Understanding good communication in ambulance pre-alerts to Emergency Department. Findings from a qualitative study of UK emergency services\nAbstract: ObjectivesPre-hospital notifications (pre-alerts) enable Emergency Department (ED) staff to prepare for the arrival of patients requiring a time-critical response. Effective communication of the pre-alert is key to enabling the ED to prepare appropriately but evidence on communication practices is lacking. We undertook qualitative research to understand how pre-alert communication may be improved to optimise the ED response for pre-alerted patients.  Design, setting and participantsData collection took place within three UK Ambulance Services and six EDs between August 2022-April 2023. We undertook semi-structured interviews with 34 ambulance and 40 ED staff and 156 hours non-participation observation of pre-alert practice (143 pre-alerts). Verbatim interview transcripts and observation notes were imported into NVivo and analysed using a thematic approach.  ResultsWe identified significant variation in how pre-alerts were communicated that influenced how effectively information was transferred. Ambulance and ED staff demonstrated a shared recognition that pre-alerts need to be communicated concisely, but both received minimal training in how to give and receive pre-alerts. Efficient pre-alerting was influenced by clinician experience and seniority. ED and ambulance clinicians following different information sharing formats (e.g. ATMIST, SBAR) sometimes led to interruptions, information loss and tensions, particularly when an early  headline clinical concern had not been shared. Ambulance clinicians sometimes questioned the appropriateness of their pre-alert when ED clinicians did not explain the rationale for not giving the expected response (i.e. being accepted into a high-priority area of ED). Additional sources of frustration included technological problems and poor communication of ETA and caller/responder identities.  ConclusionsUse of shared format including a headline  cause for concern may improve the clarity, usefulness and civility of pre-alerts, particularly when the clinician concern is not obvious from observations. Basic training on how to undertake pre-alerts for both ED and ambulance clinicians may improve understanding of the importance of pre-alert communication.  Strengths and limitations of the studyO_LIThis study triangulated findings from Emergency Department staff and Ambulance Clinicians from across three Ambulance Service regions in England to provide insights into the causes of incivility relating to pre-alert communications. C_LIO_LISemi-structured interviews and non-participant observation provide rich data regarding the experiences and practice of undertaking pre-alerts. C_LIO_LIFieldwork took place within larger Emergency Departments (major trauma centres and trauma units) rather than minor units where pre-alerts occur less frequently and may be managed differently. C_LIO_LIThe setting included only ambulance services where ambulance clinicians principally call directly to the ED, limiting transferability of findings for ambulance services who call via a control centre. C_LIO_LINon-participant observation was undertaken in Emergency Departments but not within Ambulance Services due to the small number of pre-alerts occurring per shift. C_LI\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Predicting Common Pathway Signatures Between DNA Methylation and Post Translational Modification in Type II Diabetes & Parkinson's Disease Using Heterogeneous Data Integration\nAbstract: The complex diseases, namely, Type 2 Diabetes Mellitus (T2DM) and Parkinsons Disease (PD), are extensively studied due to their prevalence in a large population group. Between these two diseases, T2DM is denoted as the zero index disease in a patient, which may lead to PD in a more advanced clinical stage. Both of these diseases may occur due to abrupt DNA methylation of genes. Likewise, both diseases may occur in a patient due to protein misfolding. Our study proposes a novel framework for building two disease-specific heterogeneous networks by integrating different tissue-based transcriptomics, epigenetics, epistasis, and PPI-based topological information. We predict the missing links between the DNA methylation and Post-Translational Modification (PTMs) associated with protein aggregation. Next, we have predicted the common signature of the prevalence of linked patterns in both diseases, further validated by relevant biological evidence.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Organizational models and patient-reported outcomes for palliative care across five tertiary hospitals in Nigeria: an Environmental Scan\nAbstract: BackgroundPalliative care (PC) is an essential, effective, and affordable component of health care. Global need is rising, with the greatest burden in low-and-middle-income countries. This is especially true in Nigeria where the need is growing rapidly, as are PC services; however, current organizational models have not yet been examined.  MethodsThis was a cross-sectional, descriptive study of five PC sites at tertiary hospitals in four of Nigerias six geopolitical zones. Surveys, informed by a Centre for Palliative Care, Nigeria (CPCN) needs assessment checklist and the Consolidated Framework for Implementation Research (CFIR), were administered at each site to leadership, frontline workers, patients, and caregivers. Surveys varied by participant group and inquired about organizational models and personal experiences of both providers and recipients of care.  ResultsAcross five sites, there was a total of 282 survey respondents: five leaders, nine frontline workers, 132 patients, and 136 caregivers. The most common diagnoses of PC patients were cancer, sickle cell disease, and HIV. Most sites reported sub-optimal administrative support (80%), hospital management support (60%), and building space (60%). Leadership responses highlighted variations in PC training requirements and opportunities. Frontline workers desired additional training, sponsorship, and governmental support. Most patients and their caregivers reported satisfaction with PC, though high levels of worry and hopelessness were reported.  ConclusionIncreased organizational support appears necessary to facilitate improvements in administrative resources, staffing, and training. Emotional and spiritual wellbeing likely require prioritization when designing palliative care delivery services in Nigeria. Further research is needed to refine current services and inform implementation efforts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A scoping review of remote and unsupervised digital cognitive assessments in preclinical Alzheimer's disease\nAbstract: Subtle cognitive changes in preclinical Alzheimers disease (AD) are difficult to detect using traditional pen-and-paper neuropsychological assessments. Remote and unsupervised digital assessments can improve scalability, measurement reliability, and ecological validity, enabling the detection and monitoring of subtle cognitive change. Here, we evaluate such tools deployed in preclinical AD samples, defined as cognitively unimpaired individuals with abnormal levels of amyloid-{beta} (A{beta}), or A{beta} and tau.  In this scoping review, we screened 1,680 unique reports for studies using remote and unsupervised cognitive assessment tools in preclinical AD samples; 23 tools were found. We describe each tools usability, validity, and reported metrics of reliability.  Construct and criterion validity according to associations with established neuropsychological assessments and measures of A{beta} and tau are reported.  With this review, we aim to present a necessary update to a rapidly evolving field, following a previous review by Ohman and colleagues (2021; Alzheimers Dement. Diagn. Assess. Dis. Monit) and addressing the open questions of feasibility and reliability of remote testing in the target population. We discuss future directions for using remote and unsupervised digital cognitive assessments in preclinical AD and how such tools may be used for longitudinal monitoring of cognitive function, scalable case finding, and individualized prognostics in both clinical trials and healthcare contexts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Domain specific Memory Impairments in Bipolar Mania: Insights from a Tertiary Care Study\nAbstract: BackgroundCognitive deficits in bipolar affective disorder (BPAD), particularly during manic episodes, are well-documented. However, research on domain-specific memory impairments in bipolar mania is limited, especially in the Indian subcontinent. This study aimed to assess memory impairments in patients with bipolar mania using the Postgraduate Institute Memory (PGI-Memory) Scale and to highlight domain-specific deficits compared to healthy controls.  MethodsThis cross-sectional study was conducted at Tertiary Care Centre in North India. Twenty patients diagnosed with bipolar mania and twenty age, sex and education-matched healthy controls between age 18 to 40 were recruited. Memory functions were assessed using the PGI-Memory scale, focusing on immediate, recent, remote, long-term memory, and associative memory. Mental control and working memory were also evaluated.  ResultsBoth groups were matched in terms of age, sex, and education. the mean (sd) age for bipolar mania group was 27.2 (4.14) years. Patients with bipolar mania demonstrated significant deficits in various memory domains, including immediate, recent, remote, long-term, and associative memory, as well as in visual reproduction and recognition tasks. In contrast, their working memory performance was comparable to that of the control group. The largest deficits were observed in long-term memory (d =2.37) and visual reproduction (d=2.30).  ConclusionsBipolar mania is associated with widespread memory impairments, particularly in long-term and associative memory, which may contribute to difficulties in emotional regulation and daily functioning. These findings emphasize the importance of considering memory impairments in the diagnosis and management of BPAD. Further studies are required to investigate the neurobiological foundations of these impairments and to develop specific interventions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The maternal and perinatal health data system in the Kilimanjaro Region, Tanzania: a landscape review including a qualitative study\nAbstract: BackgroundThe World Health Organization (WHO) advocates the use of digital health interventions to strengthen health systems globally. This landscape review evaluated how data related to maternal and neonatal health is recorded and utilized for clinical and policy decision-making in the Kilimanjaro Region of Tanzania.  MethodThis landscape review employed a dual method approach, initially quantifying data recording practices of each clinic and then using qualitative interviews to explore how data is currently captured and utilized. We conducted interviewed with seven Nurse-Midwives, eight Lead Obstetricians at district hospitals, seven District Medical Officers, and seven District Reproductive and Child Health Coordinators. Qualitative data analysis was performed using NVivo software.  ResultsIn the regions seven districts, there are 489 healthcare facilities offering Reproductive and Child Health Services, delivery, infant and child care. The facilities comprise 22 hospitals, 62 health centers, 353 dispensaries, and 52 clinics. In 2021, there were 45,343 births with a maternal mortality rate of 146 per 100,000 live births, a neonatal mortality rate of 10.1 per 1,000 live births, and a stillbirth rate of 4 per 1,000 births. Additionally, 20.3% of births were delivered via C-section.  Although there was a notable decline in maternal and neonatal mortality rates (from 112 to 51 vs 9.5 to 3.7 deaths per 100,000 live births) from 2020 to 2023, the 2021 data revealed unexpectedly high maternal mortality rates. The qualitative study highlighted issues with the data recording system, which is complex and time-consuming, involving multiple paper-based and digital records. Challenges include data volume, loss, and retrieval issues, affecting clinical decision-making. This data is crucial for identifying resource needs, monitoring health trends like low antenatal care uptake, and advocating for changes in resources, guidelines, and policies at regional and national levels.  ConclusionQuantitative data indicates a significant rise in maternal and neonatal mortality rates in the Kilimanjaro region during 2020-2021, followed by a decrease in 2022-2023. Additionally, early antenatal care (ANC) uptake remains below 50%. The qualitative study suggests that paper records are time-consuming and prone to incomplete data making it difficult to use due to their storage approach and the risk of damage to the physical books.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Maternal Diet Quality and BMI as Predictors of Human Milk Composition and Exclusive Breastfeeding Duration\nAbstract: BackgroundPoor diet quality and high body mass index (BMI) contribute to inflammation, which may influence human milk composition and exclusive breastfeeding (EBF) duration.  ObjectiveWe evaluated maternal diet and prepregnancy BMI as predictors of human milk C-reactive protein (CRP) and long chain fatty acid concentrations (%LCFA), and EBF duration.  MethodsWe utilized the Global Exploration of Human Milk Study-Cincinnati subset (n=114), where healthy dyads continued follow-up if [&ge;]75% of feeds were breastmilk at 4 weeks postpartum. We computed a Dietary Inflammatory Index (DII) from diet recalls obtained between 4-13 weeks postpartum, where higher score indicates a more proinflammatory diet. Milk CRP and fatty acid analyses were performed on week 4 milk. We compared milk CRP across 4 combinations of DIIxBMI using the Kruskal Wallis test, with BMI categorized as normal versus elevated (<25 versus >25 kg/m2), and DII split at the median. Linear regression was used to examine DII and BMI as predictors of %LCFA. Logistic regression was used to examine DII tertiles and BMI as predictors of EBF duration.  ResultsMilk CRP concentrations differed across DIIxBMI groups (p=0.009): the low DII/normal BMI group had the lowest milk CRP (n=30, median [Q1, Q3], 64.3 [38.2, 121.4] ng/mL) versus all other groups (n=70, 124.1 [71.2, 181] ng/mL, p=0.022). Lower milk %LCFA was predicted by higher DII score ({beta}{+/-}SE = -0.68 {+/-} 0.21, p=0.002, n=103) and higher BMI ({beta}{+/-}SE = -0.13 {+/-} 0.01, p=0.043, n=114). Having the highest DII tertile and elevated BMI lowered the odds of EBF at week 6 (OR [95% CI]: 0.26 [0.07, 0.85]) compared to the referent group (low or medium DII, normal BMI).  ConclusionsMilk CRP concentrations were lowest in women with a more anti-inflammatory diet and normal BMI. Both higher BMI and proinflammatory diet predict lower milk %LCFA and lower EBF prevalence at week 6.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Automated analysis of digital medical images in cervical cancer screening: A systematic review\nAbstract: BackgroundCervical cancer screening programs are poorly implemented in LMICs due to a shortage of specialists and expensive diagnostic infrastructure. To address the barriers of implementation researchers have been developing low-cost portable devices and automating image analysis for decision support.  However, as the knowledge base is growing rapidly, progress on the implementation status of novel imaging devices and algorithms in cervical cancer screening has become unclear. The aim of this project was to provide a systematic review summarizing the full range of automated technology systems used in cervical cancer screening.  MethodA search on academic databases was conducted and the search results were screened by two independent reviewers. Study selection was based on eligibility in meeting the terms of inclusion and exclusion criteria which were outlined using a Population, Intervention, Comparator and Outcome framework.  Results17 studies reported algorithms developed with source images from mobile device, viz. Pocket Colposcope, MobileODT EVA Colpo, Smartphone Camera, Smartphone-based Endoscope System, Smartscope, mHRME, and PiHRME. While 56 studies reported algorithms with source images from conventional/commercial acquisition devices. Most interventions were in the feasibility stage of development, undergoing initial clinical validations.  ConclusionResearchers have proven superior prediction performance of computer aided diagnostics (CAD) in colposcopy (>80% accuracies) versus manual analysis (<70.0% accuracies). Furthermore, this review summarized evidence of the algorithms which are being created utilizing portable devices, to circumvent constraints prohibiting wider implementation in LMICs (such as expensive diagnostic infrastructure). However clinical validation of novel devices with CAD is not yet implemented adequately in LMICs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neurocognitive and resting-state functional MRI changes in patients with diffuse gliomas after chemoradiotherapy\nAbstract: BackgroundThis prospective observational study employed resting-state functional MRI (rs-fMRI) to investigate network-level disturbances associated with neurocognitive function (NCF) changes in patients with gliomas following radiation therapy (RT).  MethodsAdult patients with either IDH-wildtype or IDH-mutant gliomas underwent computerized NCF testing and rs-fMRI before and 6 months after RT. NCF changes were quantified by the percent change in age-normalized composite scores from baseline ({Delta}NCFcomp). rs-fMRI data underwent seed-based functional connectivity (FC) analysis. Whole-brain connectivity regression analysis assessed the association between network FC changes and NCF changes, using a split-sample approach with a 26-patient training set and a 6-patient validation set, iterated 200 times. Permutation tests evaluated the significance of network selection.  ResultsBetween September 2020 and December 2023, 43 patients were enrolled, with 32 completing both initial and follow-up evaluations. The mean {Delta}NCFcomp was 2.9% (SD: 13.7%), with 38% experiencing a decline. Intra-hemispheric FC remained similar between ipsilateral and contralateral hemispheres for most patients at both time points. FC changes accounted for a moderate amount of variance in NCF changes (mean R2: 0.301, SD: 0.249), with intra-network FC of the Parietal Memory Network (PMN-PMN, P=0.001) and inter-network FC between the PMN and the Visual Network (PMN-VN, P=0.002) as the most significant factors. Similar findings were obtained by sensitivity analyses using only the FC data from the hemisphere contralateral to the tumor.  ConclusionsPost-RT rs-fMRI changes significantly predicted NCF decline, highlighting rs-fMRI as a promising imaging biomarker for neurocognitive decline after RT.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cost-effectiveness analysis of COVID-19 mRNA XBB.1.5 Fall 2023 vaccination in the Netherlands\nAbstract: ObjectiveThis study aims to assess the cost-effectiveness of the Fall 2023 COVID-19 mRNA XBB.1.5 vaccination campaign in the Netherlands, comparing the XBB1.5 updated mRNA-1273.222 with the XBB1.5 updated BNT162b2 vaccine.  MethodsA one-year decision tree-based cost-effectiveness model was developed, considering three scenarios: no Fall 2023 vaccination, BNT162b2 vaccination and mRNA-1273 vaccination in the COVID-19 high-risk population in the Netherlands. The high-risk population includes everyone of 60 and older, and younger adults at high risk as identified by the Dutch Health Council. Costs were included from a societal perspective and the modelled period started in October 2023 and ended in September 2024, including life years lost with a lifetime horizon. Sensitivity and scenario analyses were conducted to evaluate model robustness.  ResultsIn the base case, mRNA-1273 demonstrated substantial benefits over BNT162b2, potentially averting 20,629 symptomatic cases, 924 hospitalizations (including 32 ICU admissions), 207 deaths, and 2,124 post-COVID cases. Societal cost savings were {euro}12.9million (excluding vaccination costs), with 1,506 QALYs gained. The break-even incremental price of mRNA-1273 compared to BNT162b2 was {euro}16.72 or {euro}34.32 considering a willingness to pay threshold (WTP) of 20,000 or 50,000 euro per QALY gained.  ConclusionThis study provides a comprehensive cost-effectiveness analysis supporting the adoption of the mRNA-1273 vaccine in the national immunization programme in the Netherlands, provided that the Dutch government negotiates a vaccine price that is at most {euro}34.32 per dose higher than BNT162b2. Despite limitations, the findings emphasize the substantial health and economic benefits of mRNA-1273 over BNT162b2 in the high-risk population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The impact of the COVID-19 pandemic on mental health care utilization among people living with HIV: A real-world data study\nAbstract: ObjectiveThe COVID-19 pandemic has profoundly impacted mental health worldwide, particularly among vulnerable populations such as people living with HIV (PLWH). However, large-scale, real-world data on mental health care utilization and associated factors among PLWH remain limited. This study leveraged electronic health records (EHR) and Basics survey data from the All of Us program to explore mental health care utilization and associated factors among PLWH during the COVID-19 pandemic.  MethodsUsing a retrospective cohort design, we identified and included 4,575 PLWH through computational phenotyping based on relevant Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) concept sets from the All of Us program between March 2018 and March 2022. Mental health care utilization was measured using the yearly count of mental health care visits over this period. The pattern of mental health care utilization was compared between pre-pandemic (2018-2020) and during the pandemic (2020-2022). Incidence rate ratios (IRR) from the Poisson generalized linear mixed models (GLMM) were used to examine associations between mental health care utilization, history of COVID-19 infection, demographic factors, pre-existing chronic conditions (e.g., hypertension, diabetes), and socioeconomic status.  ResultsAmong 4,575 PLWH, the annual number of mental health care visits decreased significantly during the pandemic period (March 2020 - March 2022) compared to the pre-pandemic period (March 2018 - February 2020) (IRR = 0.89, p < 0.001). The Poisson regression analysis found that a history of COVID-19 infection was associated with a higher number of mental health care visits (IRR = 1.35, p < 0.001). Middle-aged groups with participants aged 30-39 (IRR= 2.35, p = 0.002), 40-49 (IRR= 3.49, p < 0.001), and 50-64 (IRR= 2.07, p = 0.004) had significantly higher visit numbers compared to the youngest group (18-29 years). Black or African American participants were less likely to have visits compared to White participants (IRR = 0.71, p = 0.002). Medicaid health insurance was associated with an increase (IRR = 1.29, p = 0.007), while employer- or union-sponsored insurance was associated with a decrease in mental health care utilization (IRR = 0.54, p < 0.001, p < 0.001). Pre-existing comorbidities greatly increased the number of mental health care visits (one comorbidity: IRR = 5.49, two or more: IRR = 10.4, p < 0.001).  ConclusionOur study reveals a significant decrease in mental health care utilization and the diverse experiences of mental healthcare among PLWH during the COVID-19 pandemic. These findings underscore the importance of addressing disparities in mental health care access, particularly during public health emergencies, and suggest the need for tailored interventions to meet the mental health care needs of PLWH.  Key PointsO_ST_ABSQuestionC_ST_ABSHow did the COVID-19 pandemic affect mental health care utilization among people living with HIV (PLWH)? What are the factors associated with mental care health utilization among PLWH across both the pre-pandemic and pandemic periods?  FindingsReal-world data from a nationwide cohort of 4,575 PLWH identified from the All of Us program in the United States between March 2018 and March 2022 were used to investigate the effect of COVID-19 pandemic on mental health care utilization (i.e., the yearly count of mental healthcare visits). There was a considerable decrease in mental health care utilization during the pandemic (2020-2022) compared to the pre-pandemic period (2018-2020). Factors associated with higher mental health care utilization during the pandemic were the experience of COVID-19 infection, being middle-aged, Medicaid health coverage, and having comorbidities. Black African American participants, those with employer- or union health insurance, and high annual income (>$35,000), had lower mental health care utilization.  MeaningOur study highlights the diverse and unequal experiences of PLWH during the pandemic, with variations in mental health care utilization over time and across different disadvantaged subgroups. These findings underscore the need for timely and targeted mental health care services and delivery in future public health crises.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bidirectional genetic and phenotypic links between smoking and striatal iron content involving dopaminergic and inflammatory pathways\nAbstract: Tobacco smoking is a major modifiable risk factor for cardiovascular and lung diseases. A better understanding of its neurobiological underpinnings will benefit the prevention of smoking-related illnesses and mortality. Recent neuroimaging studies have identified a correlation between smoking and iron concentration in the brains striatum, a subcortical region involved in habit formation and compulsive behaviour, and a central node of dopamine activity. Moreover, iron accumulation in the striatum is associated with lower cognitive performance in adults. Here, we investigated phenotypic and genetic correlations, and causal relationships between smoking initiation (ever smoked regularly) and susceptibility-weighted magnetic resonance imaging (MRI)-derived markers of iron content-T2* and quantitative susceptibility mapping (QSM)-in the bilateral putamen, caudate, and accumbens nuclei. We computed correlations between smoking and striatal iron in the UK Biobank, adjusting for a vast set of imaging and non-imaging confounders. Using genome-wide association studies (GWAS) summary statistics, we performed global genetic correlation, cross-GWAS coherence tests at the gene level, and causality analysis using Mendelian randomisation and PascalX. Smoking was positively correlated with iron content in the bilateral putamen, caudate, and in the left accumbens, with the strongest effect found when contrasting current and never smokers. Striatal iron had a positive association with pack-years and a negative relationship with years since stopping smoking, indicating a possible reversal of iron accumulation after smoking cessation. Genetic correlation paralleled phenotypic correlation. Cross-GWAS signal was coherent in genes involved in the dopaminergic and glutamatergic systems, and synaptic function. There was evidence of a causal relationship from smoking to striatal iron through genes involved in synaptogenesis and plasticity, and to a lesser extent, from striatal iron to smoking through inflammatory and immune system related genes. Moreover, the heterogeneity of genes with correlated and anti-correlated signals suggests that the neurobiological mechanisms linking iron to smoking behaviour are highly complex. Overall our results show an association between cigarette smoking and iron concentration in the striatum with complex multi-directional causal mechanisms involving synaptic transmission and inflammatory circuits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A workflow for clinical profiling of BRCA genes in Chilean breast cancer patients via targeted sequencing\nAbstract: BackgroundBreast cancer (BC) is the leading cause of cancer-related deaths among women globally and in Chile. Mutations in the tumor-suppressor genes BRCA1 and BRCA2 significantly increase the risk of developing cancer, with the probability rising by more than 50%. Identifying pathogenic variants in BRCA1 and BRCA2 is crucial for both diagnosis and treatment. Targeted panels, which focus on medically relevant subsets of genes, have become essential tools in precision oncology. Beyond technical and human resource factors, standardized bioinformatics workflows are essential for the accurate interpretation of results. We developed a robust bioinformatics pipeline, implemented with Nextflow, to process sequencing data from targeted panels to identify germline variants.  ResultsWe developed an automated and reproducible pipeline using Nextflow for the targeted sequencing of BRCA1/2 genes. The pipeline incorporates two variant callers, Strelka and DeepVariant, both of which have demonstrated high performance in detecting germline SNVs and indels. The runtime is efficient, with a median execution time of less than 3 minutes per task. We sequenced and processed 16 samples from breast cancer patients. In our analysis, we identified 8 nonsynonymous mutations in BRCA1 and 9 in BRCA2. Of the total reported germline mutations, 97% were classified as benign, 1% as pathogenic, 1% as of uncertain significance, and 1% as unknown. The allelic frequencies observed in our cohort closely resemble those of Admixed American and South Asian populations, with the greatest divergence observed in comparison to African individuals.  ConclusionWe successfully analyzed the BRCA1 and BRCA2 genes in 16 breast cancer patients at a public hospital in Chile. A custom Nextflow pipeline was developed to process the sequencing data and evaluate the pathological significance of the identified genetic variants. By employing multiple variant-calling methodologies, we were able to detect and mitigate potential false positives, thereby enhancing the accuracy and reliability of variant detection through cross-verification. A pathogenic variant was identified in one patient, while benign or likely benign variants were found in the remaining 15. Expanding the number of oncogenes sequenced per patient could improve the detection of actionable variants.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The JAK inhibitor, Tofacitinib, Corrects the Overexpression of CEACAM6 and Limits Susceptibility to AIEC Caused by Reduced Activity of the IBD Associated Gene, PTPN2\nAbstract: Background and Aims: A cohort of patients with inflammatory bowel disease (IBD) exhibit expansion of the gut pathobiont, adherent invasive E. coli (AIEC). Loss of activity of the IBD susceptibility gene, protein tyrosine phosphatase type 2 (PTPN2), results in dysbiosis of the gut microbiota both in human subjects and mice. Further, constitutive Ptpn2 knock-out (Ptpn2-KO) mice display expansion of AIEC compared to wildtype littermates. CEACAM6, a host cell surface glycoprotein, is exploited by AIEC to attach to and enter intestinal epithelial cells (IECs). Here, we investigate the role of IEC-specific PTPN2 in restricting AIEC invasion. Methods: Biopsies from IBD patients heterozygous (CT) or homozygous (CC) for the PTPN2 SNP (single nucleotide polymorphism) rs1893217 were processed for immunohistochemistry. HT29 intestinal epithelial cells (IEC) were transfected with control shRNA (PTPN2-CTL), or a shRNA targeted towards PTPN2 (PTPN2-KD). The rs1893217 SNP was inserted (PTPN2-KI), or a complete knock-out of PTPN2 (PTPN2-KO) was generated, with CRISPR-Cas9 gene editing of Caco-2BBe IEC lines. Adherence and invasion assays were performed with either the human IBD AIEC isolate, LF82, or a novel fluorescent-tagged mouse adherent invasive E. coli (mAIECred) at multiplicity of infection (MOI) of 10. IL-6 and the pan-JAK inhibitor tofacitinib were administered to interrogate JAK-STAT signaling. Protein expression was determined by western blotting and densitometry. Results: CEACAM6 expression was elevated (colon and ileum) in IBD patients carrying the PTPN2 rs1893217 SNP (CT, CC) compared to wildtype (TT) IBD patients. HT29 and Caco-2BBe cell lines deficient in PTPN2 expressed significantly higher levels of CEACAM6. Further, PTPN2-KI and PTPN2-KO cell lines also displayed greater adherence and invasion by AIEC LF82 and higher mAIECred invasion. CEACAM6 expression was further elevated after administration of IL-6 in PTPN2-deficient cell lines compared to untreated controls. Silencing of STAT1 and 3 partially reduced CEACAM6 protein expression. Tofacitinib significantly reduced the elevated CEACAM6 protein expression and the higher AIEC adherence and invasion in PTPN2-KI and PTPN2-KO cell lines compared to DMSO controls. Conclusion: Our findings highlight a crucial role for PTPN2 in restricting pathobiont entry into host cells. Our study also describes a role for the FDA-approved drug, tofacitinib (Xeljanz) in correcting the JAK-STAT-mediated overexpression of CEACAM6, used by pathobionts as an entry portal into host cells. These findings suggest a role for JAK-inhibitors in mitigating AIEC colonization in IBD susceptible hosts.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neuropsychiatric Symptoms Cluster and Fluctuate Over Time in Behavioral Variant Frontotemporal Dementia\nAbstract: Objectives: Cognitive and behavioral phenomena define behavioral variant frontotemporal dementia (bvFTD), but neuropsychiatric symptoms (NPS) outside the core criteria are common throughout the illness. Identifying how NPS cluster in bvFTD may clarify the underlying neurobiology of bvFTD-related NPS and guide development of therapies. Methodology: Participants (N=354) with sporadic and genetic bvFTD were enrolled in the ARTFL LEFFTDS Longitudinal Frontotemporal Lobar Degeneration Consortium. Dementia stage was defined as early (CDR plus NACC FTLD) or advanced (CDR plus NACC FTLD). Baseline and annual follow-up visit data were analyzed to compare NPS across stages of bvFTD. Psychiatric states were captured using the Neuropsychiatric Inventory-Questionnaire and Clinician Judgement of Symptoms. Polychoric cluster analysis was used to describe NPS clusters. Results: NPS were highly prevalent (> 90%) in early and late bvFTD. Four NPS clusters were identified based on magnitude of factor loadings: affective, disinhibited, compulsive, and psychosis. Neuropsychiatric symptoms fluctuated across visits. In the affective cluster, depression and anxiety showed the least visit-to-visit stability. In the disinhibited cluster, elation showed the least stability. Symptoms in the psychosis and compulsive clusters (hallucinations, delusions, obsessions/compulsions, and hyperorality) were largely stable, persisting from visit-to-visit in more than 50% of cases. Conclusion: NPS in bvFTD are frequent and cluster into four discrete groups in bvFTD. These clusters may result from specific neural network disruptions that could serve as targets for future interventions. The fluctuating nature of NPS in bvFTD suggests that they are not reliable markers of disease progression or stage.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Histology-guided MRI segmentation of brainstem nuclei critical to consciousness\nAbstract: While substantial progress has been made in mapping the connectivity of cortical networks responsible for conscious awareness, neuroimaging analysis of subcortical arousal networks that modulate arousal (i.e., wakefulness) has been limited by a lack of a robust segmentation procedures for brainstem arousal nuclei. Automated segmentation of brainstem arousal nuclei is an essential step toward elucidating the physiology of arousal in human consciousness and the pathophysiology of disorders of consciousness. We created a probabilistic atlas of brainstem arousal nuclei built on diffusion MRI scans of five ex vivo human brain specimens scanned at 750 micron isotropic resolution. Labels of arousal nuclei used to generate the probabilistic atlas were manually annotated with reference to nucleus-specific immunostaining in two of the five brain specimens. We then developed a Bayesian segmentation algorithm that utilizes the probabilistic atlas as a generative model and automatically identifies brainstem arousal nuclei in a resolution- and contrast-agnostic manner. The segmentation method displayed high accuracy in both healthy and lesioned in vivo T1 MRI scans and high test-retest reliability across both T1 and T2 MRI contrasts. Finally, we show that the segmentation algorithm can detect volumetric changes and differences in magnetic susceptibility within brainstem arousal nuclei in Alzheimer's disease and traumatic coma, respectively. We release the probabilistic atlas and Bayesian segmentation tool to advance the study of human consciousness and its disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Risk of Reticular Pseudodrusen in Age-Related Macular Degeneration: HTRA1/lncRNA BX842242.1 dominates, with no evidence for Complement Cascade involvement\nAbstract: Age-related macular degeneration (AMD) is a multifactorial retinal disease with a large genetic risk contribution. Reticular pseudodrusen (RPD) is a sub-phenotype of AMD with a high risk of progression to late vision threatening AMD. In a genome-wide association study of 2,165 AMD+/RPD+ and 4,181 AMD+/RPD- compared to 7,660 control participants, both chromosomes 1 (CFH) and 10 (ARMS2/HTRA1) major AMD risk loci were reidentified. However association was only detected for the chromosome 10 locus when comparing AMD+/RPD+ to AMD+/RPD- cases. The chromosome 1 locus was notably absent. The chromosome 10 RPD risk region contains a long non-coding RNA (ENSG00000285955/BX842242.1) which colocalizes with genetic markers of retinal thickness. BX842242.1 has a strong retinal eQTL signal, pinpointing the parafoveal photoreceptor outer segment layer. Whole genome sequencing of phenotypically extreme RPD cases identified even stronger enrichment for the chromosome 10 risk genotype.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic disease risks of under-represented founder populations in New York City\nAbstract: The detection of founder pathogenic variants, those observed in high frequency only in a group of individuals with increased inter-relatedness, can help improve delivery of health care for that community. We identified 16 groups with shared ancestry, based on genomic segments that are shared through identity by descent (IBD) , in New York City using the genomic data of 25,366 residents from the All Of Us Research Program and the Mount Sinai BioMe biobank. From these groups we defined 8 as founder populations, mostly communities currently under-represented in medical genomics research, such as Puerto Rican, Garifuna and Filipino/Pacific Islanders. The enrichment analysis of ClinVar pathogenic or likely pathogenic (P/LP) variants in each group identified 202 of these damaging variants across the 8 founder populations. We confirmed disease-causing variants previously reported to occur at increased frequencies in Ashkenazi Jewish and Puerto Rican genetic ancestry groups, but most of the damaging variants identified have not been previously associated with any such founder populations, and most of these founder populations have not been described to have increased prevalence of the associated rare disease. Twenty-five of 51 variants meeting Tier 2 clinical screening criteria (1/100 carrier frequency within these founder groups) have never previously been reported. We show how population structure studies can provide insights into rare diseases disproportionately affecting under-represented founder populations, delivering a health care benefit but also a potential source of stigmatization of these communities, who should be part of the decision-making about implementation into health care delivery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rare variant aggregation highlights rare disease genes associated with brain volume variation\nAbstract: Variation in brain volume is associated with common and rare disorders. Investigating the genetics of brain volume may highlight overlap between diseases and biological mechanisms that explain disease symptoms. Previous studies examining genetic variants associated with brain volume have largely focused on common variants, with rare variant studies not primarily focusing on brain volume phenotypes or focusing on large structural variants. In this study, we aggregated rare variants within genes and associated genes with 44 brain volume phenotypes in the UK Biobank (N=40,374). We found convergence between genes within the same biological pathway and convergence between common and rare variants within the same gene. Seven of the genes associated with total or regional brain volume measures were also linked with rare brain disorders in previous literature. We successfully showed that rare variants in genes linked to rare brain disorders were also associated with sub-clinical brain volume variation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mitigating Hallucinations in Large Language Models: A Comparative Study of RAG-enhanced vs. Human-Generated Medical Templates\nAbstract: The integration of Large Language Models (LLMs) is increasingly recognized for its potential to enhance various aspects of healthcare, including patient care, medical research, and education. The well-known LLM from Open AI: ChatGPT, a user-friendly GPT-4 based chatbot, has become increasingly popular. However, current limitations to LLMs, such as hallucinations, outdated information, and ethical and legal complications may pose significant risks to patients and contribute to the spread of medical disinformation. This study focuses on the application of Retrieval-Augmented Generation (RAG) to mitigate common limitations of LLMs like ChatGPT and assess its effectiveness in summarizing and organizing medical information. Up-to-date clinical guidelines were utilized as the source of information to create detailed medical templates. These were evaluated against human-generated templates by a panel of physicians, using Likert scales for accuracy and usefulness, and programmatically using BERTScores for textual similarity. The LLM templates scored higher on average for both accuracy and usefulness when compared to human-generated templates. BERTScore analysis further showed high textual similarity between ChatGPT- and Human-generated templates. These results indicate that RAG-enhanced LLM prompting can effectively summarize and organize medical information, demonstrating high potential for use in clinical settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Synthetic Data Distillation Enables the Extraction of Clinical Information at Scale\nAbstract: Large-language models (LLMs) have shown promising potential for extracting information from clinical notes. Deploying these models at scale can be challenging due to high computational costs, regulatory constraints, and privacy concerns. To address these challenges, we used synthetic data distillation to fine-tune smaller, open-source LLMs that achieve performance similar to that of larger models, including the teacher model. These smaller models can be run on less expensive local hardware or at a vastly reduced cost in cloud deployments. In this study, we used Llama-3.1-70B-Instruct to generate synthetic training examples in the form of question-answer pairs along with supporting information and model-assigned difficulty scores. These synthetic examples were used to fine-tune the smaller Llama-3.1-8B-Instruct model. We evaluated the performance of these models on an annotated synthetic dataset resembling clinical trial criteria, the i2b2 2018 Clinical Trial Eligibility Challenge, and clinical notes reflecting the clinical trial for apixaban. The fine-tuned models outperformed the 8B-Instruct model on all tasks and in some cases even exceeded the performance of the larger 70B-Instruct model. This work demonstrates the potential of synthetic data distillation to enable more scalable and efficient clinical information extraction, which could be applied toward improving accuracy and efficiency of patient phenotyping and clinical-trial matching.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Decentralizing care for cutaneous leishmaniasis and other skin diseases in Southern Ethiopia: What are the needs?\nAbstract: Abstract Background: Cutaneous leishmaniasis (CL) and other skin diseases impose a high burden in Ethiopia, yet underreporting is common due to limited access to diagnostics and treatment. Decentralizing care could improve this situation but may necessitate substantial changes in the healthcare system. This study assessed the available resources, and healthcare professionals' knowledge and skills across Southern Ethiopia's healthcare facilities to inform decentralization plans. Methodology/Principle findings: A cross-sectional study was conducted from May to July 2023 in Gamo Zone, South Ethiopia, including visits to 11 health centers, 4 primary hospitals, and 1 general hospital. Available resources were evaluated, and clinical and laboratory staff's knowledge and skills were tested through questionnaires focused on CL and other skin diseases. Most facilities had equipment for diagnosis and localized treatment. Adequate hospitalization space and necessary equipment for systemic CL treatment were found in 3 out of 4 primary hospitals but none of the health centers. Consumable and drug shortages were common across all facilities. BSc laboratory technologists scored significantly higher than diploma technicians (29 vs. 15 out of 39, p<0.001). Clinical staff scores varied significantly across education levels (p=0.007), with clinicians scoring the highest (median 33, IQR 31-36), followed by health officers (median 29, IQR 27-32), BSc nurses (median 28, IQR 16-36) and diploma nurses (median 25, IQR 19-29). Notably, no significant differences in median scores were observed between primary hospitals and health centers for both clinical and laboratory staff. Conclusions/Significance: Decentralizing diagnosis and treatment of common skin diseases and localized CL treatment to health centers appears feasible with facility adjustments and continuous staff training. CL cases requiring systemic treatment should be referred to primary hospitals. Strategic efforts to enhance and maintain skills and tackle supply shortages are crucial for successful decentralization.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Galar - a large multi-label video capsule endoscopy dataset\nAbstract: Video capsule endoscopy (VCE) is an important technology with many advantages (non-invasive, representation of small bowel), but faces many limitations as well (time-consuming analysis, short battery lifetime, and poor image quality). Artificial intelligence (AI) holds potential to address every one of these challenges, however the progression of machine learning methods is limited by the avaibility of extensive data. We propose Galar, the most comprehensive dataset of VCE to date. Galar consists of 80 videos, culminating in 3,513,539 annotated frames covering functional, anatomical, and pathological aspects and introducing a selection of 29 distinct labels. The multisystem and multicenter VCE data from two centers in Saxony (Germany), was annotated framewise and cross-validated by five annotators. The vast scope of annotation and size of Galar make the dataset a valuable resource for the use of AI models in VCE, thereby facilitating research in diagnostic methods, patient care workflow, and the development of predictive analytics in the field.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Screening for avoidant restrictive food intake disorder (ARFID) in primary care: clinical presentation and validation of the ARFID-Brief Screener in Swedish preschoolers\nAbstract: Objective: Little is known about the prevalence and clinical presentation of avoidant restrictive food intake disorder (ARFID) in preschool children, and well-validated, parent-reported screening tools are lacking. This study evaluated the diagnostic validity of the parent-reported ARFID-Brief Screener in preschool children and examined prevalence and clinical characteristics of ARFID. Method: Parents of 645 children (50.5% male, mean age 3.2 years) completed the ARFID-Brief Screener in connection with the 2.5- and 4-year routine check-ups at 21 child health services centers in West Sweden. Parents of all screen-positive and of randomly selected screen-negative children were invited to a clinical follow-up interview via phone. Co-occurring neurodevelopmental problems were assessed via questionnaire, clinical examination, and health care records. Results: Of 42 (6.5%) children screening positive for ARFID, 29 were followed up via interview, and ARFID diagnosis was confirmed in 21 (positive predicted value 72%; other diagnostic metrics: negative predictive value 94%, sensitivity 91%, specificity 79%, and overall accuracy 84%. The adjusted prevalence of ARFID was 5.9%. All children with ARFID presented with both sensory-based avoidance and low interest, and the majority (65.2%) met criteria solely through DSM-5 criterion A4 (marked interference with psychosocial functioning). The ARFID group had significantly more co-occurring neurodevelopmental problems. Discussion: ARFID is not rare among preschoolers, although prevalence might have been slightly overestimated here. The ARFID-Brief Screener showed high diagnostic validity, but follow-up assessments are necessary to confirm diagnoses and reduce false positives. Co-occurring neurodevelopmental problems were common in ARFID and may serve as early markers of increased ARFID risk.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Neural and Somatic Mechanisms Driving Clinical Improvements in Post-Acute Schizophrenia Spectrum Disorders\nAbstract: Background: A better mechanistic understanding of schizophrenia spectrum disorders is crucial to develop efficient treatment approaches. Therefore, this study investigated longitudinal interrelations between clinical outcomes, brain structure, and somatic health in post-acute individuals from the schizophrenia spectrum. Methods: A sample of 63 post-acute patients from two independent physical exercise studies were included in the final analyses. Demographic, clinical, cognitive, and somatic data were acquired at baseline and post-intervention, as were structural magnetic resonance imaging scans. Multivariate cross-lagged panel modelling including mediators was used to study the mutual interrelations over time between the clinical, neural, and somatic level. Results: A higher baseline global grey matter volume and larger regional grey matter volumes of the hippocampal formation, precuneus, and posterior cingulate drove improvements in multiple clinical outcomes, such as daily-life functioning, negative symptoms, and cognition. Increases in white matter volume from baseline to post-intervention resulted in significantly reduced positive symptoms and higher daily-life functioning following the intervention. Conclusion: Our findings suggest that stimulating neuroplasticity, especially in the hippocampal formation, precuneus, and posterior cingulate gyrus, may represent a promising treatment target in post-acute schizophrenia spectrum disorders. Physical exercise therapies and other lifestyle interventions, and brain stimulation approaches reflect promising treatment candidates. Given the exploratory character of the statistical analysis performed, these findings need to be replicated in independent longitudinal imaging cohorts of patients with schizophrenia spectrum disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Legal residency status and its relationship with health indicators among Syrian refugees in Lebanon: a nested cross-sectional study\nAbstract: Background: Failure to possess or renew legal residency permits increases the burden on a vulnerable refugee population. It risks detention or deportation, and hinders access to basic services including healthcare. This study aimed to examined the association between legal residency status and health of Syrian refugees living in Lebanon. Methods: Data were from two independent nested cross-sectional studies collected in 2022 through telephone surveys. In the first study, all Syrian refugees aged 50 years or older from households that received humanitarian assistance were invited to participate. The second included all adult Syrian refugees residing in a suburb of Beirut. The exposure was self-reported possession of a legal residency permit in Lebanon. The self-reported health outcomes were mental health status, COVID-19 vaccine uptake, and access to the needed healthcare services. Separate adjusted logistic regression models examined the association between lacking a legal residency permit and each health outcome. Results: The first sample included 3357 participants (median age 58 years (IQR:54-64), 47% female), of whom 85% reported lacking a legal residency permit. The second sample included 730 participants (median age 34 years (IQR:26-42), 49% female), of whom 79% lacked a legal residency permit. In both studies, lacking a legal residency permit increased the odds of having poor mental health [adjusted odds ratio (aOR):1.62 (95%CI:1.2-2.2); aOR:1.62 (95%CI:1.01-2.60)], and decreased the odds of COVID-19 vaccine uptake [aOR:0.64 (95%CI:0.53-0.78); aOR:0.51 (95%CI:0.32-0.81)]. In the sub-sample who needed primary healthcare, lacking a legal residency permit decreased the odds of access to primary healthcare in the second study only (aOR:0.37 (95%CI:0.17-0.84)). Conclusions: The majority of Syrian refugees from these two samples reported lacking a legal residency permit in Lebanon. This was associated with poor mental health and lower uptake of COVID-19 vaccination, potentially originating from fear of detention or deportation. These findings call for urgent action to support access to legal documentation for refugees in Lebanon.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Use it or lose it: A four-year follow-up to assess whether engagement with physical activity close to one's physical capacity may protect against decline in physical functioning among older adults\nAbstract: PURPOSE: Physical activity (PA) is distinct from physical capacity (PC), even though they are correlated in old age. PC defines the limits for PA, while activities in daily life typically remain submaximal. Individuals whose intensity of daily activities is close to physical capacity may be better protected from future decline in physical function compared to those who do not, although prospective research to support this hypothesis is lacking. Therefore, this study compared changes in physical function over a four-year follow-up between community-dwelling older adults categorized based on their combined baseline PC and PA. METHODS: This was a four-year longitudinal follow-up study of older adults aged 75-85 years at baseline (N = 312, 60% women). Baseline PC was determined based on 5-second Mean Amplitude Deviation (MAD) epoch value during the maximal 10-meter walking test, and PA was determined based on the peak 75-minutes MAD intensity threshold from thigh-worn accelerometer monitoring over 3-7 days. Baseline values of PA and PC were categorized into lowPC-lowPA, lowPC-highPA, highPC-lowPA, and highPC-highPA profiles. Physical function was evaluated using the Short Physical Performance Battery (SPPB) at baseline and at the follow-up, with total score and 5 x Sit-To-Stand (5xSTS) test time as the primary outcomes. Nonparametric tests and generalized estimating equations were used for analyses. RESULTS: From baseline to follow-up, statistically significant changes in the SPPB total score and 5xSTS test time were observed in all profiles (p<0.05) except the low PC-high PA profile. Over the follow-up period, the decrease was greater for low versus high PA profiles within both PC profiles for SPPB total score (high PC: B -0.61, SE 0.24, 95% CI -1.08, -0.15; low PC: B -0.96, SE 0.35, 95% CI -1.62, -0.32), but not for 5xSTS time. No statistically significant difference was observed in the change in 5xSTS test time between the low and high PA profiles for either PC profile. CONCLUSIONS: The findings suggest that engaging in demanding PA regardless of baseline PC may help to protect against a decline in physical functioning in old age. Consequently, older adults should be encouraged to engage in physically demanding activities that could potentially enhance their functional capacity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessing Attitudes and Perceptions of High-risk, Low-resource Communities towards Cardiopulmonary Resuscitation and Public-access Defibrillation\nAbstract: Background: Layperson cardiopulmonary resuscitation (CPR) and automated external defibrillator (AED) use are vital for improving survival rates after out-of-hospital cardiac arrest (OHCA), yet their application varies by community demographics. We evaluated the concerns and factors influencing willingness to perform CPR and use AEDs among laypersons in high-risk, low-resource communities. Methods: From April 2022 to March 2024, laypersons in Northern Manhattan's Community District 12 completed surveys assessing their attitudes toward CPR and AED use before attending Hands-Only CPR training. Fisher's Exact Test assessed differences in concerns and willingness to perform CPR and AED use across racial-ethnic groups and compared low-resource communities with high-resource groups consisting of non-clinical staff across eight ambulatory sites. Results: Among 669 respondents, 64% identified as Hispanic, 58% were under 40, and 67% were female. Significant knowledge gaps were identified: 62% had never learned CPR, and 77% were unfamiliar with AEDs. Common concerns included fear of incorrect performance (67%), causing harm (56%), and legal repercussions (53%). Willingness to perform CPR was most influenced by familiarity with the victim (55% family vs. 67% non-family). The main barrier to AED use was a lack of operational knowledge (66%). Non-Hispanic Black participants expressed significantly greater concerns than their non-Hispanic White and Hispanic counterparts. Participants in high-resource settings (n=309) showed higher CPR and AED training rates with similar concerns. Conclusions: Concerns regarding CPR and AED use stem from a lack of confidence and training. Targeted, culturally sensitive community interventions are essential to address these barriers, enhance preparedness, and improve OHCA survival rates.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Stakeholder Perspectives on an Adult Cerebral Palsy Community Registry: A Qualitative Study\nAbstract: Background: The Cerebral Palsy Research Network (CPRN) community registry has yielded valuable information about changes in function and pain in adults with cerebral palsy (CP) through a patient-reported outcomes registry. However, it requires increased enrollment and diversity of participants to produce more generalizable conclusions. Objective: To identify stakeholder perspectives about the barriers and facilitators to enrollment in the CPRN Community Registry, strategies to enhance recruitment efforts, and important questions for the registry. Methods: Qualitative descriptive study using iterative focus groups, followed by inductive thematic analysis. Participants included adults with CP and caregivers, clinical investigators, and community leaders in the CP and disability spaces. We explored perspectives about motivations for registry participation, barriers and facilitators to participation, and strategies for increasing and enhancing diversity of enrollment. Results: We conducted four focus groups (20 participants with lived experience; 10 clinical investigators; 9 community leaders). All participants valued the information provided by the registry and felt that ongoing data collection was important. Barriers and related facilitators to participation include benefits of participation, awareness, accessibility, and collaboration with community and clinical partners. Adults with lived experience seek more precisely defined health and function outcomes for adults with CP. Conclusions: Adults with lived experience, clinical investigators, and community leaders identified barriers and facilitators to participation in a patient-reported registry and important questions. Our study revealed that communicating a direct benefit to the participant, improved visibility and accessibility, leveraging collaboration with clinical and community partners and answering more precise research questions could promote enrollment.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Trial-level factors affecting accrual rate of systemic sclerosis randomized clinical trials over 20 years.\nAbstract: Objectives. To estimate the average time to complete patient enrollment and identify factors associated with accrual rates in systemic sclerosis (SSc) randomized controlled trials (RCTs). Methods. We searched published SSc-RCTs indexed in PubMed from 2000 to 2024, selecting those with recruitment completed before the COVID-19 pandemic. We recorded key trial features (country, phase, randomization ratio, intervention, blinding, funding source, outcome type) and enrollment year(s). We measured enrollment duration and accrual rate (participants per month). A multivariable negative binomial generalized linear model was used to identify factors associated with accrual rate. Results. We included 80 studies, mostly single-country (75.0%) and industry-funded (57.5%), with recruitment concentrated in Europe (36.2%) and North America (22.5%). In 65% of studies, both limited and diffuse SSc patients were enrolled. The median sample size was 40.5 patients, with 20% of RCTs enrolling more than 100 patients. The median recruitment time was 15 months (IQR 9.9-30.0), with a median accrual rate of 3.1 (IQR 1.6-5.5) participants per month. Recruitment rates varied over time, with faster accrual early in the 2000s and after 2012, and a slower period in between. Multivariable analysis showed that accrual rate was positively associated with skewed randomization, non-industry funding, international recruitment, and inclusion of both SSc subsets, especially compared to studies involving only dcSSc patients. Conclusions. Recruiting SSc patients for RCTs has been challenging, with generally slow accrual over the past 20 years and no significant improvement over time.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A New Approach to Identifying Elite Winter Sport Athletes' Risk of Relative Energy Deficiency in Sport (REDs)\nAbstract: Objectives: Relative Energy Deficiency in Sport (REDs) is a syndrome resulting from problematic low energy availability (LEA). Low areal bone mineral density (aBMD) is a primary indicator of LEA, measured by dual X-ray absorptiometry (DXA). High-resolution peripheral quantitative computed tomography (HR-pQCT) is an advanced imaging device that provides measures of volumetric BMD (vBMD), bone microarchitecture, geometry, and strength. The objective of this study was to assess prevalence of REDs in elite winter sport athletes and to observe the associations in bone parameters using HR-pQCT in athletes identified as at-risk or not at-risk of REDs. Methods: Participants included 101 elite athletes (24.1 +/- 4.4 SD years; 52% female). The REDs Clinical Assessment Tool (CAT2) was used to determine REDs risk. HR-pQCT scans of the non-dominant radius and left tibia were analyzed upon REDs risk grouping. Results: Seventeen athletes (17%; 71% female) were at-risk based on the REDs CAT2. After covarying for lean mass, odds ratios (OR) suggested higher likelihood of REDs risk classification for athletes with low cortical thickness, cortical area, total vBMD, and bone strength. Conclusions: Impaired total vBMD, bone strength and cortical bone parameters were approximately twice as likely (OR: 1.9-3.0) in athletes at-risk of REDs. Results agree with the consensus statement that HR-pQCT may identify impaired bone health in athletes at-risk of REDs. Future directions should use HR-pQCT to explore REDs risk longitudinally, utilizing bone change over time as this may provide greater insight. Using advanced imaging to explore REDs risk in a population of winter high-performance athletes is novel.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The role of plasmapheresis in snake envenoming: a systematic review\nAbstract: Background Envenoming from numerous sources, such as snakes, scorpions, and spiders, is a major health issue across the world, resulting in millions of cases and tens of thousands of deaths annually. Venom induced symptoms ranges from systemic reactions like nausea and vomiting to localised pain and swelling. One major risk is the development of venom induced consumption coagulopathy (VICC), which might result in significant consequences. Plasmapheresis is being investigated as a possible therapy for severe envenoming. Objectives We aim to assess the effectiveness and potential advantages of plasmapheresis in snakebite cases, focusing on clinical results. We seek to find if plasmapheresis improves neurological, renal, and hematological dysfunction and impacts secondary outcomes, including patient discharge rates, morbidity, mortality, duration of hospital stay, and the number of plasmapheresis sessions required. Methods Following PRISMA guidelines, we conducted a systematic search of articles published between 1980 and July 2023 across multiple databases. MeSH terms related to snakebite and plasmapheresis were applied without publication or language type restrictions. Inclusion criteria considered case reports, cross-sectional studies, or case series featuring plasmapheresis in snakebite management. Inclusions were participants aged 18 years or older with confirmed or suspected snakebites, meeting plasmapheresis indications. Exclusions included participants under 18 years, studies reporting only in vitro data, review articles, and redundant reporting. The emphasis was on Emergency Departments or Intensive Care Units. Results In a review of 147 cases (1980 to July 2023), the most common snake was the hump-nosed viper (Hypnale hypnale). Renal, neurological, and hematological dysfunctions improved after plasmapheresis. The mean plasmapheresis sessions were 2.1, and the average hospital stay was 13.13 days. Conclusion Once the data has been analyzed, the result emphasizes the clinical importance of plasmapheresis in snakebite envenoming. It helps decision-making when standard therapies are insufficient or ineffective, potentially saving lives.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Lipid trajectories improve risk models for Alzheimer's disease and mild cognitive impairment\nAbstract: To assess the relationship between lipids and cognitive dysfunction, we retrospectively analyzed blood lipid levels in clinically well characterized individuals with stable mild cognitive impairment (MCI) or Alzheimer's disease (AD) over the decade prior to first cognitive symptoms. In this case/control cohort study, AD and MCI cases were diagnosed using DSM.IV criteria; MCI cases had not progressed to dementia for 5 years; and controls were propensity matched to cases at age of symptom onset (MCI: 116 cases, 435 controls; AD: 215 cases, 483 controls). Participants were grouped based on longitudinal trajectories and quintile of variability independent of the mean (VIM) for total cholesterol, HDLC, LDLC, nonHDLC and ln(triglycerides). Models for the risk of cognitive dysfunction evaluated trajectory and VIM groups, APOE genotype, polygenic risk scores (PRS) for AD and lipid levels, age, comorbidities, and longitudinal correlates of blood-lipid concentrations. Lower HDLC trajectories (OR = 3.8, 95% CI = 1.3, 11.3) and the lowest VIM quintile of nonHDLC (OR = 2.2, 95% CI = 1.3, 3.0) were associated with higher MCI risk. Lower HDLC trajectories (OR = 3.0, 95% CI = 1.6, 5.7) and the lowest VIM quintile of total cholesterol (OR = 2.4, 95% CI = 1.5, 3.9) were associated with higher AD risk. The inclusion of lipid-trajectory and VIM groups improved risk-model predictive performance independent of APOE genotype or PRS for AD and lipid levels. These results provide an important real world perspective on the influence of lipid metabolism and blood lipid levels on the development of stable MCI and AD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Optical imaging of micro-droplets of dried saliva for oral squamous cell carcinoma diagnosis\nAbstract: Oral cancer, ranking sixth in global prevalence, is frequently diagnosed at an advanced stage, significantly impacting patient survival rates. The potential of liquid biopsy for cancer diagnosis offers a dynamic approach to tumor monitoring and disease surveillance. Objective(s): Our goal is to validate a novel diagnostic approach using optical images of dried microdroplets of saliva samples. Subjects: 1 l of saliva samples from healthy and oral cavity squamous cell carcinoma patients were pippeted on glass and platinum substrates and analized using optical microscopy. Logistic Regression (LR) and Support Vector Machine (SVM) models were deployed to categorize samples based on their distinct characteristics. The assessment included calculations for accuracy, sensitivity, specificity, and the area under the ROC curve for each model. Results: The optical density (OD) and surface area (SA) of each sample, derived from their optical imaging, served as effective parameters for distinguishing oral cavity squamous cell carcinoma from healthy individuals. Conclusion(s): SVM models demonstrate impressive accuracy of 88.10% on glass and 95.00% on Pt substrates, ensuring robust and accurate detection of oral cancer based on these salient features.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of Clonal Hematopoiesis of Indeterminate Potential after Cancer Radiation Therapy\nAbstract: Clonal hematopoiesis of indeterminate potential (CHIP) is a condition associated with aging and increased risk of hematologic malignancies and chronic diseases. While radiation therapy (RT) has been implicated as a risk factor for CHIP, the specific radiation parameters influencing the development of CHIP remain unclear. This study aimed to investigate the association between RT and CHIP and identify relevant radiation parameters affecting CHIP risk. We conducted a retrospective cohort study of cancer patients with RT exposure from an institutional biobank. DNA sequencing was performed to detect mutations in 22 CHIP-associated genes. Multivariable logistic regression models were used to evaluate the association between clinical characteristics, RT parameters, and CHIP. We identified 736 cancer patients with RT exposure and compared their risk of CHIP to a control cohort of 13,605 individuals. RT was found to be an independent risk factor for developing CHIP (OR 1.39, 95% CI 1.08-1.77, p=0.009). The prevalence of CHIP in RT patients was 22.8%. Compared to controls, RT patients showed significantly increased mutations in DNMT3A, PPM1D, TP53, and BRCC3. A positive correlation was observed between CHIP risk and biological equivalent dose of radiation. Stereotactic radiation was also associated with increased CHIP prevalence (OR 2.24, 95% CI 1.14-4.33, p=0.02). This study demonstrates that RT is associated with an increased risk of CHIP development, particularly mutations in DNA damage response genes. These findings have important implications for cancer care and long-term patient monitoring, emphasizing the need for further research into the mechanisms and consequences of RT-related CHIP.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Postoperative Lymphatic Exudate is a Proximal Source of ctDNA and Detects Recurrence in HPV-negative Head and Neck Cancer\nAbstract: ABSTRACT Relapse is a major cause of failure after surgery in HPV-human papillomavirus (HPV) negative head and neck squamous cell carcinoma (HNSCC),), with up to 50% of patients recurring within 2 years. While clinicopathologic criteria exist for adjuvant treatment, these criteria are imprecise and have not changed for decades. However, no reliable method exists to tailor adjuvant therapy for individual patients based on risk of recurrence after surgery. Using an ultra-sensitive targeted sequencing approach, we demonstrate that circulating tumor DNA (ctDNA) in lymphatic exudate collected via surgical drains (\"lymph\") 24 hours after surgery accurately identifies MRD and outperforms plasma in an initial cohort of 36 HNSCC patients. We then applied the lymph ctDNA test to an independent, multi-site cohort of 37 HNSCC patients, replicating the original finding. Lymph performance was particularly enhanced in locoregional relapse in both cohorts and generalized to early stage (I-II) patients. Analysis of matched plasma collected at this early timepoint was not predictive of recurrence. We demonstrate a liquid biopsy approach using a historically overlooked biofluid to potentially enable precision adjuvant therapy and achieve superior oncologic outcomes. SIGNIFICANCE Postoperative lymphatic exudate represents a novel proximal analyte for MRD detection in HPV- HNSCC designed specifically for use in the immediate post-surgical window when adjuvant therapy decisions must be made. Accurate MRD identification at this early timepoint has potential to augment traditional pathology and personalize adjuvant treatment paradigms in HPV-negative HNSCC.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Tear-Based Approach for Rapid Identification of Bacterial Pathogens in Corneal Ulcers Using Nanopore Sequencing\nAbstract: Purpose: Corneal ulcers pose a significant threat to vision, with the need for prompt and precise pathogen identification being critical to effective treatment. This study assesses the efficacy of using next-generation portable sequencing (Nanopore Technology) to detect and identify bacterial pathogens directly from tear samples, providing a non-invasive alternative to traditional corneal scraping and culture, which are limited by high false-negative rates. Design: Prospective observational study. Participants: Ten participants diagnosed with corneal ulcers. Methods: Tear samples were collected from the ocular surface using Schirmer strips. Corneal scrapings and cultures were performed as medically indicated. The 16S rRNA gene was amplified directly from the tear samples using polymerase chain reaction (PCR), and Nanopore sequencing was used for bacterial species identification and taxonomic classification. Comparative analysis was conducted to evaluate the concordance between Nanopore sequencing results and traditional culture methods. Main Outcome Measures: Comparison of bacterial species detected via Nanopore sequencing with those identified through traditional culture methods. Results: Bacterial DNA was identified in 8 of the 10 samples analyzed using the tear-based sequencing method. Notably, Nanopore sequencing accurately identified the causative bacteria in all 4 samples that exhibited bacterial growth on culture. Additionally, it detected bacterial pathogens in 2 of the 4 ulcers that did not show bacterial growth on culture. In 2 cases where cultures could not be obtained due to the small size of the ulcer, tear sequencing successfully identified bacterial species, highlighting potentially overlooked pathogens in corneal ulcers. Conclusions: PCR amplification of 16S RNA directly from tears followed by Nanopore sequencing is an effective, non-invasive method to identify bacterial pathogens in corneal ulcers, offering non-inferior results to traditional culture methods. This technique not only allows for the detection of traditionally hard-to-culture organisms, providing immediate diagnostic value to guide treatment, but also enhances our understanding of the microbiological landscape of corneal ulcers, thereby informing more effective treatment strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Empowering Self-Management for Chronic Low Back Pain: A Human-Centered Design Study of Spanish- and Cantonese-Preferring Patients in the United States\nAbstract: Background: Chronic low back pain (cLBP) is a leading cause of disability, with disproportionately high impacts on marginalized populations, including non-English-preferring patients. These patients face significant barriers to accessing care and adhering to self-management strategies due to language barriers, socioeconomic challenges, and cultural differences. Despite the emphasis on self-management for cLBP, limited research has focused on understanding the specific needs and preferences of Spanish- and Cantonese-preferring patients. Objective: This study aimed to explore the self-management priorities of Spanish- and Cantonese-preferring patients with cLBP at an urban, academic-affiliated county hospital. Using a human-centered design approach, we sought to identify patient preferences for self-management support materials and strategies that could be tailored to their unique needs. Methods: We conducted six focus groups (three each for Spanish- and Cantonese-preferring participants) between March and May 2024, involving 27 patients with cLBP. Patients were recruited from an urban safety-net hospital, and focus groups were conducted in participants' preferred language. Participants discussed their experiences with cLBP care, barriers to self-management, and their preferences for educational materials. Data were analyzed using an inductive coding approach to identify key themes. Results: Four primary themes emerged from the focus groups: (1) the need for empathic, tailored educational supports that fit into patients' lives, (2) the desire for self-management plans that account for social and economic constraints, (3) the recognition of mental health and social isolation as critical aspects of cLBP care, and (4) a need for clearer guidance on self-management strategies and trustworthy resources. Both Spanish- and Cantonese-preferring participants expressed a preference for video-based resources, plain-language materials, and support for understanding the causes and management of their pain. Conclusion: Spanish- and Cantonese-preferring patients with cLBP face significant barriers to self-management, but are motivated to engage in self-care if provided with culturally and linguistically appropriate resources. This study highlights the need for healthcare systems to develop and deliver tailored, accessible self-management support materials that address the unique challenges faced by these populations. Human-centered design offers a promising approach to reducing disparities in cLBP outcomes by creating patient-driven solutions that prioritize empathy, practicality, and cultural relevance.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gait-to-Contact (G2C): A novel deep learning framework to predict total knee replacement wear from gait patterns\nAbstract: Background: Total knee replacement (TKR) is the most common inpatient surgery in the US. Studies leveraging finite element analysis (FEA) models have shown that variability of gait patterns can lead to significant variability of wear rates in TKR settings. However, FEA models can be resource-intensive and time-consuming to execute, hindering further research in this area. This study introduces a novel deep learning-based surrogate modeling approach aimed at significantly reducing computational costs and processing time compared to traditional FEA models. Methods: A published method was used to generate 314 variations of ISO14243-3(2014) anterior/posterior translation, internal/external rotation, flexion/extension, and axial loading time series, and a validated FEA model was used to calculate linear wear distribution on the polyethylene liner. A deep learning model featuring a transformer-CNN based encoder-decoder architecture was trained to predict linear wear distribution using gait pattern time series as input. Model performance was evaluated by comparing the deep learning and FEA model predictions using metrics such as mean absolute percentage error (MAPE) for relevant geometric features of the wear scar, structural similarity index measure (SSIM) and normalized mutual information (NMI). Results: The deep learning model significantly reduced the computational time for generating wear predictions compared to FEA, with the former training and inferring in minutes, and the latter requiring days. Comparisons of deep learning model wear map predictions to FEA results yielded MAPE values below 6% for most of the variables and SSIM and NMI values above 0.88, indicating a high level of agreement. Conclusion: The deep learning approach provides a promising alternative to FEA for predicting wear in TKR, with substantial reductions in computational time and comparable accuracy. Future research will aim to apply this methodology to clinical patient data, which could lead to more personalized and timely interventions in TKR settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Synthetic Data Generation in Motion Analysis: A Generative Deep Learning Framework\nAbstract: Abstract Generative deep learning has emerged as a promising data augmentation technique in recent years. This approach becomes particularly valuable in areas such as motion analysis, where it is challenging to collect substantial amounts of data. The current study introduces a data augmentation strategy that relies on a variational autoencoder to generate synthetic data of kinetic and kinematic variables. The kinematic and kinetic variables consist of hip and knee joint angles and moments, respectively, in both sagittal and frontal plane, and ground reaction forces. Statistical parametric mapping (SPM) did not detect significant differences between real and synthetic data for each of the biomechanical variables considered. To further evaluate the effectiveness of this approach, a long-short term model (LSTM) was trained both only on real data (R) and on the combination of real and synthetic data (R and S); the performance of each of these two trained models was then assessed on real test data unseen during training. The predictive model achieved comparable results in terms of nRMSE when predicting knee joint moments in the frontal (R and S: 9.86% vs R:10.72%) and sagittal plane (R and S: 9.21% vs R: 9.75%), and hip joint moments in the frontal (R&S: 16.93% vs R:16.79%) and sagittal plane (R&S: 13.29% vs R:14.60%). These findings suggest that the proposed methodology is an effective data augmentation approach in motion analysis settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ancestrally diverse genome-wide association analysis highlights ancestry-specific differences in genetic regulation of plasma protein levels\nAbstract: Fully characterizing the genetic architecture of circulating proteins in multi-ancestry populations provides an unprecedented opportunity to gain insights into the etiology of complex diseases. We characterized and contrasted the genetic associations of plasma proteomes in 9,455 participants of European and African (19.8%) ancestry from the Atherosclerosis Risk in Communities Study. Of 4,651 proteins, 1,408 and 2,565 proteins had protein-quantitative trait loci (pQTLs) identified in African and European ancestry respectively, and twelve unreported potentially causal protein-disease relationships were identified. Shared pQTLs across the two ancestries were detected in 1,113 aptamer-region pairs pQTLs, where 53 of them were not previously reported (all trans pQTLs). Sixteen unique protein-cardiovascular trait pairs were colocalized in both European and African ancestry with the same candidate causal variants. Our systematic cross-ancestry comparison provided a reliable set of pQTLs, highlighted the shared and distinct genetic architecture of proteome in two ancestries, and demonstrated possible biological mechanisms underlying complex diseases.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Consensus guidelines for eligibility assessment of pathogenic variants to antisense oligonucleotide treatments\nAbstract: Of the around 7,000 known rare diseases worldwide, disease-modifying treatments are available for fewer than 5%, leaving millions of individuals without specialized therapeutic strategies. In recent years, antisense oligonucleotides (ASOs) have shown promise as individualized genetic interventions for rare genetic diseases. However, there is currently no consensus on which disease-causing DNA variants are suitable candidates for this type of genetic therapy. The Patient Identification Working Group of the N=1 Collaborative (N1C), alongside an international group of volunteer assessors, has developed and piloted consensus guidelines for assessing the eligibility of pathogenic variants towards ASO treatments. We herein present the N1C VARIANT (Variant Assessments towards Eligibility for Antisense Oligonucleotide Treatment) guidelines, including the guiding scientific principles and our approach to consensus building. Pathogenic, disease-causing variants can be assessed for the three currently best-established ASO treatment approaches: splice correction, exon skipping, and downregulation of RNA transcripts. A genetic variant is classified as either \"eligible\", \"likely eligible\", \"unlikely eligible\", or \"not eligible\" in relation to the different approaches, or \"unable to assess\". We also review key considerations for assessment for upregulation of transcripts from the wildtype allele, an emerging ASO therapeutic strategy. We provide additional tools and training material to enable clinicians and researchers to use these guidelines for their eligibility assessments. With this initial edition of our N1C VARIANT guidelines, we provide the rare genetic disease community with guidance on how to identify suitable candidates for variant-specific ASO-based therapies and the possibility of integrating such assessments into routine clinical practice.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Measuring aversion to health inequality in Canada: an equity-efficiency trade-off experiment\nAbstract: OBJECTIVES: To estimate the extent to which Canadians are averse to health inequalities, a critical component for equity-informative economic evaluations but lacking in the Canadian context. METHODS: We conducted three experiments among a representative sample of adults living in Canada to elicit value judgements about reducing income-related health inequality vs. improving population health. Each experiment compared two programs: (Experiment 1) universal and tailored vaccination; (Experiment 2) non-specific prevention programs; (Experiment 3) generic health care programs. The programs varied in terms of efficiency (additional life years), and income-related health inequality. Preferences were elicited using benefit-trade off analysis and were classified as: pro-rich (maximizing the health of individuals with the highest income); health maximizer (maximizing total health); weighted prioritarian (willing to trade some health to reduce inequalities); maximin (only improving the health of the individuals with the lowest income); and egalitarian (minimizing health inequalities). RESULTS: We recruited 1,000 participants per experiment. Preferences for the vaccination, prevention, and generic experiments were distributed as follows: pro-rich (Atkinson Index<0): 31%, 22%, and 16% respectively; health maximizers (Atkinson Index=0): 2%, 3%, and 2%, respectively; weighted prioritarians (Atkinson Index>0): 13%, 19%, and 22% respectively; maximins (Atkinson Index={infty}): 0%, 1%, and 3%, respectively; egalitarian (Atkinson Index undefined): 54%, 55%, and 57%, respectively. The median responses reflected a preference for minimizing health inequalities across the three experiments. CONCLUSIONS: Our findings suggest a strong aversion to health inequality among people living in Canada with over half of respondents willing to minimize health inequalities regardless of the impact on efficiency.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: SYSTEMATIC CHARACTERIZATION OF THE EFFECTIVENESS OF ALIGNMENT IN LARGE LANGUAGE MODELS FOR CATEGORICAL DECISIONS\nAbstract: As large language models (LLMs) are increasingly deployed in high-stakes domains like healthcare, understanding how well their decision-making aligns with human preferences and values becomes crucial, especially when we recognize that there is no single gold standard for these preferences. This paper applies a systematic methodology for evaluating preference alignment in LLMs on categorical decision-making with medical triage as a domain-specific use case. It also measures how effectively an alignment procedure will change the alignment of a specific model. Key to this methodology is a novel simple measure, the Alignment Compliance Index (ACI), that quantifies how effectively a LLM can be aligned to a given preference function or gold standard. Since the ACI measures the effect rather than the process of alignment, it is applicable to alignment methods beyond the in-context learning used in this study. Using a dataset of simulated patient pairs, three frontier LLMs (GPT4o, Claude 3.5 Sonnet, and Gemini Advanced) were assessed on their ability to make triage decisions consistent with an expert clinicians preferences. The models performance before and after alignment attempts was evaluated using various prompting strategies. The results reveal significant variability in alignment effective- ness across models and alignment approaches. Notably, models that performed well, as measured by ACI, pre-alignment sometimes degraded post-alignment, and small changes in the target preference function led to large shifts in model rankings. The implicit ethical principles, as understood by humans, underlying the LLMs decisions were also explored through targeted questioning. These findings highlight the complex, multifaceted nature of decision-making and the challenges of robustly aligning AI systems with human values. They also motivate the use of a practical set of methods and the ACI, in the near term, to understand the correspondence between the variety of human and LLM decision-making values in specific scenarios.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating the clinical utility of hand performance information from at-home egocentric video in outpatient neurorehabilitation\nAbstract: Background: Restoring hand function is a primary focus of neurorehabilitation after stroke and spinal cord injury. However, monitoring hand use outside the clinic remains challenging. We developed a clinical decision support system (CDSS) using egocentric video to provide therapists with information about their patients' hand use at home and evaluated its clinical utility. Methods: Five patient-therapist dyads were recruited. Patient-participants recorded activities of daily living using head-mounted cameras. Dashboards presenting processed video data were generated for each patient. Therapists reviewed the dashboard created for their patient and participated in semi-structured interviews and structured questionnaires. A mixed-methods approach with thematic analysis was used to evaluate the CDSS's clinical usefulness. Results: Four themes emerged: (1) Data Interpretation Preferences, (2) Bridging the Clinic-Home Divide, (3) Tailoring Therapy Through Home Observations, and (4) Practical Realities of Implementation. Therapists strongly preferred video footage over graphical data, valuing its rich insights into their patients' real-world activities. The CDSS was perceived as useful for understanding patient performance at home and potentially influencing therapy planning. Conclusions: This study demonstrates the potential of using egocentric video to inform clinical decision-making in neurorehabilitation. Therapists found the system useful, particularly for assessing performance in naturalistic settings, but voiced concerns about workflow integration. Despite challenges, therapists across technical familiarity levels expressed trust in the system and willingness to use it regularly, indicating it could enhance their ability to tailor therapy plans to patients' real-world activities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Design Approaches for Developing Quality Checklists in Healthcare Organizations: A Scoping Review.\nAbstract: Quality checklists have demonstrated benefits in healthcare and other high-reliability organizations, but there remains a gap in the understanding of design approaches and levels of stakeholder engagement in the development of these quality checklists. This scoping review aims to synthesize the current knowledge base regarding the use of various design approaches for developing quality checklists in healthcare. Secondary objectives are to explore theoretical frameworks, design principles, stakeholder involvement and engagement, and characteristics of the design methods used for developing quality checklists. The review followed the Preferred Reporting Items for Systematic Reviews 2020 checklist. Seven databases (PubMed, APA PsycInfo, CINAHL, Embase, Scopus, ACM Digital Library, and IEEE Xplore) were searched for studies using a comprehensive search strategy developed in collaboration with a health sciences librarian. Search terms  included \"checklist\"  and \"user-centered design\" and their related terms. The IAP2 Spectrum of Participation Framework was used to categorize studies by level of stakeholder engagement during data extraction. Twenty-nine studies met the inclusion criteria for this review. Twenty-three distinct design methods were identified that were predominantly non-collaborative in nature (e.g., interviews, surveys, and other methods that involved only one researcher and one participant at a given time). Analysis of the levels of stakeholder engagement revealed a gap in studies that empowered their stakeholders in the quality checklist design process. Highly effective, clear, and standardized methodology are needed for the design of quality checklists. Future work needs to explore how stakeholders can be empowered in the design process, and how different levels of stakeholder engagement might impact implementation outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and Mortality Trends of Hypertension Subtypes Among US Adults\nAbstract: Hypertension (HTN) has been demonstrated as one of the leading risk factors for development of cardiovascular disease (CVD) and CVD mortality. This study examines the prevalence and distribution of HTN subtypes (isolated diastolic hypertension [IDH], isolated systolic hypertension [ISH], and systolic-diastolic hypertension [SDH]) across age, sex, and race/ethnicity per the nationally representative National Health and Nutrition Examination Survey (NHANES) from 1999 to 2018 based on the updated 2017 ACC/AHA HTN definition and their association with CVD and all-cause mortality. Among US adults, the overall prevalence of HTN is 41.1%. Across increasing age, the prevalence of IDH decreased, ISH increased, and SDH increased and peaked in the 6th decade of life after which SDH prevalence decreased. By age 80, over 80% of persons with HTN demonstrated ISH. A sub-cohort from NHANES 1999-2008 with follow-up until 2018 showed that ISH and SDH were most strongly associated with increased risk for CVD (HR 1.20 and 1.37, p<0.01, respectively) and all-cause mortality (HR 1.17 and 1.21, p<0.01, respectively). Our data demonstrate the continuing importance of HTN subtype transitions across age and their differences in predicting future CVD and total mortality.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence and Trends in Cardiovascular Risk Factors Among Middle Aged Persons from Five Race and Ethnic Groups in the United States: A Longitudinal Analysis of Two Cohort Studies\nAbstract: Importance: It is well established that people of South Asian background have a high burden of atherosclerotic cardiovascular disease (ASCVD). However, few studies have comprehensively examined if South Asian adults in the United States (US) develop cardiovascular risk factors at younger ages than adults from other race and ethnic groups. Objective: To compare the prevalence and change in ASCVD risk factors across age strata by race and ethnic group. Design: We combined data from the Mediators of Atherosclerosis in South Asians Living in America (MASALA) and the Multi-Ethnic Study of Atherosclerosis (MESA) cohort studies. Longitudinal data from all eligible participants at all available exam visits were used to estimate the prevalence of risk factors at ages 45 and 55 years for each race and ethnic group. Setting: Multicenter longitudinal cohort study in 7 field centers across the U.S. Participants: The baseline study sample included individuals free of clinical ASCVD; 554 South Asians, 796 White, 588 Black, 517 Hispanic/Latino, and 245 Chinese adults aged 45-55 years were included. Exposures: Self-identified race (Black, Chinese, South Asian, or White) or ethnic group (Hispanic/Latino). Main Outcome(s) and Measure(s): Prevalence of clinical (prediabetes & diabetes, hypertension, dyslipidemia, BMI) and behavioral (diet quality, alcohol use, exercise) ASCVD risk factors at age 45 and age 55. Results: At age 45, South Asian men and women had the highest prevalence of pre-diabetes and diabetes and higher prevalence of hypertension compared to White, Chinese, and Hispanic/Latino men and women. South Asian men had a higher prevalence of dyslipidemia than White, Chinese, and Black men, and South Asian women had a higher prevalence than Chinese and Black women. All groups had worse diet quality than South Asian men and women at age 45, and most also had higher rates of alcohol use. Conclusions and Relevance: We observed significant differences in the prevalence of risk factors for South Asian adults compared to adults from other U.S. race and ethnic groups at age 45 years. Understanding trends and disparities in cardiovascular risk and protective factors across the life course can help equitably improve prevention and treatment strategies for US populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PTSD-related differences in resting-state functional connectivity and associations with sex hormones\nAbstract: Background: Posttraumatic stress disorder (PTSD) is a debilitating condition that disproportionately impacts individuals who are female. Prior research indicates that males with PTSD exhibit hypoconnectivity of frontal brain regions measured with resting electroencephalography (EEG). The present study examined functional connectivity among females with PTSD and trauma-exposed controls, as well as the impact of sex hormones. Methods: Participants included 61 females (Mage = 31.41, SD = 8.64) who endorsed Criterion A trauma exposure. Resting state EEG data were recorded for five minutes in the eyes open position. Using a Linear Mixed Effects model, paired region-of-interest power envelope connectivity of the theta band (4-7 Hz) served as the response variables. Results: Compared to controls, the PTSD group displayed hyperconnectivity between visual brain regions and the rest of the cerebral cortex (pFDR < 0.05). Additionally, participants with PTSD demonstrated enhanced connectivity between the default mode network and frontoparietal control network compared to controls (pFDR < 0.05), as well as increased connectivity between the ventral attention network and the rest of the cerebral cortex (pFDR < 0.05). Estradiol was associated with higher connectivity, while progesterone was associated with lower connectivity, but these did not survive correction. Conclusions: Results are consistent with prior research indicating that PTSD is associated with altered connectivity in visual brain regions, which may reflect disrupted visual processing related to reexperiencing symptoms (e.g., intrusive memories). Our findings provide additional support for the relevance of the theta frequency range in PTSD given its role in fear learning and regulation processes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: COMET-LF: A Compartmental Model of Dynamics of Infection, Disease, and Elimination Strategies for Lymphatic Filariasis\nAbstract: Lymphatic filariasis (LF) is a mosquito-borne neglected tropical disease (NTD) caused by filarial worms. India accounted for 55% of the global population at risk of LF in 2021. The World Health Organization (WHO) has targeted LF elimination by 2030; however, India aims to achieve LF elimination prior to the global WHO NTD target. Mathematical models are useful tools to evaluate and guide elimination strategies. We propose a new compartmental model - COmpartmental Modelling of Elimination strategies and Transmission of Lymphatic Filariasis (COMET-LF) - to assess the impact of mass drug administration (MDA) on LF elimination. Our model incorporates drug efficacy data from a clinical trial and generates estimates of disease (lymphoedema and hydrocele) prevalence. The model is calibrated to publicly available microfilaria (Mf) and disease prevalence data (2008-2013) from Bihar, India. Predictions of the number of MDA rounds needed for achieving the elimination threshold were generated for various endemic scenarios. The projected estimates were compared with established micro - (LYMFASIM) and macro - (EPIFIL) simulation models for LF transmission. Disease burden estimates and the impact of MDA on disease burden were generated using COMET-LF for different endemic scenarios. Our simulations suggest that the disease burden reduces over much longer timescales - ~20 years for a reduction of 8%-11.5% following 5 rounds of MDA. We extended COMET-LF to a meta-population model to investigate the role of migration among neighbouring regions on elimination and resurgence probabilities. We found that high Mf prevalence in the spatial neighbourhood can increase the number of required MDA rounds for elimination up to 3 additional rounds for the two-drug regimen. Furthermore, we assess the impact of migration on the resurgence probability in a non-endemic region which is spatially adjacent to a high-Mf prevalence region and show that there is a  significant risk of resurgence if Mf prevalence exceeds 5%. Our model can be easily tailored to specific blocks and districts to guide programmatic intervention for disease management and LF elimination.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Identification of genetic variants and their causal association underlying autism spectrum disorder\nAbstract: Abstract Background: Autism spectrum disorder (ASD) is an early-onset neurodevelopmental disorder with a complex genetic architecture characterized by persistent deficits in social communication and social interaction along with restricted and repetitive behavior patterns, interests and activities. Over the years its prevalence has increased and affects 1% children globally. Etiology of ASD is remained unclear, but it is well recognized as a complex disorder involving interactions of several genes and environmental risk factors. Studies signify the role of whole exome sequencing in identifying rare genetic variation related to neurodevelopmental disorders and have greatly improved the chance of identifying known as well as novel responsible genes. This study aimed to identify genetic variant in a patient affected with autism spectrum disorder. Methods: A male patient of age range 0-5 years was investigated and identified according to DSM-5 criteria for autism spectrum disorder. Peripheral blood sample was collected followed by genomic DNA extraction and whole exome sequencing. The functional impact of variant, gene interaction network and pathway enrichment analysis were done using in silico tools and databases. Results: Two heterozygous missense variants one in SHANK2 (c.401C>G) another in CSNK2A1 (c.572G>A) were identified. Both of these variants were predicted to be deleterious by pathogenicity prediction tool. Gene interaction network and pathway enrichment analysis revealed the involvement of SHANK2 and CSNK2A1 in various biological pathways such as protein binging, synaptogenesis, chromosome condensation and cell cycle regulation. Conclusion: This study revealed a novel SHANK2 variant along with a known CSNK2A1 variant that expands the spectrum of genetic variants related to autism spectrum disorder and further enhances the understanding of the molecular mechanism underlying SHANK2 and CSNK2A1 pathophysiology.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Interplay Between White Matter Hyperintensities and Alzheimer Disease: A Brain-Body Perspective\nAbstract: MRI-detected white matter hyperintensities (WMH) are often recognized as markers of cerebrovascular abnormalities, an index of vascular brain injury, and are frequently present in individuals with Alzheimer disease (AD). Given the emerging bidirectional communication between the brain-body axis in both WMHs and AD, it is important to understand their genetic underpinnings across the whole body. However, literature on this is scarce. We investigated the brain-body axis by breaking down heritability estimates of these phenotypes across the whole body, i.e., partitioning heritability. Our aims were to identify genetic underpinnings specific to WMHs, and common between WMHs and AD, by assessing (a) the partitioned heritability of WMHs and AD across the brain-body axis with tissue-specific annotations, (b) the partitioned heritability of WMHs and AD across the brain-body axis with cell-specific annotations, and (c) the genes associated with WMHs and AD, and verifying their expression levels across the whole body. Our tissue-specific analysis revealed that WMH-associated SNPs were significantly enriched in tissues beyond the brain, namely liver, cardiovascular, and kidney with liver being a common tissue enriched for both WMHs and AD. Our cell-specific analysis showed enrichment of vascular endothelial cells across the tissue types enriched for WMHs, highlighting their central role in the development of WMHs. Additionally, our gene-level analysis highlighted overlapping patterns of tissue enrichment for both WMHs and AD, and showed interactions between WMH and AD associated genes. Our findings provide new insights into the systemic influences potentially contributing to WMH pathology, in particular, multi-system endothelial disorder. We hope that our multisystemic genetic findings will stimulate future WMH-research into specific pathways across the brain-body axis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Resolution of SLC6A1 variable expressivity in a multi-generational family using deep clinical phenotyping and Drosophila models\nAbstract: Variants of uncertain significance pose a difficult diagnostic and therapeutic problem, even when the candidate gene has previously been associated with Mendelian disease. Variants in SLC6A1 result in a rare neurodevelopmental disorder characterized by a variable clinical presentation of symptoms including developmental delay, epilepsy, motor dysfunction, and autism spectrum disorder. SLC6A1 encodes the {gamma}-aminobutyric acid (GABA) transporter (GAT-1) protein that is responsible for the reuptake of GABA from the synapse to maintain homeostasis of excitatory and inhibitory neurotransmitters. SLC6A1 haploinsufficiency has been confirmed as the predominant pathway of SLC6A1-related neurodevelopmental disorders, however, the molecular mechanism underlying the variable presentation of clinical features remains unclear. Here, through work of the Undiagnosed Diseases Network, we identify an undiagnosed individual with an inherited p.(A334S) variant of uncertain significance. Pedigree analysis identifies variable symptoms between family members with the same variant. To resolve this case, we first compare proband phenotypes to a cohort of cases diagnosed with SLC6A1-related neurodevelopmental disorders and find significant symptom overlap. We then functionally compare this variant to other variants by creating an allelic series in the fruit fly Drosophila melanogaster. We identify phenotypes in flies expressing SLC6A1 variants consistent with a loss-of-function mechanism and conclude that the p.(A334S) variant is a hypomorphic allele. Through clinical and functional genomics, we begin to elucidate the underlying variability in SLC6A1-neurodevelopmental disorders. These insights will inform clinical diagnosis, prognosis, treatment planning, and aid in the design of targeted therapeutics for those living with SLC6A1-related neurodevelopmental disorders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Evaluating large language model workflows in clinical decision support: referral, triage, and diagnosis\nAbstract: Accurate medical decision-making is critical for both patients and clinicians. Patients often struggle to interpret their symptoms, determine their severity, and select the right specialist. Simultaneously, clinicians face challenges in integrating complex patient data to make timely, accurate diagnoses. Recent advances in large language models (LLMs) offer the potential to bridge this gap by supporting decision-making for both patients and healthcare providers. In this study, we benchmark multiple LLM versions and an LLM-based workflow incorporating retrieval-augmented generation (RAG) on a curated dataset of 2,000 medical cases derived from the Medical Information Mart for Intensive Care database. Our findings show that these LLMs are capable of providing personalized insights into likely diagnoses, suggesting appropriate specialists, and assessing urgent care needs. These models may also support clinicians in refining diagnoses and decision-making, offering a promising approach to improving patient outcomes and streamlining healthcare delivery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Outcome of Graves' Disease and Associated Genetic Predisposition: A Systematic Review of Literature\nAbstract: Background: Graves' disease (GD) is an autoimmune hyperthyroidism that primarily affects the thyroid gland. The susceptibility, activity, and risk of recurrence of GD may be influenced by various genetic factors, which can interact with environmental triggers to precipitate disease relapse. This review examines the literature on the genetic predisposition to GD recurrence. Methods: Literature from PubMed, EBSCOhost, and SCOPUS were searched. Three reviewers performed study selection and critical appraisal. Result: Five studies were selected. The literature indicates a risk of relapse in PTPN22, CTLA-4, TSH-R, IL-21, KREC, and HLA gene abnormalities. Conclusion: Several genes are associated with GD relapse. However, predicting relapse risk requires consideration of multiple factors beyond genetic predisposition.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cognitively healthy young adults with APOEe4 gene show disrupted functional connectivity of graph properties in multiple resting-state networks\nAbstract: The apolipoprotein (APOE) e4 allele is associated with brain changes in healthy carriers that are similar to changes observed in patients with Alzheimers Disease, including abnormalities in functional connectivity. The trajectory of these changes across the lifespan, specifically in early adulthood is still not clear. This study explores the link between the APOE genotype and functional connectivity in 129 cognitively healthy Chinese Han college students (aged 17-22 years). By using graph theory, we assessed the connectivity in seven resting-state networks of interest using three different thresholding methods and three different forms of network parcellation. Average Path Length and Closeness Centrality were disrupted in e4 carriers in the sensorimotor, visual, salience, and Default Mode salience networks; with effects replicated using different thresholding but not different parcellation methods. This study demonstrated the genetics-related vulnerability in the brain of young APOEe4 carriers across multiple resting-state networks.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Southern African Map of Blood Regulatory Variation Enables GWAS Interpretation\nAbstract: Functional genomics resources are critical for interpreting human genetic studies, however they are predominantly from European-ancestry individuals. Here we present the Southern African Blood Regulatory (SABR) resource, a map of blood regulatory variation that includes three South Eastern Bantu-speaking groups. Using paired whole genome and blood transcriptome data from over 600 individuals, we map the genetic architecture of 40 blood cell traits derived from deconvolution analysis, as well as expression, splice, and cell type interaction quantitative trait loci. We comprehensively compare SABR to the Genotype Expression (GTEx) Project and characterize the thousands of African-enriched and African-specific regulatory variants mapped. Finally, we demonstrate the increased utility of SABR for interpreting African association studies by identifying putatively causal genes and molecular mechanisms through colocalization analysis of 83 blood-relevant traits from the PAN-UK Biobank. Importantly, we make full SABR summary statistics publicly available to support the African genomics community.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: PP mediated the relationship between METS-IR and AIS in non-diabetic patients\nAbstract: Background: The correlation between metabolic score for insulin resistance (METS-IR) and high insulin normal glucose clamp test is stronger than other non-insulin-based insulin resistance scores. Insulin resistance was related to the occurrence and development of hypertension and stroke, however, the association between METS-IR and hypertension, as well as ischemic stroke is lack of evidence. This study aimed to determine the association between METS-IR and acute ischemic stroke in non-diabetic patients, and the mediating role of blood pressure parameters on it. Methods: This hospital-based study included 557 non-diabetic subjects diagnosed with premature acute ischemic stroke. Logistic regression models and mediation analyses were conducted to assess the role of blood pressure parameters (systolic blood pressure, diastolic blood pressure, pulse pressure and mean arterial pressure) in the associations between METS-IR and risk of acute ischemic stroke. Results: After adjusting for potential covariates, each SD increment of METS-IR was associated with 26% higher odds (OR = 1.26, 95% CI: 1.06-1.52) increment in ORs of acute ischemic stroke. The OR for acute ischemic stroke in patients with highest quartile of METS-IR was 1.73 hold (OR = 1.73, 95% CI: 1.12-2.70) higher than that in those with the lowest quartile of METS-IR. Furthermore, mediation analyses indicated that pulse pressure partially mediate the detrimental effect of insulin resistance (assessed by the METS-IR) on acute ischemic stroke (mediation percentage: 11.70%). Conclusions: Our study suggests a relationship between METS-IR and acute ischemic stroke, and the association of METS-IR with acute ischemic stroke was partially mediated by pulse pressure.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Predicting Mobile Health Clinic Utilization for COVID-19 Vaccination in South Carolina: A Statistical Framework for Strategic Resource Allocation\nAbstract: Background: Mobile health clinics (MHCs) are effective tools for providing health services to disadvantaged populations, especially during health emergencies. However, patient utilization of MHC services varies substantially. Strategies to increase utilization are therefore needed to maximize the effectiveness of MHC services by serving more patients in need. The purpose of this study is to develop a statistical framework to identify and prioritize high-risk communities for delivery of MHCs during health emergencies. Methods: Prisma Health MHCs delivered COVID-19 vaccines to communities throughout South Carolina between February 20, 2021, and February 17, 2022. In this retrospective study, we use generalized linear mixed effects model and ordinal logistic regression model to identify factors associated with, and predict, MHC utilization for COVID-19 vaccination by census tract. Results: The MHCs conducted 260 visits to 149 sites and 107 census tracts. The site-level analysis showed that visits to schools (RR=2.17, 95% CI=1.47-3.21), weekend visits (RR=1.38, 95% CI=1.03-1.83), and visits when the resources were limited (term 1: 7.11, 95% CI=4.43-11.43) and (term 2: 2.40, 95% CI=1.76-3.26) were associated with greater MHC utilization for COVID-19 vaccination. MHC placement near existing vaccination centers (RR=0.79, 95% CI=0.68-0.93) and hospitals (RR=0.83, 95% CI=0.71-0.96) decreased utilization. Predictive models identified 1,227 (94.7%) census tracts with more than 250 individuals per MHC visit when vaccine resources were limited. Predictions showed satisfactory accuracy (72.6%). The census tracts with potential of high MHC demand had higher adolescent, 30-44 years old, non-White populations, lower Primary Care Practitioners per 1,000 residents, fewer hospitals, and higher cumulative COVID-19 emergency department visits and deaths (compared to census tracts in the low MHC demand category). After the vaccines became widely available, the demand at MHCs declined. Conclusion: These study findings can be used to improve MHC allocation by identifying and prioritizing medically underserved communities for strategic delivery of these limited resources.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Socioeconomic inequalities and diabetes complications: An analysis of administrative data from Hungary\nAbstract: Background. Diabetes complications are associated with increased healthcare costs and worsened patient outcomes. In this paper we analyze how individual-level demographic and territorial-level socioeconomic and healthcare variables influence the presence and severity of diabetes complications and their relationship with mortality. Methods. Our study utilizes anonymized administrative data from Hungary, containing outpatient and inpatient records of all diabetes patients between 2010 to 2017. We construct settlement-year level and individual-year level panel datasets to analyze diabetes prevalence, incidence and complications, employing Poisson and logit models to explore associations between complications and the explanatory variables. The adapted Diabetes Complications Severity Index (aDCSI) is employed to quantitatively evaluate the severity of complications by aggregating individual complication scores from ICD-10 diagnosis codes. Results. Diabetes prevalence and incidence are higher in settlements with above-median unemployment rates, where patients exhibit more severe complications, as shown by higher average aDCSI scores. Among socioeconomic factors, unemployment rate is particularly associated with increased aDCSI scores, while better healthcare access is associated with lower aDCSI scores in unadjusted but with higher scores in adjusted models. The presence and severity of complications, especially renal, cardio-vascular and peripheral vascular ones, substantially increase five-year inpatient mortality. Most of the mortality difference by settlement-level unemployment rate disappears when complications are accounted for. Conclusions. Territorial-level socioeconomic disparities, especially elevated unemployment rates, significantly exacerbate the severity of diabetes complications, which subsequently heightens the mortality risk among diabetic patients. Enhancing health-care access in lower socioeconomic regions may alleviate these disparities and lessen the impact of complications.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Remote cognitive tests predict neurodegenerative biomarkers in the Insight 46 cohort\nAbstract: BACKGROUND: Alzheimer's disease-related biomarkers detect pathology years before symptoms emerge, when disease-modifying therapies might be most beneficial. Remote cognitive testing provides a means of assessing early changes. We explored the relationship between neurodegenerative biomarkers and cognition in cognitively normal individuals. METHODS: We remotely deployed 13 computerised Cognitron tasks in 255 members of the Insight 46 study. We generated whole brain, hippocampal and white matter hyperintensity volumes at ages 69-73, rates of change over two-years, amyloid load and positivity. We examined the relationship between Cognitron, biomarkers, and standard neuropsychological tests. RESULTS: Slower response time on a delayed recognition task predicted amyloid positivity (OR=1.79,CI:1.15, 2.95). Brain and hippocampal atrophy rates correlated with poorer visuospatial performance (b=-0.42, CI:-0.80, -0.05) and accuracy on immediate recognition (b=-0.01, CI:-0.01, -0.001), respectively. Standard tests correlated with Cognitron composites (rho=0.43, p<0.001). DISCUSSION: Remote computerised testing correlates with standard supervised assessments and holds potential for studying early cognitive changes associated with neurodegeneration.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Trends in Intervention Modality for Hospitalizations with Infectious Intracranial Aneurysms: A Nationwide Analysis\nAbstract: Background/Objective: Data regarding treatment of infectious intracranial aneurysms most effectively remains sparse. With growing utilization of endovascular therapy for cerebrovascular disease, we examined trends in endovascular versus neurosurgical treatment of infectious aneurysms and investigated the impact of treatment modality on outcomes. Methods: Using data from the National Inpatient Sample from 2000 to 2019, we conducted a trends analysis on rates of treatment modalities among hospitalizations with infective endocarditis with ruptured or unruptured cerebral aneurysms. Treatment modalities were categorized as endovascular versus open neurosurgical repair based on ICD-9 and ICD-10 codes. Logistic regressions were utilized to assess the association between treatment modality and the outcomes of in-hospital mortality and discharge disposition. Results: We identified 24,461 hospitalizations with an infectious intracranial aneurysm in the setting of infective endocarditis. Mean age was 56.0 years (SD, 17.8) and 61.8% were male. The overall rate of intervention was 5.8% (95% CI, 5.0-6.5%), and this did not change over time (p=0.669). There was a significant increase in the rate of endovascular repair (APC=3.6%; 95% CI, 1.2%-8.1%) and a significant decrease in the rate of open neurosurgical repair (APC= -5.4%; 95% CI, -8.1% to -3.5%). Treatment modality was not associated with in-hospital mortality (p=0.698) or non-home discharge disposition (p=0.897). Conclusion: Although rates of infectious intracranial aneurysm intervention for infective endocarditis did not change, utilization of endovascular treatment increased while the use of open neurosurgical treatment decreased. Further directions include elucidating predictors of favorable outcomes for undergoing intervention and the most beneficial timing for the procedure during hospitalization.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Common pathogenic mechanisms for COVID-19 and differentiated thyroid cancer: a proteomic analysis\nAbstract: Background: Previous studies have proved that viral infection might have potential associations with differentiated thyroid cancer. COVID-19 has spread to hundreds of millions of individuals since Dec 2019. This study aimed to investigate the common pathogenic mechanisms of differentiated thyroid cancer and SARS-CoV-2 infection in thyroid tissues. Methods: The proteomic profiles of COVID-19 and differentiated thyroid cancer were downloaded from iProx database and were analyzed for differentially expressed proteins. After the common proteins were identified using the Venn diagram, gene ontology and pathway enrichment analysis were performed. Subsequently, a protein-protein interaction network was constructed and hub genes were identified with eight algorithms. The diagnostic performance of hub genes was tested with the receiver operator characteristics curve. The associations between hub genes and diseases were evaluated with the Comparative Toxicogenomics Database. Results: Forty-nine common differentially expressed proteins were identified. Functional analysis revealed that the metabolism and transport of lipid and cholesterol and coagulation process were the main common biological activities affected by the two diseases. In addition, twelve genes, including AGT, AHSG, APOA2, APOM, C3, GC, ITIH2, KNG1, SERPINA1, SERPINC1, TF and TTR, were identified as the hub genes. These genes could serve as diagnostic markers for COVID-19 and differentiated thyroid cancers. Conclusion: The current study revealed common pathogenic mechanisms of COVID-19 and differentiated thyroid cancer. The concomitant infection of SARS-CoV-2 might exert adverse effects on patients with thyroid cancers.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The effect of trauma quality improvement programme implementation on quality of life among trauma patients in urban India\nAbstract: Trauma accounts for around 4.4 million deaths annually and is among the leading causes of death, disproportionately affecting low- and middle-income countries. Trauma quality improvement programmes may reduce adverse patient outcomes but lack robust evidence. This study assessed the effect of implementing a trauma quality improvement programme using audit filters on health-related quality of life in adult trauma patients in urban India. We conducted a controlled interrupted time series study (ClinicalTrials.gov ID NCT03235388) across four tertiary care university hospitals. Adult ([&ge;]18 years) trauma patients, who were alive at 90 days post-admission, were included. After a 14-month observation phase, two hospitals were randomized to the intervention arm and implemented the trauma quality improvement programme, while two control hospitals did not implement any interventions. The study spanned from 2017 to 2022. Health-related quality of life was assessed 90 days post-admission using the EuroQol 5-dimensions (EQ-5D) questionnaire. The main outcome was EQ-5D health status, scaled from 0 to 100, analyzed using a difference-in-differences (DiD) approach. Descriptive analysis was performed for the five individual EQ-5D dimensions. 2307 participants were eligible for the analyses. The DiD analysis showed a statistically significant reduction in the EQ-5D health status score in the intervention arm (DiD estimate -4.07 [95% CI: -7.00; -1.15]). For the 819 patients with major trauma, there was a more pronounced, but statistically insignificant reduction (DiD estimate -4.86 [95% CI: -9.87; 0.15]). In the intervention arm, mobility, self-care, and pain/discomfort improved, while usual activities and anxiety/depression worsened. Implementing trauma quality improvement programmes using audit filters may reduce the average health-related quality of life of trauma patients if more severely injured patients survive, highlighting the importance of assessing quality of life after the implementation of such programmes and ensuring adequate rehabilitation resources to support long-term recovery.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessment of Health-Related Quality of Life (HRQoL) of Type 2 Diabetic Patients in Ghana\nAbstract: Background: Over the last decades, non-communicable diseases such as diabetes have remarkably increased due to rapid urbanization, unhealthy lifestyles, and aging. The World Health Organization (WHO) indicates that the diabetes epidemic will continue in the coming decades, yielding enormous human and economic costs around the world. This study aims at accessing the health-related Quality of Life (QoL) of Type 2 Diabetic Patients in Ghana. Method: This was a hospital-based cross-sectional descriptive study conducted in the 3 regions in Ghana among 1194 patients with type 2 diabetes who were seeking healthcare at the regional hospitals of the selected regions for at least 12 months. A multi-stage sampling technique was used in recruiting the participants. The WHOQOL-BREF tool was adopted to assess the health-related QoL of diabetic patients. Data was analyzed using STATA version 16.1, and the findings were presented in the tables. Statistical significance was set at (P < 0.05). Results: Out of the 1194 participants, 90% (1079) reported a satisfactory quality of life. The majority (60.3%) of participants were above 50 years of age. The overall mean score of the QoL was 6.25 (1.28) for all four domains: psychological, physical, social, relationship, and environmental health. Marital status, occupational status, and self-reported health status predicted overall QOL. Males have a better quality of life than females, and those below 50 also have a better quality of life than those above 50. Similarly, those employed had a better quality of life than the unemployed; however, those who were married, unmarried, educated, and non-educated had no significant differences in their quality of life. Sex was associated with all the domains. Marital status was associated with the environmental, social, and psychological domains. Age was associated with psychological and physical domains. On predictors of quality of life, all demographic variables (age, sex, educational status, marital status, and employment status) predicted quality of life across all domains. Conclusion: This study provided valuable insights on predictors of health-related QoL among type 2 diabetic patients in Ghana, which would guide policymakers, healthcare providers, and stakeholders in improving diabetes management and ultimately enhancing the quality of life for individuals living with diabetes in Ghana. Evidence-based interventions should be implemented to address the factors influencing the QoL of diabetic patients in Ghana. Keywords: Health-Related, Quality of Life (QoL), Type 2 Diabetic, Ghana\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Investigating the integration of sustainable food initiatives in healthcare institutions in Ontario, Canada: A grey literature scoping review protocol\nAbstract: Introduction The climate emergency and other sustainability challenges interact to threaten human and planetary health. Efforts to improve the sustainability of food initiatives within healthcare institutions could mitigate these threats by addressing the four pillars of sustainability: health, social, economic, and environmental. Understanding current initiatives to incorporate sustainability into food programs and the sustainability pillars that guide those initiatives is important to inform priorities for action. This scoping review was undertaken to investigate the extent to which major healthcare institutions in Ontario, Canada, have publicly committed to, discussed, planned, and/or implemented sustainable food initiatives. Methods and Analysis Steps are based on guidance from the Joanna Briggs Institute and Arksey & O'Malley. First, the current strategic plans of 57 healthcare institutions in Ontario, Canada, will be retrieved from their websites and used to examine whether they include any commitments to or discussion, planning, and/or implementation of relevant initiatives. The healthcare institution websites, along with those of selected sustainability organizations, will be searched for grey literature from 2015 to 2024 describing sustainable food initiatives within these institutions. Documents will be screened for eligibility by two researchers. Data related to the incorporation of sustainable food into institutional food programs, and the sustainability pillars addressed, will be extracted by one researcher, with 10% of entries verified by a second researcher. The data will be synthesized to summarize publicly reported progress toward integrating sustainable food into healthcare institutions. Ethics and Dissemination This review will use publicly available grey literature with no expectation of privacy and no research participants; therefore, no ethics clearance is required. Results will be shared with stakeholders in sustainability organizations, as well as at relevant conferences and in peer-reviewed journals, such as the Healthy Cities Conference and the Journal of Canadian Food Studies. Keywords or Phrases Climate resilient healthcare; Malnutrition; Planetary health; Sustainable diet This protocol is registered on the Open Science Framework and can be accessed at the following URL: https://doi.org/10.17605/OSF.IO/CU9P6\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The extraordinarily long lead times of screen-detected lung cancer in never-smokers\nAbstract: ABSTRACT Background The randomized trials of low dose computed tomography (LDCT) screening enrolled individuals at high risk of lung cancer: heavy cigarette smokers. Nevertheless, opportunistic screening of never smokers has become commonplace in certain regions of East Asia. Lung cancer detection rates reported for this low-risk group regularly exceed those reported in the randomized trials. We sought to determine the lead time, the length of time between screen detection and when symptoms would manifest (clinical presentation) associated with LDCT detection rates reported in Taiwan. Objective To estimate the lead time for LDCT lung cancer detection in never smoking Taiwanese females, under the assumption that all detected cancers progress. Methods We analyzed data from the Taiwan Lung Cancer Screening in Never-Smoker Trial (TALENT), a prospective cohort of 12000~ never smokers aged 55 to 75, and compared age-specific screen detection rates to lung cancer incidence rates in the pre-screening period. Lead time was estimated using Morrison's approximation: one-half the ratio of screen detection to pre-screening incidence. Results: Invasive lung cancer detection rates in non-smoking females were 18 (age 70-74) to 37 (age 55-59) times higher than the respective age-specific lung cancer incidence rates prior to widespread screening. The estimated lead times for invasive lung cancers thus ranged from 9 (age 70 to 74) to 18.5 years (age 55 to 59). Had we included in situ lung cancer detection, the estimated lead time of screening would range from approximately 10 to 20 years. Conclusion If all detected cancers progress, the lead times for LDCT lung cancer detection in never smokers would be 5 to 20 times longer than that reported in the randomized trials of heavy smokers (1 to 2 years). Such extended lead times are not only undesirable (Why label and treat a patient for a cancer not destined to clinically present in the next 1 or 2 decades?), but also a major source of overdiagnosis, providing plenty of time for a patient to die from other causes before developing a symptomatic cancer (Type 1 overdiagnosis). Furthermore, some screen-detected cancers may not progress and thus have an infinite lead time (Type 2 overdiagnosis). Regardless, it appears that substantial overdiagnosis has occurred in screening low-risk, never smoking individuals.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Early child development in England: cross-sectional analysis of ASQ(R)-3 records from the 2-21/2-year universal health visiting review using national administrative data (Community Service Dataset, CSDS)\nAbstract: Introduction The Ages & Stages Questionnaire 3rd Edition (ASQ(R)-3) is a tool to measure developmental delay for children aged between 1 - 66 months originally developed in the United States. This measure has been collected in England since 2015 as a part of mandated 2-2[1/2]-year health visiting reviews and collated nationally in the Community Services Dataset (CSDS). CSDS is known to be incomplete and to-date there have not been any published analyses of ASQ(R)-3 held within CSDS. Objectives We aimed to a) identify a subset of complete child development data for children aged two in England using ASQ(R)-3 data in CSDS between 2018/19-2020/21; b) use this subset of data to analyse child development age 2-2[1/2] years in England. Methods We compared counts of ASQ(R)-3 records in CSDS by local authority and financial quarter against national, publicly available health visiting metrics to identify local authorities with complete ASQ(R)-3 records in CSDS. We described child development in this subset of the data using both a binary cut-off of whether a child reached expected level of development and the continuous ASQ(R)-3 score. Results Among the 226,505 children from 64 local authorities in our sample with complete ASQ(R)-3 records, 86.2% met expected level of development. Children from the most deprived neighbourhoods (82.6%), children recorded as Black (78.9%), and boys (81.7%) were less likely to meet expected level of development. Conclusions To fully understand child development in England, the completeness of ASQ(R)-3 data in the CSDS requires improvement. Second, to interpret the national CSDS data on child development, ASQ(R)-3 should be standardised and validated in an English context. Developmental support is needed for at least 13.8% of the children who did not meet the expected level of development, in particular children living in the most deprived neighbourhoods, those with Black ethnicity, and boys. Key words Child development, early years, Ages and Stages Questionnaire, health visiting, Community Service Dataset\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Validity and reliability of the Hypersensitive Narcissism Scale in China\nAbstract: Background: Wink distinguishes between explicit and implicit narcissism, the latter being hypersensitive narcissism, which manifests itself as outward humility and inhibition masking an underlying pompous outlook and sense of entitlement. Early measures of hypersensitive narcissism used Murray's Narcissism Scale, which was explored by measuring the narcissism levels of Harvard undergraduates. Hendin and Cheek subsequently developed the Hypersensitive Sensitive Narcissism Scale based on this narcissism scale. In addition to this, there are few ways to measure vulnerability-sensitive narcissism, and Chinese measurement tools on narcissism mainly measure explicit narcissism, neglecting to accurately measure vulnerability-sensitive narcissism, and failing to completely respond to an individual's implicit narcissistic traits. Aim: The hypersensitive narcissism scale was applied to college students to explore the factor structure of the scale under the background of Chinese culture, and to test its reliability and validity. Methods 1000 questionnaires were distributed to college students, and 912 valid questionnaires were collected. Self-Esteem Scale, Aggression Scale and Narcissism subscale of Dark Triad Scale were used as the criterion. After 3 weeks, 100 college students were randomly selected for retest. Results: The exploratory factor analysis showed that one dimension should be extracted. Eigenvalue was 5.352 and 53.518% cumulative variance interpretation rate. The confirmatory factor analysis showed that the scale structure validity was good. Internal consistency reliability of the scale was 0.785; The test-retest reliability was 0.833, and the criterion correlation validity reached a significant level. Conclusion: The Chinese version of hypersensitive narcissism scale has good reliability and validity, which can effectively measure hypersensitive narcissism. The localisation of the scale can better serve the research and development of the university student population on the one hand, and on the other hand, it can help the research in this field to have a more in-depth development in China.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Explainable Artificial Intelligence to Diagnose Early Parkinson's Disease via Voice Analysis\nAbstract: Background: Parkinson's disease (PD) is a progressive neurodegenerative disorder that affects motor control, leading to symptoms such as tremors or impaired balance. Early diagnosis of PD is crucial for effective treatment, yet traditional diagnostic models are often costly and lengthy. This study explores the use of Artificial Intelligence (AI) and Machine Learning (ML) techniques, particularly voice analysis, to identify early signs of PD and make a precise diagnosis. Objectives: This paper aims to create an automatic detection and prediction of PD binary classification using vocal biomarkers. We will also use explainability to identify latent and important patterns in the input data in retrospect to the target to inform the definition of Parkinson's through voice characteristics. Finally, a probability generation will be generated to create a scoring system of a patient's odds of PD as a spectrum. Methods: We utilized a dataset comprising 81 voice recordings from both healthy control (HC) and PD patients, applying a hybrid AI model combining Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Multiple Kernel Learning (MKL), and Multilayer Perceptron (MLP). The model's architecture was designed to extract and analyze acoustic features such as Mel-Frequency Cepstral Coefficients (MFCCs), local jitter, and local shimmer, which are all indicative of PD-related voice impairments. Once features are extracted, the AI model will generate prediction labels for HC or PD files. Then, a scoring system will assign a number ranging from 0-1 to each file, indicating the stage of PD development. Results: Our champion model yielded the following results: diagnostic accuracy of 91.11%, recall of 92.50%, precision of 89.84%, an F1 score of 0.9113, and an area under curve (AUC) of 0.9125. Furthermore, the use of SHapley Additive exPlanations (SHAP) provided detailed insight into the model's decision-making process, highlighting the most influential features contributing to a PD diagnosis. The outcomes of the implemented scoring system demonstrate a distinct separation in the probability assessments for PD across the 81 analyzed audio samples, validating our scoring system by confirming that the vocal biomarkers in the audio files accurately correspond with their assigned scores. Conclusion: This study highlights the efficacy of AI, particularly a hybrid model combining CNN, RNN, MKL, and Deep Learning in diagnosing early PD through voice analysis. The model demonstrated a robust ability to distinguish between HC and PD patients with significant accuracy by leveraging key vocal biomarkers such as MFCCs, jitter, and shimmer.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Distribution of White Matter Hyperintensities across Arterial Territories in Neurodegenerative Diseases\nAbstract: MRI-detected white matter hyperintensities (WMH) are often recognized as markers of cerebrovascular abnormalities and an index of vascular brain injury. The literature establishes a strong link between WMH burden and cognitive decline, and suggests that the anatomical distribution of WMH mediates cognitive dysfunction. Pathological remodeling of major cerebral arteries (anterior, ACA; middle, MCA; posterior, PCA) may increase WMH burden in an arterial territory (AT)-specific manner. However, this has not been systematically studied across neurodegenerative diseases (NDDs). To address this gap, we aimed to assess WMH distribution (i) across ATs per clinical category, (ii) across clinical categories per AT, and (iii) between men and women. We also investigated the association between AT-specific WMH burden and cognition. Using two cohorts - Canadian CCNA-COMPASS-ND (N=927) and US-based NIFD (N=194) - we examined WMH distribution across ten clinical categories: cognitively unimpaired (CU), subjective cognitive decline (SCD), mild cognitive impairment (MCI), Alzheimer disease (AD), MCI and AD with high vascular injury (+V), Lewy body dementia, frontotemporal dementia, Parkinson's disease (PD), and PD with cognitive impairment or dementia. WMH masks were segmented from FLAIR MRI and mapped onto an arterial atlas. Cognitive performance was assessed using four psychometric tests evaluating reaction time and overall cognition, namely Simple Reaction Time (SRT), Choice Reaction Time (CRT), Digit Symbol Substitution Test (DSST), and Montreal Cognitive Assessment (MoCA). Statistical analyses involved linear regression models, controlling for demographic factors, with a 5% False Discovery Rate for multiple comparisons. Our transdiagnostic analysis revealed unique AT-specific WMH burden patterns. Comparisons between ACA and PCA territories revealed distinct burden patterns in clinical categories with similar whole-brain WMH burden, while the MCA territory consistently exhibited the highest burden across all categories, despite accounting for AT size. Hemispheric asymmetries were noted in seven diagnostic categories, with most showing higher WMH burden in the left MCA territory. Our results further revealed distinct AT-specific WMH patterns in diagnostic groups that are more vascular than neurodegenerative (i.e., MCI+V, AD+V). Categories often misdiagnosed in clinical practice, such as FTD and AD, displayed contrasting WMH signatures across ATs. SCD showed distinct AT-specific WMH patterns compared to CU and NDD participants. Additionally, sex-specific differences emerged in five NDDs, with varying AT effects. Importantly, AT-specific WMH burden was associated with slower processing speed in MCI (PCA) and AD (ACA, MCA). This study highlights the importance of evaluating WMH distribution through a vascular-based brain parcellation. We identified ATs with increased vulnerability to WMH accumulation across NDDs, revealing distinct WMH signatures for multiple clinical categories. In the AD continuum, these signatures correlated with cognitive impairment, underscoring the potential for vascular considerations in imaging criteria to improve diagnostic precision.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Planning and developing an intervention to improve the psychological wellbeing of people living with persistent pain: De-Stress Pain\nAbstract: Background: People with persistent musculoskeletal (MSK) pain often report depressive symptoms. Distress and depression have been found to predict the development of chronic pain conditions. Evidence suggests pain-related distress is qualitatively different from depressive illness, and current referral pathways and available interventions are sub-optimal for people with persistent MSK pain and distress. We aimed to develop and test the acceptability and proof of concept of an intervention to reduce pain-related distress in people with chronic MSK pain. Methods: The Person-Based Approach (PBA)(1) informed the processes undertaken to inform intervention development. This included semi-structured interviews with people with persistent pain and with General Practitioners (GPs); and a stakeholder discussion with social prescribers. Patient and Public Involvement (PPI) representatives had input throughout all development work. Findings from these activities were triangulated to inform the development of a prototype intervention which was tested in a repeated-measures, mixed methods proof-of-concept study called De-Stress Pain. The De-Stress Pain intervention offered 4-6 social prescriber sessions over 12 weeks, and access to a study website. 16 participants were recruited from general practices, and 4 social prescribers were recruited from Primary Care Networks (PCNs) and charitable organisations. Both quantitative measures and qualitative interviews were completed by participants at baseline and 12 weeks post-baseline. Quantitative measures included questions about mood (DAPOS, WEMWBS, 4DSQ), pain chronicity, pain intensity and musculoskeletal health (MSK-HQ). Semi-structured interviews with participants explored the participants context, their experiences of pain related distress, and their experiences of the intervention. Social prescribers were interviewed to explore their experiences of delivering the intervention. Interviews were analysed using thematic analysis. Results: The De-Stress Pain intervention was acceptable both to patients and to social prescribers. Some participants experienced positive changes such as improved mood, increased hope and increased activity. The social prescribers (\"De-Stress Coaches\") provided accountability and supported motivation. All measures of mood showed improvement. Limited time and money were identified as barriers to engagement, along with participants holding the view that increasing pleasurable activities was indulgent. Some participants were already socially engaged and busy at the point of entering the study. Conclusions: We have confirmed the intervention is needed, acceptable and welcomed by people with pain. Social prescribers found the intervention acceptable to deliver. We identified the barriers that need to be addressed in future versions of the intervention.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Quantifying the impact of real-world evidence: the sacubitril/valsartan experience\nAbstract: Background: The impact of RWE publication on use of approved therapies, including the existence of an effect and timing of impact, is unknown. Methods: We assessed the relationship between the cadence of RWE publications and sales of sacubitril/valsartan (Entresto) following launch. Publication data were derived from a PubMed search over 7/01/2015-12/31/2023 for English-language, human subject studies with the drug name (Entresto or sacubitril) and indication (heart failure) in the title or abstract. Quarterly RWE publication data were combined with quarterly information on sacubitril/valsartan sales over the 34-quarter period spanning Q3 2015 through Q4 2023. Quarter-to-quarter change in total sales was modeled with linear regression as a function of counts of previously published RWE-related studies, adjusting for a linear time trend to control for any underlying trends in sales growth; change in total sales from the quarter prior to publication to the quarter of publication to control for recent sales changes; and the cumulative count of RWE publications from Q3 2015 through the previous quarter to control for the contribution of previous RWE publications to future sales. Results: The PubMed search identified 888 studies; of these, 333 (37.5%) were classified as RWE-related. An additional RWE-related publication (in quarter q) was associated with an estimated mean increase in quarterly sales of $1.8M (from quarter q to q+1 following publication), $3.5M (from q+1 to q+2), and $2.7M (from q+2 to q+3). In adjusted models, an additional RWE publication was associated with a mean gain in sales from quarter q+1 to q+2 of $2.6M (95% CI $0.2M to $5.4M). RWE publications were not associated with an increase in sales in the quarter following publication, and the association was attenuated by third quarter following publication. Conclusion: RWE studies were associated with increased use of sacubitril/valsaratan, providing preliminary evidence of RWE's ability to support therapy adoption.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Social Determinants of Health Factors Associated with Metabolic Dysfunction-Associated Steatotic Liver Disease Prevalence and Severity: A Systematic Review and Meta-analysis\nAbstract: Background & Aims: Social determinants of health (SDOH) impact disease risk and severity leading to health disparities and impeding health equity. Though important in mitigating adverse health outcomes, SDOH impacting metabolic dysfunction-associated steatotic liver disease (MASLD) prevalence and severity are understudied and results are conflicting. The aim of this systematic review and meta-analysis was to assess the impact of specific SDOH factors on MASLD disease burden for adults in the United States (US). Methods: We searched MEDLINE, Embase and Cochrane databases per the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines. Studies from January 2010- May 2024 were included. Quantitative studies of adults in the US that evaluated SDOH beyond race/ethnicity were included. Outcomes included prevalence of MASLD, metabolic dysfunction-associated steatohepatitis (MASH), MASH-associated advanced fibrosis or cirrhosis and clinical outcomes. Results: We identified 18 studies comprising of 547,634 total subjects from 11 unique cohorts. Nine studies evaluated MASLD prevalence, three MASH prevalence, eight MASH-associated advanced fibrosis/cirrhosis prevalence, and nine clinical outcomes. High diet quality was the most consistent SDOH factor associated with both MASLD and MASH-associated advanced fibrosis/cirrhosis prevalence (summarized OR of 0.76 p <0.01, and 0.74 p <0.01, respectively). Lower income was most consistently associated with risk of clinical outcomes (significant in 3/9 studies). Conclusions: Diet quality was the most consistent SDOH associated with disease prevalence and severity in MASLD, with the remainder of SDOH showing inconsistent associations. Prospective assessments using consistent, validated tools to assess the impact of specific SDOH on MASLD disease burden are needed to inform public health interventions to mitigate health disparities in MASLD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Histopathological profile of triple negative breast carcinomas seen in patients in National Hospital, Abuja over a 10-year period (January 2010 - December 2019)\nAbstract: Background: Triple negative breast carcinoma (TNBC) cases in Africa and the black race which are most commonly seen among the reproductive age group are highly aggressive and have a high mortality rate. Based on its protein expression using immunohistochemical methods it does not express the hormone receptors (oestrogen and progesterone) and the human epidermal growth factor receptor 2 (HER2). As a result the only means of treating TNBC patients so far is by conventional chemotherapy +/- radiotherapy. Even then only 50.0 % of these patients will respond to the chemotherapy. Further studies which may help improve treatment and survival in these patients are important. Objective: This study is aimed at knowing the histopathological profile of TNBCs in Abuja with the expression of androgen receptor; an important marker in these patients. Method: Two hundred formalin-fixed paraffin embedded TNBC tissue blocks were selected for the study. The histological type and their respective histological grades (based on the Nottingham grading system) were noted from the haematoxylin and eosin(H&E) sections. Immunohistochemical staining was done using antibodies against androgen receptor (Biocare) and CK5/6 (Invitrogen) with in-house controls. The androgen receptor and CK5/6 expressions were analysed using a semi-quantitative scoring method: -A tumour was considered positive for LAR if [&ge;] 1.0 % of tumour cell nuclei were staining and positive for CK5/6 if [&ge;]10.0 % of tumour cells had membrane staining. Other biographic data like tumour size, presence or absence of lymphovascular permeation were also analysed. Correlation between the histological types and grades were also done using SPSS version 21 statistical package. Results: The 30-49 age group had the highest frequency of TNBC. The commonest histological type seen among TNBCs is Invasive carcinoma; NST at 93.0%. The most frequent histological grade is grade 2 at 56.0 %. The androgen receptor subtype constituted 19.0 %. The basal subtype formed 28.5 % of the total sample size. There was no significant correlation between the histological type and grade of TNBC. 73.3% of the patients had tumour size of pT1 and pT2. Conclusion: This study shows that the percentage of androgen positive cases among triple negative breast carcinomas is significant enough to warrant routine luminal AR testing for TNBCs. Furthermore, this study has shown that the most frequent histological type is Invasive carcinoma; Non-specific type (NST) regardless of the molecular subtype and presence or absence of lympho-vascular permeation. It has also shown that the most frequent histological grade seen among patients with TNBCs is Grade 2.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Association Between Estimated Glomerular Filtration Rate and Left Ventricular Function in Children With Chronic Kidney Disease.\nAbstract: Background: Cardiovascular disease is the leading cause of morbidity and mortality in pediatric patients with chronic kidney disease (CKD). However, the kidney-heart relationship in this population remains poorly understood, particularly in the context of dialysis modality and duration. This study aims to investigate the associations between estimated glomerular filtration rate (eGFR), left ventricular ejection fraction (LVEF), left ventricular (LV) mass, and dialysis modality and duration in pediatric CKD patients. Methods: This retrospective study included 16 pediatric CKD patients (median age 3.6 years; 31.3% female and 68.75% male), stratified by the presence of cardiac dysfunction (LVEF [&le;] 50%). Clinical data, including eGFR, LVEF, LV mass, and dialysis history (hemodialysis or peritoneal dialysis), were collected. Independent T-tests, Wilcoxon Two-Sample tests, and Spearman's correlations were performed to assess renal and cardiac function relationships. Multivariate regression models were employed to evaluate predictors of LVEF over time. Results: Cardiac dysfunction was observed in 25% of the cohort, with significantly lower LVEF and fractional shortening compared to those without dysfunction. Patients with cardiac dysfunction were younger at CKD diagnosis (p < 0.0001), suggesting an earlier progression of renal and cardiac impairment. Following dialysis, eGFR significantly decreased in patients without cardiac dysfunction (p < 0.0001) but remained unchanged in those with dysfunction. Conversely, LVEF improved post-dialysis in patients with cardiac dysfunction (p = 0.0034) but remained stable in those with normal cardiac function. Prolonged dialysis duration was negatively correlated with eGFR (r = -0.31, p = 0.008) and LV mass (r = -0.26, p = 0.024). Hemodialysis duration was positively correlated with LVEF (r = 0.73, p < 0.001), suggesting potential cardiovascular benefits from prolonged hemodialysis treatment. Conclusions: Pediatric CKD patients, particularly those with cardiac dysfunction, experience significant alterations in both renal and cardiac parameters, requiring tailored dialysis strategies in this population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The fathers singing voice may impact premature infants brain more than their mothers: A study protocol and preliminary data on a singing and EEG randomized controlled trial (RCT) based on the fundamental frequency of voice and kinship parameters\nAbstract: This article presents the study protocol for a randomized controlled trial (RCT) investigating the impact of singing on the brain activity of premature infants in the Neonatal Intensive Care Unit (NICU). The study focuses on how the differentiation of voices, as defined by the fundamental frequency (F0) shaped by biological sex and kinship, influences neurophysiological responses when measured by electroencephalography (EEG). Premature infants, who are highly sensitive to auditory stimuli, may benefit from music-based interventions; however, there is limited understanding of how voice variations between male and female caregivers, and whether they are biologically related, affect brain activity. Our protocol outlines a structured intervention where infants are exposed to singing by four facilitators - a male music therapist, a female music therapist, the mother, and the father - and includes two singing stages: a sustained note (A at 440 Hz) and a 90-second lullaby, both interspersed with silent periods to allow for baseline measurements. EEG recordings track brain activity throughout these sessions, followed by quantitative EEG (qEEG) analysis and thorough statistical computations (e.g., mixed-effects models, spectral power analysis, and post-hoc tests) to explore how these auditory stimuli influence brain function. Preliminary data from five infants show that maternal singing elicits the highest delta spectral power in all measured conditions except during the  lullaby song, where paternal singing elicits the highest effects followed by the male music therapist and then the mother. These early findings highlight the potential influence of parental voices, particularly the fathers voice, on neonatal brain development, while the detailed study protocol ensures rigor and replicability, providing a robust framework for future research. Additionally, this protocol lays the groundwork for exploring the long-term effects of music-based interventions, with the goal of improving neurodevelopmental outcomes in premature infants through tailored auditory stimulation. (clinincaltrials.gov unique identifier: NCT06398912)\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cross-trial prediction of treatment response to transcranial direct current stimulation in patients with major depressive disorder\nAbstract: Machine-learning (ML) classification may offer a promising approach for treatment response prediction in patients with major depressive disorder (MDD) undergoing non-invasive brain stimulation. This analysis aims to develop and validate such classification models based on easily attainable sociodemographic and clinical information across two randomized controlled trials on transcranial direct-current stimulation (tDCS) in MDD. Using data from 246 patients with MDD from the randomized-controlled DepressionDC and ELECT-TDCS trials, we employed an ensemble machine learning strategy to predict treatment response to either active tDCS or sham tDCS/placebo, defined as [&ge;] 50% reduction in the Montgomery-Asberg Depression Rating Scale at 6 weeks. Separate models for active tDCS and sham/placebo were developed in each trial and evaluated for external validity across trials and for treatment specificity across modalities. Additionally, models with above-chance detection rates were associated with long-term outcomes to assess their clinical validity. In the DepressionDC trial, models achieved a balanced accuracy of 63.5% for active tDCS and 62.5% for sham tDCS in predicting treatment responders. The tDCS model significantly predicted MADRS scores at the 18-week follow-up visit (F(1,60) = 4.53, pFDR = .037, R2 = 0.069). Baseline self-rated depression was consistently ranked as the most informative feature. However, response prediction in the ELECT-TDCS trial and across trials was not successful. Our findings indicate that ML-based models have the potential to identify responders to active and sham tDCS treatments in patients with MDD. However, to establish their clinical utility, they require further refinement and external validation in larger samples and with more features.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Cannabidiol treatment is associated with broadband spectral electrophysiological changes and improved cognition in boys with low-functioning autism spectrum disorder\nAbstract: Oral cannabidiol (CBD) treatment has been suggested to alleviate negative symptoms of autism spectrum disorder (ASD). While many CBD preparations have been studied in randomized clinical trials involving ASD, none have used purified CBD preparations or preparations approved by the U.S. Food and Drug Administration, nor have they focused on low-functioning children with ASD. Previous studies have identified several candidate electrophysiological biomarkers for the cognitive and behavioral disabilities in ASD, with one emerging biomarker being aperiodic neural activity. Here we examined whether periodic (oscillatory) and/or aperiodic electroencephalography (EEG) features are predictive of any symptomatic changes in ASD following pharmacological CBD intervention. To do this, we leveraged resting-state EEG from children with low-functioning ASD (24 boys, aged 7-14 years) using data obtained during a prior double-blind, placebo-controlled, crossover Phase III Clinical Trial (NCT04517799) that investigated using cannabidiol to treat severe behavior problems in children with ASD. Using linear mixed effect models, we found that aperiodic EEG signal features varied directly with 7-COOH-CBD metabolite levels in blood, as evidenced by a larger aperiodic offset (p < 0.001) and decreased aperiodic exponent (p < 0.05) across the scalp. Furthermore, 7-COOH-CBD metabolite levels in blood had a positive association with nonverbal intelligence and visuomotor coordination (p < 0.05). Finally, changes in visuomotor coordination attributed to occipital oscillatory EEG activity were mediated by changes in 7-COOH-CBD metabolite levels in blood, with distinct effects observed for the delta frequency band (p < 0.05). Our analytical results suggest that this daily CBD preparation and administration schedule exerted some benefits, with improvements to cognitive and behavioral abilities in a low-functioning ASD children population. Our findings support the inclusion of resting-state, aperiodic signal features as candidate biomarkers for tracking the clinical impact of CBD treatment, in addition to traditional oscillatory EEG measures, within a neurodevelopmental context.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The causal connections between gut microbiota and chronic pain and pain phenotypes through the gut-brain axis: A Mendelian randomization study and mediation analysis\nAbstract: Recent studies have increasingly highlighted a potential link between gut microbiota (GM) and chronic pain. However, existing research has yielded mixed results, leaving many questions unanswered. We employed a two-sample Mendelian randomization design to investigate whether GM directly influences multisite chronic pain (MCP) and eight phenotypes. We then used a combination of meta-analysis, genetic colocalization analysis, and Bayesian weighted mendelian randomization to further strengthen the evidence for causal relationship. Additionally, we examined how GM might be associated with human brain structures. Finally, we used mediation analysis to explore whether the structure and function of specific brain regions play a role in the relationship between GM and MCP and the pain phenotypes. We observed a significant causal association between 13 GM and chronic pain. Eight GM protected against pain phenotypes, whereas seven increased risk. The results indicate that GM could potentially affect the area, thickness, and volume of brain region cortices involved in sensory, emotional, and cognitive aspects of pain. Importantly, our findings indicated that the causal effect between the Genus Odoribacter and neck/shoulder pain could be mediated by the mean optical density in the left Fornix cres+Stria terminalis. In conclusion, different pain phenotypes were causally associated with different GM among European ancestry. Core GM may influence chronic pain by affecting complex brain networks. Notably, we constructed a basic gut-brain axis model for neck/shoulder pain, involving the Genus Odoribacter, left Fornix cres+Stria terminalis, and neck/shoulder pain.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Interplay of Perceived Mental Health and Suicidal Ideation among Aboriginal Peoples in Canada: A Secondary Analysis of Aboriginal Peoples Survey\nAbstract: The disproportionately high suicide rates among Aboriginal populations in Canada, linked to historical trauma and systemic inequities, necessitate targeted mental health interventions. This study investigated the relationship between perceived mental health and suicidal ideation among the Aboriginal population in Canada, First Nations, Inuit, and Metis, using data from the 2012 Aboriginal Peoples Survey (APS) (n=4,725). The analysis employed chi-square tests and bivariate logistic regression to examine the association between self-perceived mental health, suicidal ideation, and socio-demographic factors. Results revealed significant associations between suicidal ideation, age group (p<.001), and sex (p<.001), with younger individuals (18-24 years) and females reporting a higher prevalence of suicidal thoughts. Also, bivariate logistic regression showed that being between the ages of 25 and 34 was a strong predictor of suicidal thoughts (OR = 1.954, p =.000), while being female (OR =.648, p =.000) and having a higher socioeconomic status (OR =.678, p =.000) were weaker predictors. Although Aboriginal identity was not significantly associated with suicidal ideation, self-perceived mental health was. These results made it clear that focused and targeted mental health interventions and culturally appropriate suicide prevention strategies are needed right away in Aboriginal communities in Canada. These strategies need to meet the needs of vulnerable groups, like younger people and women.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Atypical gut microbial ecosystem from athletes with very high exercise capacity improves insulin sensitivity and muscle glycogen store in mice\nAbstract: Background. The gut bacterial ecosystem plays a key role in the host's energy metabolism, and potentially in the host's exercise capacity, recognized as a powerful predictor of health status and risk of mortality. Objective. To deepen our understanding of the gut bacterial ecosystem relationship with host's exercise capacity and energy metabolism, we characterized the gut microbiota in a cohort of healthy humans with heterogeneous exercise capacities, and next determined the impact of fecal microbiota transplantation (FMT) from donors of this cohort on energy metabolism and exercise capacity of recipient mice. Design. 50 male normo-weight participants (from inactive to elite endurance athletes) performed food frequency questionnaire (FFQ) and exercise tests to determine exercise capacity parameters (VO2max, fat oxidation, exercise energy expenditure). Metagenomic shotgun and metabolomic analyses were performed to characterize gut microbiota ecosystem and short-chain fatty acids (SCFAs) on human and mice fecal samples. Mice performed running exercise capacity tests and metabolic parameters were determined in skeletal muscle and plasma samples. Results. While our data support that the bacterial ecosystem appears to be modestly altered between individuals with low to high exercise capacities, we report that gut bacterial alpha-diversity, density, and functional richness are significantly reduced in athletes with very high exercise capacity. By using FMT, we report that the engraftment of these atypical gut microbiota improves insulin sensitivity and muscle glycogen stores into transfected mice. Conclusion. Our data highlight promising therapeutic perspectives in fecal transplantation from human donors selected based on exercise capacity parameters.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: \u03b1-Synuclein seeding activity and progression in sporadic and genetic forms of Parkinson's disease in the Parkinson's Progression Markers Initiative cohort\nAbstract: Background -Synuclein (-syn) seed amplification assays (SAAs) have shown remarkable potential as a diagnostic tool for Parkinson's disease (PD). Using data from the Parkinson's Progression Markers Initiative (PPMI) cohort, we aimed to assess whether -syn seeding and seed concentration are associated with progression in sporadic PD, LRRK2-associated PD (LRRK2 PD), and GBA-associated PD (GBA PD). Methods Using a linear mixed-effects model adjusted for potential confounding factors, we analyzed 14 years of motor and cognitive assessments and five years of dopamine transporter imaging data from 878 PPMI participants to establish comprehensive progression profiles for sporadic PD (n=473), LRRK2 PD (n=275), and GBA PD (n=130). By introducing -syn SAA results from 586 participants (n=351 sporadic PD, 163 LRRK2 PD, and 72 GBA PD), we determined whether baseline -syn seeding positivity (95% sporadic PD, 69% LRRK2 PD, and 94% GBA PD) and the time to 50% of the maximum fluorescence (T50), an indicator of seed concentration, are associated with progression in PD. Findings Participants with sporadic PD (yearly change in MDS-UPDRS III: 1.50 points; 95% confidence interval 1.41-1.58) and GBA PD (1.52; 1.31-1.72)(p=0.873) progressed similarly while those with LRRK2 PD progressed slower (1.05; 0.89-1.20)(p<0.001). There was no significant difference between -syn SAA+ sporadic PD (1.48; 1.03-1.92) and LRRK2 PD (1.09; 0.76-1.44) participants and their negative counterparts (1.25; 0.81-1.70)(p=0.347) (0.80; 0.50-1.10)(P=0.087). Similarly, -syn seeding activity was not significantly associated with progression in GBA PD. Furthermore, there was no statistically significant difference in progression between sporadic PD participants with high (1.46; 1.33-1.59), medium (1.45; 1.30-1.61)(p=0.948), and low seed concentration (1.42; 1.11-1.73)(p=0.804). Similarly, seed concentration was not significantly associated with progression in LRRK2 or GBA PD. Interpretation Baseline -syn seeding activity and seed concentration were not statistically significantly associated with PD progression in the PPMI cohort. More longitudinal investigations into the relationship between -syn seeding activity, seed concentration, and progression are needed before concretely establishing -syn aggregation as the primary driver of PD. Funding This study was funded in part by Aligning Science Across Parkinson's No. ASAP-237603 through the Michael J. Fox Foundation for Parkinson's Research and the National Institute of Health through the National Institute of Neurological Disorders and Stroke grants R01NS102735 and 5R01NS126260.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: DETERMINANTS OF COMPLIANCE WITH IRON-FOLIC ACID SUPPLEMENTATION AMONG PREGNANT MOTHERS IN BULE HORA DISTRICT, SOUTHERN ETHIOPIA: UNMATCHED CASE-CONTROL STUDY\nAbstract: Background World Health Organization has recommended a daily supplementation of iron folic acid, to avert anemias during pregnancy. However, due to many factors, compliance of pregnant women with this recommendation of iron and folic acid supplementation remains low, both in Africa and Ethiopia. The findings from previous studies show in concurrent finding regarding determinants of iron and folic acid compliance. Objective This study aimed to assess determinants of iron and folic acid supplementation compliance among antenatal care attendee pregnant women in the Bule Hora district, south Ethiopia, in 2023.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Etiological Factors of Risk for Occupational Illness in Nursing Professionals: Etiology and Risk Review Protocol\nAbstract: Aim: To describe the protocol for a systematic review of etiology and risk to identify the etiological factors of Risk for Occupational Illness in nursing professionals. Design: Etiology and risk review protocol, conducted according to JBI guidelines. Methods: This is an etiology and risk review protocol to be carried out following the JBI guidelines in the following data sources: CINAHL, MEDLINE/PubMed, Cochrane Library, Scopus, EMBASE, Latin American and Caribbean Literature in Health Sciences, National Institute of Security and Health at Work and National Institute of Health at Work. The inclusion criteria are studies that address workers aged 18 years until retirement, demonstrate etiological factors that condition the susceptibility of the ND in question and address analyses regarding the identification, definition and association of factors with the Risk of Occupational Illness. The exclusion criteria are studies that did not address the topic, opinion articles, letters to the editor and editorials. Expected Results: The results of this review will be publicly disclosed in scientific journals in the health area and will contribute to increasing the level of evidence of the Nursing Diagnosis Risk for Occupational Illness, so that they remain in future editions of NANDA International and that the diagnosis is updated and revised based on the current scientific literature. Conclusion: It is expected  identify the possible uses of the concept; determine the essential critical attributes; identify the antecedents and consequences of the concept; and define the empirical references and to highlight the etiological factors that are consistent with susceptibility to occupational illness.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The willingness to accept and to pay for non-communicable disease screenings in rural Bangladesh: A contingent valuation study\nAbstract: Background Bangladesh is experiencing a rapid increase in non-communicable diseases (NCDs). Early screening is essential to enable timely treatment. In Bangladesh, access to screening services for NCDs is often limited. This study aimed to elicit the willingness to accept (WTA) and the willingness to pay (WTP) for four screening packages for NCDs and their association with the respondents sociodemographic characteristics among rural communities in Bangladesh. Methods A cross-sectional survey using contingent valuation was conducted in six villages of Faridpur district, Bangladesh. The WTP was elicited using a double-bounded dichotomous choice and bidding game approach, with initial bid amounts based on local market prices. Logistic regression was used to identify factors associated with WTA and WTP, and a two-part model was employed to estimate mean WTP and its determinants. We used a double-limit dichotomous choice model with the respondents who took part in the bidding exercise. Results We found that 83% of the 346 respondents were willing to accept at least one screening package and among these 44% would be willing to pay to accept all screenings. The willingness to accept and pay varied largely by the type of screening being offered, with much lower proportions for obesity than for hypertension and diabetes. The results suggested that individuals from households with a member with an NCD were more willing to accept and pay for screening compared to those from households without an NCD. Married individuals in the highest wealth and expenditure tertiles were also more willing to pay than not-married individuals from middle- and low-wealth and expenditure tertiles. Sex and occupation influenced the amount individuals were willing to pay. Conclusions Our results encourage the development of screening interventions for NCDs in rural populations. Further research is needed to assess their feasibility, effectiveness and equity in Bangladesh on a larger scale.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Unveiling AI-ECG using Generative Counterfactual XAI Framework\nAbstract: Background: The application of artificial intelligence (AI) to electrocardiograms (ECGs) has shown great promise in the screening and diagnosis of cardiovascular diseases, often matching or surpassing human expertise. However, the black-box nature of deep learning models poses significant challenges to their clinical adoption. While Explainable AI (XAI) techniques, such as Saliency Maps, have attempted to address these issues, they have not been able to provide clear, clinically relevant explanations. We developed the Generative Counterfactual ECG XAI (GCX) framework, which uses counterfactual scenarios to explain AI predictions, enhancing interpretability and aligning with medical knowledge. Methods: We designed a study to validate the GCX framework by applying it to eight AI-ECG models, including those focused on regression of six ECG features, potassium level regression, and atrial fibrillation (AF) classification. PTB-XL and MIMIC-IV were used to develop and test. GCX generated counterfactual (CF) ECGs to visualize how changes in the ECG relate to AI-ECG predictions. We visualized CF ECGs for qualitative comparisons, statistically compared ECG features, and validated these findings with conventional ECG knowledge. Results: The GCX framework successfully generated interpretable ECGs aligned with clinical knowledge, particularly in the context of ECG feature regression, potassium level regression, and AF classification. For ECG feature regression, GCX demonstrated clear and consistent changes in features, reflecting the corresponding morphological alterations. CF ECGs for hyperkalemia showed a prolonged PR, discernible P wave, increased T wave amplitude, and widened QRS complex, whereas those for AF demonstrated the disappearance of the P wave and irregular rhythms. Conclusion: The GCX framework enhances the interpretability of AI-ECG models, offering clear relevant explanations for AI predictions. This approach holds substantial potential for improving the trust and utility of AI in clinical practice, although further validation across diverse datasets is required.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Transplantation and old stem cell age independently increase the risk of clonal hematopoiesis in long-term survivors of pediatric HCT\nAbstract: In pediatric hematopoietic cell transplantation (HCT) recipients, transplanted donor cells may need to function far beyond normal human lifespan. Here, we investigated the risk of clonal hematopoiesis (CH) in 144 pediatric long-term HCT survivors, compared to 115 healthy controls. CH was detected in 16% of HCT survivors, at variant allele frequencies (VAFs) of 0.01-0.31. Mutations were predominantly in DNMT3A (80%) and TET2 (20%). Older stem cell age and the HCT procedure independently increased the risk of CH (odds ratios 1.07 per year increase (p<0.001) and 2.61 for HCT (p=0.02)), indicating both aging- and transplantation-induced effects. Large clones (VAF >0.10) were found exclusively in HCT recipients. Notably, CH was also detected within 15 years after cord blood HCT. Inflammatory processes around graft infusion were associated with CH presence. Future studies are required to track the evolution of post-transplant CH and its impact on future cardiovascular disease, second malignancies and overall survival.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Bibliometric Analysis of Research Hotspots and Frontiers in Diabetes and Cardiovascular Disease Comorbidity from 2005 to 2024\nAbstract: Nearly two decades ago, diabetes mellitus (DM) and cardiovascular disease (CVD) emerged as major global health threats, with research interest steadily increasing. Despite ongoing in-depth studies in the DM+CVD field, a systematic analysis of overall development trends and future hotspots remains lacking. This study employs bibliometric methods, utilizing CiteSpace and VOSviewer software to analyze and visualize 5,505 DM+CVD-related publications from 2005 to May 2024. The findings reveal a rapid growth trend in the field, with publications peaking at 751 in 2022, and the United States and China as major contributing countries. Keyword analysis identifies research hotspots including oxidative stress, insulin resistance, and heart failure. Highly cited literature analysis shows that the relationship between DM+CVD and obesity, disease mechanisms, treatment strategies, lifestyle interventions, and novel drugs are primary research themes. Analysis of highly cited literature from the past three years indicates that the application of SGLT2 inhibitors and GLP-1 receptor agonists, the association between metabolic abnormalities and DM+CVD, precise management of heart failure and cardiomyopathy, and in-depth epidemiological studies are current and future research priorities. This study not only reveals research hotspots and development trends in the DM+CVD field but also provides important references for optimizing research resource allocation and promoting multidisciplinary collaboration.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Periodontal health status in people with Parkinson's disease: a French cohort study.\nAbstract: Introduction: People with Parkinson's disease (PD) may have difficulty maintaining good oral hygiene due to their motor impairments. This generally leads to a higher prevalence of oral infections, including periodontal disease. To date, no study has addressed this issue in a French population. Objective: The aim of the study, part of the PARKIDENT clinical trial, was to assess the periodontal health of people with PD and to evaluate changes in their periodontal parameters 6 months after receiving hygiene advice. Methods: Data were collected from 40 participants at both baseline and 6-month follow-up. These data included demographic information and an assessment of the participants' PD stage. Oral health assessments included oral hygiene and periodontal status. Microbiological samples were also collected and the data collected during the two visits were compared. Results: Forty people with PD participated in the study. An improvement in oral hygiene habits and a reduction in the plaque index were observed at follow-up. The frequency of patients with significant periodontal pockets (> 6mm) was also reduced (from 20% to 3%). The improvement in these periodontal parameters was associated with a reduction in bacterial load, particularly for Treponema denticola (p=0.003). Conclusion: The study suggests that hygiene advice can improve periodontal health in patients with PD, potentially preventing tooth loss and improving their quality of life. Clinical Significance: This study, the first in France on the periodontal health of people with PD, suggests that dental visits and hygiene advice can improve their oral health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Gut microbial dysbiosis is associated with occurrence and post-surgical prognosis of unraptured cerebral aneurysm\nAbstract: BACKGROUND: The microbiota has been reported to play an important role in the occurrence of brain aneurysms (CA). However, no microbiota or metabolite has been used for diagnosis or therapy of CA till now. METHODS: The microbial DNA was extracted from the stool samples of the CA and healthy volunteer groups. The 16S rDNA gene was sequenced on a MiSeq system. R software package was used to analyze the sequence, and the variations in microbial composition was obtained. The correlation analysis of the differential intestinal bacteria, metabolites and blood parameters was explored based on a logistic regression model. A random forest algorithm was used to predict the classification of samples for further exploring the relationship between fecal microbiota and CA. RESULTS: The -diversity indexes demonstrated an altered within-sample microbial diversities between patients and healthy people. The subsequent beta diversity results indicated that shift in the between-sample microbial diversities of the intestinal microbiota was associated with the occurrence of cerebral aneurysm. Specifically, the abundance of some gut bacterial genera, such as Blautia and Faecalibacterium, changed significantly after CA. Intestinal metabolite enrichment results highlight the role of carbohydrate metabolic pathways in CA, including sedoheptulose 7-phosphate (S-7-P). The correlation analysis of the differential intestinal bacteria, metabolites and blood parameters indicated that intestinal bacteria and metabolites were related to host blood parameters. Then, the predictive models were employed to test the significance of the combination of differential bacteria, metabolites and blood parameters in CA diagnosis and prognosis. The predictive model built by Faecalibacterium and s7p obtained an area under ROC curve (AUC) of 99.7%, and Faecalibacterium and s-7-p were also associated with some metabolite that have significance in post-surgery prognosis of CA. Conclusions: The gut microbiota and metabolites profiles of patients with CA were significantly altered. Bacterial genus Faecalibacterium and metabolite s-7-p could serve as potential biomarkers in CA prediction and post-surgery prognosis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Impact of Buoy on Hydration Status of Active Men and Women\nAbstract: Background: Hypo-hydration is a major health concern that affects performance and is associated with increasing morbidity and growing health care costs. There is an emerging interest in optimum hydration and identifying how factors such as ingestion rate and beverage composition affect hydration. This study examined three beverages with varying ingestion rates and measured markers of hydration. Methods: Thirty healthy, active participants between ages 18 to 45 years were given three different beverages on three separate days. The beverages were of identical volumes (1 Liter), but differed in the rate of ingestion, carbohydrate content and electrolyte content. Beverage 1 (Buoy, San Diego, CA) and water-alone were both consumed at a metered rate of one liter over four hours, whereas Beverage 2 was used as a positive control and consumed at a bolus rate of one liter in 30 minutes. Findings: After six hours Beverage 1 significantly improved markers of hydration compared to water-alone or Beverage 2. Beverage 1 decreased cumulative urine output vs water-alone by 32% (absolute difference 0.33L; CI 0.16 to 0.51) and vs Beverage 2 by 26% (absolute difference 0.26L; CI 0.13 to 0.38). Beverage 1 increased the beverage hydration index vs water-alone by 64% (absolute difference 0.64L; CI 0.36 to 0.92) and vs Beverage 2 by 48% (absolute difference 0.53L; CI 0.30 to 0.76) Interpretation: Beverage 1 is superior to water-alone at improving hydration when ingested at similar rates. Moreover, metered ingestion of Beverage 1 improved hydration compared to a bolus ingestion of Beverage 2, this could be due to the dissimilar ingestion rates and/or beverage composition.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Disrupted functional brain network associated with presence of hallucinations in Parkinsons Disease\nAbstract: Background Hallucinations negatively impact quality of life in Parkinsons disease, yet their neural mechanisms remain poorly understood, particularly in early disease stages. This study aimed to identify functional connectivity differences associated with visual hallucinations in early Parkinsons Disease and to validate these findings across independent datasets. Methods Resting state fMRI data from two prior independent studies was used (total N=185; N=84 hallucinators and N=101 non-hallucinators). Group differences in functional connectivity were assessed within predefined cytoarchitectonic cortical classes and functional networks, followed by whole-brain analysis using Network-Based Statistics (NBS). Associations with clinical measures, including hallucination severity, motor symptoms, cognition, and attention, were also evaluated. Results NBS identified a subnetwork of reduced functional connectivity in hallucinators, connecting regions involved in the default mode, somatomotor and attentional networks. This subnetwork was replicated in a matched sample from our independent cohort (N=50; p<0.01). Functional connectivity within the identified network was significantly associated with hallucination severity (Rsquare = 0.35, p = 0.01), and with baseline and future motor symptoms, cognition, and attention in hallucinators. Conclusions The identified functional subnetwork shows promise as a potential biomarker and therapeutic target for Parkinsons disease psychosis, warranting further investigation and validation in future studies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Performance of rapid diagnostic tests, microscopy, and qPCR for detection of parasites among community members with or without symptoms of malaria in villages with high levels of artemisinin partial resistance in North-western Tanzania\nAbstract: Background: Despite the implementation of different control interventions, infections in the communities (among asymptomatic and symptomatic individuals) still play a crucial role in sustaining malaria transmission. This study evaluated the performance of rapid diagnostic tests (RDTs), microscopy, and quantitative PCR (qPCR) in detecting malaria parasites among community members in five villages of Kyerwa district, Kagera region, an area where artemisinin partial resistance (ART-R) has been recently confirmed. Methods: A community cross-sectional survey of asymptomatic and symptomatic participants (n=4454) aged [&ge;]6 months was conducted in July and August 2023. Malaria infections were detected using RDTs, microscopy, and qPCR (using the 18S RNA gene). Performance of RDTs and microscopy was assessed by sensitivity, specificity, and predictive values, using qPCR as the reference method. Factors affecting the accuracy of these methods were explored using a multivariate logistic regression model. Results: The prevalence of malaria infections was 44.4% (n = 1979/4454), 32.1% (n = 1431/4454), and 39.8% (n = 1771/4454) by RDTs, microscopy, and qPCR, respectively. The prevalence of P. malariae and P. ovale mono-infection by microscopy was 0.2% (n = 7/4454) and 0.3% (n = 12/4454), while by qPCR was 0.4% (n = 16/4454) and 0.5% (n = 24/4454), respectively. The geometric mean parasite densities (GMPDs) by microscopy were 642 (95% confidence intervals (CI) = 570 - 723), 126 (95% CI = 98 - 162), and 124 (95% CI = 82 - 160) asexual parasites/[micro]L; while by qPCR, the GMPDs were 1180 (95% CI = 1032 - 1349), 44 (95% CI = 32 - 61), and 50 (95% CI = 29 - 89) parasites/[micro]L for P. falciparum, P. ovale spp, and P. malariae, respectively. The sensitivity and specificity of RDTs were 94.0% (95% CI = 92.8% - 95.1%) and 87.5% (95% CI = 86.2% - 88.7%), respectively; whereas those of microscopy were 74.6% (95% CI = 72.5% - 76.6%) and 95.2% (95% CI = 94.3% - 96.0%), respectively. The sensitivity of RDTs and microscopy was low at very low parasitemia (<100 parasite/[micro]L), but increased significantly with increasing parasitemia, reaching [&ge;]99.6% at >10000 parasites/{micro}L (p<0.001). Conclusion: A higher prevalence of malaria was detected and the performance of RDTs and qPCR were comparable, but microscopy had a lower performance. Higher sensitivity by RDTs compared to microscopy, indicates that RDTs are effective for the detection of malaria infections for routine case management and surveillance of malaria in this area with confirmed ART-R; and can be utilized in the ongoing plans to develop a response to ART-R.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Lifecycle of Electronic Health Record Data in HIV-Related Big Data Studies: A Qualitative Study of Instances of and Potential Opportunities to Minimize Bias\nAbstract: Background: Electronic health record (EHR) data are widely used in public health research, including HIV-related studies, but are limited by potential bias due to incomplete and inaccurate information, lack of generalizability, and lack of representativeness. This study explores how workflow processes within HIV clinics, among data scientists, and within state health departments may introduce and minimize bias within EHRs. Methods: Using a constructivist grounded theory approach, in-depth individual interviews were conducted with 16 participants purposively sampled in South Carolina from August 2023-April 2024. A focus group with 3 health department professionals with expertise in HIV disease surveillance was also conducted. Analysis was conducted as outlined by Charmaz (2006). Results: To reduce bias in EHR data, information entry forms should be designed to expansively include patient self-reported social determinants of health (SDOH) information. During data collection, healthcare providers should create a supportive healthcare environment, facilitate SDOH information disclosure, and accurately document patient information. Patients should have access to their EHRs to confirm that SDOH information are correctly recorded. During data curation, data scientists should inspect datasets for completeness, accuracy, and educate public health researchers on dataset limitations. During data management and utilization, health department professionals should crossmatch data across the state, customize data collection systems to reflect local needs, and provide community-based data education and stigma management. Conclusion: Study results suggest that future research is needed to understand how healthcare systems can be incentivized to create and implement EHR bias reduction strategies across all workflows and between stakeholders.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Self-management of multimorbidity in sub-Saharan Africa: a systematic review and meta-synthesis with focus on diabetes, hypertension, chronic kidney disease and HIV infection\nAbstract: Background The increasing prevalence of multimorbidity in sub-Saharan Africa (SSA) is an urgent concern for health systems delivery. It is uncertain how best to promote self-management approaches or the actions that patients and carers take to maintain physical and mental health, in this context. This review aims to identify, critically appraise, and synthesize qualitative evidence that describes self-management of multimorbidity among patients and their carers in SSA. Methods We systematically searched PubMed, MEDLINE, CINAHL Global Health, Google Scholar and grey literature for studies on self-management of multimorbidity or common individual chronic diseases (HIV, diabetes, hypertension or chronic kidney disease) in SSA published between 1 January 2000 and 28 to 15th September 2024. Using qualitative meta-synthesis techniques to formulate the questions and synthesize findings. We used a 10-point Critical Appraisal Skills Program (CASP)-Qualitative-Checklist to assess the quality of the studies and NVivo 12 software to facilitate a thematic analysis approach. Results We screened 2010 articles for inclusion and 20 studies met inclusion criteria. We identified themes related to medical, diet, emotional and physical self-management activities. Patients negotiate self-management based on immediacy of needs and available family support. Patients are motivated to apply biomedical management but are limited by factors such as drug stock-outs and out-of-pocket expenditure. Limited knowledge and low self-efficacy toward self-management of multimorbidity impact decision making and problem solving. We found that diabetes mellitus presents the biggest stressor in terms of burden of treatment; temporal discontinuation of medications is more prevalent amongst patients with hypertension; and patients with multimorbidity are frequently hypervigilant about their health, more likely to suffer from stress and to seek healthcare.     Conclusions We found that there is relative lack of data on self-management of multimorbidity among patients and their carers in SSA. Where data exists, we observed significant health literacy gaps, low health literacy support and limited self-efficacy as barriers to implementation of self-management. Context sensitive programmes are required to improve health literacy to increase patient autonomy and their toolkit of options to manage chronic disease.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Sustained attention processes in very preterm adolescents and their relationship to socio-emotional competence.\nAbstract: Very preterm (VPT) adolescents are at high risk of impaired sustained attention processes, as well as behavioral and socio-emotional problems. Previous studies have highlighted altered attentional patterns of brain activation in this population, but results are inconsistent. The current study aims to explore brain activity related to sustained attention in VPT and full-term adolescents aged 11 18, as well as its associations with attentional capacities and socio emotional competences. Event related functional MRI (fMRI) was used to assess sustained attention performance and associated brain activations by comparing VPT (n = 34) and their age matched full term (FT, n = 28) peers from a previously validated continuous performance task with gradual onset (gradCPT) paradigm, using two different modality versions (i.e., face and scene). In both groups, linear regression analyses were performed to examine associations between attentional and socio emotional difficulties and brain activations related to sustained attention. Results show preserved sustained attention processes in VPT adolescents, indicated by comparable behavioral attentional performance and cerebral patterns of activations in both groups across the two modalities of the gradCPT. In addition, VPT adolescents showed over recruitments in posterior occipital areas compared to FT adolescents. Moreover, higher socio emotional difficulties (i.e., higher anxiety and social difficulties) in VPT were linked to altered activations specifically in the right middle frontal gyrus, occipito temporal gyri and bilateral cerebellum, but exclusively observed during the face modality of the gradCPT. Overall, these results suggest that despite preserved sustained attention competences, VPT adolescents present a less mature sustained attention cerebral network, particularly during a task with a social context.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Investigation of the urinary peptidome to unravel collagen degradation in health and kidney disease\nAbstract: Naturally occurring fragments of collagen type I alpha 1 chain (COL1A1) have been previously associated with chronic kidney disease (CKD), with some fragments showing positive and others negative associations. Using urinary peptidome data from healthy individuals (n=1131) and CKD patients (n=5585) this aspect was investigated in detail. Based on the hypothesis that many collagen peptides are derived not from the full, mature collagen molecule, but from (larger) collagen degradation products, relationships between COL1A1 peptides containing identical sequences were investigated, with the smaller (offspring) peptide being a possible degradation product of the larger (parent) one. The strongest correlations were found for relationships where the parent differed by a maximum of 3 amino acids from the offspring, indicating an exopeptidase-regulated stepwise degradation process. Regression analysis indicated that CKD affects this degradation process. Comparison of matched CKD patients and control individuals (n=612 each) showed that peptides at the start of the degradation process were consistently downregulated in CKD, indicating an attenuation of COL1A1 endopeptidase-mediated degradation. However, as these peptides undergo further degradation, likely mediated by exopeptidases, this downregulation can become less significant or even reverse, leading to an upregulation of later stage fragments and potentially explaining the inconsistencies observed in previous studies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Ultra-processed food consumption and risk of lung cancer: Results from a Prospective Study\nAbstract: Background and Aims: There is limited evidence on the link between ultra-processed food (UPF) intake and the risk of lung cancer (LC). This study examined the association between UPF and LC risk using data from the Prostate, Lung, Colorectal, and Ovarian (PLCO) cancer trial. Methods: This study involved PLCO participants (n = 96,607, aged [&ge;] 55 years) who were followed between 1998 and 2009. Food items were categorized based on the NOVA classification. Cox regression models with inverse probability of censoring weighting (IPCW) were utilized to estimate the association between UPF intake and LC risk. The joint effect of UPF and diabetes was explored using additive hazard models to calculate the additional number of LC cases. Results: During a median follow-up period of 9.4 years, 1,596 incident LC cases were identified. UPF consumption (in %gram/day) showed no significant association with the overall risk of LC. However, adults with diabetes in the highest quintile of UPF intake had a significantly higher risk of LC (HR = 2.44; 95% CI: 1.27, 4.67) compared to participants without diabetes. A small excess risk due to the interaction between UPF and diabetes (0.13; 95% CI -0.32, 0.58) was observed, resulting in an additional 201 cases of LC per 105 person-years (95% CI: 70, 332) attributed to the highest UPF intake and diabetes interaction. Furthermore, a 10% increment in UPF intake (%kcal/day) increased the risk of LC by 32%. Conclusions: While UPF, in terms of weight contribution, is associated with a higher risk of LC in participants with diabetes, UPF (in %kcal/day), is associated with an increased risk of LC in all participants. Lowering UPF intake may help reduce the risk of LC in both diabetic patients and the general population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Identification of novel nutrient-sensitive human yolk sac functions required for embryogenesis\nAbstract: The human yolk sac (hYS) is essential for embryo nutrient biosynthesis/transport and development. However, there lacks a comprehensive study of hYS nutrient-gene interactions. Here we performed a secondary analysis of hYS transcript profiles (n=9 samples) to identify nutrient-sensitive hYS genes and regulatory networks, including those that associate with adverse perinatal phenotypes with embryonic origins. Overall, 14.8% highly expressed hYS genes are nutrient-sensitive; the most common nutrient cofactors for hYS genes are metals and B-vitamins. Functional analysis of highly expressed hYS genes reveals that nutrient-sensitive hYS genes are more likely to be involved in metabolic functions than hYS genes that are not nutrient-sensitive. Through nutrient-sensitive gene network analysis, we find that four nutrient-sensitive transcription regulators in the hYS (with zinc and/or magnesium cofactors) are predicted to collectively regulate 30.9% of highly expressed hYS genes. Lastly, we identify 117 nutrient-sensitive hYS genes that associate with an adverse perinatal outcome with embryonic origins. Among these, the greatest number of nutrient-sensitive hYS genes are linked to congenital heart defects (n=54 genes), followed by microcephaly (n=37). Collectively, our study characterises nutrient-sensitive hYS functions and improves understanding of the ways in which nutrient-gene interactions in the hYS may influence both typical and pathological development.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Standardizing Phenotypic Algorithms for the Classification of Degenerative Rotator Cuff Tear from Electronic Health Record Systems\nAbstract: ABSTRACT: Background: Degenerative rotator cuff tears (DCTs) are the leading cause of shoulder pain, affecting 30% to 50% of individuals over 50. Current phenotyping strategies for DCT rely on heterogeneous combinations of procedural and diagnostic codes, leading to concerns about misclassification. We aimed to create universal phenotypic algorithms to classify DCT status across EHR systems. Methods: Using Vanderbilt University Medical Center's de-identified EHR system, we developed and validated two sets of algorithms - one requiring imaging verification and one without imaging verification - to identify DCT cases and controls. The algorithms used combinations of ICD and CPT codes, as well as natural language processing (NLP), to increase diagnostic certainty. Manual chart reviews by trained personnel blinded to case-control determinations were conducted to compute positive (PPV) and negative predictive values (NPV). Results: The algorithm development process resulted in five phenotypes with an overall predictive value of 94.5%. By approach: 1) code only cases that required imaging confirmation (PPV = 89%), 2) code only cases that did not require imaging verification (PPV = 92%), 3) NLP-based cases that did not require imaging verification (PPV = 89%), 4) code-based controls that were confirmed by imaging (NPV = 90%), and 5) code and NLP-based controls that did not require imaging verification (NPV = 100%). External validation demonstrated 94% sensitivity and 75% specificity for the code-only algorithms. The addition of NLP increased the number of identified cases without compromising predictive values. Conclusions: These algorithms represent an improvement over current phenotyping strategies and allows for EHR studies of unprecedented size\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Adverse respiratory events during treatment with gabapentin and opioids among older adults with spine-related conditions: a propensity-matched cohort study in the US Medicare population\nAbstract: Background Context: Recent work indicates no increased mortality risk with concurrent gabapentin and opioid use when using an active comparator control design. However, concurrent gabapentin and opioid prescriptions have been associated with greater risk of respiratory depression in some studies. Purpose: To compare the risk of respiratory events among Medicare enrollees with spine-related diagnoses treated with gabapentin + opioids vs those treated with tricyclic antidepressants (TCA) or duloxetine + opioids. We hypothesized that enrollees treated with gabapentin + opioids would have increased risk of adverse respiratory events compared to those treated with an active control + opioids. Study Design/Setting: Propensity score-matched cohort study with an incident user, active comparator (TCA/duloxetine) control design. The primary analysis included those who concurrently (within 30 days) filled [&ge;]1 incident gabapentin + [&ge;]1 opioid or [&ge;]1 incident TCA/duloxetine + [&ge;]1 opioid prescription. Patient Sample: U.S. Medicare beneficiaries with spine-related diagnoses 2017-2019. People treated with gabapentin + opioids (n=66,580) were matched on demographic and clinical factors to people treated with TCAs/duloxetine + opioids (n=66,580). Outcome Measures: Time to a composite respiratory outcome consisting of mechanical ventilation, intubation, respiratory failure, pneumonia, or acute respiratory distress syndrome. Methods: Cox proportional hazard regression was used to estimate adjusted hazard ratios (aHRs) and 95% confidence intervals (95% CIs). Results: Among 133,160 Medicare enrollees (median age 73.3 years; 66.7% female), 6089 (4.6%) experienced respiratory events before the end of follow-up. A total of 3297 (5.0%) of people who were treated with gabapentin + opioids (median initial dose/day of gabapentin was 338 mg) had respiratory events compared to 2792 (4.2%) of those treated with an active control + opioids. The increased risk in those treated with gabapentin + opioids was statistically significant after adjustment (HR 1.14; 95% CI 1.09, 1.20; p<0.0001). The most common respiratory events were pneumonia (3.5% of people in the gabapentin + opioids group versus 3.0% of people in the TCA/duloxetine + opioids group) and respiratory failure (2.2% in the gabapentin + opioids group versus 1.8% in the TCA/duloxetine + opioids group). Results were similar in analyses (a) restricted to [&le;]30-day follow-up and (b) that required [&ge;]2 fills of each prescription. Conclusions: While recent work has indicated no increased mortality risk with concurrent gabapentin and opioid use, the current findings suggest clinicians should exercise caution in prescribing gabapentin to people experiencing pain who are also being treated with opioids, due to the potentially increased risk of respiratory events.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The neurodevelopmental spectrum of CASK-related disorder\nAbstract: Background: Pathogenic CASK variants are associated with neurodevelopmental disorders of variable severity including X-linked intellectual disability (XLID) and microcephaly with pontocerebellar hypoplasia (MICPCH). Although the number of diagnosed cases is rising, current understanding of the CASK-related neurodevelopmental spectrum is limited. Here, we systematically review the published characteristics of individuals with CASK-related disorder, and compare these to a more recently-diagnosed group. We provide quantitative information about the ranges of adaptive abilities, motor function, visual function and social-emotional-behavioural characteristics, and explore within-group associations. Methods: 151 individuals with CASK variants were identified in published literature. 31 children and young people with CASK variants were recruited to the UK-based Brain and Behaviour in Neurodevelopmental disorder of Genetic Origin (BINGO) project. BINGO-participating caregivers completed a bespoke medical history questionnaire and battery of standardised neurodevelopmental measures. Results: Comparing the recently diagnosed BINGO CASK-related disorder group to previously reported individuals, we found consistent prevalence of tone abnormalities, sensorineural hearing loss and epilepsy, but lower prevalence of severe/profound ID, MICPCH, optic atrophy and nystagmus. Areas of frequent difficulty not highlighted in previous reports include sleep difficulties and cerebral visual impairment (CVI). Neurodevelopmental characteristics were highly variable within the BINGO CASK-related disorder group, and group-wide patterns were similar to those observed in other rare genetic conditions. Within the BINGO CASK-related group, epilepsy is significantly associated with ID severity, after controlling for age. Sub-groups with MICPCH or microcephaly only have equivalent ranges of adaptive function, but MICPCH may be associated with more severe motor difficulties. Conclusion: The spectrum of neurodevelopmental characteristics associated with CASK-related disorder appears to be broadening with increased access to genome-wide diagnostic testing. Further studies are needed to elucidate the relationships between CASK variants, structural brain development, epilepsy, and neurodevelopmental characteristics.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genome-wide association study of delay discounting in 134,935 individuals identifies novel loci and transdiagnostic associations across mental and physical health\nAbstract: Delay discounting (DD), a person's preference for smaller immediate rewards over larger delayed rewards, is a heritable trait that is associated with psychiatric and physical outcomes, yet the biological mechanisms underlying these links are not known. We performed a GWAS of DD using 134,935 adults and identified 14 genome-wide significant loci. We observed genetic correlations between DD and 73 behavioral, physical and neuroimaging traits, many of which persisted even after accounting for educational attainment, intelligence, and executive function. Network analysis revealed that the associations between DD and certain traits were explained by both overlapping and trait-specific biological processes. In a hospital-based cohort (N = 66,917), DD polygenic scores were associated with 212 medical conditions. These results demonstrate that DD has a pleiotropic and polygenic common variant architecture, and is genetically associated with numerous outcomes, making it a promising endophenotype for psychiatric and physical health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Long-Read Sequencing Increases Diagnostic Yield for Pediatric Sensorineural Hearing Loss\nAbstract: The diagnostic yield of genetic testing for pediatric sensorineural hearing loss (SNHL) has remained at around 40% for over a decade despite newly discovered causative genes and the expanded use of exome sequencing (ES). This stagnation may be due to (1) a focus on coding regions of the genome and (2) an inability to resolve variants in complex genomic regions due to reliance on short-read sequencing technologies. Short-read genome sequencing (srGS) and long-read genome sequencing (lrGS) both provide exonic single nucleotide variant (SNV) and small indel detection at the same sensitivity as ES, but also evaluate intronic regions. lrGS provides improved resolution for structural variants (SV) and repetitive genomic regions. We sought to investigate the potential utility of lrGS in the diagnostic evaluation of a small cohort of patients with SNHL of unknown etiology after ES and srGS. 19 pediatric patients with SNHL underwent lrGS via PacBio SMRT sequencing. Sequencing data were processed using the PacBio WGS variant pipeline. The diagnostic yield for this lrGS cohort was 4/19 (21%). Relevant variants detected only with lrGS included a hemizygous deletion in trans with a missense variant in an area of high genomic homology (OTOA) and two single nucleotide loss-of-function variants in trans to a known copy-number-loss for a gene with a highly homologous pseudogene (STRC). A complex inversion was identified in the MITF gene which was also identified on post-hoc analysis by srGS. LrGS provides improved resolution for complex genomic structural variation which may increase diagnostic yield for genetic pediatric SNHL, and, potentially, rare disease more broadly.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Advancing precision care in pregnancy through an actionable fetal findings list\nAbstract: The use of genomic sequencing (GS) for prenatal diagnosis of fetuses with sonographic abnormalities has grown tremendously over the past decade. Fetal GS also offers an opportunity to identify incidental genomic variants that are unrelated to the fetal phenotype, but may be relevant to fetal and newborn health. There are currently no guidelines for reporting incidental findings from fetal GS. In the United States, GS for adults and children is recommended to include a list of \"secondary findings\" genes (ACMG SF v3.2) that are associated with disorders for which surveillance or treatment can reduce morbidity and mortality. The genes on ACMG SF v3.2 predominantly cause adult-onset disorders. Importantly, many genetic disorders with fetal and infantile onset are actionable as well. A proposed solution is to create a \"fetal actionable findings list,\" which can be offered to pregnant patients undergoing fetal GS or eventually, as a standalone cell-free fetal DNA screening test. In this integrative review, we propose criteria for an actionable fetal findings list, then identify genetic disorders with clinically available or emerging fetal therapies, and those for which clinical detection in the first week of life might lead to improved outcomes. Finally, we synthesize the potential benefits, limitations, and risks of an actionable fetal findings list.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The contribution of coding variants to the heritability of multiple cancer types using UK Biobank whole-exome sequencing data\nAbstract: Genome-wide association studies have been highly successful at identifying common variants associated with cancer, however, they do not explain all the inherited risk of cancer. Family-based studies, targeted sequencing and, more recently, exome-wide association studies have identified rare coding variants in some genes associated with cancer risk, but the overall contribution of these variants to the heritability of cancer is less clear. Here we describe a method to estimate the genome-wide contribution of rare coding variants to heritability that fits models to the burden effect sizes using an empirical Bayesian approach. We apply this method to the burden of protein-truncating variants in over 15,000 genes for 11 cancers in UK Biobank, using whole-exome sequencing data on over 400,000 individuals. We extend the method to consider the overlap of genes contributing to pairs of cancers. We found ovarian cancer to have the greatest proportion of heritability attributable to protein-truncating variants in genes (46%). The joint cancer models highlight significant clustering of cancer types, including a near complete overlap in susceptibility genes for breast, ovarian, prostate and pancreatic cancer. Our results provide insights into the contribution of rare coding variants to the heritability of cancer and identify additional genes with strong evidence of susceptibility to multiple cancer types.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Aladyn Individual: Bayesian Hierarchical Dynamic Genetic Modeling of Comorbidity Progression\nAbstract: Early identification of high-risk individuals through the analysis of their unique disease trajectories has a strong potential to support efficient prevention and clinical management across a range of chronic conditions. In this paper we present a novel approach for dynamic modeling of the evolution of chronic disease risks over time, incorporating individual genetic predispositions. Our approach uses a hierarchical Bayesian topic model including Gaussian Processes to capture age effects. It accounts for genetic predisposition through a time-warping function and topic-dependent genetic scores, enabling both simultaneous learning and updated predictions of complex comorbidity patterns, inclusive of genomic and non-genomic effects. We systematically compare to previous approaches and provide detailed simulations at https://bookdown.org/sarahmurbut/dynamic_ehr/ https://surbut.shinyapps.io/dynamic_ehr.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The international trial of nasal oxygen therapy after cardiac surgery (NOTACS) in patients at high risk of postoperative pulmonary complications: Economic evaluation protocol and analysis plan\nAbstract: Introduction High-Flow Nasal Therapy (HFNT) is an innovative non-invasive form of respiratory support. Compared to standard oxygen therapy (SOT), there is an equipoise regarding the effect of HFNT on patient-centred outcomes among those at high risk of developing postoperative pulmonary complications after undergoing cardiac surgery. The NOTACS trial aims to determine the clinical and cost-effectiveness of HFNT compared to SOT within 90 days of surgery in the United Kingdom, Australia, and New Zealand. This protocol describes the methods and analyses planned for economic evaluation embedded within the ongoing NOTACS trial.   Methods and analysis The economic evaluation will identify, measure and value resources and health outcomes in both trial arms and compare changes in costs with  days alive and at home and EQ-5D-5L quality adjusted life years (QALYs) from the perspective most relevant to the decision-making country. Results from pooling data across the trial will use health and social care sector perspective. All patient-specific data including hospital/community care and health outcomes will be collected prospectively. Unit costs will be sourced from national, published or local data. Missing data will be assessed, with values replaced depending on assumed mechanism of missingness, and impact of replacement on cost-effectiveness assessed. Costs and outcomes by trial arm will be presented as components and totals per patient using a range of descriptive statistics. Regression models for costs and effects will account for patient characteristics, quality of life and health service utilization at baseline. Uncertainty in parameters, sampling and heterogeneity will be addressed through deterministic, probabilistic and subgroup analyses to assess the impact of varying methods and assumptions for costs, outcomes and approaches used in base-case analysis. Results will be interpreted using recommended national cost-effectiveness thresholds.     Registration details The study is registered with ISRCTN (ISRCTN14092678) on 13/05/2020.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Determining the indirect costs of suicide in Sweden between 2010 and 2019: A cost of illness study\nAbstract: Background: Globally, more than 700 thousand people commit suicide annually. In Sweden, the yearly incidence is between 1000 and 1500 people, which is higher than the global average. Understanding the economic burden of suicide could help highlight the importance and urgency of finding more effective treatments and preventative measures to help people suffering from suicidal thoughts and support studies evaluating the cost-effectiveness of various interventions.   Method: This national population-based cross-sectional study estimated the indirect costs associated with all suicides in Sweden between 2010 and 2019. Indirect costs were estimated using the human capital approach. Data regarding average salaries and employment rates were extracted from publicly available data in Sweden. Productivity loss was estimated over two time horizons, the year following the suicide and over a lifetime horizon. Estimations were performed in total numbers for the yearly cohorts as well as per person.   Results: Between 2010 and 2019, 1 406 to 1 591 suicides occurred every year in Sweden. In total, approximately 26 500 productive life years are lost every year due to suicide. In 2019, the productivity loss due to all suicides in Sweden was estimated to be 44 million euros over a one-year time horizon, where 10 million euros are direct losses in local and regional authority taxes. Over a lifetime, productivity losses amounted to 935 million euros. The corresponding estimations per person were 37 and 778 thousand euros respectively over a one-year and a lifetime time horizon Over a one-year time horizon, the productivity loss was highest in the older age groups.   Conclusions: This study provides valuable insights into the economic burden of suicide on Swedish society. It underlines the potential economic benefits of effective suicide prevention, aligning with previous research highlighting the substantial returns--both monetary and in terms of human well-being--that successful prevention strategies can yield.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Physician- and Large Language Model-Generated Hospital Discharge Summaries: A Blinded, Comparative Quality and Safety Study\nAbstract: Importance: High quality discharge summaries are associated with improved patient outcomes but contribute to clinical documentation burden. Large language models (LLMs) provide an opportunity to support physicians by drafting discharge summary narratives. Objective: To determine whether LLM-generated discharge summary narratives are of comparable quality and safety to those of physicians. Design: Cross-sectional study. Setting: University of California, San Francisco. Participants: 100 randomly selected Inpatient Hospital Medicine encounters of 3-6 days duration between 2019-2022. Exposure: Blinded evaluation of physician- and LLM-generated narratives was performed in duplicate by 22 attending physician reviewers. Main Outcomes and Measures: Narratives were reviewed for overall quality, reviewer preference, comprehensiveness, concision, coherence, and three error types - inaccuracies, omissions, and hallucinations. Each error individually, and each narrative overall, were assigned potential harmfulness scores on a 0-7 adapted AHRQ scale. Results: Across 100 encounters, LLM- and physician-generated narratives were comparable in overall quality on a 1-5 Likert scale (average 3.67 [SD 0.49] vs 3.77 [SD 0.57], p=0.213) and reviewer preference ({chi}2 = 5.2, p=0.270). LLM-generated narratives were more concise (4.01 [SD 0.37] vs. 3.70 [SD 0.59]; p<0.001) and more coherent (4.16 [SD 0.39] vs. 4.01 [SD 0.53], p=0.019) than their physician-generated counterparts, but less comprehensive (3.72 [SD 0.58] vs. 4.13 [SD 0.58]; p<0.001). LLM-generated narratives contained more unique errors (average 2.91 [SD 2.54] errors per summary) than physician-generated narratives (1.82 [SD 1.94]). Averaged across individual errors, there was no significant difference in the potential for harm between LLM- and physician-generated narratives (1.35 [SD 1.07] vs 1.34 [SD 1.05], p=0.986). Both LLM- and physician-generated narratives had low overall potential for harm (<1 on 0-7 scale), although LLM-generated narratives scored higher than physician narratives (0.84 [SD 0.98] vs 0.36 [SD 0.70], p<0.001). Conclusions and Relevance: In this cross-sectional study of 100 inpatient Hospital Medicine encounters, LLM-generated discharge summary narratives were of similar quality, and were preferred equally, to those generated by physicians. LLM-generated summaries were more likely to contain errors but had low overall harmfulness scores. Our findings suggest that LLMs could be used to draft discharge summary narratives of comparable quality and safety to those written by physicians.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Pretrained Patient Trajectories for Adverse Drug Event Prediction Using Common Data Model-based Electronic Health Records\nAbstract: Pretraining electronic health record (EHR) data through language models by treating patient trajectories as natural language sentences has improved various medical tasks. However, EHR pretraining models have never been utilized in adverse drug event (ADE) prediction. Here, we propose a novel pretraining scheme for common data model (CDM) based EHR data, named CDM-BERT. We utilized diagnosis, prescription, measurement, and procedure domains from observational medical outcomes partnership (OMOP)-CDM. We newly adopted domain embedding (DE) to simplify pretraining procedure and to improve comprehension of medical context. ADE prediction was selected as a finetuning task. For drug groups, we included nonsteroidal anti-inflammatory drugs (NSAID), anticoagulants (AC), glucocorticoids (GC), and chemotherapy (Chemo). For corresponding adverse events, we selected peptic ulcer (PU), intracranial hemorrhage (ICH), osteoporosis (OP), and neutropenic fever (NF), respectively. CDM-BERT was validated by internal and external datasets with 510,879 and 419,505 adult inpatients. CDM-BERT outperformed all the other baselines in all cohorts, demonstrating the effectiveness of DE (area under the receiver operating characteristic curve (AUROC) of 0.977, 0.908, 0.980, 0.989 for NSAID-PU, AC-ICH, GC-OP, Chemo-NF cohorts in internal validation, and 0.967, 0.960, 0.972, 0.959 in external validation, respectively). We also identified important features for each cohort, and several prior studies and clinical knowledge suggested the results. CDM-BERT has demonstrated its potential as a foundation model through its prediction performance, interpretability, and compatibility.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: I answer to clinical scenarios as a real doctor because I \"Think\": \"ChatGPTo1\" new reasoning ability.\nAbstract: The adoption of the ChatGPT o1 model represents a significant advancement in the management of clinical cases due to the introduction of a new structured reasoning capability, the \"chain-of-thought reasoning\" (CoT). In this study, 350 general medicine clinical cases were tested using ChatGPT o1 and ChatGPT o1 mini, and their performance was compared with ChatGPT 4o and ChatGPT 4o mini to evaluate diagnostic accuracy. The results showed that ChatGPT o1 achieved a correct answer rate of 93.4%, outperforming both ChatGPT 4o (82.2%) and the mini versions (ChatGPT o1 mini: 70.2% and ChatGPT 4o mini: 66.2%). The CoT technique enabled the model to provide more coherent and transparent responses, reducing the occurrence of so-called \"hallucinations.\" This study highlights how the ChatGPT o1 model can be a valuable tool in clinical practice, although its use requires supervision to ensure patient safety, especially in critical settings.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Machine learning framework for predicting the presence of high-risk clonal haematopoiesis using complete blood count data: a population-based study of 431,531 UK Biobank participants\nAbstract: Background Clonal haematopoiesis (CH), the disproportionate expansion of a haematopoietic stem cell and its progeny, driven by somatic DNA mutations, is a common age-related phenomenon that engenders an increased risk of developing myeloid neoplasms (MN). At present, CH is identified by targeted sequencing of peripheral blood DNA, which is impractical to apply at population scale. The complete blood count (CBC) is an inexpensive, widely used clinical test. Here, we explore whether machine learning (ML) approaches applied to CBC data could predict individuals likely to harbour CH and prioritise them for DNA sequencing. Methods The UK Biobank was filtered to identify 431,531 participants with paired CBC and whole exome sequencing (WES). Somatic mutations were previously identified from blood WES using Mutect2 to classify individuals with CH driver mutations. Using 18 CBC indices/features and basic demographics (age and sex), we trained a range of tree-based ML classifiers to infer as binary output, the presence/ absence of CH. Findings Using Random Forest (RF) classifiers, we predicted the presence/absence of CH driven by mutations in one of five genes known to confer a high-risk of incident MN (JAK2, CALR, SF3B1, SRSF2 and U2AF1). We subsequently developed a unified, optimised RF classifier for high-risk CH driven by any of these genes and assessed its performance (median AUC 0.85). However, the low prevalence of high-risk CH implies that our model cannot be generalised to population scale without compromising its sensitivity (20.1% using stringent cutoff probability score). Interpretation We showcase a proof-of-concept that the presence of high-risk CH can be inferred from CBC perturbations using RF classifiers. The future integration of raw blood cell analyser data can help improve the performance of our model and facilitate its application at scale.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of cardiovascular disease in patients with classical Hodgkin lymphoma: a Danish nationwide register-based cohort study\nAbstract: The risk of cardiovascular disease (CVD) in patients with classical Hodgkin lymphoma (cHL) undergoing contemporary treatment is unclear. Methods: All patients with cHL [&ge;]18 years at diagnosis treated with doxorubicin-containing chemotherapy between 2000-2022 were matched with comparators in a 1:5 ratio on birth year, sex, and Charlson Comorbidity Index at time of matching (score of 0 or [&ge;]1). The cause-specific cumulative incidence of a composite of CVDs and corresponding 95% confidence intervals (CIs) were computed with death and lymphoma relapse as competing events using the Aahlen-Johansen estimator. Results: A total of 1,905 patients and 9,525 comparators with a median follow-up of 10 years (interquartile range, [IQR]: 5.9-17.4). Median age was 39 years (IQR: 27-56), median cumulative doxorubicin dose was 250 mg/m2 (IQR: 200-300). The CVD cumulative incidences were 4.7% (95% CI: 3.6-5.7) for patients vs. 2.6% (95% CI: 2.3-2.9) for comparators at 5 years, 8.9% (95% CI: 7.2-10.5) vs. 5.5% (95% CI: 4.9-6.0) at 10 years, and 17.0% (95% CI: 14.1-19.9) vs. 8.2% (95% CI: 7.4-9.0) at 15 years. Conclusions: CVD remains a substantial effect after contemporary treatment for cHL, suggesting that awareness of symptoms and a low threshold for referral to diagnostic examination are still important measures during survivorship.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Acceptability and implementation considerations of the patient-collected rectal swab for sexually transmitted infections testing among men who have sex with men and transgender women in Kigali, Rwanda\nAbstract: Background Rectal sexually transmitted infections (STI) are prevalent among men who have sex with men (MSM) and transgender women (TGW). Self-collection of rectal specimens is widely used globally, but limited data exist on its implementation in Africa. We report experiences of MSM/TGW self-collecting rectal STI specimens in Kigali. Methods From March to August 2018, 738 MSM/TGW were recruited in a cross-sectional study using respondent-driven sampling in Kigali. We tested for Neisseria gonorrhea and Chlamydia trachomatis using the Cepheid GeneXpert CT/NG platform on self-collected rectal swabs. Likert scales assessed self-collection difficulty and comfort. Ordered logistic regression analyses were performed to characterize factors associated with self-collection difficulty. Results Overall, 14%(106) identified as TGW. In total, 78%(577) found rectal swab self-collection easy/very easy, while 15%(108) found it difficult/very difficult. Most, 92%(679), were comfortable/very comfortable with the test, and 98%(730) said they would repeat the test in the future. In multivariable RDS-adjusted analyses, discomfort with the swab was positively associated with difficulty in self-collection (adjusted cumulative odds ratios ((aCOR): 7.9(95%CI: 4.9-12.8)) and having a prevalent rectal STI (aCOR: 4.19, 95%CI: 2.02-8.72) was significantly associated with difficulty. Furthermore, 10%(75) of rectal swabs returned indeterminate results (65 invalid results and 10 errors). Conclusion Most MSM/TGW found self-collection of rectal swabs easy, comfortable, and collected valid samples. Self-collection of rectal swabs could be used alongside clinic- and community-based STI testing to improve diagnosis and treatment in Rwanda. However, measures to optimize sample collection and processing are needed to reduce the cost and clinical implications of indeterminate results\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Altered association of plasmatic oxytocin with affective stress responses in alcohol use disorder\nAbstract: Oxytocin has been proposed to play a role in the development and maintenance of alcohol use disorder (AUD) through its interactions with stress pathways. Empirical evidence that indicates altered associations between endogenous oxytocin and stress reactivity in AUD is currently lacking. In this study, we investigated baseline plasmatic oxytocin concentrations of early-abstinent patients with AUD (N = 40) and matched healthy control participants (N = 37), who completed the Trier Social Stress Test (TSST) as well as a control task on two separate visits. We measured salivary cortisol and pulse rate as indicators of a physiological stress response, and anxiety ratings as an indicator of an affective stress response at multiple time points. Baseline oxytocin levels did not significantly differ between the groups. However, our results suggest an altered association of oxytocin and affective stress responses in participants with AUD: while participants with AUD showed a positive relationship between plasmatic oxytocin levels and stress-induced anxiety increase, the opposite relationship was found in control participants. We did not find evidence for an association of oxytocin with physiological stress responses. Assuming that affective stress responses mediate addiction-related behaviors like craving and relapse, our findings suggest that administering exogenous oxytocin might not be beneficial in treating AUD, at least during the early stages of abstinence.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Understanding Thromboembolus Transport Patterns In The Brain For Stroke In The Presence Of Carotid Artery Stenosis\nAbstract: Deciphering the source of an embolism is a common challenge encountered in stroke treatment. Carotid stenosis is a key source of embolic strokes. Carotid interventions can be indicated when a patient has greater than 50% stenosis in the carotid ipsilateral to the cerebral infarction, which is designated as the symptomatic carotid. However, there are often significant number of cases where carotid emboli travel contralaterally leading to ambiguity regarding which carotid is symptomatic. We use a patient-specific computational embolus-hemodynamics interaction model developed in prior works to conduct an in silico experiment spanning 30 heart-to-brain arterial models with differing combinations of bilateral severe and mild stenosis degrees. We used these models to study source-to-destination transport of thromboemboli released from left/right carotid disease sites, and cardiogenic sources. Across all cases considered, thromboemboli from left and right carotid sources showed non-zero contralateral transport. We also found that cardiogenic thromboemboli do not have an altered hemisphere distribution or distinct transport preference dependent on stenosis degree, thus potentially making the underlying etiology more cryptic. In patients with carotid stenosis or chronic occlusion ipsilateral to the area affected by stroke, we have demonstrated that the presence of contralateral stenosis can cause emboli that travel across the Circle of Willis (CoW) which can potentially lead to ambiguity when deciding which carotid is truly symptomatic.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Bridging Cultures to Defeat COVID-19: An Innovative Virtual Exchange Program in Global Medical Education\nAbstract: The problem and opportunity: There is a critical and growing need to train globally focused, culturally fluent clinicians and scientists who can collaboratively defeat current and future public health threats across international boundaries. In parallel, academic conferences bring together thousands of diverse international healthcare professionals every year, yet their potential to provide the crucial professional development training necessary to advance internationalized medicine is often underutilized. The solution: We developed and now first report an innovative healthcare education program that used an academic conference as the framework around which to build a structured, non-incidental virtual exchange (VE) for training globally and culturally proficient healthcare professionals. Herein we further describe the program's design and content, successes and challenges, and lessons learned. Program Overview: Using a smartphone based social-networking and conference management app with available translation capabilities, pre- and post-graduate trainees prepared and participated in poster presentations, seminars, and workshops to learn current research and best-practices in COVID-19 medicine, while engaging with their international peers in networking and professional-development exercises. The 2-week intensive program included daily synchronous interactive seminars on various topics in COVID-19 medicine, international team-based asynchronous activities such as preparing, presenting, and constructively critiquing research posters at virtual poster sessions, and expert-led wellness and cultural-competence workshops. Participants received initial training in the norms of intercultural communication, syllabus content and expectations, incentives, icebreaker activities, and program technology. They learned then-current COVID-19 medical research, therapies, and best practices, as well as professional \"soft skills\" including leadership, team building, scientific/clinical presentation, verbal/written communication skills, and intercultural competence. The program vastly expanded participants' international professional networks to enhance their mentorship and career development opportunities. Conclusions: Participants reported receiving substantial benefits from the program, with many reporting immediate translation of lessons learned toward improving healthcare education or practice in their home communities.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Clioquinol improves catalytic activity of PHGDH and shows antiseizure efficacy in patients\nAbstract: Drug-resistant epilepsy (DRE) affects over 25 million people worldwide and is associated with neuroinflammation. We identified haloquinolines from a drug repurposing library as potent activators of phosphoglycerate dehydrogenase (PHGDH) enzyme, which converts 3-phosphoglycerate to generate serine and the neurotransmitter glycine, and steers anti-inflammatory responses. The most promising haloquinoline clioquinol can increase the catalytic activity of PHGDH up to 2.5-fold, thereby increasing de novo glycine biosynthesis and resulting in reduced glutamate levels. Moreover, we show that clioquinol has PHGDH-dependent antiseizure activity as well as anti-inflammatory properties in vivo using various zebrafish and mouse epilepsy models. Finally, we demonstrate the efficacy of clioquinol as add-on treatment in severe DRE patients. Therefore, increasing activity of PHGDH is a promising new approach to treat DRE.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic and Demographic Determinants of Fuchs Endothelial Corneal Dystrophy Risk and Severity\nAbstract: Importance: Understanding the pathogenic mechanisms of Fuchs endothelial corneal dystrophy (FECD) is essential for developing gene-targeted therapies. Objective: To investigate associations between demographic data and age at first keratoplasty in a large genetically refined FECD cohort. Design, Setting, and Participants: This retrospective cohort study recruited 894 individuals with FECD at Moorfields Eye Hospital (London) and General University Hospital (Prague). Ancestry was inferred from genome-wide SNP array data. CTG18.1 status was determined by short tandem repeat and/or triplet-primed PCR. One or more expanded alleles (>49 repeats) were classified as expansion-positive (Exp+). Expansion-negative (Exp-) cases were whole exome sequenced. Main Outcome(s) and Measure(s): Association between variants in FECD-associated genes, demographic data and age at first keratoplasty. Results: Within the total cohort (n=894), 77.3% were Exp+. The majority of European (668/829, 80.6%) and South Asian (14/22, 63.6%) patients were Exp+, whereas the majority of those with African (30/37, 81.1%), East Asian (2/3,66.7%), and American Admixture (2/3, 66.7%) ancestry were Exp-. The percentage of females was significantly higher (151, 74.4%) in the Exp- cohort compared to the Exp+ (395, 57.2%; P<.001). The median (IQR) age at first keratoplasty of the Exp+ patients (68.2 [63.2 to 73.6] years) was older than the Exp- patients (61.3 [52.6 to 70.4] years; P<.001). The CTG18.1 repeat length of the largest expanded allele within the Exp+ group was inversely correlated with the age at first keratoplasty (r = -0.087 [95% CI: -0.162 to -0.012], P=.02). The ratio of biallelic to monoallelic expanded alleles was higher in the FECD cohort compared to an unaffected control group (P<.001), indicating that two Exp+ alleles increase disease penetrance compared to one expansion. We only identified potentially pathogenic variants (MAF <0.01; CADD >15) in FECD-associated genes in 13 (10.1%) Exp- individuals. Conclusions and Relevance: CTG18.1 expansions are present in most European and South Asian patients with FECD. Repeat length and zygosity status of CTG18.1 modify disease severity and penetrance. Known disease-associated genes account for only a minority of Exp- cases, with unknown risk factors determining disease in the rest of this subgroup. These data have important implications for the development of future FECD gene-targeted therapies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A newly identified pathology of Episodic Angioedema with Hypereosinophilia (Gleich's Syndrome) revealed by Multi-Omics Analysis\nAbstract: Episodic Angioedema with Eosinophilia (Gleich syndrome) is a rare disease characterized by periodic angioedema, fever, and marked eosinophilia. This study aimed to elucidate the pathogenic factors of severe Gleich syndrome through comprehensive multi-omics analysis, including whole genome sequencing (WGS) and RNA sequencing (RNA-seq). A young female patient (age: 16-20 years old) presenting with periodic high fever, extensive urticaria/eczema, and marked eosinophilia was diagnosed with Gleich syndrome. The symptoms were severe, with no spontaneous remission, but responded well to oral steroids, showing mild resolution. WGS analysis of the patient's blood samples identified high-impact pathogenic mutations in 16 genes, including PRDM16. RNA-seq analysis revealed differentially expressed genes (DEGs) associated with immune response regulation and viral defense. Combined z-score analysis of WGS and RNA-seq data identified ACE as a key gene. ACE expression was markedly downregulated during disease progression and recovered with treatment. IFNG was also identified. The results of this study suggest that a marked decrease in ACE, driven by genetic mutations in PRDM16 and altered expression of IFNG, leading to increased bradykinin and enhanced activation of the arachidonic acid cascade, may have caused the clinical presentation of Gleich syndrome, including dramatic inflammation and angioedema. This study underscores the importance of integrating WGS and RNA-seq data to elucidate the molecular basis of rare diseases and provides a foundation for developing therapeutic strategies for hypereosinophilic conditions.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Impaired speaking-induced suppression in schizophrenia predicts auditory verbal hallucinations\nAbstract: A successful efference copy self-prediction suppresses auditory signals in the primary auditory cortex (A1) is necessary for speakers to successfully compare auditory feedback during speech production with auditory feedback during passive listening, this is called speaker-induced suppression (SIS). The top-rank positive symptom in schizophrenic (SZ) patients, auditory verbal hallucination, for instance, is hypothesized to relate to failure to distinguish the internal voice and external sounds, and this deficit is thought to be associated with impaired self-prediction in comparing external and self-generated contents. In this magnetoencephalographic imaging (MEGI) study, we compared SIS M100 in the primary auditory cortex (A1) between the healthy controls (HC; N = 30) and SZ patients (N = 22). The SZ patients displayed reduced SIS and M100 in the A1, and this impairment is negatively correlated with auditory hallucinations. These outcomes suggest that the SZ patients' hallucinatory symptoms are caused by misattribution between the external and self-generated stimuli. We proposed that the weakened self-agency and neural oscillations may lead to this misattribution.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Reversible and Noninvasive Modulation of a Historical Surgical Target for Depression with Low Intensity Focused Ultrasound\nAbstract: Major depressive disorder has a point prevalence of 5% of the world population and is the main cause of disability, with up to a third of patients not responding to first-line treatments. Surgical neuromodulation is offered to only an anecdotal proportion of these patients, because while these methods are curative in some individuals, the proportion of responders rarely exceeds 50%. Recent efforts to establish reliable brain circuit-symptom relationships and thus predict response have involved mapping with multiple intracranial electrodes, but the impracticality of this approach currently prevents its application at scale. In the present study (ClinicalTrials.gov identifier NCT05697172; FDA Q220192) we begin to address this gap by leveraging low-intensity focused ultrasound (LIFU), a novel noninvasive technique, to modulate the anterior limb of the internal capsule, which is an established surgical deep white matter target for depression. We based our study on burgeoning in vitro evidence that LIFU attenuates axonal conduction by operating mechanosensitive channels in nodes of Ranvier. Compared with sham stimulus, active LIFU produced a functional disconnection of gray matter hubs reached by the sonicated axonal tracts, an increase in positive emotion, and top-down effects on the cardiovascular autonomic balance. Our results using LIFU of deep-brain white matter tracts in humans open three potential avenues to understand the mechanisms and improve the outcome of depression, namely attaining a personalized definition of brain circuit-symptom relationships, serving as a noninvasive probe for neuromodulation before irreversible procedures in a \"try before you buy\" approach, and ultimately emerging as a therapeutic intervention itself.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Mapping the Mind in the Virtual Metaverse: An Initial In-Depth Thematic Exploration of Youth Mental Health within VRChat\nAbstract: Background: VRChat is a virtual reality (VR) social video game where users play a personalized avatar and socialize with others in community-built worlds. Its immersive nature and diverse community may impact youth users' mental health, yet no research has explored this. This study is a thematic exploration of VRChat's effect on youth mental health. Methods: Semi-structured interviews were conducted with 20 active VRChat users aged 18-24 years. Interviews were transcribed and analyzed using grounded theory principles to identify themes related to VRChat use and mental health. Results: Nine major themes emerged: Frequency of use; purpose of use; positive effects on mental health; negative effects on mental health; social connection and COVID-19; anonymity; cyberbullying and toxic behaviors; addiction; and recommendations for a safer environment. Positive effects identified included enhanced social connection, creative expression, and self-confidence. Negative effects included addiction, cyberbullying, predatory behaviors, and worsening of existing mental illnesses. The anonymity of VRChat created a paradoxical environment that can foster both genuine self-expression and toxic behaviors. During the COVID-19 pandemic, VRChat served as an important substitute for real-life social interactions. Participants also provided recommendations for developers, parents, and clinicians to promote a safer VRChat experience. Conclusion: The immersive and interactive social experience offered by VRChat is conducive for positive effects on youth users' mental health, such as social connectivity and self-expression. However, it also presents risks such as addiction and toxic behaviors. Given the interactive nature of VRChat, further research may elucidate its potential as a psychotherapeutic intervention for youth mental health.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Non-invasive Real-time Detection of Potassium level Changes in Skeletal Muscles during Exercise by Magnetic Resonance Spectroscopy\nAbstract: Introduction: Potassium is essential in cellular functions, with specific importance in muscle activity and cardiovascular health. It is the main intracellular cation in the human body with 70% located in muscle. Traditional methods to measure potassium levels are invasive and lack specificity for intracellular concentrations. Recently, non-invasive in vivo investigation of K+ ion homeostasis has become feasible by using 39K Magnetic Resonance Imaging (MRI) and MR spectroscopy (MRS) at ultrahigh magnetic fields. However, studies demonstrating the sensitivity of 39K MRI or MRS to detect potassium alterations in disease or upon intervention are sparse. This study utilizes 39K MRS to non-invasively track real-time intramuscular potassium changes during exercise, providing an assessment of potassium dynamics and explores the potential for technical artifacts in the measurements. Methods: Five healthy subjects (three males, two females) were recruited to perform standardized dynamic knee extensions inside a 7T MR scanner. Potassium levels were measured using a 39K MRS protocol that included periods of rest, moderate, and heavy exercise followed by recovery. Additionally, possible measurement artifacts due to muscle movement or changes in coil position relative to the thigh were evaluated using 39K MRS and 1H MRI monitoring in separate sessions. Results: The study revealed a consistent decrease in potassium levels during both moderate and heavy exercise, with an average decrease of 5-6%. These changes were rapidly detectable and were reversed upon cessation of exercise, indicating effective in vivo monitoring capability. Possible experimental artifacts were investigated, and the results suggested not to be responsible for the detected potassium changes during exercise. The results of the non-localized 39K MRS measurements during exercise correlated well with expected physiological changes based on previous literature. Discussion: The application of 39K MRS provides a valuable non-invasive tool for studying potassium dynamics in human skeletal muscle. This technique could enhance our understanding of muscle physiology and metabolic disorders. The ability to measure these changes in real time and non-invasively highlights the potential for clinical applications, including monitoring of diseases affecting muscle and cellular metabolism.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A systematic review to identify research gaps in studies modeling vaccination strategies against Neisseria infections\nAbstract: The genus Neisseria includes two major human pathogens: N. meningitidis causing bacterial meningitis/septicemia and N. gonorrhoeae causing gonorrhoea. Mathematical models have been used to simulate their transmission and control strategies, and the recent observation of a meningitis vaccine being partially effective against gonorrhoea has led to an increased modeling interest. Here we conducted a systematic review of the literature, focusing on studies that model vaccination strategies against Neisseria incidence and antimicrobial resistance. Using journal, preprint, and grey literature repositories, we identified 52 studies that we reviewed for validity, model approaches and assumptions. Most studies showed a good quality of evidence, and the variety of approaches along with their different modeling angles, was assuring especially for gonorrhoea studies. We identified options for future research, including the combination of both meningococcal and gonococcal infections in studies to have better estimates for vaccine benefits, and the spill over of gonorrhoea infections from the heterosexual to the MSM community and vice versa. Cost-effectiveness studies looking at at-risk and the wider populations can then be used to inform vaccine policies on gonorrhoea, as they have for meningococcal disease.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Diagnostic Efficacy of Various Imaging Modalities Across Different Stages of Prostate Cancer: A Network Meta-Analysis of Diagnostic Studies\nAbstract: Purpose: To assess the diagnostic performance of various imaging modalities in detecting and monitoring prostate cancer across different disease stages using diagnostic test accuracy (DTA) and network meta-analysis (NMA). Methods: A systematic literature review was conducted to identify studies evaluating, mpMRI, PSMA PET/CT, MRE, MRSI, BS, CT, PET, and other tracers for prostate cancer detection. Data on sensitivity, specificity, PPV, NPV, and detection rate were extracted and analyzed using NMA. Result: Across 123 studies involving 9,371 patients, 68Ga-P16-093 PET/CT and 68Ga-PSMA-617 PET/CT showed high diagnostic accuracy in early-phase prostate cancer. For lymph node metastasis, 68Ga-PSMA-11 PET/MRI was most sensitive, 18F-DCFPyL PET/CT had the highest specificity and PPV, while 18F-PSMA-1007 PET/CT had the highest NPV. In bone metastasis, 18F-PSMA-1007 PET/MRI excelled in sensitivity and NPV, while 18F-Fluciclovine PET/CT had the highest specificity and PPV. For biochemical recurrence, 18F-PSMA-1007 PET/CT had the highest lesion detection rate, and for different radiotracers, 18F-PSMA-1007 had the highest detection rate. Conclusion: This network meta-analysis comprehensively evaluated the diagnostic efficacy of various imaging modalities for prostate cancer across different stages. Our findings underscore the strengths and limitations of each imaging technique in detecting and staging prostate cancer.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Beta-blockers Increase Cardiovascular Mortality in Hemodialysis Patients with Orthostatic Hypotension\nAbstract: Background: Orthostatic hypotension (OH) is prevalent among dialysis patients and is a known cardiovascular (CV) risk factor. Beta-blockers (BBs) are commonly prescribed to mitigate CV mortality in this population despite potential risks associated with OH. This study examines the impact of BBs on CV mortality among dialysis patients with OH. Methods: We conducted a prospective analysis of 134 dialysis patients from the PRECADIA program at the Centro de Educacion Medica e Investigaciones Clinicas (CEMIC) focusing on hemodynamic assessments including blood pressure changes from supine to standing positions and evaluating CV mortality over a 3-year follow-up. OH was defined by a decrease of 10 mmHg or more in diastolic blood pressure or 20 mmHg or more in systolic blood pressure upon standing. Cox regression analyses were utilized to identify independent predictors of CV mortality. Results: Of the patients, 23.1% were identified with OH. No significant differences in demographic or baseline clinical characteristics were observed between patients with and without OH, except for a higher diabetes prevalence in the OH group. OH patients treated with BBs demonstrated significantly higher CV mortality (29.6%) compared to those not receiving BBs. Independent predictors of CV mortality included age, time on dialysis, and BB use, with BBs significantly associated with increased CV mortality risk. Conclusions: Dialysis patients with OH exhibit a high CV mortality rate significantly influenced by BB usage. While BBs are recommended for managing CV risks in dialysis patients, their association with increased CV mortality in patients with OH necessitates careful consideration and management strategies.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Measuring Multi-Joint Upper Limb Proprioceptive Position Sense in Children with Unilateral Spastic Cerebral Palsy using 3D Kinematics\nAbstract: Background: Proprioceptive position sense (PPS), which provides the awareness of the positions of one's limbs in space, is compromised in children with unilateral spastic cerebral palsy (USCP). Relationships between decreased PPS, skill acquisition, and performance are not well understood partly due to differences between measurement modalities of PPS. During assessments, individual joints are often constrained to a single plane of movement. We introduce ways to estimate PPS, simultaneously from multiple upper limb joints during unconstrained pose matching tasks, using 3D kinematics. Methods: Nineteen children with USCP, 14 age-matched typically developing children (TDC) and, 16 typically developed adults (TDA) were recruited. Participants performed contralateral upper limb pose matching tasks while blindfolded. Using 3D kinematic data extracted by a VICON Nexus motion-capture system, three ways of measuring matching performance were calculated: joint angle symmetry, joint distance symmetry, and orientation symmetry. Mann-Whitney U tests were used to statistically compare scores between groups. Spearman's rank correlation was used to investigate relationships between PPS symmetry measures and hand function in children with USCP. Results: Children with USCP presented significantly lower angle, distance, and orientation symmetries compared to TDC. TDA scores were not statistically significantly different compared to TDC. In children with USCP, orientation symmetry measures strongly correlated with several clinical hand function scores such as the box and blocks test. Conclusions:We introduced a new way to conveniently measure multi-joint PPS. Children with USCP presented lower PPS estimates compared to TDC. We also observed that orientation symmetry (limb coordination) strongly correlates with hand function.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Feasibility of an App-Assisted and Home-Based Video Version of the Timed up and Go Test for Patients with Parkinson Disease: vTUG\nAbstract: Background: Parkinson Disease (PD) is a progressive neurological disorder. Current therapeutic trials investigate treatments that can potentially modify the disease course. Testing their efficiency requires frequent and precise clinical outcome assessments (COA) of symptoms that remain problematic under symptomatic treatments, such as gait and balance. Home-based examinations may enhance patient compliance and, in addition, produce more reliable results by assessing patients more regularly in their familiar surroundings. Objective: The objective of this study was to assess the feasibility of a digitized COA designed to video record the Timed up and Go (vTUG) test at home via a study-specific smartphone app for patients with PD. Method: In this study, 28 patients were recruited and asked to perform at home each week a set of three consecutive vTUG tests over a period of 12 weeks using an app. The videos were subjected to a manual review to ascertain the durations of the individual vTUG phases, as well as to identify any errors or deviations in the setup that might have influenced the result. To evaluate the usability and user-friendliness of the vTUG and app, the System Usability Scale (SUS) and User Experience Questionnaire (UEQ) were administered to patients at the study end. Results: Overall, 19 patients completed the 12-week study, 17 of which recorded 10 videos or more. A total of 706 vTUGs with complete timings were recorded. Random Forest Regression yielded time to walk up as the most important segment of the vTUG for predicting the total time. Variance of vTUG total time was significantly higher between weeks than it was between the three consecutive vTUGs at one time point [F(254,23) = 6.50, p < 0.001]. The correlation between vTUG total time and UPDRS III total score was weak (r = 0.24). Yet, correlation between vTUG and a derived gait subscore (UPDRS III items 9-13) was strong (r = .59). A linear mixed-effects model revealed a significant effect of patient-reported motion status on vTUG total time. Including additional variables such as UPDRS III gait subscore, different footwear, and chairs used, further improved the model fit. Conclusion: Assessment of gait and balance by home-based vTUG is feasible. Factors influencing the read-out were identified and could be controlled for future use and longitudinal trials.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Large Scale Multi-dataset Investigation of Brain Metastases Distribution Based on Primary Cancer Type\nAbstract: Brain metastases (BM) present a significant clinical challenge, characterized by poor prognosis and high morbidity. Previous research has demonstrated heterogeneous distribution patterns of BMs depending on the primary tumor type. This study aims to further investigate the distribution patterns of BMs. Utilizing three public datasets and one private dataset, we analyzed 1,344 patients with a total of 9,431 identified BMs, categorizing them into lung, breast, melanoma, kidney cancer, and other groups. Our findings indicate that lung cancer BMs predominantly localize in the cerebellum, as well as the frontal, temporal, occipital, and parietal lobes. Breast cancer BMs are commonly found in the cerebellum, frontal, occipital, and temporal lobes, while melanoma BMs are most frequently located in the occipital, temporal, and frontal lobes. Kidney cancer BMs, less studied in existing literature, primarily affect the frontal and temporal lobes. Additionally, we explored the relationship between BM volume and tumor type, revealing that lung and breast cancer BMs are more likely to have smaller tumor volumes compared to melanoma and kidney cancer BMs. These findings confirm and expand upon previous research, offering new insights into the distribution and characteristics of kidney cancer BMs.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Harvard-Emory ECG Database\nAbstract: The Harvard-Emory ECG Database (HEEDB) is a large collection of 12-lead electrocardiogram (ECG) recordings, developed through a collaboration between Harvard University and Emory University. The database consists of 10,608,417 unique ECG recordings from 1,818,247 patients from Massachusetts General Hospital (MGH) and 1,452,964 recordings from 552,481 patients from Emory University Hospital (EUH) collected in clinical settings as part of routine patient care since the early 1990s. Continuously updated with new data, the recordings consist of 10-second, 12-lead ECGs sampled at 250 and 500 Hz, and stored in WFDB format. Future updates will include demographic information such as age, sex, race, and ethnicity. Additionally, 12SL annotations-encompassing ECG diagnoses, morphology, and rhythms-are available for 10,471,531 recordings from MGH and 1,268,277 recordings from EUH. Shortly, ICD-9/10 codes, CPT codes, and medication history will also be made publicly available.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Artificial Intelligence Applied to Electrocardiographic Images for Scalable Screening of Transthyretin Amyloid Cardiomyopathy\nAbstract: Background: Transthyretin amyloid cardiomyopathy (ATTR-CM) remains largely under-recognized, under-diagnosed, and under-treated. We hypothesized that the myocardial remodeling of ATTR-CM may be detectable through artificial intelligence (AI) applied to 12-lead electrocardiographic (ECG) images. Methods: Across 5 hospitals of a large U.S.-based hospital system, we identified patients with ATTR-CM, defined by the presence of a positive nuclear scan with an approved bone radiotracer or pharmacotherapy with an approved transthyretin stabilizer between 2015 and the first half of 2023. The development cohort consisted of 1,011 ECGs from 234 patients (age 79 [IQR:70-85] years, n=176 [17.4%] women), who were age- and sex-matched in a 10:1 ratio to 10,110 ECGs from 10,110 controls (age 79 [IQR:70-85] years, n=1,800 [17.7%] female). A convolutional neural network (CNN) pre-trained using a bio-contrastive pretext on ECGs before 2015 was fine-tuned for ATTR-CM using 5-fold cross-validation and subsequently tested in an independent set of cases (139 ECGs in 47 patients; age 80 [75-86] years, n=44 (31.7% women)) and matched controls (1390 ECGs and patients) from the second half of 2023. Results: The AUROC (area under the receiver operating characteristic curve) of the AI-ECG model for discriminating ATTR-CM in the leave-out, temporally distinct dataset was 0.906 [95%CI: 0.89-0.94] (A), with a sensitivity of 0.85 [95%CI: 0.79-0.91] and specificity 0.80 [95%CI 0.78-0.82]. Conclusions: We demonstrate that AI applied directly to ECG images represents a promising and scalable approach for the screening of ATTR-CM.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Postpartum Tubal Sterilization in Sickle Cell Disease in the 2012-2019 National Inpatient Sample\nAbstract: Importance: Sickle cell disease (SCD) is associated with high-risk pregnancy and low rates of hormonal contraception use. Intersectional vulnerabilities among individuals with SCD in the United States (US) raise historically and socially contingent questions about tubal sterilization in individuals with SCD. However immediate postpartum tubal sterilization (TS) rates among individuals with SCD in the US are unknown. Objective: To compare rates of TS in deliveries to people with SCD and without SCD, and to determine the modifying effect of severe maternal morbidity (SMM) on the odds of TS. Design, Setting, and Participants: This repeated cross-sectional study used the 2012-2019 National Inpatient Sample to estimate the rate of TS among delivery hospitalizations to people with SCD, without SCD (non-SCD), Black people with and without SCD, and people with cystic fibrosis (CF). Logistic regression models estimated the odds of TS between SCD and non-SCD deliveries, SCD and non-SCD deliveries with Black race, and SCD and CF deliveries. We examined whether SMM modified the association between TS and SCD in interaction analyses. Exposure: SCD, CF Results: Among 29,822,518 deliveries, 6.7% underwent TS. Among 18,860 SCD deliveries, 8.8% underwent TS. Among 2,945 CF deliveries, 6.6% underwent TS. After adjusting for patient and hospital characteristics, SCD had higher odds of TS compared to non-SCD deliveries (aOR= 1.38 [1.06,1.79]) and in a stratified analysis of deliveries coded with Black race (aOR= 1.42 [1.06,1.90]). After adjusting for patient and hospital characteristics, there was no difference in the odds of TS between SCD or CF deliveries (aOR=1.0 [0.51,2.24]). SMM more than doubled the odds of TS in SCD deliveries (interaction: aOR=2.34 [1.57,3.47]; aOR= 2.14 [1.40,3.24] in deliveries coded with Black race). Conclusion: Even after accounting for patient and hospital characteristics, people with SCD have higher odds of immediate postpartum TS compared to control groups. SMM at delivery increased the odds of TS in SCD compared to all non-SCD deliveries and compared to CF deliveries. Possibly SMM severity, patient preference, or clinician recommendations inform this finding. SMM is 3-7 times more common in SCD than non-SCD pregnancies and may be a modifiable risk factor for TS in SCD deliveries.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Assessing sustained attention processes and related cerebral activations in typically developing adolescents using the gradual-onset continuous performance task (gradCPT)\nAbstract: Introduction: Sustained attention and inhibition processes are fundamental components of attention that mature during adolescence, a transitive period between childhood and adulthood characterized by a rapid behavioral and cognitive development. The current study aimed to provide a better understanding of sustained attention and inhibition processes in typically developing adolescents (n = 26) aged 11-18. Methods: Functional magnetic resonance images (fMRI) were acquired during two different modalities (the face and the scene) from a previously validated gradual-onset continuous (gradCPT) paradigm to evaluate sustained attention performances. In addition, we performed linear regression analyses to investigate how cerebral activation varied as a function of covariates of interest. Results: We showed a bilateral fronto-parieto-occipito brain activation during response inhibition regardless the type of task. Participants demonstrated better behavioral performances during the scene gradCPT. We observed a mainly left-lateralized pattern of activation in a fronto-cingulo-cerebellum area during the face gradCPT and an extended bilateral fronto-temporo-parieto-occipital activation during the scene gradCPT. Finally, we found associations between brain activity and behavioral attentional responses. Conclusion: This study gives a better understanding of the neural correlates of sustained attention and inhibition in a typically developing adolescent population.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Concordance between Infectious Disease Society of America Criteria for Urinary Tract Infection Testing and Treating Vs. Emergency Department Actual Practice\nAbstract: Introduction Symptomatic and asymptomatic urinary tract infections (UTIs) are common. The Infectious Disease Society of America (IDSA) discourages testing and treating ASB other than in pregnant women during routine obstetric visit screening and patients undergoing urologic procedures with expected mucosal bleeding. Unnecessary urinalysis (UA) and inappropriate antibiotic use persist in Emergency Departments (EDs). This study aims to evaluate UA testing and antibiotic treatment patterns for ASB in an urban ED, assessing adherence to IDSA guidelines and setting baseline rates for an educational intervention to align testing and treatment with IDSA guidelines. Methods We conducted a 15-month study to assess adherence to IDSA guidelines for proper UTI screenings and prescribing. We reviewed records of 50 adult patients who had a UA at the Long Island Jewish Medical Center ED to determine whether they met IDSA criteria for UA testing and appropriate antibiotic use. Patients with sepsis or other conditions requiring empiric antibiotics were excluded. We performed a univariate analysis to describe the population and factors associated with treating urinalysis findings. Statistical significance was set at p <0.05. Results Sixty-four percent of patients were asymptomatic and 36% were symptomatic. None of the asymptomatic patients met IDSA criteria for UA testing. Symptomatic patients were nearly-statistically more likely than asymptomatic patients to have a positive UA ( 72.2% vs. 43.8%, p = 0.06), and were more-often prescribed antibiotics for a positive UA (61.5% vs. 14.3%; p = 0.0128). They were also more-often prescribed antibiotics for a negative UA (20.0% vs. 0%; p = 0.05). Discussion The study findings revealed significant discordance between IDSA guidelines and current ED practices, with 64% of UA tests deemed unnecessary for ASB patients. These results align with previous studies highlighting the prevalence of over-testing with UAs and over-treatment of ASB. Unnecessary testing and inappropriate antibiotic treatment lead to increased costs and risks of antibiotic resistance, adverse drug events, and Clostridium difficile infection. This study highlights the necessity for planned educational initiatives to reduce unnecessary UAs and treatment and improve adherence to evidence-based guidelines.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Anthocyanin-rich extract mitigates the contribution of the pathobiont genus Haemophilus in mild-to-moderate ulcerative colitis patients\nAbstract: Objective: Anthocyanins (AC) have been shown to elicit anti-inflammatory and antioxidant effects in several animal models of colitis. Furthermore, AC lowered biochemical disease activity in our double-blind randomized trial in patients with ulcerative colitis. Here, we report on the changes in the faecal microbiome composition in the patient upon AC exposure in this trial. Methods: Ulcerative colitis patients received a 3g daily dose of an AC-rich bilberry extract (ACRE) for eight weeks. We determined the microbiome composition in longitudinal stool samples from 24 patients and quantified the degree of change over time. We also correlated the relative abundances of individual microbial taxa at different time points to faecal concentration measurements of calprotectin. Results: Microbiome compositions did not change over time as a result of the intervention, both in terms of alpha and beta diversity. Before the intervention, Haemophilus parainfluenzae was positively correlated with faecal calprotectin concentrations, and this correlation persisted in placebo-treated subjects throughout the study. In contrast, the correlation between H. parainfluenzae and the concentration of faecal calprotectin vanished in ACRE-treated subjects, while the relative abundance of H. parainfluenzaae did not change. Conclusion: Our results suggest that ACRE treatment mitigates the contribution of H. parainfluenzae to inflammation. Further research is warranted to better comprehend the role of microbial composition in response to medical therapy including AC-rich extract in ulcerative colitis patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prevalence of dementia risk factors in a memory clinic setting: The Oxford Brain Health Clinic\nAbstract: With promising disease-modifying therapies (DMTs) emerging and good evidence to support risk reduction in the delay of dementia onset and progression, it is important to understand the profile of patients attending memory assessment services to estimate what proportion of patients might benefit from different types of interventions. The Oxford Brain Health Clinic (OBHC) is a psychiatry-led, clinical-research service that offers memory clinic patients detailed clinical assessments and equal access to research opportunities as part of their secondary care pathway. In this work, we describe the characteristics of OBHC patients in terms of demographics, diagnoses and prevalence of potentially modifiable risk factors compared with a cohort of healthy volunteers and the average memory clinic population. Our results suggest that high research consent rates (91.5%) in the OBHC resulted in a highly representative cohort of the clinical population. Based on Lecanemab trial inclusion criteria, 24.6% of the OBHC population may be suitable for further investigation into DMTs. Furthermore, 67.4% of OBHC patients have at least one potentially modifiable risk factor that may benefit from lifestyle interventions, particularly those focused on depression, sleep and physical activity.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Persistently high TB prevalence in Nairobi County neighbourhoods, 2015-2022\nAbstract: National and sub-national population-based surveys, when performed at intervals, may assess important changes in TB prevalence. In 2022 we re-surveyed nine Nairobi County neighbourhoods that were previously surveyed in 2015. We aimed to determine pulmonary TB prevalence, compare prevalence to 2015 estimates, and evaluate changes in risk groups. Participants who reported cough of any duration and/or whose chest x-ray suggested TB submitted sputum for smear microscopy, Xpert Ultra, and liquid culture. We defined prevalent TB as Mycobacterium tuberculosis detection by sputum Xpert or culture, excepting individuals who were only trace positive. Our methods differed from 2015, which used solid media, Xpert MTB/RIF, and cough duration >2 weeks. We calculated TB prevalence using random-effects logistic regression models with missing value imputations and inverse probability weighting. In 2022 among 6369 participants, 1582 submitted >1 sputum sample, among whom 42 (2{middle dot}7%) had TB, a weighted TB prevalence of 806/100,000 (95% confidence interval (CI), 518-1096). An additional 31 (2{middle dot}0%) participants tested Ultra trace-positive/culture-negative. For comparison to 2015, we excluded 2022 participants (n=2) whose only criterion for sputum was cough <2 weeks. There was no evidence for a decline in overall TB prevalence from 2015 to 2022. TB prevalence among men was high (1368/100,000) but unchanged compared to 2015 (p-value = 0{middle dot}50). The age group with the highest estimated prevalence remained people ages 45-54 years. Among people with prevalent TB who reported cough, 76% had not sought health care. Dissimilar from other serial surveys that showed declines in TB prevalence, we found persistently high TB prevalence over a 7-year period in Nairobi County. Limitations of this study include changes in methodology between the two surveys and complex effects of the COVID-19 pandemic.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Yearly trends in cause-specific age-adjusted mortality from 1999-2020 in Black and White Non-Hispanic Americans\nAbstract: From 1999 to 2020, disparities in all-cause age-adjusted mortality rates between Black and White Non-Hispanic Americans decreased then stagnated and increased. Consistent improvement in racial disparities were made for cancer, HIV, and sepsis regardless of all-cause trends. In contrast, conditions like heart disease and external causes of death mirrored the overall trends.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: End-to-End Machine Learning based Discrimination of Neoplastic and Non-neoplastic Intracerebral Hemorrhage on Computed Tomography\nAbstract: Purpose: To develop and evaluate an automated segmentation and classification tool for the discrimination of neoplastic and non-neoplastic intracerebral hemorrhage (ICH) on admission Computed Tomography (CT) utilizing images containing hemorrhage and perihematomal edema. Materials and Methods: The models were developed and evaluated using a retrospective dataset of patients who presented with acute ICH of unknown cause upon admission, using CT scans obtained from a single institution between January 2016 and May 2020 for both training and testing. Etiology of ICH were binarized into non-neoplastic and neoplastic ICH according to follow-up MRI results based on the ATOMIC ICH classification. Masks for ICH and PHE were manually segmented. Two separate models were trained: 1) An nnU-Net segmentation model 2) A ResNet-34 classification model. An end-to-end tool was evaluated by concatenating the two models which allowed the segmentation model to preprocess the images for the classification model. Performance enhancement was assessed by fine-tuning the model on a randomly selected, small subset of the external cohort. To assess the model's generalizability, the performance was additionally validated on an external dataset. Evaluation metrics were accuracy (Acc), area under the curve (AUC) and corresponding sensitivities and specificities. Results: A total of 291 patients were included of whom 116 (39.86%) presented with neoplastic and 175 (60.14%) with non- neoplastic ICH. The end-to-end classification tool achieved an Acc of 86% and an AUC of 85% with a sensitivity and specificity of 80% and 93% in the test set. On the external validation cohort (n=58), the classification pipeline achieved an AUC of 68% and Acc of 66% (sensitivity 64%; specificity 67%). Fine-tuning on a selected small subset of the external cohort enhanced performance, achieving an AUC and accuracy of 70% (sensitivity 70%; specificity 71%). Conclusion: An end-to-end classification tool achieved a high diagnostic performance and generalizability in classifying neoplastic from non-neoplastic ICH on CT, suggesting a robust framework for a potential clinical implementation as a decision-aided tool in early ICH management.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Prism Adaptation-Induced Modulation of Cortical Excitability of Upper and Lower Limb Muscles is Enhanced with Electrical Stimulation\nAbstract: Background: Prism adaptation (PA) is a behavioral training paradigm shown to induce immediate changes in visuospatial and motor function. PA may modulate the input and output stages of processing spatial cognitive information. However, the cortical plasticity mechanisms related to the behavioral effects of PA are poorly understood. Non-invasive sensorimotor electrical stimulation (Stim) may upregulate corticomotor excitability and is commonly used as a therapeutic adjunct during motor training. Objective: To evaluate the effects of combining PA with Stim on corticomotor excitability and visuo-spatial-motor behavior. Methods: We used a repeated-measures design to evaluate the effects of 1 session of PA with and without Stim in 15 young able-bodied individuals (18-35 years). Corticomotor output, intracortical inhibition, and facilitation were evaluated before and after PA with motor-evoked potentials (MEPs) elicited from single and paired-pulse transcranial magnetic stimulation (TMS) delivered to M1 hotspots of bilateral upper and left lower limbs. Results: Behaviorally, both PA+Stim and PA+Sham showed significant sensorimotor aftereffects (visuo-spatial and proprioceptive pointing). Neurophysiologically, suprathreshold MEP amplitude increased in the left first dorsal interossei, left tibialis anterior, and left soleus following the PA+Stim condition compared to the PA+Sham condition. Additionally, following PA+Stim, Short Interval Intra-Cortical Inhibition (SICI) increased in the left tibialis anterior and left soleus. Conclusion: Although both PA+Stim and PA+Sham had similar behavioral aftereffects, only PA+Stim increased cortical excitability in M1 representations of the left upper and lower limb (toward the direction of the PA aftereffect), suggesting that PA+Stim may elicit greater neurophysiological changes than PA alone. Keywords: visuomotor adaptation; sensorimotor adaptation; non-invasive brain stimulation; young adults; neuroplasticity; electrical stimulation.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Change in Social Participation of Adults with Spinal Cord Injury During the First Two Waves of the COVID-19 Pandemic in Canada\nAbstract: Introduction: The change in environmental and social context measures during the COVID-19 pandemic affected daily activities of people with spinal cord injury (SCI), their inter-actions within the community, and consequently their social participation during the first wave of the pandemic. However, there is little information about the changes in social participation as the pandemic evolved in Canada. Objective: To describe the change in social participation of adults with SCI after the first two years of the COVID-19 pandemic in Canada. Methods: A follow-up from a previous study exploring the social participation of adults with SCI living during the first wave was conducted eight months later (second wave). Social participation was measured using the Assessment of Life Habits (LIFE-H 4.0) and Measure of Quality of the Environment (MQE)) among 18 adults with SCI. Results: Participants reported increases between both waves of COVID-19 in life habits categories, including mobility, personal care and health, nutrition, and recreation. New environmental factors were identified as facilitators, including the increased availability of businesses in the community. Conclusion: These findings suggest that people with SCI increased fulfillment and satisfaction of certain life habits. Reduced environmental barriers and increased facilitators improved social participation as the pandemic evolved.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rapid, Non-Invasive Breath Analysis for Enhancing Detection of Silicosis Using Mass Spectrometry and Interpretable Machine Learning\nAbstract: Occupational lung diseases, such as silicosis, are a significant global health concern, especially with increasing exposure to engineered stone dust. Early detection of silicosis is helpful for preventing disease progression, but existing diagnostic methods, including X-rays, CT scans, and spirometry, often detect the disease only at late stages. This study investigates a rapid, non-invasive diagnostic approach using atmospheric pressure chemical ionization-mass spectrometry (APCI-MS) to analyse volatile organic compounds (VOCs) in exhaled breath from 31 silicosis patients and 60 healthy controls. Six different interpretable machine learning (ML) models with Shapley additive explanations (SHAP) were applied to classify these samples and determine VOC features that contribute the most significantly to model accuracy. The extreme gradient boosting (XGB) classifier demonstrated the best performance, achieving an area under the receiver-operator characteristic curve of 0.933 with the top ten SHAP features. The m/z 442 feature, potentially corresponding to leukotriene-E3, emerged as a significant predictor for silicosis. The VOC sampling and measurement process takes less than five minutes per sample, highlighting its potential suitability for large-scale population screening. Moreover, the ML models are interpretable through SHAP, providing insights into the features contributing to the model's predictions. This study suggests that APCI-MS breath analysis could enable early and non-invasive diagnosis of silicosis, helping to improve disease outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Head kinematics associated with off field head injury assessment (HIA1) events in a season of English elite-level club men's and women's rugby union matches.\nAbstract: Objectives: To investigate head kinematic variables in elite men's and women's rugby union and their ability to predict player removal for an off-field (HIA1) head injury assessment. Methods: Instrumented Mouthguard (iMG) data were collected for 250 men and 132 women from 1,865 and 807 player-matches, respectively, and synchronised to video-coded match footage. Head peak resultant linear acceleration (PLA), peak resultant angular acceleration (PAA) and peak change in angular velocity (dPAV) were extracted from each head acceleration event (HAE). HAEs were linked to documented HIA1 events, with ten logistical regression models for men and women, using a random subset of non-case HAEs, calculated to identify kinematic variables associated with HIA1 events. Receiver operating characteristic curves (ROC) were used to describe thresholds for HIA1 removal. Results: Increases in PLA, and dPAV were significantly associated with an increasing likelihood of HIA1 removal in the men's game, with an OR ranging from 1.05-1.12 and 1.13-1.18, respectively. The optimal values to maximise for both sensitivity and specificity for detecting an HIA1 were 1.96krad.s-2, 24.29g, and 14.75rad.s-1 for PAA, PLA, and dPAV respectively. Only one model had any significant variable associated with increasing the likelihood of a HIA1 removal in the women's game - PAA with an OR of 8.51 (1.23-58.66). The optimal values for sensitivity and specificity for women were 2.01krad.s-2, 25.98g, and 15.38rad.s-1 for PAA, PLA, and dPAV respectively. Conclusion: PLA and dPAV were predictive of men's HIA1 events. Further HIA1 data are needed to understand the role of head kinematic variables in the women's game. The calculated spectrum of sensitivity and specificity of iMG alerts for HIA1 removals in men and women present a starting point for further discussion about using iMGs as an additional trigger in the existing HIA process.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Brain-heart interactions are associated with mortality and acute encephalopathy in ICU patients with severe COVID-19\nAbstract: Objective: Research in critical care has revealed the significance of autonomic dysfunctions, and more recently of brain-heart interactions, as valuable biomarkers for evaluating patients' physiological status. These biomarkers provide insights into consciousness levels, severity, and outcomes. This study aims to determine the potential of these biomarkers in predicting the mortality and neurological outcome of severe COVID-19 patients. Methods: We examined severe COVID-19 patients who required mechanical ventilation and observed them both during sedation and after sedation cessation. Standard EEG and ECG recordings were conducted at bedside, from which 5 minutes of continuous data were analyzed. Using a synthetic data generation model, we evaluated bidirectional brain-heart interactions from EEG power and heartbeat dynamics series. Results: Our findings indicate that brain-heart interactions, especially involving cardiac parasympathetic activity, can provide information about patients' severity. We observed correlations with acute encephalopathy duration (coma and delirium), particularly evident in top-down markers (from brain to heart) while bottom-up signaling (from heart to brain) correlated with ICU mortality. Additionally, we noted stronger modulation of brain-heart interactions in milder patients when comparing sedation versus non-sedation conditions, compared to those in more severe states. Conclusions: Our results imply that autonomic dysfunctions, as measured through brain-heart interactions, can track the pathophysiology of comatose states following COVID-19 infection. Significance: These findings highlight the potential of brain-heart interactions as an integrated marker for autonomic function in critical care, offering a more accurate assessment of patient severity and outcomes compared to isolated cardiac or brain measures.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Social Determinants of Health and Functional Brain Connectivity Predict Long-Term Physical Activity Adherence in Older Adults After a New Cardiovascular Diagnosis\nAbstract: Physical activity is a crucial modifiable risk factor for preventing cognitive decline, stroke, and dementia. A new cardiovascular disease diagnosis offers an opportunity to improve health outcomes through lifestyle changes. However, sustaining behavior change, even with effective exercise interventions, remains challenging. Understanding the neurobehavioral mechanisms behind successful long-term behavior change can help tailor therapeutic strategies to enhance physical activity and reduce dementia and stroke risks in older adults. This study followed 295 cognitively unimpaired older adults from the UK-Biobank cohort, all newly diagnosed with cardiovascular disease, over five years. We aimed to predict future changes in moderate-to-vigorous physical activity (MVPA) engagement using baseline resting-state functional connectivity, along with sociodemographic factors (e.g., age, sex, socioeconomic status), behavioral characteristics (e.g., general health, pain, depression), cognitive function (e.g., attention, fluid intelligence), social factors (e.g., networks and support), and environmental context (e.g., access to green spaces). Our findings revealed that greenspace percentage, social support, and retirement status significantly predicted increased MVPA at follow-up. A support vector machine (SVM) model, utilizing baseline functional connectivity matrices, achieved 84% accuracy in predicting successful MVPA engagement at follow-up. Key features contributing to the model's accuracy included functional connectivity between brain regions located in distinct large-scale networks, particularly the heteromodal cortex. Notably, the default mode network, frontoparietal control network, and salience/ventral attention network were prominently involved. These results underscore the importance of social and structural determinants of health, such as greenspace and social support, in promoting physical activity behavior change. Furthermore, they provide preliminary evidence of neural mechanisms that may underlie successful lifestyle modifications, informing future interventions to prevent vascular contributions to late-life cognitive decline.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Information processing speed modulation by electrical brain stimulation in multiple sclerosis: Towards individually-tailored protocols\nAbstract: Information processing speed (IPS) is a core cognitive process, highly relevant in everyday-life and the most frequent and disabling cognitive symptom in patients with Relapsing Multiple Sclerosis (pwRMS). By using regionally-specific focalized transcranial direct current stimulation (tDCS) in healthy individuals and pwRMS, we provide causal evidence for superior parietal lobe (SPL) involvement in IPS and identified a clinical predictor of tDCS-response in pwRMS. The study employed a registered, randomized, sham-tDCS controlled, three-way blinded, cross-over trial and a mixed-factors design with eight arms [between-subjects: group (pwRMS, controls); tDCS-polarity (excitatory, inhibitory); within-subjects: stimulation (active-, sham-tDCS)]. Concurrently with tDCS, participants completed a computerized version of the Symbol-Digit-Modalities-Test (SDMT), the current gold standard for quantifying IPS impairment in pwRMS. Bayesian modeling with generalized linear mixed models provided strong evidence for polarity specific modulation of IPS by SPL-tDCS and a double-dissociation of stimulation response in pwRMS and controls. Healthy individuals showed the canonical pattern of significantly enhanced and reduced processing speed during excitatory or inhibitory tDCS. In pwRMS, a re-versed pattern was found and tDCS-response was predicted by baseline SDMT performance; i.e., more or less impaired patients benefited from inhibitory or excitatory tDCS, respectively. Our results provide direct causal evidence for SPL involvement in IPS in health and disease and suggest that the degree of IPS impairment in pwRMS reflects compensatory or dysfunctional neuroplastic processes that can be counteracted in a polarity specific way. Identified standardized transition scores for the effectiveness of excitatory or inhibitory tDCS will inform future individually-tailored stimulation protocols in pwRMS.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: TMS target comparison identifies motor network reorganization associated with behavioral improvement in writer's cramp dystonia: A randomized, double-blind, sham-controlled clinical trial\nAbstract: Background: Writer's cramp (WC) dystonia is an involuntary movement disorder with distributed abnormalities in the brain's motor network. Prior studies established the potential for repetitive transcranial magnetic stimulation (rTMS) to either premotor cortex (PMC) or primary somatosensory cortex (PSC) to modify symptoms. However, clinical effects have been modest with limited understanding of the neural mechanisms hindering therapeutic advancement of this promising approach. Objective: This study aimed to understand the motor network effects of rTMS in WC that correspond with behavioral efficacy. We hypothesized that behavioral efficacy is associated with modulation of cortical and subcortical regions of the motor network. Methods: In a double-blind, cross-over design, twelve WC participants underwent weekly 10 Hz rTMS in one of three conditions (Sham-TMS, PSC-TMS, PMC-TMS) while engaged in a writing task to activate dystonic movements and measure writing fluency. Brain connectivity was evaluated using task-based fMRI after each TMS session. Results: 10 Hz rTMS to PSC, but not PMC, significantly improved writing dysfluency. PSC-TMS also significantly weakened cortico-basal ganglia, cortico-cerebellum, and intra-cerebellum functional connectivity (FC), and strengthened striatal connectivity relative to Sham. Increased PSC BOLD activity was associated with reduced dysfluent writing behavior. Conclusions: 10 Hz rTMS to PSC improved writing dysfluency by redistributing motor network connectivity and strengthening somatosensory-parietal connectivity. A key signature for effective stimulation at PSC and improvement in writing dysfluency may be strengthening of intra-cortical connectivity between primary somatosensory and superior parietal cortices. These findings offer mechanistic hypotheses to advance the therapeutic application of TMS for dystonia.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Determinants of acute malnutrition among children under five in arid regions, Kenya\nAbstract: Acute malnutrition, defined as a weight-for-height Z-score below -2 standard deviations of the WHO growth standards, is prevalent among children in low- and middle-income countries. Our study aimed to identify immediate, underlying, and basic determinants of acute malnutrition among children in Turkana and Samburu, two arid and semi-arid regions in Kenya. Data are from a longitudinal study that recruited children under 3 years of age, with follow-up every 4 months over six waves. Generalized estimating equations were used to assess risk factors of acute malnutrition in this population. Among immediate factors, children who recently experienced diarrhea had 19% and 23% higher odds of acute malnutrition and those who consumed animal-source foods had 12% and 22% lower odds of acute malnutrition in Turkana and Samburu, respectively. Among underlying factors, children in Turkana whose caregivers used alcohol had 32% higher odds of acute malnutrition. Among basic factors, children in Turkana whose caregivers had 3-5 or 6 or more children had 39% and 70% higher odds, whereas those in female-headed households had 34% and 81% higher odds of acute malnutrition in Turkana and Samburu, respectively. Children in Turkana fisherfolk communities had 36% higher odds of acute malnutrition compared with those in urban or peri-urban areas. Key risk factors for acute malnutrition included child diarrhea, caregivers use of alcohol (in Turkana), caregivers number of children, female-headed households, and fisherfolk livelihood (in Turkana), while consuming animal-source foods was associated with lower risk. Interventions should target these intersecting factors to reduce acute malnutrition in these counties.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Spatial and temporal changes in choroid morphology associated with long-duration spaceflight\nAbstract: Purpose The development of neuro-ophthalmic symptoms during long-duration spaceflight presents major risks to astronauts and their missions. Amid efforts to understand spaceflight associated neuro-ocular syndrome (SANS), uncovering the role of the choroid in its etiology is challenged by the accuracy of image segmentation. The present study extends deep learning-based choroid quantification from optical coherence tomography (OCT) to the characterization of pulsatile and topological changes in the macular plane and investigates changes in response to prolonged microgravity exposure. Methods We analyzed OCT macular videos and volumes acquired from astronauts before, during and after long-duration spaceflight. Deep learning models were fine-tuned for choroid segmentation and combined with further image processing towards vascularity quantification. Statistical analysis was performed to determine changes in time-dependent and spatially averaged variables from preflight baseline for OCT data. Results For 13 astronauts with a mean age of 47 {+/-} 9 years, there were significant increases in choroid thickness (CT) and luminal area (LA) of 14 {+/-} 25 m (P = 0.01) and 0.11 {+/-} 0.2 mm2 (P = 0.009) and no significant change in choroid vascularity index (CVI) averaged over OCT macular video segments. There was no significant change in the amplitude of pulsatile CT fluctuation ({Delta}CT), but significant increases in both pulsatile LA ({Delta}LA) and CVI ({Delta}CVI) of 0.077 {+/-} 0.14 mm2 (P = 0.009) and 0.03 {+/-} 0.06 (P = 0.01), respectively. For a subgroup of 6 astronauts for which inflight imaging was available, choroid volume, luminal volume and CVI over the macular region all increased significantly during spaceflight with the greatest differences reached at 90 days following launch. Conclusions The findings show that localized choroid pulsatile changes occur following prolonged microgravity exposure. They suggest that the choroid vessels expand in a manner similar to the choroid layer across the macular region during spaceflight, accompanied by a relative increase in the space they occupy. The methods developed provide new tools and avenues for studying and establishing effective countermeasures to risks associated with long-duration spaceflight.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: SeqFirst: Building equity access to a precise genetic diagnosis in critically ill newborns\nAbstract: Access to a precise genetic diagnosis (PrGD) in critically ill newborns is limited and inequitable because complex inclusion criteria used to prioritize testing eligibility omits many patients at high risk for a genetic condition. SeqFirst-neo is a program to test whether a genotype-driven workflow using simple, broad exclusion criteria to assess eligibility for rapid whole genome sequencing (rWGS) increases access to a PrGD in critically ill newborns. All 408 newborns admitted to a neonatal intensive care unit between January 2021 and February 2022 were assessed and of 240 eligible infants, 126 were offered rWGS (i.e., intervention group [IG]) and compared to 114 infants who received conventional care in parallel (i.e., conventional care group [CCG]). A PrGD was made in 62/126 (49.2%) IG neonates compared to 11/114 (9.7%) CCG infants. The odds of receiving a PrGD was ~9 times greater in the IG vs. the CCG, and this difference was maintained at 12 months follow up. Access to a PrGD in the IG versus CCG differed significantly between infants identified as non-white (34/74, 45.9% vs. 6/29, 20.7%; p=0.024) and Black (8/10, 80.0% vs. 0/4; p=0.015). Neonatologists were significantly less successful at predicting a PrGD in non-white than non-Hispanic white patients. Use of a standard workflow in the IG with a PrGD revealed that a PrGD would have been missed in 26/62 (42%) of infants. Use of simple, broad exclusion criteria that increases access to genetic testing significantly increases access to a PrGD, improves access equity and results in fewer missed diagnoses.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Risk of Incident Cytopenia in Clonal Hematopoiesis\nAbstract: Clonal hematopoiesis of indeterminate potential (CHIP) is an asymptomatic condition associated with elevated risk for myeloid neoplasms (MN). Patients with CHIP and cytopenia are at greater risk of MN. Quantifying the incidence of cytopenia and identifying risk factors among CHIP patients is critical for improving clinical management. We analyzed sequencing data from 805,249 participants in the NIH All of Us Research Program (AoU), Vanderbilt's BioVU repository, and UK Biobank (UKB). Genetic mutations, laboratory values, and MN diagnoses were included in survival analyses to determine predictors of cytopenia in individuals with CHIP and matched controls. The cohort contained 9,374 CHIP cases and 24,749 controls. Cytopenia occurred in 13.5% of cases and 11.6% of controls (HR = 1.17, 95% confidence interval: 1.10 -- 1.25, P=2.5 x 10-6). Cytopenia risk factors included smoking, male sex, variant allele frequency [&ge;] 0.20, age [&ge;] 65, mean corpuscular volume [&ge;] 100 femtoliters, red cell distribution width [&ge;] 15%, mutations in high-risk CHIP genes, and [&ge;] 2 CHIP mutations. In BioVU, 45% of participants with [&ge;] 4 risk factors progressed to cytopenia within two years. Individuals with CHIP and cytopenia progressed to MN at a rate of ~2% per year, compared to <0.1% per year for those without cytopenia. Longitudinal analysis across three cohorts demonstrated an increased risk of cytopenia in CHIP patients and identified those at highest risk. These findings suggest that cytopenia is a critical step in progression from CHIP to MN, underscoring its utility as an endpoint in cancer prevention trials for CHIP patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: FBXO22 deficiency defines a pleiotropic syndrome of growth restriction and multi-system anomalies associated with a unique epigenetic signature\nAbstract: FBXO22 encodes an F-box protein which acts as a substrate-recognition component of the SKP1-CUL1-F-box (SCF) E3 ubiquitin ligase complex. Despite its known roles in the post-translational ubiquitination and degradation of specific substrates, including histone demethylases, the impact of FBXO22 on human development remains unknown. Here, we characterize a pleiotropic syndrome with prominent prenatal onset growth restriction and notable neurodevelopmental delay across 14 cases from 12 families. Through exome and genome sequencing, we identify three distinct homozygous loss-of-function FBXO22 variants segregating with the disease: p.(Arg53Serfs*13), p.(Pro3Leufs*3) and p.(Val240Alafs*6), all predicted to lead to premature translation termination due to frameshift effects. We confirm that patient-derived primary fibroblasts are bereft of FBXO22 and show increased levels of the known substrate histone H3K9 demethylase KDM4B. Accordingly, we delineate a unique epigenetic signature for this disease in peripheral blood. Altogether, we identify and demonstrate that FBXO22 deficiency leads to a pleiotropic syndrome in humans encompassing growth restriction and neurodevelopmental delay, the pathogenesis of which may be explained by broad chromatin alterations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Genetic Association of Glutathione S-Transferase Omega 2 (GSTO2) Gene Variant (rs156697) with Chronic Kidney Disease Patients of Pakistani Origin\nAbstract: Chronic Kidney Disease (CKD) poses a significant global health challenge. The kidneys can be compromised by internal diseases, environmental influences and various genetic factors. Among the genetic factors, particularly, GSTO2 gene plays a crucial role in cellular processes and enzyme performance, which can lead to interstitial kidney damage and contribute to CKD. The current study investigates the genetic association between the GSTO2 gene variation (rs156697) and CKD in the Punjabi community. This study examined the association between the GSTO2 gene locus (c.424A>T) and CKD in a Punjabi population using ARMS-PCR genotyping. A total of 50 samples were analyzed, revealing 19 homozygous wild-type, 25 heterozygous and 6 homozygous mutants. PLINK data analysis toolset indicated an insignificant genotypic association with CKD phenotype with an observed p-value of 0.7177 and an odds ratio of 0.85. Similarly, the alternative allele frequency of 0.34 and 0.375 was also observed in CKD and normal controls respectively. In the future, further studies with more genetic markers along with functional studies with large sample data may be performed for robust statistical evidence of the association of subject gene with CKD patients in Pakistan.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Biomedical Text Normalization through Generative Modeling\nAbstract: ABSTRACT Objective: Around 80% of electronic health record (EHR) data consists of unstructured medical language text. By its nature, this text is flexible and inconsistent, making it challenging to use for clinical trial matching, decision support, and predictive modeling. In this study, we develop and assess text normalization pipelines built using large-language models. Materials and Methods: Here, we evaluated four LLM-based normalization strategies: Zero-Shot Recall, Prompt Recall, Semantic Search, and Retrieval-Augmented Generation (RAG) and one baseline, TF-IDF based String Matching. We compared normalization performance across two datasets of condition terms mapped to SNOMED, one tailored to oncology, and one covering a wide range of medical conditions. Additionally, we benchmarked our models against the TAC 2017 drug label annotations, which normalizes terms to the Medical Dictionary for Regulatory Activities (MedDRA) Preferred Terms. Results: RAG, which effectively combines Prompt Recall and Semantic Search, was the most effective, accurately identifying the correct term 88.31% of the time for the domain-specific dataset and 79.97% for the broader dataset. Our model achieved a micro F1 score of 88.01 on task 4 of the TAC2017 conference, surpassing all other models without relying on the provided training data. Discussion: These findings demonstrate the potential of LLMs in medical text normalization. We find that retrieval-focused approaches overcome traditional LLM limitations for this task. Conclusion: Large language models combined with retrieval-augmented generation should be explored for text normalization of biomedical free text.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Derivation and validation of a prediction rule for sedative-associated delirium during acute respiratory failure requiring mechanical ventilation\nAbstract: Abstract Background: Delirium during acute respiratory failure is common and morbid. Pharmacologic sedation is a major risk factor for delirium, but some sedation is often necessary for the provision of safe care of mechanically ventilated patients. A simple, transparent model that predicts sedative-associated delirium in mechanically ventilated ICU patients could be used to guide decisions about personalized sedation. Research Question: Can the risk of sedative-associated delirium be estimated in mechanically-ventilated ICU patients? Study Design and Methods: Using the subset of patients in a previously-published ICU cohort who received mechanical ventilation, we performed backward stepwise logistic regression to derive a model predictive of sedative-associated delirium. We validated this model internally using hundredfold bootstrapping. We then validated this model externally in a separate prospective cohort of mechanically ventilated ICU patients. Results: 836 patients comprised the derivation cohort. Backwards stepwise regression produced a model with age, BMI, sepsis, SOFA, malignancy, COPD, stroke, sex, and doses of sedatives (opioids, propofol, and/or benzodiazepines) as predictors of sedative-associated delirium. The model had very good discriminative power, with an area under the receiver-operator curve (AUROC) of 0.83. Internal validation via bootstrapping showed preserved discriminatory function with an AUROC of 0.81 and graphical evidence of good calibration. External validation in a separate set of 340 patients showed good discrimination, with AUROC of 0.70. Interpretation: Sedative-associated delirium during acute respiratory failure requiring mechanical ventilation can be predicted using a simple, transparent model, which can now be validated in a prospective study.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Solid-state esophageal pressure sensor for the estimation of pleural pressure: a bench and first-in-human validation study\nAbstract: Background: Advanced respiratory monitoring through the measurement of esophageal pressure (Pes) as a surrogate of pleural pressure helps guiding mechanical ventilation in ICU patients. Pes measurement with an esophageal balloon catheter, the current clinical reference standard, needs complex calibrations and a multitude of factors influence its reliability. Solid-state pressure sensors might be able to overcome these limitations. Objectives: To evaluate the accuracy of a new solid-state Pes transducer (Pessolid). We hypothesized that measurements are non-inferior to those obtained with a properly calibrated balloon catheter (Pesbal). Methods: Absolute and relative solid-state sensor Pes measurements were compared to a reference pressure in a 5-day bench setup, and to simultaneously placed balloon catheters in 15 spontaneously breathing healthy volunteers and in 16 mechanically ventilated ICU patients. Bland-Altman analysis was performed with nonparametric bootstrapping to estimate bias and upper and lower limits of agreement (LoA). Results: Bench study: Solid-state pressure transducers had a positive bias (Psolid - Pref) of around 1 cmH2O for the absolute minimal and maximum pressures, and no bias for pressure swings. Healthy volunteers: the solid-state transducer revealed a bias (Pessolid - Pesbal) [upper LoA; lower LoA] of 1.58 [8.19; -5.03], -2.37 [3.96; -8.69] and 3.94 [11.09; -3.20] cmH2O for end-expiratory, end-inspiratory and delta Pes values, respectively. ICU patients: the solid-state transducer showed a bias (Pessolid-Pesbal) [upper LoA; lower LoA] during controlled / assisted ventilation of: -0.15 [1.39; -1.70] / -0.20 [5.02; -5.41], 0.32 [3.35; -2.72] / -0.54 [4.60; -5.68] and 0.47 [3.79; -2.85] / 0.35 [3.88; -3.18] cmH2O for end-expiratory, end-inspiratory and delta Pes values, respectively. LoA were <2cmH2O for static measurements on controlled ventilation. Conclusions: the novel solid-state pressure transducer showed good accuracy on the bench, in healthy volunteers and in ventilated ICU-patients. This could contribute to the implementation of Pes as advanced respiratory monitoring technique. Trial registration: Clinicaltrials.gov identifier: NCT05817968 (patient study). Registered on 18 April 2023.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Physical Activity, Sleep, and Quality of Life in Pulmonary Arterial Hypertension: Novel Insights from Wearable Devices\nAbstract: Background: Reduced functional capacity and poor sleep quality are common in pulmonary arterial hypertension (PAH). We aimed to determine whether Fitbit-derived activity and sleep trends provide clinically meaningful information in patients with PAH. Methods: Our prospective observational study recruited patients with PAH from across the United States. Participants with PAH wore a Fitbit device for 12-weeks at baseline and a subgroup with one-year follow-up. A matched control cohort was generated from the All of Us Research Program and we evaluated changes in patients with PAH compared to matched controls. Results: Among 109 patients with baseline monitoring, average daily steps correlated with 6MWD (r=0.66, p < 0.001) and percent rapid eye movement (REM) sleep (r=0.26, p=0.016). In 44 PAH participants who completed baseline and one-year monitoring, there was a group-time interaction for percent light sleep (p=0.024) and percent REM sleep (p=0.034), which demonstrated that sleep quality worsened in patients with PAH over one year compared to matched controls. Average daily steps in patients with PAH decreased from 5200 [IQR 3212 - 7458] at baseline to 4651 [IQR 2912 - 6827] at one year (p=0.008). Compared to matched controls, activity levels were significantly lower in patients with PAH at both time points. Conclusions: Our study demonstrated the potential clinical value of wearable devices by showing that activity and sleep quality are reduced in PAH compared to matched controls and these measures decline over time. Future studies should investigate if monitoring these health behaviors detects early functional decline and whether targeted interventions may improve outcomes.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Multiomics identifies unique modulators of calf muscle pathophysiology in peripheral artery disease and chronic kidney disease\nAbstract: BACKGROUND: Chronic kidney disease (CKD) has emerged as a significant risk factor that accelerates atherosclerosis, decreases muscle function, and increases the risk of amputation or death in patients with peripheral artery disease (PAD). However, the modulators underlying this exacerbated pathobiology are ill-defined. Recent work has demonstrated that uremic toxins are associated with limb amputation in PAD and have pathological effects in both the limb muscle and vasculature. Herein, we utilize multiomics to identify novel modulators of disease pathobiology in patients with PAD and CKD. METHODS: A cross-sectional study enrolled four groups of participants: controls without PAD or CKD (n=28), patients with PAD only (n=46), patients with CKD only (n=31), and patients with both PAD and CKD (n=18). Both targeted (uremic toxins) and non-targeted metabolomics in plasma were performed using mass spectrometry. Calf muscle biopsies were used to measure histopathology, perform bulk and single-nucleus RNA sequencing (snRNAseq), and assess mitochondrial function. Differential gene and metabolite analyses, as well as pathway and gene set enrichment analyses were performed. RESULTS: Patients with both PAD and CKD exhibited significantly lower calf muscle strength and smaller muscle fiber areas compared to controls and those with only PAD. Compared to controls, mitochondrial function was impaired in CKD patients, with or without PAD, but not in PAD patients without CKD. Plasma metabolomics revealed substantial alterations in the metabolome of patients with CKD, with significant correlations observed between uremic toxins (e.g., kynurenine, indoxyl sulfate) and both muscle strength and mitochondrial function. RNA sequencing analyses identified downregulation of mitochondrial genes and pathways associated with protein translation in patients with both PAD and CKD. Single nucleus RNA sequencing further highlighted a mitochondrial deficiency in muscle fibers along with unique remodeling of fibro-adipogenic progenitor cells in patients with both PAD and CKD, with an increase in adipogenic cell populations. CONCLUSIONS: CKD significantly exacerbates ischemic muscle pathology in PAD, as evidenced by diminished muscle strength, reduced mitochondrial function, and altered transcriptome profiles. The correlation between uremic toxins and muscle dysfunction suggests that targeting these metabolites may offer therapeutic potential for improving muscle health in PAD patients with CKD.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A novel patient-level computational model of atrial fibrillation patterns and clinical outcomes for evaluating screening strategies\nAbstract: Background The dynamic, heterogenous nature of atrial fibrillation (AF) episodes and poor symptom-rhythm correlation make early AF detection challenging. The optimal screening strategy for early AF detection and its role in stroke prevention in different subpopulations are unknown. We developed a computational patient-level AF model able to simulate the dynamic occurrence of AF and AF-associated outcomes during the entire lifetime of a virtual patient cohort to elucidate the impact of AF screening in virtual randomized clinical trials (V-RCTs). Methods The Markov-like computer model has 7 clinical states (sinus rhythm, symptomatic/asymptomatic AF, each with/without previous stroke, and death). AF-related atrial remodeling was incorporated, which influenced the age-/sex-dependent transition probabilities between states. Model calibration/validation was performed by replicating a wide range of clinical studies. AF screening strategies and stroke rates in the presence of defined interventions were assessed in V-RCTs. Results The model simulates the entire lifetime of virtual patients with minute-level resolution and provides perfect information on the occurrence of AF episodes and clinical outcomes (stroke, death). It replicates numerous age/sex-specific episode- and population-level AF metrics, including AF incidence/prevalence, progression rates, burden, episode duration, and stroke/mortality incidence. The benefits of intermittent AF screening in V-RCTs were frequency- and duration- dependent, with systematic thrice-daily single-ECG recordings providing the highest detection rates (64.6% of AF patients being diagnosed before their symptom-based clinical diagnosis). Screening groups had comparable 5-year stroke rates and lower 25-year stroke rates than the control group. These differences were increased by more effective anticoagulation therapy, in patients with higher baseline stroke risk, or in patients with delayed clinical AF diagnosis. Conclusions We present a novel computational patient-level AF model consistent with a large body of real-world data, enabling for the first time the systematic assessment of AF-management strategies. Screening protocols with more frequent and longer monitoring have higher AF-detection rates, but stroke reduction in screening-detected individuals is highly dependent on patients' and healthcare-systems' characteristics. V-RCTs suggest that frequent AF screening with effective anticoagulation can reduce stroke incidence in patients with high likelihood of delayed AF diagnosis.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Prototype Machine Learning Pipeline for Assessing and Tracking Keloid Scars\nAbstract: Dysregulated wound healing, marked by excessive collagen deposition, is the hallmark to keloid scar formation. Current methods for assessing keloids in clinical settings rely heavily on subjective measures, which are prone to interrater variability. This study introduces a machine learning (ML) pipeline prototype, designed to automate the detection, measurement, and colour analysis of keloid scars. Using a convolutional neural network (CNN), the pipeline segments keloid lesions from 2D images, applies fiducial markers for accurate size measurement, and utilizes K-Means clustering for colorimetry analysis. The CNN achieved a classification accuracy of 98% on a small test dataset. Segmentation was further refined using binary masks and contour-based detection. Colorimetry analysis revealed heterogeneity in pigmentation across keloid lesions, was varied by patient skin type, and tracked changes over time. The pipeline was validated on patients over a 5 and 6 month period, accurately detecting changes in keloid size and colour. While the algorithm was highly effective in most cases, challenges were noted in patients with nascent keloid or those with dark skin tones where the contrast between keloid and skin was insufficient for accurate segmentation. Additionally, early-stage keloid detection showed inconsistencies in defining lesion boundaries, particularly when keloids expanded rapidly. Despite these limitations, the ML pipeline presents a promising tool for objective keloid assessment, offering a practical, accessible, and accurate alternative to current clinical practices.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Subphenotypes of youth-onset type 2 diabetes mellitus and their association with distal symmetrical polyneuropathy\nAbstract: Context: Individuals with youth-onset type 2 diabetes mellitus (T2DM) display substantial, but unexplained, heterogeneity in their clinical presentations and risk of complications such as diabetic neuropathy. Data-driven clustering may be useful in characterizing this heterogeneity. Objective: To identify data-driven subphenotypes of newly diagnosed youth-onset T2DM and study their association with distal symmetric polyneuropathy (DSPN) at time of diagnosis. Design: Cross-sectional Setting: USA Participants: 641 individuals with newly diagnosed T2DM aged 10-19 years from the SEARCH for Diabetes in Youth Study and the Treatment Options for Type 2 Diabetes in Adolescents and Youth (TODAY) study. Exposure(s): Body mass index, HbA1c, fasting C-peptide, systolic blood pressure, diastolic blood pressure, LDL cholesterol and HDL cholesterol Main Outcome Measures: Data-driven subphenotypes were identified from k-means clustering. The cross-sectional association of subphenotypes with DSPN, based on expert examination scores ([&ge;]2.5) from the Michigan Neuropathy Screening Instrument, were assessed using Poisson regressions with robust standard errors. Results: Among 641 youth-onset T2DM, 58.2% were female, with 38.2% of participants [&le;]13 years having average BMI of 34.5 kg/m2 (SD: 6.5 kg/m2), and average HbA1c of 6.1% (IQR: 5.6-7.0). Three youth-onset subphenotypes were identified: mild obesity related diabetes (yMOD, 48.5%), severe insulin deficient diabetes (ySIDD, 18.7%) and severe insulin resistant diabetes (ySIRD, 32.7%). After adjusting for covariates, the prevalence of abnormal DSPN were 2.58 (95%CI: 1.74, 3.81) and 2.02 (95%CI: 1.40, 2.93) times among those classified as the ySIDD and ySIRD subphenotypes, relative to the yMOD subphenotype. Conclusions: Youth-onset T2DM consisted of heterogeneous clinical subphenotypes with differences prevalence of DSPN. Management of youth-onset T2DM may need to consider strategies tailored to each subphenotype. Keywords: precision medicine, diabetes endotypes, clusters\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Outcomes of endoscopic ultrasound-guided transmural drainage for postoperative peripancreatic fluid collection with an external drainage-first approach\nAbstract: Abstract Objectives: Endoscopic ultrasound-guided transmural drainage (EUS-TD) is widely performed to treat postoperative peripancreatic fluid collection (POPFC). Recent reports on EUS-TD lack a consensus on stent selection. This study aimed to assess the efficacy of EUS-TD for POPFC using an external drainage-first approach. Methods: We retrospectively examined the medical records of patients with POPFC treated with EUS-TD using external drainage between October 2016 and July 2024. Technical success was defined as successful placement of the external drainage. Clinical success was defined as the disappearance of fluid collection on follow-up computed tomography without additional intervention. Results: This study included 14 patients. The median duration from surgery to endoscopic treatment was 13 (range: 11-26) days. The median procedural time was 26 (range: 13-35) min. The technical success rate was 100%, and 6 Fr endoscopic nasocystic drainage was performed in all patients. The clinical success rate was 64.3%, and no adverse events were observed. In 35.7% (5/14) of the patients, additional endoscopic internal drainage was required; the POPFC was successfully controlled in all patients. The reasons for conversion to internal drainage were prolonged inflammation in one patient, remaining fluid collection in one patient, and requests from surgeons in three patients. Conclusions: EUS-TD for POPFC with external drainage proved to be safe and effective, with a short procedure time. However, in certain patients, additional internal drainage is required.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Hydroxyzine in Acute Hypertension: A Cohort Study.\nAbstract: Captopril, an ACE inhibitor, is widely used for acute hypertensive episodes, while hydroxyzine, an antihistamine with sedative and anxiolytic effects, is also employed in Poland despite limited research on its efficacy for this purpose. o our knowledge, no prior studies have specifically investigated the direct impact of hydroxyzine on hypertension, despite its common use in Polish medical practice. A retrospective cohort analysis of 2144 patients who required emergency intervention for hypertension or had high blood pressure during other interventions. Effectiveness was based on blood pressure improvement post-intervention. 84.28% of interventions were performed by basic emergency teams, and 15.72% by specialist teams. Captopril and hydroxyzine were the most commonly used medications. Blood pressure improved in 36.61% of patients, with no improvement in 41.47%. Hydroxyzine was more frequently administered by paramedic teams, while captopril was favored by specialist teams. There were no statistically significant differences in captopril use across age groups, with approximately 80% receiving it. Hydroxyzine use did not vary significantly by age, though its overall use was low. Hydroxyzine showed a non-significant trend towards greater blood pressure reduction compared to captopril. Captopril is the primary treatment for acute hypertension in emergency settings, but hydroxyzine may have potential benefits, especially in patients with anxiety-related hypertension. However, due to the lack of significant evidence and current guidelines advising against hydroxyzine in elderly patients, further research is needed to establish protocols and optimize hypertension treatment strategies. Additionally, incorporating anxiolytics into guidelines and an official statement on their use would aid clinical practice.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Outcomes of Endovascular Thrombectomy in Patients with Cerebral Venous Thrombosis: A Cohort Study of 36,005 Patients\nAbstract: Introduction/Purpose: Cerebral venous thrombosis (CVT) is traditionally managed with anticoagulation. However, for patients who fail anticoagulation or with severe symptoms, endovascular thrombectomy (EVT) has emerged as a treatment option. Objective: This study evaluates outcomes, complications, and comorbidities associated with EVT in patients with CVT. Methods: The 2015-2019 National Inpatient Sample (NIS) was queried for patients admitted to hospitals with ICD-10 diagnosis codes for CVT and procedure codes for EVT. Demographics, comorbidities, complications, and discharge dispositions were compared between patients undergoing EVT and medical management. Multivariate logistic regression determined independent predictors of outcomes, controlling for age, gender, cerebral edema/herniation, hemorrhage, mechanical ventilation, Elixhauser Comorbidity Index, and National Institute of Health Stroke Scale (NIHSS) severity. Odds ratios (OR) were calculated for each complication/outcome. All statistical analyses were performed using Statistical Product and Service Solutions (SPSS) Statistical Software Version 29. Results: A total of 36,005 patients with CVT were identified. Of those, 325 (0.9%) underwent EVT. Patients who underwent EVT were older (49.28{+/-}19.08 years vs 43.62{+/-}23.29 years, p < 0.001), more likely to be female (61.5% vs. 54.8%, p = 0.016), and had higher rates of diabetes mellitus (18.5% vs. 13.5%, p = 0.012), hypertension (47.7% vs. 31.3%, p < 0.001), and obesity (13.8% vs. 8.1%, p < 0.001). They also had higher NIHSS scores (13.15 vs. 6.17, p < 0.001). EVT was associated with higher in-hospital mortality (15.4% vs. 4.6%, OR 1.627, p = 0.007) and lower routine discharge (29.2% vs. 57%, OR 0.599, p < 0.001). Conclusions: EVT patients had more severe conditions and higher mortality, potentially reflecting baseline severity rather than risks of EVT itself. Careful patient selection is crucial to improving outcomes in this population. Further studies are needed to refine patient selection criteria for EVT in CVT.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Depth diagnosis of colorectal cancer located on a colorectal fold by quantitative evaluation of a width of colorectal - fold lateral contour using a lateral split-view computed tomographic air-contrast enema image\nAbstract: Purpose: To investigate the usefulness of quantitative evaluation of a width of lateral contour on a lateral split-view computed tomographic air-contrast enema (CT enema) image for diagnosing the invasion depth of colorectal cancer (CRC) located on a colorectal fold. Methods: The cases of 22 patients with 22 fold-located CRCs (12 early CRCs and 10 advanced CRCs) who underwent a pretherapeutic computed tomographic colonography were retrospectively examined. T1-stage CRCs were classified into two categories according to the Japanese guideline: T1a-stage, carcinoma invading the superficial submucosa (< 1000 um); and T1b-stage, carcinoma invading the deeper submucosa ([&ge;] 1000 um). The maximum width of a lateral contour of the colorectal fold on which the CRC was located, i.e., the gap distance between the two adjacent haustrations, was calculated from the lateral split-view CT enema image by two gastrointestinal radiologists. These values were compared between the intramucosal / T1a CRCs and the T1b / more deeply invading CRCs. The inter-rater intraclass correlation coefficients were also evaluated for reliability. Results: The maximum widths of a lateral contour of the colorectal fold were significantly higher in the T1b / more deeply invading CRCs than in the intramucosal / T1a CRCs (p<0.0001). The optimum cut-off value of the maximum width of a lateral contour of the colorectal fold for differentiating the former from the latter was 6.0 mm, with a sensitivity and specificity of 100% and 100%, respectively. The inter-rater intraclass correlation coefficient for measurement of a lateral contour of the colorectal fold was 0.958. Conclusions: We demonstrated for the first time that quantitative evaluation of a width of lateral contour using a lateral split-view CT enema image can improve the diagnostic accuracy of the invasion depth for CRCs located on a colorectal fold.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Interpreting Health Differences between Self-reported Black and White Children in U.S.: Insights from a Methodological Perspective\nAbstract: Understanding health differences among racial groups in child development is crucial for addressing inequalities that may affect various aspects of a child's life. However, factors such as household and neighborhood socioeconomic status (SES) often covary with health differences between races, making it challenging to accurately reveal these differences using conventional covariate-control methods such as multiple regression. Alternative methods, such as Propensity Score Matching (PSM), may provide better covariate control. Supporting this notion, we found that PSM is more sensitive than regression-based methods in detecting health differences between self-reported Black and White children across a wide range of behavioral and neural measurements in the ABCD (5636 White, 1350 Black). Puberty status, an index of physical maturation, emerged as the largest difference between races and mediated the health differences between races on the majority of behavioral and neural variables. These findings highlight the importance of controlling for pubertal status and using more effective covariate-control methods to accurately represent health differences between Black and White children.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Quantifying the Trainability of Peripheral Nerve Function in Young and Older Adults\nAbstract: It is well known that the natural progression of age can result in motor neuron degeneration. Consequently, this leads to slowing of nerve conduction, denervation, and reduced motor function. Slower neural conduction can negatively alter an individual's response time, which could increase the risk of falls. Further investigation is needed to determine the potential role exercise interventions may afford in mitigating age-related nerve deterioration. The purpose was two-fold: first, to determine the effects of resistance training on nerve conduction velocity (NCV), and second, to determine if changes in NCV are dependent on age. We hypothesized that training would result in faster nerves in both young and older adults, albeit to a lesser extent in older adults. Forty-eight subjects (18-84 yrs) completed this study (n = 26 younger, 22 older). Motor NCV and maximal strength were recorded before and after 4-weeks of handgrip training in both limbs. Training was conducted 3x/week with the use of a grip training kit. Mixed-factorial ANOVAs revealed significant increases in NCV for both the young (p < 0.001) and older training groups (p < 0.001), but neither control groups (p > 0.05). The young training group showed increased handgrip strength after four weeks (p = 0.004), while the other groups did not. The results of this study suggest that resistance training may be a viable method to counteract age-related nerve deterioration. These outcomes have the potential to improve quality of life and generate greater independence for our older populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Differential benefit of adjuvant everolimus according to endocrine therapy backbone in the randomized UNIRAD trial\nAbstract: Background: The randomized, double-blind UNIRAD trial evaluating the addition of 2 years of everolimus to endocrine therapy in patients with high-risk, early luminal breast cancer failed to demonstrate a benefit. We report the subgroup analyses. Patients and Methods: We randomized 1278 patients in a 1:1 ratio to receive 2 years of placebo or everolimus, added to endocrine therapy for up to 4 years after initiation. Randomization was stratified by endocrine therapy agent, prior adjuvant versus neoadjuvant therapy, progesterone receptor expression, and lymph node involvement. Subgroup analyses by each stratification factor were prespecified. Post hoc analyses were performed according to menopausal status and age. We also analyzed treatment adherence. Results: We observed a limited trend toward more favorable prognostic features in tamoxifen-treated patients, with more frequent ER+/PR+ tumors (88.5% vs. 84.1%, p=0.026) and less frequent pN2+ status (39.8% vs. 46%, p=0.032). In premenopausal women, we observed a numerical benefit of everolimus: 3y-DFS was 86% in the placebo group and 90% in the everolimus group [HR=0.76 (95%CI: 0.43-1.34)]. In premenopausal patients treated with tamoxifen (n=153; 12.3%), we observed an even stronger trend in favor of everolimus as 3-year DFS was 84% in the placebo group and 91% in the everolimus group [HR=0.54 (95%CI: 0.28-1.02)]. Early discontinuation of either everolimus or placebo was less frequent in the tamoxifen group than in the AI group: 48.0% vs. 56.9% (p=0.028). Conclusions: The present post-hoc analyses generate hypotheses regarding the interaction between menopausal status, tamoxifen and everolimus in patients with high-risk, ER-positive, HER2-negative early breast cancer. They suggest that tamoxifen alone is no longer the standard of care in high-risk premenopausal patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The expression alteration of Golim4 (Gpp130) and its prognostic value in epithelial ovarian cancer\nAbstract: Background: Among common cancers in women, ovarian cancer has the lowest incidence; however, mortality rates are more than other gynecological cancers due to the lack of specific symptoms during early stages and absence of diagnostic markers. Golgi integral membrane protein 4 (GOLIM4) is a member of transporter complex which is located to the cis/medial of Golgi, and its role in tumor is unknown. In this study we aimed to assess the expression of Golim4 (GPP130) in epithelial ovarian cancer (EOC) patients. Methods: The expression levels of Golim4 in 58 malignant EOC specimens and 11 benign and normal control tissues were determined by real-time RT-PCR. Clinicopathological characteristics were analyzed. Non-parametric survival analysis was estimated by using Kaplan-Meier and log-rank test. Parametric survival analysis was evaluated through multivariate Cox regression analysis and generalized Gamma survival model. Result: Our findings showed that Golim4 was significantly down-regulated in Serous Papillary type of EOC tissue specimens than in non-cancerous tissues (P<0.001); however; the expression of Golim4 in total EOC tissue specimens revealed non-significant up-regulation. Kaplan- Meier analysis and log-rank test have suggested that EOC patients with low Golim4 expression have shorter overall survival when compared with patients with other expression groups (log-rank test P<0.05). Semi-parametric Cox proportional hazards model indicated that the status of Golim4 were independent predictor of overall survival in patients with EOC. Correlation analysis has been done by Spearman Rank correlation coefficient.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Probabilistic Graphical Models for Evaluating the Utility of Data-Driven ICD Code Categories in Pediatric Sepsis\nAbstract: Electronic health records (EHRs) are digitalized medical charts and the standard method of clinical data collection. They have emerged as valuable sources of data for outcomes research, offering vast repositories of patient information for analysis. Definitions for pediatric sepsis diagnosis are ambiguous, resulting in delayed diagnosis and treatment, highlighting the need for precise and efficient patient categorizing techniques. Nevertheless, the use of EHRs in research poses challenges. EHRs, although originally created to document patient encounters, are now primarily used to satisfy billing requirements. As a result, EHR data may lack granularity, potentially leading to misclassification and incomplete representation of patient conditions. We compared data-driven ICD code categories to chart review using probabilistic graphical models (PGMs) due to their ability to handle uncertainty and incorporate prior knowledge. Overall, this paper demonstrates the potential of using PGMs to address these challenges and improve the analysis of ICD codes for sepsis outcomes research.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A novel modelling framework to simulate the effects of HIV stigma on HIV transmission dynamics\nAbstract: Introduction HIV remains a global public health challenge, with social determinants such as stigma influencing transmission dynamics, access to testing, and treatment. HIV stigma shapes both individual behaviour and community responses to HIV. However, modelling approaches have rarely represented the complex role of stigma in HIV epidemics. Our study introduces an innovative modelling framework designed to capture the interplay between stigma and HIV transmission dynamics. Methods We modelled effects of anticipated, internalised, and experienced HIV stigma on HIV testing, antiretroviral treatment initiation, and treatment adherence. We built an individual-based model representing the HIV epidemic (HIV-IBM) in a USA-like population of 3 million individuals that accounts for community demography, behaviour, and healthcare access. Stigma parameters were based on a scoping review focused on the prevalence and effects of stigma in people living with and without HIV. HIV-IBM was used to assess effects of interventions targeting different types of stigma. We tested reductions of stigma by 50% and 100% across the simulated population and performed a sensitivity analysis to identify effects of each type of stigma on the simulated HIV epidemic. Results Without reduced stigma, the HIV-IBM had an annual incidence rate of 12.6 (95% credible interval [CI]: 11.4-13.5) new cases per 100,000 people. Reducing the overall level of stigma in the population by 50% resulted in an annual incidence rate of 9.6 (95% CI: 8.6-10.3) per 100,000, and a 100% reduction in stigma resulted in an annual incidence rate of just 6.8 (95% CI: 6.1-7.3) per 100,000. In addition to reducing HIV incidence, reducing stigma resulted in a substantial increase of viral suppression among people living with HIV (50% stigma reduction: +10.5%; 100% stigma reduction: +16.4%). Sensitivity analysis showed that outcomes resulting from interventions targeting each type of stigma were highly heterogeneous. Conclusion Simulation results suggest that reducing HIV stigma could have a large effect on HIV incidence and viral suppression. Our model framework provides a dynamic approach to understanding the role of stigma in HIV outcomes that facilitates exploration of stigma reduction strategies and offers insights to inform evidence-based policies and interventions for reducing stigma and curtailing HIV.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Typical indicators of neighborhood change that are used to define gentrification have opposing associations with infant mortality\nAbstract: Infant mortality (IM), or death prior to the first birthday, is a key public health metric that increases with neighborhood structural inequities. However, neighborhood exposures shift as communities undergo gentrification, a pattern of neighborhood change defined by increasing affluence (in wealth, education, and housing costs). Gentrification has inconsistent associations with infant health outcomes like IM, which may be due to differing relationships between its composite measures and such outcomes. We designed a retrospective cohort analysis of all births and deaths from 2010-2019 across 4 metropolitan areas in Michigan to determine how gentrification and its neighborhood-change components are associated with risk of IM, using multilevel multivariable logistic regression models. Among 672,432 infants, 0.52% died before 1 year. IM was not associated with gentrification. Census tracts with greater increases in income and education had lower rates of IM, but tracts with greater increases in rent costs had higher rates of IM. In unadjusted models, odds of IM were 40% and 15% lower for infants living in tracts in the top quartile increase in household income and college completion, respectively, compared to infants from tracts with the least amount of change. Odds of IM were also increased 29% in infants from tracts with the most increases in rent, though these differences were attenuated when adjusting for individual social factors. Indicators of increasing community affluence have opposing relationships with IM. Policies and interventions that address rising housing costs may reduce IM.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Human bioaccumulation of micro- and nanoplastics is primarily determined by the organs' vascular volume\nAbstract: Recent studies have demonstrated the accumulation of micro- and nanoplastics (MNPs) in human organs, particularly in the brain, at an alarming rate (Campen et al., 2024, doi.org/10.21203/rs.3.rs-4345687/v1). This study examines the phenomenon of bioaccumulation in relation to up to six distinct biological and biomedical parameters pertaining to vascular structure and composition in three organ tissues: the brain cortex, kidney, and liver. As anticipated based on fundamental mechanistic considerations of bioaccumulation (washing rate), the MNP content appears to be proportional to the inverse of the capillary volume fraction ($V_c$), exhibiting no correlation with any other geometric variable, such as capillary diameter or capillary segment length. This finding is consistent with the small size spectra of MNPs in comparison to these dimensions. However, contrary to expectations, no correlation was observed between MNP content and biological composition (lipid, water, or carbohydrate content), while a likely non-causal correlation was observed between MNP content and protein content, which may be simply attributed to the non-linear correlation between protein content and $V_c$. The conclusions that point to a possibly exceedingly large number of MNP particles currently in our brains call for urgent further investigation and the revision of the published data.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Large language models for abstract screening in systematic- and scoping reviews: A diagnostic test accuracy study\nAbstract: Introduction We investigated if large language models (LLMs) can be used for abstract screening in systematic- and scoping reviews. Methods Two broad reviews were designed: a systematic review structured according to the PRISMA guideline with abstract inclusion based on PICO criteria; and a scoping review, where we defined abstract characteristics and features of interest to look for. For both reviews 500 abstracts were sampled. Two readers independently screened abstracts with disagreements handled with arbitrations or consensus, which served as the reference standard. The abstracts were analysed by six LLMs (GPT-4o, GPT-4T, GPT-3.5, Claude3-Opus, Claude3-Sonnet, and Claude3-Haiku). Primary outcomes were diagnostic test accuracy measures for abstract inclusion, abstract characterisation and feature of interest detection. Secondary outcome was the degree of automation using LLMs as a function of the error rate. Results In the systematic review 12 studies were marked as include by the human consensus. GPT-4o, GPT-4T, and Claude3-Opus achieved the highest accuracies (97% to 98%) comparable to the human readers (96% and 98%), although sensitivity was low (33% to 50%). In the scoping review 130 features of interest were present and the LLMs achieved sensitivities between 74-84%, comparable to the human readers (73% and 86%). The specificity of GPT-4o (98%) and GPT-4T (>99%) greatly surpassed the other LLMs (between 33% and 93%). For abstract characterization all LLMs achieved above 95% accuracy for language, manuscript type and study participant characterisation. For characterisation of disease-specific features only GPT-4T and GPT-4o showed very high accuracy. For abstract inclusion the highest automation rate (91%) at the lowest error rate (8%) was achieved by use of two LLMs with disagreement solved by human arbitration. An LLM pre screening before human abstract screening achieved an automation rate of 55% with no missed abstracts. Conclusion Abstract characterisation and specific feature of interest detection with LLMs is feasible and accurate with GPT-4o and GPT-4T. The majority of abstract screenings for systematic reviews can be automated with use of LLMs, at low error rates.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: A Method For Mimicking Tumour Tissue In Brain Ex-Vivo Ultrasound For Research Application And Clinical Training\nAbstract: Introduction: Intraoperative ultrasound is becoming a common tool in neurosurgery. However, effective simulation methods are limited. Current, commercial, and homemade phantoms lack replication of anatomical correctness and texture complexity of brain and tumour tissue in ultrasound images. Materials and Methods: We utilise ex-vivo brain tissue, as opposed to synthetic materials, to achieve realistic echogenic complexity and anatomical correctness. Agar, at 10-20\\% concentrate, is injected into the brain tissue to simulate the tumour mass. A commercially available phantom was purchased for benchmarking. Results: Qualitative analysis is performed by experienced professionals, measuring the impact of the addition of agar and comparing it to the commercial phantom. Overall, the use of ex vivo tissue was deemed more accurate and representative, compared to the synthetic materials-based phantom, as it provided good visualisation of real brain anatomy and good contrast within tissue. The agar tumour correctly produced a region of higher echogenicity with slight diffusion along the margin and expected interaction with the neighbouring anatomy. Discussion: Using human samples for training is limited due to high logistical and ethical challenges. Sparsity of online neurosurgical US data further compounds this. The proposed method successfully produced a better simulation of tumours in brain tissue than the phantom which suffers from surface texture dissimilarity, ultrasound echogenic homogeneity, and lack of anatomical correctness. Conclusion: The proposed method for creating tumour-mimicking tissue in brain tissue is inexpensive, accurate, and simple. Beneficial for both the trainee clinician and the researcher. A total of 576 annotated images are made publicly available upon request. Word count {approx} 3400.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Percentile Scores for the Revised University of Pennsylvania Smell Identification Test for 16,972 Individuals 60 years of Age and Older\nAbstract: Background and Objectives The University of Pennsylvania Smell Identification Test (UPSIT) is a widely employed objective measure of smell function. A revised version of this test, termed the UPSIT-R, was developed in 2020 to update certain odorants and response options. The goal of this study was to establish normative age- and sex-specific data for the UPSIT-R in a large adult cohort and to compare the resultant percentiles to those of the original UPSIT. A second study was performed to compare the relative performance of these two tests in a small cohort of persons with and without Parkinson's disease (PD). Methods UPSIT-R percentiles were derived separately by age (60-64, 65-69, 70-74, 75-59, and [&ge;]80 years) and sex (male, female) categories in 16,972 volunteers who were predominantly white and non-Hispanic. Percentiles were derived statistically using an empirical distribution averaging procedure. A Bland-Altman plot was employed to visualize the level of agreement between percentiles for the UPSIT-R and UPSIT. For the second study, non-parametric statistics were employed to compare the results of those with and without PD. Results UPSIT-R performance declined with increasing age; deficits were more pronounced in men than in women. The magnitude of the difference between the original and revised test percentile scores differed by age and sex; women had up to a 3-point improvement with the UPSIT-R whereas the oldest male age had up to a 3-point decline in percentile scores. Olfactory deficits in PD were confirmed on the UPSIT-R. Discussion This study provides normative data clinically useful for assessing the relative degree of dysfunction in persons 60 years of age and older using the UPSIT-R. Like the traditional version of the UPSIT, this version demonstrates that smell function declines with age and is generally better in women than in men, providing a solid clinical basis for physicians to accurately determine the degree of smell dysfunction in their patients.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Alternative per-protocol estimates: secondary analyses of data from the Balanced randomised controlled trial\nAbstract: Background The Balanced trial was designed to answer the question of whether anaesthetic depth affects postoperative mortality when a vulnerable patient undergoes major surgery. Patients were recruited between 2012 and 2017 at 73 centres in seven countries. In the intention-to-treat analysis (n=6644), there was no significant difference in one year mortality between patients randomised to surgery under deep (target BIS 35) or light anaesthesia (target BIS 50). However the separation between randomised groups was only 8.4 BIS units and the trial was criticised for being underpowered. Methods In a secondary analysis of this trial's data, we made alternative per-protocol estimates designed to improve the power of the trial. We added an additional covariate - each patient's deviation from target BIS - to the original analysis, statistically recreating the desired separation of 15 BIS units between randomised groups. We used multiple imputation to recover missing BIS values. We also assessed whether a proportional hazards Cox model was appropriate for the analysis of one year mortality. Results Our alternative per-protocol estimates did not differ materially from the original per-protocol estimate. The gain in precision through using all intent-to-treat patients for our per-protocol estimates was offset by the additional variance introduced when modelling missing BIS values. When modelling missing BIS, we found regional differences: in China, the separation between randomised groups was far higher (13.6 BIS units) than in any other region. Estimates and plots assessing proportional hazards suggested increasing late mortality under deep anaesthesia, most notably in China. Conclusion Our hypothesis is that deep anaesthesia in the Balance trial led to higher postoperative delirium, which in turn led to an increase in late mortality. In future trials, patients should be followed for more than a year and cause of death recorded.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Atherosclerotic fibrous plaques in females are characterized by endothelial-to-mesenchymal transition and linked to smoking\nAbstract: Background: Sex and plaque histology are intertwined, with fibrous atherosclerotic plaques being more prevalent in women and pointing to general smooth muscle cell plasticity and estrogen signaling. Plaque erosion, a significant contributor to acute coronary syndromes (ACSs), is linked to fibrous plaques and is more prevalent in women as compared to men. We hypothesize that the molecular drivers of histologically determined fibrous plaques differ between men and women. Methods: Human end-stage atherosclerotic plaques were isolated from consecutive patients who underwent carotid endarterectomy and were included in the Athero-Express biobank. Fibrous plaques from both female and male patients were histologically assessed and further processed to obtain protein, bulk RNA, single-cell RNA and DNA methylation data. We leveraged sex-differential expression and deconvolution analyses to uncover sex-biased molecular mechanisms and cellular dynamics which were experimentally validated using an EndMT in vitro model. Results: Out of 1,889 atherosclerotic plaques (1,309 male and 580 female), fibrous lesions were observed in 50% of female (n=290) and 31% of male patients (n=416). Compared to patients with atheromatous plaques (n=494), women with fibrous plaques exhibited a higher prevalence of smoking (41% vs. 33%), while men with fibrous plaques presented more often with diabetes (29% vs. 20%). Transcriptional and proteomic phenotyping highlighted more immune-dependent and inflammatory processes in male fibrous plaques. Genes and proteins with higher abundance in female fibrous plaques pointed to endothelial-to-mesenchymal transition (EndMT) and extracellular matrix remodelling. Using single-cell RNA sequencing, we identified a dominant role of endothelial and smooth muscle cells in female plaques, and more macrophages in males. Finally, at the cellular level, we show that sex -specific, smoking-mediated promoter methylation changes may explain these differences. Conclusions: Patients with end-stage fibrous atherosclerotic plaques have a distinct clinical profile, with men more often having diabetes and women more often smoking. This clinical profile associates with sex differences that point to different cellular and molecular compositions of fibrous plaques. These mechanisms might be candidate pathways to understand plaque erosion from a molecular point of view and may provide promising targets for atherosclerosis therapies, as they account for the sex-specific differences in plaque phenotype.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: The Role of Interoception in Lifestyle Factors: A Systematic Review\nAbstract: Background Interoception, the perception of the internal state of the body, offers an underrepresented and intriguing potential avenue for altering lifestyle-related behaviors. Interoception is intrinsically related to maintaining homeostasis and the flexible allostatic regulation of complex demands. Internal bodily states may also be influenced by lifestyle factors and related problems. This systematic review aimed to provide insight into the current state of evidence about the role of interoception in lifestyle factors. Methods Studies from three databases (PubMed, Embase, and Web of Science) were screened for eligibility based on two inclusion criteria: 1) at least one measure of interoception (e.g., interoceptive accuracy, attention, or awareness), and 2) at least one measure of a lifestyle factor (i.e., alcohol consumption, cognitive leisure and relaxation activities, eating behavior, exercise, sleep, or smoking). Risk of bias was assessed using an adjusted quality score checklist, consisting of five items related to study design, population size, exposure measurement, outcome measurement, and adjustment for confounders. Results The review included 73 studies. Out of the included studies, 51 measured interoceptive accuracy and 36 measured interoceptive attention. Six studies quantified interoceptive awareness. In terms of lifestyle factors, 26 studies on cognitive leisure and relaxation activities, 19 studies on eating behavior, 12 studies focused on alcohol consumption, 10 studies on exercise, five studies on smoking, and four studies on sleep were identified. Findings show positive relations between interoception and cognitive leisure and relaxation activities, eating behavior, and exercise. Conversely, the consumption of alcohol is negatively related to interoception. Studies in the smoking and sleep lifestyle factors were sparse and of varying methodological quality. Discussion The findings of this review show that interoceptive domains are associated with various lifestyle factors, but the quality of the evidence is limited. Future longitudinal studies with more objective measures of interoception are needed in order to better understand the interrelations between interoception and lifestyle factors.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Comprehensive Systematic Review and Meta-Analysis of Solute Carrier Family 19, Member 1 (SLC19A1) G80A Gene Polymorphism and Its Association with Congenital Heart Defects in Fetal Development: Implications for Genetic Susceptibility and Prenatal Risk Assessment\nAbstract: Congenital heart defects (CHD) are a major cause of neonatal mortality, highlighting the importance of identifying genetic risk factors in fetal development. The SLC19A1 gene, encoding the reduced folate carrier, is critical for folate metabolism, essential for DNA synthesis during embryogenesis. The G80A polymorphism in SLC19A1 may influence folate transport efficiency and contribute to CHD risk. This meta-analysis aimed to investigate the association between SLC19A1 G80A polymorphism and CHD susceptibility. A systematic review of major databases, including PubMed and EMBASE, was conducted to identify relevant case-control studies. Genetic risk models, such as allele (A vs G), heterozygous (GA vs GG), homozygous (AA vs GG), dominant (GA + AA vs GG), and recessive (AA vs GG + GA), were analyzed using RevMan 5.4.1, with odds ratios (ORs) and 95% confidence intervals (CIs) calculated. Initial results across most genetic models did not show a significant association between G80A polymorphism and CHD. However, after excluding outliers, a moderate association was observed between the GA genotype and increased CHD risk (OR: 1.34, CI: 1.07, 1.66). These findings suggest a minimal genetic effect, warranting further research in diverse populations.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Identification of novel associations of candidate loci with Alzheimer's disease by leveraging the shared genetic basis with hippocampal volume\nAbstract: Objective: Alzheimer's disease (AD) is a complex neurodegenerative disorder with a considerable genetic contribution that remains not fully understood. The hippocampus plays a critical role in learning and memory, with its volume loss being a core hallmark of AD. Hippocampal volume also has a strong heritable component and its genetic underpinnings may help us to understand the complex biological mechanism underlying AD. Methods: We performed cross-trait analysis of exisiting GWAS data on late-onset AD and Hippocampal volumes using the conjunctional false discovery rate (conjFDR) framework to identify the specific shared genetic basis.For identified SNPs, we performed functional annotation and phenome-wide association studies (PheWAS). Results: Our cross-trait analyses identified 11 non-APOE lead genetic loci, of which 7 loci showed discordant directional effects (loci associated with decreased risk for AD and smaller hippocampal volumes, and vice versa). We found that SHARPIN and TNIP1 genes play a role in AD by affecting the hippocampal volumes. In addition, we observed 9 novel AD-hippocampus loci in genes previously implicated in AD (IGIP and ACE) and novel AD-genes (KCTD13, HINT1, SH3TC2, FAM53B, TPM1, IL34 and SSH2). Phenome-wide association study highlighted varying degrees of pleiotropy, including brain imaging measurements, white blood cell markers, red blood cell markers, and lipids in multiple shared loci. Conclusions: Our integrating GWAS study reveals a shared genetic basis between AD and hippocampal volumes. By integrating GWAS summary statistics for these two traits, we identified both novel and previously reported AD-hippocampus loci. Functional analysis highlights the roles of immune cells and lipid markers in the shared loci and traits, suggesting a shared neurobiological basis for both traits.\n"}, {"role": "assistant", "content": "no"}]}
{"messages": [{"role": "system", "content": "You are a researcher that, given the title and the abstract of a pre print, you need to classify whether this pre print is about infectious disease or not (answer in yes or no)"}, {"role": "user", "content": "Title: Rare pathogenic variants in G-protein coupled receptor genes involved in gut-to-host communication are associated with cardiovascular disease risk\nAbstract: Background: Gut microbial metabolites called short-chain fatty acids (SCFA) confer protective effects against cardiovascular disease and high blood pressure. Proposed mechanisms include anti-inflammatory signalling mediated by SCFA-sensing G-protein-coupled receptors (GPCR), particularly GPR41, GPR43, and GPR109a, as suggested by knockout mouse models. We aimed to determine if rare pathogenic variants (RPVs) affecting GPCR genes in humans increase the risk of hypertension (HTN) and major adverse cardiac events (MACEs), including acute coronary syndrome, heart failure, and ischemic stroke. Methods: Using UK Biobank whole-exome sequencing data from 393,649 European participants, we identified rare (minor allele frequency <1%) pathogenic variants with predicted high-impact functional consequences in GPCR genes, based on Ensembl Variant Effect Predictor annotations. For missense variants, pathogenicity likelihood scores from AlphaMissense, Mendelian Clinically Applicable Pathogenicity, and Combined Annotation Dependent Depletion were assessed. Multivariable logistic regression models, adjusted for age, sex, BMI, genetic ancestry, and other potential confounders, were conducted to compare RPV prevalence between cases and controls. Results: We identified a total of 158 RPVs in SCFA-sensing GPCR genes. The prevalence of RPV carriers was significantly higher in patients with HTN (OR=1.12, P=0.014) and MACEs (OR=1.18, P=0.009) than controls. In single GPCR gene analyses, RPVs in the FFAR2 gene (encoding GPR43) were associated with an increased risk of HTN (OR=1.23, P=0.005). RPVs in the HCAR2 gene (encoding GPR109A) were associated with a markedly increased risk of heart failure (OR=1.57, P=0.012). Conclusions: These findings confirm and extend previous results from knockout animal models in a large population-based cohort, highlighting the potential of GPCRs as therapeutic targets for HTN and cardiovascular diseases in humans.\n"}, {"role": "assistant", "content": "no"}]}
